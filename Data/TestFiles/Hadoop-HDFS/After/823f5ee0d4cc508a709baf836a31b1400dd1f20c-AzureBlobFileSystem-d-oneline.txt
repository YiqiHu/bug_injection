public class AzureBlobFileSystem extends FileSystem    implements IOStatisticsSource {  public static final Logger LOG = LoggerFactory.getLogger(AzureBlobFileSystem.class);  private URI uri;  private Path workingDir;  private AzureBlobFileSystemStore abfsStore;  private boolean isClosed;  private final String fileSystemId = UUID.randomUUID().toString();  private boolean delegationTokenEnabled = false;  private AbfsDelegationTokenManager delegationTokenManager;  private AbfsCounters abfsCounters;  private String clientCorrelationId;  private TracingHeaderFormat tracingHeaderFormat;  private Listener listener;    private String blockOutputBuffer;    private DataBlocks.BlockFactory blockFactory;    private int blockOutputActiveBlocks;    private RateLimiting rateLimiting;  @Override  public void initialize(URI uri, Configuration configuration)      throws IOException {    uri = ensureAuthority(uri, configuration);    super.initialize(uri, configuration);    setConf(configuration);    LOG.debug("Initializing AzureBlobFileSystem for {}", uri);    this.uri = URI.create(uri.getScheme() + "://" + uri.getAuthority());    abfsCounters = new AbfsCountersImpl(uri);        this.blockOutputBuffer = configuration.getTrimmed(DATA_BLOCKS_BUFFER,        DATA_BLOCKS_BUFFER_DEFAULT);        this.blockFactory =        DataBlocks.createFactory(FS_AZURE_BLOCK_UPLOAD_BUFFER_DIR,            configuration, blockOutputBuffer);    this.blockOutputActiveBlocks =        configuration.getInt(FS_AZURE_BLOCK_UPLOAD_ACTIVE_BLOCKS,            BLOCK_UPLOAD_ACTIVE_BLOCKS_DEFAULT);    if (blockOutputActiveBlocks < 1) {      blockOutputActiveBlocks = 1;    }        AzureBlobFileSystemStore.AzureBlobFileSystemStoreBuilder        systemStoreBuilder =        new AzureBlobFileSystemStore.AzureBlobFileSystemStoreBuilder()            .withUri(uri)            .withSecureScheme(this.isSecureScheme())            .withConfiguration(configuration)            .withAbfsCounters(abfsCounters)            .withBlockFactory(blockFactory)            .withBlockOutputActiveBlocks(blockOutputActiveBlocks)            .build();    this.abfsStore = new AzureBlobFileSystemStore(systemStoreBuilder);    LOG.trace("AzureBlobFileSystemStore init complete");    final AbfsConfiguration abfsConfiguration = abfsStore        .getAbfsConfiguration();    clientCorrelationId = TracingContext.validateClientCorrelationID(        abfsConfiguration.getClientCorrelationId());    tracingHeaderFormat = abfsConfiguration.getTracingHeaderFormat();    this.setWorkingDirectory(this.getHomeDirectory());    if (abfsConfiguration.getCreateRemoteFileSystemDuringInitialization()) {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.CREATE_FILESYSTEM, tracingHeaderFormat, listener);      if (this.tryGetFileStatus(new Path(AbfsHttpConstants.ROOT_PATH), tracingContext) == null) {        try {          this.createFileSystem(tracingContext);        } catch (AzureBlobFileSystemException ex) {          checkException(null, ex, AzureServiceErrorCode.FILE_SYSTEM_ALREADY_EXISTS);        }      }    }    LOG.trace("Initiate check for delegation token manager");    if (UserGroupInformation.isSecurityEnabled()) {      this.delegationTokenEnabled = abfsConfiguration.isDelegationTokenManagerEnabled();      if (this.delegationTokenEnabled) {        LOG.debug("Initializing DelegationTokenManager for {}", uri);        this.delegationTokenManager = abfsConfiguration.getDelegationTokenManager();        delegationTokenManager.bind(getUri(), configuration);        LOG.debug("Created DelegationTokenManager {}", delegationTokenManager);      }    }    AbfsClientThrottlingIntercept.initializeSingleton(abfsConfiguration.isAutoThrottlingEnabled());    rateLimiting = RateLimitingFactory.create(abfsConfiguration.getRateLimit());    LOG.debug("Initializing AzureBlobFileSystem for {} complete", uri);  }  @Override  public String toString() {    final StringBuilder sb = new StringBuilder(        "AzureBlobFileSystem{");    sb.append("uri=").append(uri);    sb.append(", user='").append(abfsStore.getUser()).append('\'');    sb.append(", primaryUserGroup='").append(abfsStore.getPrimaryGroup()).append('\'');    sb.append('}');    return sb.toString();  }  public boolean isSecureScheme() {    return false;  }  @Override  public URI getUri() {    return this.uri;  }  public void registerListener(Listener listener1) {    listener = listener1;  }  @Override  public FSDataInputStream open(final Path path, final int bufferSize) throws IOException {    LOG.debug("AzureBlobFileSystem.open path: {} bufferSize: {}", path, bufferSize);        return open(path, Optional.empty());  }  private FSDataInputStream open(final Path path,      final Optional<OpenFileParameters> parameters) throws IOException {    statIncrement(CALL_OPEN);    Path qualifiedPath = makeQualified(path);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.OPEN, tracingHeaderFormat, listener);      InputStream inputStream = abfsStore          .openFileForRead(qualifiedPath, parameters, statistics, tracingContext);      return new FSDataInputStream(inputStream);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);      return null;    }  }    @Override  protected CompletableFuture<FSDataInputStream> openFileWithOptions(      final Path path, final OpenFileParameters parameters) throws IOException {    LOG.debug("AzureBlobFileSystem.openFileWithOptions path: {}", path);    AbstractFSBuilderImpl.rejectUnknownMandatoryKeys(        parameters.getMandatoryKeys(),        Collections.emptySet(),        "for " + path);    return LambdaUtils.eval(        new CompletableFuture<>(), () ->            open(path, Optional.of(parameters)));  }  @Override  public FSDataOutputStream create(final Path f,      final FsPermission permission,      final boolean overwrite,      final int bufferSize,      final short replication,      final long blockSize,      final Progressable progress) throws IOException {    LOG.debug("AzureBlobFileSystem.create path: {} permission: {} overwrite: {} bufferSize: {}",        f,        permission,        overwrite,        blockSize);    statIncrement(CALL_CREATE);    trailingPeriodCheck(f);    Path qualifiedPath = makeQualified(f);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.CREATE, overwrite, tracingHeaderFormat, listener);      OutputStream outputStream = abfsStore.createFile(qualifiedPath, statistics, overwrite,          permission == null ? FsPermission.getFileDefault() : permission,          FsPermission.getUMask(getConf()), tracingContext);      statIncrement(FILES_CREATED);      return new FSDataOutputStream(outputStream, statistics);    } catch (AzureBlobFileSystemException ex) {      checkException(f, ex);      return null;    }  }  @Override  @SuppressWarnings("deprecation")  public FSDataOutputStream createNonRecursive(final Path f, final FsPermission permission,      final boolean overwrite, final int bufferSize, final short replication, final long blockSize,      final Progressable progress) throws IOException {    statIncrement(CALL_CREATE_NON_RECURSIVE);    final Path parent = f.getParent();    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.CREATE_NON_RECURSIVE, tracingHeaderFormat,        listener);    final FileStatus parentFileStatus = tryGetFileStatus(parent, tracingContext);    if (parentFileStatus == null) {      throw new FileNotFoundException("Cannot create file "          + f.getName() + " because parent folder does not exist.");    }    return create(f, permission, overwrite, bufferSize, replication, blockSize, progress);  }  @Override  @SuppressWarnings("deprecation")  public FSDataOutputStream createNonRecursive(final Path f,      final FsPermission permission,      final EnumSet<CreateFlag> flags,      final int bufferSize,      final short replication,      final long blockSize,      final Progressable progress) throws IOException {            final EnumSet<CreateFlag> createflags =        EnumSet.of(CreateFlag.CREATE, CreateFlag.OVERWRITE);    final boolean overwrite = flags.containsAll(createflags);        return this.createNonRecursive(f, permission, overwrite,        bufferSize, replication, blockSize, progress);  }  @Override  @SuppressWarnings("deprecation")  public FSDataOutputStream createNonRecursive(final Path f,      final boolean overwrite, final int bufferSize, final short replication, final long blockSize,      final Progressable progress) throws IOException {    return this.createNonRecursive(f, FsPermission.getFileDefault(),        overwrite, bufferSize, replication, blockSize, progress);  }  @Override  public FSDataOutputStream append(final Path f, final int bufferSize, final Progressable progress)      throws IOException {    LOG.debug(        "AzureBlobFileSystem.append path: {} bufferSize: {}",        f.toString(),        bufferSize);    statIncrement(CALL_APPEND);    Path qualifiedPath = makeQualified(f);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.APPEND, tracingHeaderFormat,          listener);      OutputStream outputStream = abfsStore          .openFileForWrite(qualifiedPath, statistics, false, tracingContext);      return new FSDataOutputStream(outputStream, statistics);    } catch (AzureBlobFileSystemException ex) {      checkException(f, ex);      return null;    }  }  public boolean rename(final Path src, final Path dst) throws IOException {    LOG.debug("AzureBlobFileSystem.rename src: {} dst: {}", src, dst);    statIncrement(CALL_RENAME);    trailingPeriodCheck(dst);    Path parentFolder = src.getParent();    if (parentFolder == null) {      return false;    }    Path qualifiedSrcPath = makeQualified(src);    Path qualifiedDstPath = makeQualified(dst);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.RENAME, true, tracingHeaderFormat,        listener);        if (makeQualified(parentFolder).equals(qualifiedDstPath)) {      return tryGetFileStatus(qualifiedSrcPath, tracingContext) != null;    }    FileStatus dstFileStatus = null;    if (qualifiedSrcPath.equals(qualifiedDstPath)) {                              dstFileStatus = tryGetFileStatus(qualifiedDstPath, tracingContext);      if (dstFileStatus == null) {        return false;      }      return dstFileStatus.isDirectory() ? false : true;    }        if (!abfsStore.getIsNamespaceEnabled(tracingContext) && dstFileStatus == null) {      dstFileStatus = tryGetFileStatus(qualifiedDstPath, tracingContext);    }    try {      String sourceFileName = src.getName();      Path adjustedDst = dst;      if (dstFileStatus != null) {        if (!dstFileStatus.isDirectory()) {          return qualifiedSrcPath.equals(qualifiedDstPath);        }        adjustedDst = new Path(dst, sourceFileName);      }      qualifiedDstPath = makeQualified(adjustedDst);      abfsStore.rename(qualifiedSrcPath, qualifiedDstPath, tracingContext, null);      return true;    } catch (AzureBlobFileSystemException ex) {      LOG.debug("Rename operation failed. ", ex);      checkException(          src,          ex,          AzureServiceErrorCode.PATH_ALREADY_EXISTS,          AzureServiceErrorCode.INVALID_RENAME_SOURCE_PATH,          AzureServiceErrorCode.SOURCE_PATH_NOT_FOUND,          AzureServiceErrorCode.INVALID_SOURCE_OR_DESTINATION_RESOURCE_TYPE,          AzureServiceErrorCode.RENAME_DESTINATION_PARENT_PATH_NOT_FOUND,          AzureServiceErrorCode.INTERNAL_OPERATION_ABORT);      return false;    }  }    @InterfaceAudience.Private  public ResilientCommitByRename createResilientCommitSupport(final Path path)      throws IOException {    if (!hasPathCapability(path,        CommonPathCapabilities.ETAGS_PRESERVED_IN_RENAME)) {      throw new UnsupportedOperationException(          "Resilient commit support not available for " + path);    }    return new ResilientCommitByRenameImpl();  }    public class ResilientCommitByRenameImpl implements ResilientCommitByRename {        public Pair<Boolean, Duration> commitSingleFileByRename(        final Path source,        final Path dest,        @Nullable final String sourceEtag) throws IOException {      LOG.debug("renameFileWithEtag source: {} dest: {} etag {}", source, dest, sourceEtag);      statIncrement(CALL_RENAME);      trailingPeriodCheck(dest);      Path qualifiedSrcPath = makeQualified(source);      Path qualifiedDstPath = makeQualified(dest);      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.RENAME, true, tracingHeaderFormat,          listener);      if (qualifiedSrcPath.equals(qualifiedDstPath)) {                throw new PathIOException(qualifiedSrcPath.toString(), "cannot rename object onto self");      }            final Duration waitTime = rateLimiting.acquire(1);      try {        final boolean recovered = abfsStore.rename(qualifiedSrcPath,            qualifiedDstPath, tracingContext, sourceEtag);        return Pair.of(recovered, waitTime);      } catch (AzureBlobFileSystemException ex) {        LOG.debug("Rename operation failed. ", ex);        checkException(source, ex);                return null;      }    }  }  @Override  public boolean delete(final Path f, final boolean recursive) throws IOException {    LOG.debug(        "AzureBlobFileSystem.delete path: {} recursive: {}", f.toString(), recursive);    statIncrement(CALL_DELETE);    Path qualifiedPath = makeQualified(f);    if (f.isRoot()) {      if (!recursive) {        return false;      }      return deleteRoot();    }    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.DELETE, tracingHeaderFormat,          listener);      abfsStore.delete(qualifiedPath, recursive, tracingContext);      return true;    } catch (AzureBlobFileSystemException ex) {      checkException(f, ex, AzureServiceErrorCode.PATH_NOT_FOUND);      return false;    }  }  @Override  public FileStatus[] listStatus(final Path f) throws IOException {    LOG.debug(        "AzureBlobFileSystem.listStatus path: {}", f.toString());    statIncrement(CALL_LIST_STATUS);    Path qualifiedPath = makeQualified(f);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.LISTSTATUS, true, tracingHeaderFormat,          listener);      FileStatus[] result = abfsStore.listStatus(qualifiedPath, tracingContext);      return result;    } catch (AzureBlobFileSystemException ex) {      checkException(f, ex);      return null;    }  }    private void statIncrement(AbfsStatistic statistic) {    incrementStatistic(statistic);  }    private void incrementStatistic(AbfsStatistic statistic) {    if (abfsCounters != null) {      abfsCounters.incrementCounter(statistic, 1);    }  }    private void trailingPeriodCheck(Path path) throws IllegalArgumentException {    while (!path.isRoot()) {      String pathToString = path.toString();      if (pathToString.length() != 0) {        if (pathToString.charAt(pathToString.length() - 1) == '.') {          throw new IllegalArgumentException(              "ABFS does not allow files or directories to end with a dot.");        }        path = path.getParent();      } else {        break;      }    }  }  @Override  public boolean mkdirs(final Path f, final FsPermission permission) throws IOException {    LOG.debug(        "AzureBlobFileSystem.mkdirs path: {} permissions: {}", f, permission);    statIncrement(CALL_MKDIRS);    trailingPeriodCheck(f);    final Path parentFolder = f.getParent();    if (parentFolder == null) {            return true;    }    Path qualifiedPath = makeQualified(f);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.MKDIR, false, tracingHeaderFormat,          listener);      abfsStore.createDirectory(qualifiedPath,          permission == null ? FsPermission.getDirDefault() : permission,          FsPermission.getUMask(getConf()), tracingContext);      statIncrement(DIRECTORIES_CREATED);      return true;    } catch (AzureBlobFileSystemException ex) {      checkException(f, ex);      return true;    }  }  @Override  public synchronized void close() throws IOException {    if (isClosed) {      return;    }        super.close();    LOG.debug("AzureBlobFileSystem.close");    if (getConf() != null) {      String iostatisticsLoggingLevel =          getConf().getTrimmed(IOSTATISTICS_LOGGING_LEVEL,              IOSTATISTICS_LOGGING_LEVEL_DEFAULT);      logIOStatisticsAtLevel(LOG, iostatisticsLoggingLevel, getIOStatistics());    }    IOUtils.cleanupWithLogger(LOG, abfsStore, delegationTokenManager);    this.isClosed = true;    if (LOG.isDebugEnabled()) {      LOG.debug("Closing Abfs: {}", toString());    }  }  @Override  public FileStatus getFileStatus(final Path f) throws IOException {    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.GET_FILESTATUS, tracingHeaderFormat,        listener);    return getFileStatus(f, tracingContext);  }  private FileStatus getFileStatus(final Path path,      TracingContext tracingContext) throws IOException {    LOG.debug("AzureBlobFileSystem.getFileStatus path: {}", path);    statIncrement(CALL_GET_FILE_STATUS);    Path qualifiedPath = makeQualified(path);    try {      return abfsStore.getFileStatus(qualifiedPath, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);      return null;    }  }    public void breakLease(final Path f) throws IOException {    LOG.debug("AzureBlobFileSystem.breakLease path: {}", f);    Path qualifiedPath = makeQualified(f);    try (DurationInfo ignored = new DurationInfo(LOG, false, "Break lease for %s",        qualifiedPath)) {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.BREAK_LEASE, tracingHeaderFormat,          listener);      abfsStore.breakLease(qualifiedPath, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(f, ex);    }  }    @Override  public Path makeQualified(Path path) {                if (path != null) {      String uriPath = path.toUri().getPath();      path = uriPath.isEmpty() ? path : new Path(uriPath);    }    return super.makeQualified(path);  }  @Override  public Path getWorkingDirectory() {    return this.workingDir;  }  @Override  public void setWorkingDirectory(final Path newDir) {    if (newDir.isAbsolute()) {      this.workingDir = newDir;    } else {      this.workingDir = new Path(workingDir, newDir);    }  }  @Override  public String getScheme() {    return FileSystemUriSchemes.ABFS_SCHEME;  }  @Override  public Path getHomeDirectory() {    return makeQualified(new Path(        FileSystemConfigurations.USER_HOME_DIRECTORY_PREFIX            + "/" + abfsStore.getUser()));  }    @Override  public BlockLocation[] getFileBlockLocations(FileStatus file,      long start, long len) {    if (file == null) {      return null;    }    if ((start < 0) || (len < 0)) {      throw new IllegalArgumentException("Invalid start or len parameter");    }    if (file.getLen() < start) {      return new BlockLocation[0];    }    final String blobLocationHost = abfsStore.getAbfsConfiguration().getAzureBlockLocationHost();    final String[] name = {blobLocationHost};    final String[] host = {blobLocationHost};    long blockSize = file.getBlockSize();    if (blockSize <= 0) {      throw new IllegalArgumentException(          "The block size for the given file is not a positive number: "              + blockSize);    }    int numberOfLocations = (int) (len / blockSize)        + ((len % blockSize == 0) ? 0 : 1);    BlockLocation[] locations = new BlockLocation[numberOfLocations];    for (int i = 0; i < locations.length; i++) {      long currentOffset = start + (i * blockSize);      long currentLength = Math.min(blockSize, start + len - currentOffset);      locations[i] = new BlockLocation(name, host, currentOffset, currentLength);    }    return locations;  }  @Override  protected void finalize() throws Throwable {    LOG.debug("finalize() called.");    close();    super.finalize();  }    public String getOwnerUser() {    return abfsStore.getUser();  }    public String getOwnerUserPrimaryGroup() {    return abfsStore.getPrimaryGroup();  }  private boolean deleteRoot() throws IOException {    LOG.debug("Deleting root content");    final ExecutorService executorService = Executors.newFixedThreadPool(10);    try {      final FileStatus[] ls = listStatus(makeQualified(new Path(File.separator)));      final ArrayList<Future> deleteTasks = new ArrayList<>();      for (final FileStatus fs : ls) {        final Future deleteTask = executorService.submit(new Callable<Void>() {          @Override          public Void call() throws Exception {            delete(fs.getPath(), fs.isDirectory());            if (fs.isDirectory()) {              statIncrement(DIRECTORIES_DELETED);            } else {              statIncrement(FILES_DELETED);            }            return null;          }        });        deleteTasks.add(deleteTask);      }      for (final Future deleteTask : deleteTasks) {        execute("deleteRoot", new Callable<Void>() {          @Override          public Void call() throws Exception {            deleteTask.get();            return null;          }        });      }    } finally {      executorService.shutdownNow();    }    return true;  }    @Override  public void setOwner(final Path path, final String owner, final String group)      throws IOException {    LOG.debug(        "AzureBlobFileSystem.setOwner path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.SET_OWNER, true, tracingHeaderFormat,        listener);    if (!getIsNamespaceEnabled(tracingContext)) {      super.setOwner(path, owner, group);      return;    }    if ((owner == null || owner.isEmpty()) && (group == null || group.isEmpty())) {      throw new IllegalArgumentException("A valid owner or group must be specified.");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.setOwner(qualifiedPath,          owner,          group,          tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public void setXAttr(final Path path,      final String name,      final byte[] value,      final EnumSet<XAttrSetFlag> flag)      throws IOException {    LOG.debug("AzureBlobFileSystem.setXAttr path: {}", path);    if (name == null || name.isEmpty() || value == null) {      throw new IllegalArgumentException("A valid name and value must be specified.");    }    Path qualifiedPath = makeQualified(path);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.SET_ATTR, true, tracingHeaderFormat,          listener);      Hashtable<String, String> properties = abfsStore          .getPathStatus(qualifiedPath, tracingContext);      String xAttrName = ensureValidAttributeName(name);      boolean xAttrExists = properties.containsKey(xAttrName);      XAttrSetFlag.validate(name, xAttrExists, flag);      String xAttrValue = abfsStore.decodeAttribute(value);      properties.put(xAttrName, xAttrValue);      abfsStore.setPathProperties(qualifiedPath, properties, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public byte[] getXAttr(final Path path, final String name)      throws IOException {    LOG.debug("AzureBlobFileSystem.getXAttr path: {}", path);    if (name == null || name.isEmpty()) {      throw new IllegalArgumentException("A valid name must be specified.");    }    Path qualifiedPath = makeQualified(path);    byte[] value = null;    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.GET_ATTR, true, tracingHeaderFormat,          listener);      Hashtable<String, String> properties = abfsStore          .getPathStatus(qualifiedPath, tracingContext);      String xAttrName = ensureValidAttributeName(name);      if (properties.containsKey(xAttrName)) {        String xAttrValue = properties.get(xAttrName);        value = abfsStore.encodeAttribute(xAttrValue);      }    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }    return value;  }  private static String ensureValidAttributeName(String attribute) {        return attribute.replace('.', '_');  }    @Override  public void setPermission(final Path path, final FsPermission permission)      throws IOException {    LOG.debug("AzureBlobFileSystem.setPermission path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.SET_PERMISSION, true, tracingHeaderFormat, listener);    if (!getIsNamespaceEnabled(tracingContext)) {      super.setPermission(path, permission);      return;    }    if (permission == null) {      throw new IllegalArgumentException("The permission can't be null");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.setPermission(qualifiedPath, permission, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public void modifyAclEntries(final Path path, final List<AclEntry> aclSpec)      throws IOException {    LOG.debug("AzureBlobFileSystem.modifyAclEntries path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.MODIFY_ACL, true, tracingHeaderFormat,        listener);    if (!getIsNamespaceEnabled(tracingContext)) {      throw new UnsupportedOperationException(          "modifyAclEntries is only supported by storage accounts with the "              + "hierarchical namespace enabled.");    }    if (aclSpec == null || aclSpec.isEmpty()) {      throw new IllegalArgumentException("The value of the aclSpec parameter is invalid.");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.modifyAclEntries(qualifiedPath, aclSpec, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public void removeAclEntries(final Path path, final List<AclEntry> aclSpec)      throws IOException {    LOG.debug("AzureBlobFileSystem.removeAclEntries path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.REMOVE_ACL_ENTRIES, true,        tracingHeaderFormat, listener);    if (!getIsNamespaceEnabled(tracingContext)) {      throw new UnsupportedOperationException(          "removeAclEntries is only supported by storage accounts with the "              + "hierarchical namespace enabled.");    }    if (aclSpec == null || aclSpec.isEmpty()) {      throw new IllegalArgumentException("The aclSpec argument is invalid.");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.removeAclEntries(qualifiedPath, aclSpec, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public void removeDefaultAcl(final Path path) throws IOException {    LOG.debug("AzureBlobFileSystem.removeDefaultAcl path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.REMOVE_DEFAULT_ACL, true,        tracingHeaderFormat, listener);    if (!getIsNamespaceEnabled(tracingContext)) {      throw new UnsupportedOperationException(          "removeDefaultAcl is only supported by storage accounts with the "              + "hierarchical namespace enabled.");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.removeDefaultAcl(qualifiedPath, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public void removeAcl(final Path path) throws IOException {    LOG.debug("AzureBlobFileSystem.removeAcl path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.REMOVE_ACL, true, tracingHeaderFormat,        listener);    if (!getIsNamespaceEnabled(tracingContext)) {      throw new UnsupportedOperationException(          "removeAcl is only supported by storage accounts with the "              + "hierarchical namespace enabled.");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.removeAcl(qualifiedPath, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public void setAcl(final Path path, final List<AclEntry> aclSpec)      throws IOException {    LOG.debug("AzureBlobFileSystem.setAcl path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.SET_ACL, true, tracingHeaderFormat,        listener);    if (!getIsNamespaceEnabled(tracingContext)) {      throw new UnsupportedOperationException(          "setAcl is only supported by storage accounts with the hierarchical "              + "namespace enabled.");    }    if (aclSpec == null || aclSpec.size() == 0) {      throw new IllegalArgumentException("The aclSpec argument is invalid.");    }    Path qualifiedPath = makeQualified(path);    try {      abfsStore.setAcl(qualifiedPath, aclSpec, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);    }  }    @Override  public AclStatus getAclStatus(final Path path) throws IOException {    LOG.debug("AzureBlobFileSystem.getAclStatus path: {}", path);    TracingContext tracingContext = new TracingContext(clientCorrelationId,        fileSystemId, FSOperationType.GET_ACL_STATUS, true, tracingHeaderFormat, listener);    if (!getIsNamespaceEnabled(tracingContext)) {      throw new UnsupportedOperationException(          "getAclStatus is only supported by storage account with the "              + "hierarchical namespace enabled.");    }    Path qualifiedPath = makeQualified(path);    try {      return abfsStore.getAclStatus(qualifiedPath, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(path, ex);      return null;    }  }    @Override  public void access(final Path path, final FsAction mode) throws IOException {    LOG.debug("AzureBlobFileSystem.access path : {}, mode : {}", path, mode);    Path qualifiedPath = makeQualified(path);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.ACCESS, tracingHeaderFormat,          listener);      this.abfsStore.access(qualifiedPath, mode, tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkCheckAccessException(path, ex);    }  }    @Override  public boolean exists(Path f) throws IOException {    statIncrement(CALL_EXIST);    return super.exists(f);  }  @Override  public RemoteIterator<FileStatus> listStatusIterator(Path path)      throws IOException {    LOG.debug("AzureBlobFileSystem.listStatusIterator path : {}", path);    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.LISTSTATUS, true, tracingHeaderFormat, listener);      AbfsListStatusRemoteIterator abfsLsItr =          new AbfsListStatusRemoteIterator(path, abfsStore,              tracingContext);      return RemoteIterators.typeCastingRemoteIterator(abfsLsItr);    } else {      return super.listStatusIterator(path);    }  }    @Override  protected RemoteIterator<LocatedFileStatus> listLocatedStatus(      final Path path,      final PathFilter filter)      throws FileNotFoundException, IOException {    LOG.debug("AzureBlobFileSystem.listStatusIterator path : {}", path);            final RemoteIterator<FileStatus> sourceEntries = filteringRemoteIterator(        listStatusIterator(path),        (st) -> filter.accept(st.getPath()));            return mappingRemoteIterator(sourceEntries,        st -> new AbfsLocatedFileStatus(st,            st.isFile()                ? getFileBlockLocations(st, 0, st.getLen())                : null));  }  private FileStatus tryGetFileStatus(final Path f, TracingContext tracingContext) {    try {      return getFileStatus(f, tracingContext);    } catch (IOException ex) {      LOG.debug("File not found {}", f);      statIncrement(ERROR_IGNORED);      return null;    }  }  private boolean fileSystemExists() throws IOException {    LOG.debug(        "AzureBlobFileSystem.fileSystemExists uri: {}", uri);    try {      TracingContext tracingContext = new TracingContext(clientCorrelationId,          fileSystemId, FSOperationType.TEST_OP, tracingHeaderFormat, listener);      abfsStore.getFilesystemProperties(tracingContext);    } catch (AzureBlobFileSystemException ex) {      try {        checkException(null, ex);                              } catch (FileNotFoundException e) {        statIncrement(ERROR_IGNORED);        return false;      }    }    return true;  }  private void createFileSystem(TracingContext tracingContext) throws IOException {    LOG.debug(        "AzureBlobFileSystem.createFileSystem uri: {}", uri);    try {      abfsStore.createFilesystem(tracingContext);    } catch (AzureBlobFileSystemException ex) {      checkException(null, ex);    }  }  private URI ensureAuthority(URI uri, final Configuration conf) {    Preconditions.checkNotNull(uri, "uri");    if (uri.getAuthority() == null) {      final URI defaultUri = FileSystem.getDefaultUri(conf);      if (defaultUri != null && isAbfsScheme(defaultUri.getScheme())) {        try {                    uri = new URI(              uri.getScheme(),              defaultUri.getAuthority(),              uri.getPath(),              uri.getQuery(),              uri.getFragment());        } catch (URISyntaxException e) {                    throw new IllegalArgumentException(new InvalidUriException(uri.toString()));        }      }    }    if (uri.getAuthority() == null) {      throw new IllegalArgumentException(new InvalidUriAuthorityException(uri.toString()));    }    return uri;  }  private boolean isAbfsScheme(final String scheme) {    if (scheme == null) {      return false;    }    if (scheme.equals(FileSystemUriSchemes.ABFS_SCHEME)        || scheme.equals(FileSystemUriSchemes.ABFS_SECURE_SCHEME)) {      return true;    }    return false;  }  @VisibleForTesting  <T> FileSystemOperation<T> execute(      final String scopeDescription,      final Callable<T> callableFileOperation) throws IOException {    return execute(scopeDescription, callableFileOperation, null);  }  @VisibleForTesting  <T> FileSystemOperation<T> execute(      final String scopeDescription,      final Callable<T> callableFileOperation,      T defaultResultValue) throws IOException {    try {      final T executionResult = callableFileOperation.call();      return new FileSystemOperation<>(executionResult, null);    } catch (AbfsRestOperationException abfsRestOperationException) {      return new FileSystemOperation<>(defaultResultValue, abfsRestOperationException);    } catch (AzureBlobFileSystemException azureBlobFileSystemException) {      throw new IOException(azureBlobFileSystemException);    } catch (Exception exception) {      if (exception instanceof ExecutionException) {        exception = (Exception) getRootCause(exception);      }      final FileSystemOperationUnhandledException fileSystemOperationUnhandledException          = new FileSystemOperationUnhandledException(exception);      throw new IOException(fileSystemOperationUnhandledException);    }  }  private void checkCheckAccessException(final Path path,      final AzureBlobFileSystemException exception) throws IOException {    if (exception instanceof AbfsRestOperationException) {      AbfsRestOperationException ere = (AbfsRestOperationException) exception;      if (ere.getStatusCode() == HttpURLConnection.HTTP_FORBIDDEN) {        throw (IOException) new AccessControlException(ere.getMessage())            .initCause(exception);      }    }    checkException(path, exception);  }    @VisibleForTesting  public static void checkException(final Path path,      final AzureBlobFileSystemException exception,      final AzureServiceErrorCode... allowedErrorCodesList) throws IOException {    if (exception instanceof AbfsRestOperationException) {      AbfsRestOperationException ere = (AbfsRestOperationException) exception;      if (ArrayUtils.contains(allowedErrorCodesList, ere.getErrorCode())) {        return;      }            String message = ere.getMessage();      switch (ere.getStatusCode()) {      case HttpURLConnection.HTTP_NOT_FOUND:        throw (IOException) new FileNotFoundException(message)            .initCause(exception);      case HttpURLConnection.HTTP_CONFLICT:        throw (IOException) new FileAlreadyExistsException(message)            .initCause(exception);      case HttpURLConnection.HTTP_FORBIDDEN:      case HttpURLConnection.HTTP_UNAUTHORIZED:        throw (IOException) new AccessDeniedException(message)            .initCause(exception);      default:        throw ere;      }    } else if (exception instanceof SASTokenProviderException) {      throw exception;    } else {      if (path == null) {        throw exception;      }            throw new PathIOException(path.toString(), exception);    }  }    private Throwable getRootCause(Throwable throwable) {    if (throwable == null) {      throw new IllegalArgumentException("throwable can not be null");    }    Throwable result = throwable;    while (result.getCause() != null) {      result = result.getCause();    }    return result;  }    @Override  public synchronized Token<?> getDelegationToken(final String renewer) throws IOException {    statIncrement(CALL_GET_DELEGATION_TOKEN);    return this.delegationTokenEnabled ? this.delegationTokenManager.getDelegationToken(renewer)        : super.getDelegationToken(renewer);  }    @Override  public String getCanonicalServiceName() {    String name = null;    if (delegationTokenManager != null) {      name = delegationTokenManager.getCanonicalServiceName();    }    return name != null ? name : super.getCanonicalServiceName();  }  @VisibleForTesting  FileSystem.Statistics getFsStatistics() {    return this.statistics;  }  @VisibleForTesting  void setListenerOperation(FSOperationType operation) {    listener.setOperation(operation);  }  @VisibleForTesting  static class FileSystemOperation<T> {    private final T result;    private final AbfsRestOperationException exception;    FileSystemOperation(final T result, final AbfsRestOperationException exception) {      this.result = result;      this.exception = exception;    }    public boolean failed() {      return this.exception != null;    }  }  @VisibleForTesting  public AzureBlobFileSystemStore getAbfsStore() {    return abfsStore;  }  @VisibleForTesting  AbfsClient getAbfsClient() {    return abfsStore.getClient();  }    @VisibleForTesting  AbfsDelegationTokenManager getDelegationTokenManager() {    return delegationTokenManager;  }  @VisibleForTesting  boolean getIsNamespaceEnabled(TracingContext tracingContext)      throws AzureBlobFileSystemException {    return abfsStore.getIsNamespaceEnabled(tracingContext);  }    @VisibleForTesting  Map<String, Long> getInstrumentationMap() {    return abfsCounters.toMap();  }  @VisibleForTesting  String getFileSystemId() {    return fileSystemId;  }  @VisibleForTesting  String getClientCorrelationId() {    return clientCorrelationId;  }  @Override  public boolean hasPathCapability(final Path path, final String capability)      throws IOException {        final Path p = makeQualified(path);    switch (validatePathCapabilityArgs(p, capability)) {    case CommonPathCapabilities.FS_PERMISSIONS:    case CommonPathCapabilities.FS_APPEND:    case CommonPathCapabilities.ETAGS_AVAILABLE:      return true;    case CommonPathCapabilities.ETAGS_PRESERVED_IN_RENAME:    case CommonPathCapabilities.FS_ACLS:      return getIsNamespaceEnabled(          new TracingContext(clientCorrelationId, fileSystemId,              FSOperationType.HAS_PATH_CAPABILITY, tracingHeaderFormat,              listener));    default:      return super.hasPathCapability(p, capability);    }  }    @Override  public IOStatistics getIOStatistics() {    return abfsCounters != null ? abfsCounters.getIOStatistics() : null;  }}