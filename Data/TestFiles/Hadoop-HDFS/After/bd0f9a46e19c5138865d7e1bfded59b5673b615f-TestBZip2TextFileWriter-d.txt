
package org.apache.hadoop.io.compress.bzip2;

import java.io.ByteArrayInputStream;
import java.io.ByteArrayOutputStream;
import java.io.IOException;
import java.util.List;

import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import static org.apache.hadoop.io.compress.bzip2.BZip2TextFileWriter.BLOCK_SIZE;
import static org.junit.Assert.assertEquals;

public final class TestBZip2TextFileWriter {

  private static final byte[] DELIMITER = new byte[] {'\0'};

  private ByteArrayOutputStream rawOut;
  private BZip2TextFileWriter writer;

  @Before
  public void setUp() throws Exception {
    rawOut = new ByteArrayOutputStream();
    writer = new BZip2TextFileWriter(rawOut);
  }

  @After
  public void tearDown() throws Exception {
    rawOut = null;
    writer.close();
  }

  @Test
  public void writingSingleBlockSizeOfData() throws Exception {
    writer.writeRecord(BLOCK_SIZE, DELIMITER);
    writer.close();

    List<Long> nextBlocks = getNextBlockMarkerOffsets();
    assertEquals(0, nextBlocks.size());
  }

  @Test
  public void justExceedingBeyondBlockSize() throws Exception {
    writer.writeRecord(BLOCK_SIZE + 1, DELIMITER);
    writer.close();

    List<Long> nextBlocks = getNextBlockMarkerOffsets();
    assertEquals(1, nextBlocks.size());
  }

  @Test
  public void writingTwoBlockSizesOfData() throws Exception {
    writer.writeRecord(2 * BLOCK_SIZE, DELIMITER);
    writer.close();

    List<Long> nextBlocks = getNextBlockMarkerOffsets();
    assertEquals(1, nextBlocks.size());
  }

  @Test
  public void justExceedingBeyondTwoBlocks() throws Exception {
    writer.writeRecord(2 * BLOCK_SIZE + 1, DELIMITER);
    writer.close();

    List<Long> nextBlocks = getNextBlockMarkerOffsets();
    assertEquals(2, nextBlocks.size());
  }

  private List<Long> getNextBlockMarkerOffsets() throws IOException {
    ByteArrayInputStream in = new ByteArrayInputStream(rawOut.toByteArray());
    return BZip2Utils.getNextBlockMarkerOffsets(in);
  }
}
