public class StagingCommitter extends AbstractS3ACommitter {  private static final Logger LOG = LoggerFactory.getLogger(      StagingCommitter.class);    public static final String NAME = "staging";  private final Path constructorOutputPath;  private final long uploadPartSize;  private final String uuid;  private final boolean uniqueFilenames;  private final FileOutputCommitter wrappedCommitter;  private ConflictResolution conflictResolution;  private String s3KeyPrefix;    private Path commitsDirectory;    public StagingCommitter(Path outputPath,      TaskAttemptContext context) throws IOException {    super(outputPath, context);    this.constructorOutputPath = checkNotNull(getOutputPath(), "output path");    Configuration conf = getConf();    this.uploadPartSize = conf.getLongBytes(        MULTIPART_SIZE, DEFAULT_MULTIPART_SIZE);    this.uuid = getUploadUUID(conf, context.getJobID());    this.uniqueFilenames = conf.getBoolean(        FS_S3A_COMMITTER_STAGING_UNIQUE_FILENAMES,        DEFAULT_STAGING_COMMITTER_UNIQUE_FILENAMES);    setWorkPath(buildWorkPath(context, uuid));    this.wrappedCommitter = createWrappedCommitter(context, conf);    setOutputPath(constructorOutputPath);    Path finalOutputPath = getOutputPath();    Preconditions.checkNotNull(finalOutputPath, "Output path cannot be null");    S3AFileSystem fs = getS3AFileSystem(finalOutputPath,        context.getConfiguration(), false);    s3KeyPrefix = fs.pathToKey(finalOutputPath);    LOG.debug("{}: final output path is {}", getRole(), finalOutputPath);        ConflictResolution mode = getConflictResolutionMode(getJobContext(),        fs.getConf());    LOG.debug("Conflict resolution mode: {}", mode);  }  @Override  public String getName() {    return NAME;  }    protected FileOutputCommitter createWrappedCommitter(JobContext context,      Configuration conf) throws IOException {        initFileOutputCommitterOptions(context);    commitsDirectory = Paths.getMultipartUploadCommitsDirectory(conf, uuid);    return new FileOutputCommitter(commitsDirectory, context);  }    protected void initFileOutputCommitterOptions(JobContext context) {    context.getConfiguration()        .setInt(FileOutputCommitter.FILEOUTPUTCOMMITTER_ALGORITHM_VERSION, 1);  }  @Override  public String toString() {    final StringBuilder sb = new StringBuilder("StagingCommitter{");    sb.append(super.toString());    sb.append(", conflictResolution=").append(conflictResolution);    if (wrappedCommitter != null) {      sb.append(", wrappedCommitter=").append(wrappedCommitter);    }    sb.append('}');    return sb.toString();  }    public static String getUploadUUID(Configuration conf, String jobId) {    return conf.getTrimmed(        InternalCommitterConstants.FS_S3A_COMMITTER_STAGING_UUID,        conf.getTrimmed(SPARK_WRITE_UUID,            conf.getTrimmed(SPARK_APP_ID, jobId)));  }    public static String getUploadUUID(Configuration conf, JobID jobId) {    return getUploadUUID(conf, jobId.toString());  }    private static Path buildWorkPath(JobContext context, String uuid)      throws IOException {    if (context instanceof TaskAttemptContext) {      return taskAttemptWorkingPath((TaskAttemptContext) context, uuid);    } else {      return null;    }  }    public Boolean useUniqueFilenames() {    return uniqueFilenames;  }    public FileSystem getJobAttemptFileSystem(JobContext context)      throws IOException {    Path p = getJobAttemptPath(context);    return p.getFileSystem(context.getConfiguration());  }    public static Path getJobAttemptPath(JobContext context, Path out) {    return getJobAttemptPath(getAppAttemptId(context), out);  }    private static Path getJobAttemptPath(int appAttemptId, Path out) {    return new Path(getPendingJobAttemptsPath(out),        String.valueOf(appAttemptId));  }  @Override  protected Path getJobAttemptPath(int appAttemptId) {    return new Path(getPendingJobAttemptsPath(commitsDirectory),        String.valueOf(appAttemptId));  }    private static Path getPendingTaskAttemptsPath(JobContext context, Path out) {    return new Path(getJobAttemptPath(context, out), TEMPORARY);  }    public static Path getTaskAttemptPath(TaskAttemptContext context, Path out) {    return new Path(getPendingTaskAttemptsPath(context, out),        String.valueOf(context.getTaskAttemptID()));  }    private static Path getPendingJobAttemptsPath(Path out) {    Preconditions.checkNotNull(out, "Null 'out' path");    return new Path(out, TEMPORARY);  }    public Path getCommittedTaskPath(TaskAttemptContext context) {    return getCommittedTaskPath(getAppAttemptId(context), context);  }    private static void validateContext(TaskAttemptContext context) {    Preconditions.checkNotNull(context, "null context");    Preconditions.checkNotNull(context.getTaskAttemptID(),        "null task attempt ID");    Preconditions.checkNotNull(context.getTaskAttemptID().getTaskID(),        "null task ID");    Preconditions.checkNotNull(context.getTaskAttemptID().getJobID(),        "null job ID");  }    protected Path getCommittedTaskPath(int appAttemptId,      TaskAttemptContext context) {    validateContext(context);    return new Path(getJobAttemptPath(appAttemptId),        String.valueOf(context.getTaskAttemptID().getTaskID()));  }  @Override  public Path getTempTaskAttemptPath(TaskAttemptContext context) {    throw new UnsupportedOperationException("Unimplemented");  }    protected List<LocatedFileStatus> getTaskOutput(TaskAttemptContext context)      throws IOException {        Path attemptPath = getTaskAttemptPath(context);    Preconditions.checkNotNull(attemptPath,        "No attemptPath path in {}", this);    LOG.debug("Scanning {} for files to commit", attemptPath);    return listAndFilter(getTaskAttemptFilesystem(context),        attemptPath, true, HIDDEN_FILE_FILTER);  }    protected String getFinalKey(String relative, JobContext context) {    if (uniqueFilenames) {      return getS3KeyPrefix(context) + "/" + Paths.addUUID(relative, uuid);    } else {      return getS3KeyPrefix(context) + "/" + relative;    }  }    protected final Path getFinalPath(String relative, JobContext context)      throws IOException {    return getDestS3AFS().keyToQualifiedPath(getFinalKey(relative, context));  }    @Override  public Path getBaseTaskAttemptPath(TaskAttemptContext context) {        return getWorkPath();  }    @Override  public Path getJobAttemptPath(JobContext context) {    return wrappedCommitter.getJobAttemptPath(context);  }    @Override  public void setupJob(JobContext context) throws IOException {    LOG.debug("{}, Setting up job {}", getRole(), jobIdString(context));    context.getConfiguration().set(        InternalCommitterConstants.FS_S3A_COMMITTER_STAGING_UUID, uuid);    wrappedCommitter.setupJob(context);    super.setupJob(context);  }    @Override  protected ActiveCommit listPendingUploadsToCommit(      JobContext context)      throws IOException {    return listPendingUploads(context, false);  }    protected ActiveCommit listPendingUploadsToAbort(      JobContext context) throws IOException {    return listPendingUploads(context, true);  }    protected ActiveCommit listPendingUploads(      JobContext context, boolean suppressExceptions) throws IOException {    try (DurationInfo ignored = new DurationInfo(LOG,        "Listing pending uploads")) {      Path wrappedJobAttemptPath = getJobAttemptPath(context);      final FileSystem attemptFS = wrappedJobAttemptPath.getFileSystem(          context.getConfiguration());      return ActiveCommit.fromStatusList(attemptFS,          listAndFilter(attemptFS,              wrappedJobAttemptPath, false,              HIDDEN_FILE_FILTER));    } catch (FileNotFoundException e) {                  maybeIgnore(suppressExceptions, "Pending upload directory not found", e);    } catch (IOException e) {            maybeIgnore(suppressExceptions, "Listing pending uploads", e);    }        return ActiveCommit.empty();  }  @Override  public void cleanupStagingDirs() {    Path workPath = getWorkPath();    if (workPath != null) {      LOG.debug("Cleaning up work path {}", workPath);      ignoreIOExceptions(LOG, "cleaning up", workPath.toString(),          () -> deleteQuietly(workPath.getFileSystem(getConf()),              workPath, true));    }  }  @Override  @SuppressWarnings("deprecation")  protected void cleanup(JobContext context,      boolean suppressExceptions)      throws IOException {    maybeIgnore(suppressExceptions, "Cleanup wrapped committer",        () -> wrappedCommitter.cleanupJob(context));    maybeIgnore(suppressExceptions, "Delete destination paths",        () -> deleteDestinationPaths(context));    super.cleanup(context, suppressExceptions);  }  @Override  protected void abortPendingUploadsInCleanup(boolean suppressExceptions)      throws IOException {    if (getConf()        .getBoolean(FS_S3A_COMMITTER_STAGING_ABORT_PENDING_UPLOADS, true)) {      super.abortPendingUploadsInCleanup(suppressExceptions);    } else {      LOG.info("Not cleanup up pending uploads to {} as {} is false ",          getOutputPath(),          FS_S3A_COMMITTER_STAGING_ABORT_PENDING_UPLOADS);    }  }  @Override  protected void abortJobInternal(JobContext context,      boolean suppressExceptions) throws IOException {    String r = getRole();    boolean failed = false;    try (DurationInfo d = new DurationInfo(LOG,        "%s: aborting job in state %s ", r, jobIdString(context))) {      ActiveCommit pending = listPendingUploadsToAbort(context);      abortPendingUploads(context, pending, suppressExceptions, true);    } catch (FileNotFoundException e) {            LOG.debug("No job directory to read uploads from");    } catch (IOException e) {      failed = true;      maybeIgnore(suppressExceptions, "aborting job", e);    } finally {      super.abortJobInternal(context, failed || suppressExceptions);    }  }    protected void deleteDestinationPaths(JobContext context) throws IOException {    Path attemptPath = getJobAttemptPath(context);    ignoreIOExceptions(LOG,        "Deleting Job attempt Path", attemptPath.toString(),        () -> deleteWithWarning(            getJobAttemptFileSystem(context),            attemptPath,            true));            deleteWithWarning(getDestFS(),        new Path(getOutputPath(), TEMPORARY),        true);        deleteTaskWorkingPathQuietly(context);  }  @Override  public void setupTask(TaskAttemptContext context) throws IOException {    Path taskAttemptPath = getTaskAttemptPath(context);    try (DurationInfo d = new DurationInfo(LOG,        "%s: setup task attempt path %s ", getRole(), taskAttemptPath)) {            taskAttemptPath.getFileSystem(getConf()).mkdirs(taskAttemptPath);      wrappedCommitter.setupTask(context);    }  }  @Override  public boolean needsTaskCommit(TaskAttemptContext context)      throws IOException {    try (DurationInfo d = new DurationInfo(LOG,        "%s: needsTaskCommit() Task %s",        getRole(), context.getTaskAttemptID())) {            Path attemptPath = getTaskAttemptPath(context);      FileSystem fs = getTaskAttemptFilesystem(context);                  FileStatus[] stats = fs.listStatus(attemptPath);      LOG.debug("{} files to commit under {}", stats.length, attemptPath);      return stats.length > 0;    } catch (FileNotFoundException e) {                  LOG.info("No files to commit");      throw e;    }  }  @Override  public void commitTask(TaskAttemptContext context) throws IOException {    try (DurationInfo d = new DurationInfo(LOG,        "%s: commit task %s", getRole(), context.getTaskAttemptID())) {      int count = commitTaskInternal(context, getTaskOutput(context));      LOG.info("{}: upload file count: {}", getRole(), count);    } catch (IOException e) {      LOG.error("{}: commit of task {} failed",          getRole(), context.getTaskAttemptID(), e);      getCommitOperations().taskCompleted(false);      throw e;    } finally {      destroyThreadPool();    }    getCommitOperations().taskCompleted(true);  }    protected int commitTaskInternal(final TaskAttemptContext context,      List<? extends FileStatus> taskOutput)      throws IOException {    LOG.debug("{}: commitTaskInternal", getRole());    Configuration conf = context.getConfiguration();    final Path attemptPath = getTaskAttemptPath(context);    FileSystem attemptFS = getTaskAttemptFilesystem(context);    LOG.debug("{}: attempt path is {}", getRole(), attemptPath);            Path commitsAttemptPath = wrappedCommitter.getTaskAttemptPath(context);    FileSystem commitsFS = commitsAttemptPath.getFileSystem(conf);            int commitCount = taskOutput.size();    final Queue<SinglePendingCommit> commits = new ConcurrentLinkedQueue<>();    LOG.info("{}: uploading from staging directory to S3 {}", getRole(),        attemptPath);    LOG.info("{}: Saving pending data information to {}",        getRole(), commitsAttemptPath);    if (taskOutput.isEmpty()) {                  LOG.warn("{}: No files to commit", getRole());    } else {      boolean threw = true;            context.progress();      PendingSet pendingCommits = new PendingSet(commitCount);      pendingCommits.putExtraData(TASK_ATTEMPT_ID,          context.getTaskAttemptID().toString());      try {        Tasks.foreach(taskOutput)            .stopOnFailure()            .suppressExceptions(false)            .executeWith(buildSubmitter(context))            .run(stat -> {              Path path = stat.getPath();              File localFile = new File(path.toUri().getPath());              String relative = Paths.getRelativePath(attemptPath, path);              String partition = Paths.getPartition(relative);              String key = getFinalKey(relative, context);              Path destPath = getDestS3AFS().keyToQualifiedPath(key);              SinglePendingCommit commit = getCommitOperations()                  .uploadFileToPendingCommit(                      localFile,                      destPath,                      partition,                      uploadPartSize,                      context);              LOG.debug("{}: adding pending commit {}", getRole(), commit);              commits.add(commit);            });        for (SinglePendingCommit commit : commits) {          pendingCommits.add(commit);        }                                LOG.debug("Saving {} pending commit(s)) to file {}",            pendingCommits.size(),            commitsAttemptPath);        pendingCommits.save(commitsFS, commitsAttemptPath, false);        threw = false;      } finally {        if (threw) {          LOG.error(              "{}: Exception during commit process, aborting {} commit(s)",              getRole(), commits.size());          try(CommitOperations.CommitContext commitContext                  = initiateCommitOperation();              DurationInfo ignored = new DurationInfo(LOG,                  "Aborting %s uploads", commits.size())) {            Tasks.foreach(commits)                .suppressExceptions()                .run(commitContext::abortSingleCommit);          }          deleteTaskAttemptPathQuietly(context);        }      }            Paths.clearTempFolderInfo(context.getTaskAttemptID());    }    LOG.debug("Committing wrapped task");    wrappedCommitter.commitTask(context);    LOG.debug("Cleaning up attempt dir {}", attemptPath);    attemptFS.delete(attemptPath, true);    return commits.size();  }    @Override  public void abortTask(TaskAttemptContext context) throws IOException {            try (DurationInfo d = new DurationInfo(LOG,        "Abort task %s", context.getTaskAttemptID())) {      deleteTaskAttemptPathQuietly(context);      deleteTaskWorkingPathQuietly(context);      wrappedCommitter.abortTask(context);    } catch (IOException e) {      LOG.error("{}: exception when aborting task {}",          getRole(), context.getTaskAttemptID(), e);      throw e;    } finally {      destroyThreadPool();    }  }    private static Path taskAttemptWorkingPath(TaskAttemptContext context,      String uuid) throws IOException {    return getTaskAttemptPath(context,        Paths.getLocalTaskAttemptTempDir(            context.getConfiguration(),            uuid,            context.getTaskAttemptID()));  }    protected void deleteTaskWorkingPathQuietly(JobContext context) {    ignoreIOExceptions(LOG, "Delete working path", "",        () -> {          Path path = buildWorkPath(context, getUUID());          if (path != null) {            deleteQuietly(path.getFileSystem(getConf()), path, true);          }        });  }    private String getS3KeyPrefix(JobContext context) {    return s3KeyPrefix;  }    protected String getUUID() {    return uuid;  }    public final ConflictResolution getConflictResolutionMode(      JobContext context,      Configuration fsConf) {    if (conflictResolution == null) {      this.conflictResolution = ConflictResolution.valueOf(          getConfictModeOption(context, fsConf, DEFAULT_CONFLICT_MODE));    }    return conflictResolution;  }    protected PathExistsException failDestinationExists(final Path path,      final String description) {    LOG.error("{}: Failing commit by job {} to write"            + " to existing output path {}.",        description,        getJobContext().getJobID(), path);            try {      int limit = 10;      RemoteIterator<LocatedFileStatus> lf          = getDestFS().listFiles(path, true);      LOG.info("Partial Directory listing");      while (limit > 0 && lf.hasNext()) {        limit--;        LocatedFileStatus status = lf.next();        LOG.info("{}: {}",            status.getPath(),            status.isDirectory()                ? " dir"                : ("file size " + status.getLen() + " bytes"));      }    } catch (IOException e) {      LOG.info("Discarding exception raised when listing {}: " + e, path);      LOG.debug("stack trace ", e);    }    return new PathExistsException(path.toString(),        description + ": " + InternalCommitterConstants.E_DEST_EXISTS);  }    public static String getConfictModeOption(JobContext context,      Configuration fsConf, String defVal) {    return getConfigurationOption(context,        fsConf,        FS_S3A_COMMITTER_STAGING_CONFLICT_MODE,        defVal).toUpperCase(Locale.ENGLISH);  }    @Override  public void preCommitJob(      final JobContext context,      final ActiveCommit pending) throws IOException {        precommitCheckPendingFiles(context, pending);  }}