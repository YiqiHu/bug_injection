

package org.apache.hadoop.fs.azurebfs;

import org.junit.Test;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;



public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {
  public ITestAbfsStreamStatistics() throws Exception {
  }

  private static final Logger LOG =
      LoggerFactory.getLogger(ITestAbfsStreamStatistics.class);

  private static final int LARGE_NUMBER_OF_OPS = 999999;

  
  @Test
  public void testAbfsStreamOps() throws Exception {
    describe("Test to see correct population of read and write operations in "
        + "Abfs");

    final AzureBlobFileSystem fs = getFileSystem();
    Path smallOperationsFile = new Path("testOneReadWriteOps");
    Path largeOperationsFile = new Path("testLargeReadWriteOps");
    FileSystem.Statistics statistics = fs.getFsStatistics();
    String testReadWriteOps = "test this";
    statistics.reset();

    
    assertReadWriteOps("write", 0, statistics.getWriteOps());

    
    assertReadWriteOps("read", 0, statistics.getReadOps());

    FSDataOutputStream outForOneOperation = null;
    FSDataInputStream inForOneOperation = null;
    try {
      outForOneOperation = fs.create(smallOperationsFile);
      statistics.reset();
      outForOneOperation.write(testReadWriteOps.getBytes());

      
      assertReadWriteOps("write", 1, statistics.getWriteOps());

      
      outForOneOperation.hflush();
      inForOneOperation = fs.open(smallOperationsFile);
      statistics.reset();
      int result = inForOneOperation.read(testReadWriteOps.getBytes(), 0,
          testReadWriteOps.getBytes().length);

      LOG.info("Result of Read operation : {}", result);
      
      assertTrue(String.format("The actual value of %d was not equal to the "
              + "expected value of 2 or 3", statistics.getReadOps()),
          statistics.getReadOps() == 2 || statistics.getReadOps() == 3);

    } finally {
      IOUtils.cleanupWithLogger(LOG, inForOneOperation,
          outForOneOperation);
    }

    
    assertTrue("Mismatch in content validation",
        validateContent(fs, smallOperationsFile,
            testReadWriteOps.getBytes()));

    FSDataOutputStream outForLargeOperations = null;
    FSDataInputStream inForLargeOperations = null;
    StringBuilder largeOperationsValidationString = new StringBuilder();
    try {
      outForLargeOperations = fs.create(largeOperationsFile);
      statistics.reset();
      int largeValue = LARGE_NUMBER_OF_OPS;
      for (int i = 0; i < largeValue; i++) {
        outForLargeOperations.write(testReadWriteOps.getBytes());

        
        largeOperationsValidationString.append(testReadWriteOps);
      }
      LOG.info("Number of bytes of Large data written: {}",
          largeOperationsValidationString.toString().getBytes().length);

      
      assertReadWriteOps("write", largeValue, statistics.getWriteOps());

      inForLargeOperations = fs.open(largeOperationsFile);
      for (int i = 0; i < largeValue; i++) {
        inForLargeOperations
            .read(testReadWriteOps.getBytes(), 0,
                testReadWriteOps.getBytes().length);
      }

      
      assertReadWriteOps("read", largeValue, statistics.getReadOps());

    } finally {
      IOUtils.cleanupWithLogger(LOG, inForLargeOperations,
          outForLargeOperations);
    }
    
    assertTrue("Mismatch in content validation",
        validateContent(fs, largeOperationsFile,
            largeOperationsValidationString.toString().getBytes()));

  }

  

  private void assertReadWriteOps(String operation, long expectedValue,
      long actualValue) {
    assertEquals("Mismatch in " + operation + " operations", expectedValue,
        actualValue);
  }
}
