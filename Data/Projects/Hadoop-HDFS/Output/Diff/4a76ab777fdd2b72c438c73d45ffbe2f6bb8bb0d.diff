diff --git a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java
index b7c2b03e5def..57983802528b 100644
--- a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java
+++ b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/java/org/apache/hadoop/hdfs/server/federation/router/RouterClientProtocol.java
@@ -1921,6 +1921,8 @@ private HdfsFileStatus getMountPointStatus(
     FsPermission permission = FsPermission.getDirDefault();
     String owner = this.superUser;
     String group = this.superGroup;
+    EnumSet<HdfsFileStatus.Flags> flags =
+        EnumSet.noneOf(HdfsFileStatus.Flags.class);
     if (subclusterResolver instanceof MountTableResolver) {
       try {
         String mName = name.startsWith("/") ? name : "/" + name;
@@ -1940,6 +1942,9 @@ private HdfsFileStatus getMountPointStatus(
             owner = fInfo.getOwner();
             group = fInfo.getGroup();
             childrenNum = fInfo.getChildrenNum();
+            flags = DFSUtil
+                .getFlags(fInfo.isEncrypted(), fInfo.isErasureCoded(),
+                    fInfo.isSnapshotEnabled(), fInfo.hasAcl());
           }
         }
       } catch (IOException e) {
@@ -1971,6 +1976,7 @@ private HdfsFileStatus getMountPointStatus(
         .path(DFSUtil.string2Bytes(name))
         .fileId(inodeId)
         .children(childrenNum)
+        .flags(flags)
         .build();
   }
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java
index 572b33d47b91..77ec47a7a7f1 100644
--- a/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java
+++ b/hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterMountTable.java
@@ -37,6 +37,7 @@
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.hdfs.DistributedFileSystem;
 import org.apache.hadoop.hdfs.protocol.ClientProtocol;
 import org.apache.hadoop.hdfs.protocol.DirectoryListing;
 import org.apache.hadoop.hdfs.protocol.HdfsFileStatus;
@@ -663,4 +664,20 @@ public void testRenameMountPoint() throws Exception {
       nnFs0.delete(new Path("/testrename2"), true);
     }
   }
-}
\ No newline at end of file
+
+  @Test
+  public void testListStatusMountPoint() throws Exception {
+    try {
+      MountTable addEntry = MountTable.newInstance("/mount/testLsMountEntry",
+          Collections.singletonMap("ns0", "/testLsMountEntryDest"));
+      assertTrue(addMountTable(addEntry));
+      nnFs0.mkdirs(new Path("/testLsMountEntryDest"));
+      DistributedFileSystem routerDfs = (DistributedFileSystem) routerFs;
+      Path mountPath = new Path("/mount/testLsMountEntry");
+      routerDfs.setErasureCodingPolicy(mountPath, "RS-6-3-1024k");
+      assertTrue(routerDfs.listStatus(new Path("/mount"))[0].isErasureCoded());
+    } finally {
+      nnFs0.delete(new Path("/testLsMountEntryDest"), true);
+    }
+  }
+}
