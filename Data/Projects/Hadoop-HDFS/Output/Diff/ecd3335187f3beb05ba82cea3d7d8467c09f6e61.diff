diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java
index d45c0c30d490..8925f0075faf 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSDirSnapshotOp.java
@@ -36,6 +36,8 @@
 import org.apache.hadoop.hdfs.util.ReadOnlyList;
 import org.apache.hadoop.util.ChunkedArrayList;
 import org.apache.hadoop.util.Time;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -43,6 +45,9 @@
 import java.util.List;
 
 class FSDirSnapshotOp {
+  public static final Logger LOG =
+      LoggerFactory.getLogger(FSDirSnapshotOp.class);
+
   /** Verify if the snapshot name is legal. */
   static void verifySnapshotName(FSDirectory fsd, String snapshotName,
       String path)
@@ -118,7 +123,7 @@ static String createSnapshot(
     }
     fsd.getEditLog().logCreateSnapshot(snapshotRoot, snapshotName,
         logRetryCache, now);
-
+    LOG.info("Created Snapshot for SnapshotRoot {}", snapshotRoot);
     return snapshotPath;
   }
 
@@ -141,6 +146,8 @@ static void renameSnapshot(FSDirectory fsd, FSPermissionChecker pc,
     }
     fsd.getEditLog().logRenameSnapshot(path, snapshotOldName,
         snapshotNewName, logRetryCache, now);
+    LOG.info("Snapshot renamed from {} to {} for SnapshotRoot {}",
+        snapshotOldName, snapshotNewName, path);
   }
 
   static SnapshottableDirectoryStatus[] getSnapshottableDirListing(
@@ -271,6 +278,8 @@ static INode.BlocksMapUpdateInfo deleteSnapshot(
     final INode.BlocksMapUpdateInfo collectedBlocks = deleteSnapshot(
         fsd, snapshotManager, iip, snapshotName, now, snapshotRoot,
         logRetryCache);
+    LOG.info("Snapshot {} deleted for SnapshotRoot {}",
+        snapshotName, snapshotName);
     return collectedBlocks;
   }
 
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
index 70b12b3e198f..cfb0d444051f 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRpcServer.java
@@ -1899,6 +1899,8 @@ public DataEncryptionKey getDataEncryptionKey() throws IOException {
   public String createSnapshot(String snapshotRoot, String snapshotName)
       throws IOException {
     checkNNStartup();
+    LOG.debug("*DIR* NameNode.createSnapshot: Path {} and SnapshotName {}",
+        snapshotRoot, snapshotName);
     if (!checkPathLength(snapshotRoot)) {
       throw new IOException("createSnapshot: Pathname too long.  Limit "
           + MAX_PATH_LENGTH + " characters, " + MAX_PATH_DEPTH + " levels.");
@@ -1925,6 +1927,8 @@ public String createSnapshot(String snapshotRoot, String snapshotName)
   public void deleteSnapshot(String snapshotRoot, String snapshotName)
       throws IOException {
     checkNNStartup();
+    LOG.debug("*DIR* NameNode.deleteSnapshot: Path {} and SnapshotName {}",
+        snapshotRoot, snapshotName);
     if (snapshotName == null || snapshotName.isEmpty()) {
       throw new IOException("The snapshot name is null or empty.");
     }
@@ -1964,6 +1968,9 @@ public void disallowSnapshot(String snapshot) throws IOException {
   public void renameSnapshot(String snapshotRoot, String snapshotOldName,
       String snapshotNewName) throws IOException {
     checkNNStartup();
+    LOG.debug("*DIR* NameNode.renameSnapshot: Snapshot Path {}, " +
+        "snapshotOldName {}, snapshotNewName {}", snapshotRoot,
+        snapshotOldName, snapshotNewName);
     if (snapshotNewName == null || snapshotNewName.isEmpty()) {
       throw new IOException("The new snapshot name is null or empty.");
     }
diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java
index 16e654c04cdf..68bf998e0d8f 100644
--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java
+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.java
@@ -457,7 +457,8 @@ public String createSnapshot(final LeaseManager leaseManager,
       // requests.
       throw new SnapshotException(
           "Failed to create the snapshot. The FileSystem has run out of " +
-          "snapshot IDs and ID rollover is not supported.");
+          "snapshot IDs and ID rollover is not supported " +
+              "and the max snapshot limit is: " + maxSnapshotLimit);
     }
     int n = numSnapshots.get();
     checkFileSystemSnapshotLimit(n);
