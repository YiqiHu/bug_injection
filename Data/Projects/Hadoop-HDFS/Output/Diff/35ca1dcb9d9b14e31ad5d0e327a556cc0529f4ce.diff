diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
index a2273ef34fab..085b20442546 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
@@ -50,9 +50,9 @@
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
+import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
-import org.junit.Rule;
 import org.junit.Test;
 
 import static org.apache.hadoop.conf.StorageUnit.BYTES;
@@ -60,7 +60,6 @@
 import static org.apache.hadoop.conf.StorageUnit.KB;
 import static org.apache.hadoop.conf.StorageUnit.MB;
 import static org.apache.hadoop.conf.StorageUnit.TB;
-import static org.hamcrest.core.Is.is;
 import static org.junit.Assert.*;
 
 import org.apache.commons.lang3.StringUtils;
@@ -78,14 +77,10 @@
 import org.apache.log4j.AppenderSkeleton;
 import org.apache.log4j.Logger;
 import org.apache.log4j.spi.LoggingEvent;
-import org.hamcrest.CoreMatchers;
-import org.junit.rules.ExpectedException;
 import org.mockito.Mockito;
 
 public class TestConfiguration {
 
-  @Rule
-  public ExpectedException thrown= ExpectedException.none();
   private static final double DOUBLE_DELTA = 0.000000001f;
   private Configuration conf;
   final static String CONFIG = new File("./test-config-TestConfiguration.xml").getAbsolutePath();
@@ -1488,61 +1483,64 @@ public void testStorageUnit() {
 
     conf.setStorageSize(key, 10, MB);
     // This call returns the value specified in the Key as a double in MBs.
-    assertThat(conf.getStorageSize(key, "1GB", MB),
-        is(10.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1GB", MB))
+        .isEqualTo(10.0);
 
     // Since this key is missing, This call converts the default value of  1GB
     // to MBs are returns that value.
-    assertThat(conf.getStorageSize(nonKey, "1GB", MB),
-        is(1024.0));
+    Assertions.assertThat(conf.getStorageSize(nonKey, "1GB", MB))
+        .isEqualTo(1024.0);
 
 
     conf.setStorageSize(key, 1024, BYTES);
-    assertThat(conf.getStorageSize(key, 100, KB), is(1.0));
+    Assertions.assertThat(conf.getStorageSize(key, 100, KB)).isEqualTo(1.0);
 
-    assertThat(conf.getStorageSize(nonKey, 100.0, KB), is(100.0));
+    Assertions.assertThat(conf.getStorageSize(nonKey, 100.0, KB))
+        .isEqualTo(100.0);
 
     // We try out different kind of String formats to see if they work and
     // during read, we also try to read using a different Storage Units.
     conf.setStrings(key, "1TB");
-    assertThat(conf.getStorageSize(key, "1PB", GB), is(1024.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1PB", GB))
+        .isEqualTo(1024.0);
 
     conf.setStrings(key, "1bytes");
-    assertThat(conf.getStorageSize(key, "1PB", KB), is(0.001));
+    Assertions.assertThat(conf.getStorageSize(key, "1PB", KB))
+        .isEqualTo(0.001);
 
     conf.setStrings(key, "2048b");
-    assertThat(conf.getStorageSize(key, "1PB", KB), is(2.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1PB", KB)).isEqualTo(2.0);
 
     conf.setStrings(key, "64 GB");
-    assertThat(conf.getStorageSize(key, "1PB", GB), is(64.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1PB", GB)).isEqualTo(64.0);
 
     // Match the parsing patterns of getLongBytes, which takes single char
     // suffix.
     conf.setStrings(key, "1T");
-    assertThat(conf.getStorageSize(key, "1GB", TB), is(1.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1GB", TB)).isEqualTo(1.0);
 
     conf.setStrings(key, "1k");
-    assertThat(conf.getStorageSize(key, "1GB", KB), is(1.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1GB", KB)).isEqualTo(1.0);
 
     conf.setStrings(key, "10m");
-    assertThat(conf.getStorageSize(key, "1GB", MB), is(10.0));
+    Assertions.assertThat(conf.getStorageSize(key, "1GB", MB)).isEqualTo(10.0);
 
 
 
     // Missing format specification, this should throw.
     conf.setStrings(key, "100");
-    thrown.expect(IllegalArgumentException.class);
-    conf.getStorageSize(key, "1PB", GB);
+    assertThrows(IllegalArgumentException.class,
+        () -> conf.getStorageSize(key, "1PB", GB));
 
     // illegal format specification, this should throw.
     conf.setStrings(key, "1HB");
-    thrown.expect(IllegalArgumentException.class);
-    conf.getStorageSize(key, "1PB", GB);
+    assertThrows(IllegalArgumentException.class,
+        () -> conf.getStorageSize(key, "1PB", GB));
 
     // Illegal number  specification, this should throw.
     conf.setStrings(key, "HadoopGB");
-    thrown.expect(IllegalArgumentException.class);
-    conf.getStorageSize(key, "1PB", GB);
+    assertThrows(IllegalArgumentException.class,
+        () -> conf.getStorageSize(key, "1PB", GB));
   }
 
   @Test
@@ -2424,10 +2422,10 @@ public void testGetPasswordDeprecatedKeyStored() throws Exception {
 
     Configuration.addDeprecation(oldKey, newKey);
 
-    assertThat(conf.getPassword(newKey),
-        CoreMatchers.is(password.toCharArray()));
-    assertThat(conf.getPassword(oldKey),
-        CoreMatchers.is(password.toCharArray()));
+    Assertions.assertThat(conf.getPassword(newKey))
+        .isEqualTo(password.toCharArray());
+    Assertions.assertThat(conf.getPassword(oldKey))
+        .isEqualTo(password.toCharArray());
 
     FileUtil.fullyDelete(tmpDir);
   }
@@ -2453,10 +2451,10 @@ public void testGetPasswordByDeprecatedKey() throws Exception {
 
     Configuration.addDeprecation(oldKey, newKey);
 
-    assertThat(conf.getPassword(newKey),
-        CoreMatchers.is(password.toCharArray()));
-    assertThat(conf.getPassword(oldKey),
-        CoreMatchers.is(password.toCharArray()));
+    Assertions.assertThat(conf.getPassword(newKey))
+        .isEqualTo(password.toCharArray());
+    Assertions.assertThat(conf.getPassword(oldKey))
+        .isEqualTo(password.toCharArray());
 
     FileUtil.fullyDelete(tmpDir);
   }
@@ -2469,7 +2467,7 @@ public void testGettingPropertiesWithPrefix() throws Exception {
     }
     conf.set("different.prefix" + ".name", "value");
     Map<String, String> prefixedProps = conf.getPropsWithPrefix("prefix.");
-    assertThat(prefixedProps.size(), is(10));
+    Assertions.assertThat(prefixedProps).hasSize(10);
     for (int i = 0; i < 10; i++) {
       assertEquals("value" + i, prefixedProps.get("name" + i));
     }
@@ -2480,7 +2478,7 @@ public void testGettingPropertiesWithPrefix() throws Exception {
       conf.set("subprefix." + "subname" + i, "value_${foo}" + i);
     }
     prefixedProps = conf.getPropsWithPrefix("subprefix.");
-    assertThat(prefixedProps.size(), is(10));
+    Assertions.assertThat(prefixedProps).hasSize(10);
     for (int i = 0; i < 10; i++) {
       assertEquals("value_bar" + i, prefixedProps.get("subname" + i));
     }
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyProviderCryptoExtension.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyProviderCryptoExtension.java
index e897423b3954..0f9d6dc95f42 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyProviderCryptoExtension.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyProviderCryptoExtension.java
@@ -25,6 +25,7 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import javax.crypto.Cipher;
 import javax.crypto.spec.IvParameterSpec;
@@ -58,7 +59,7 @@ public class TestKeyProviderCryptoExtension {
   private static KeyVersion encryptionKey;
 
   @Rule
-  public Timeout testTimeout = new Timeout(180000);
+  public Timeout testTimeout = new Timeout(180000, TimeUnit.MILLISECONDS);
 
   @BeforeClass
   public static void setup() throws Exception {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestKMSClientProvider.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestKMSClientProvider.java
index b87f45ac97a3..e437acc3e058 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestKMSClientProvider.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestKMSClientProvider.java
@@ -36,6 +36,7 @@
 import java.net.URI;
 import java.net.URISyntaxException;
 import java.net.URL;
+import java.util.concurrent.TimeUnit;
 
 import static org.apache.hadoop.crypto.key.kms.KMSDelegationToken.TOKEN_KIND;
 
@@ -57,7 +58,7 @@ public class TestKMSClientProvider {
   private final String oldTokenService = "host:16000";
 
   @Rule
-  public Timeout globalTimeout = new Timeout(60000);
+  public Timeout globalTimeout = new Timeout(60000, TimeUnit.MILLISECONDS);
 
   {
     GenericTestUtils.setLogLevel(KMSClientProvider.LOG, Level.TRACE);
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestLoadBalancingKMSClientProvider.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestLoadBalancingKMSClientProvider.java
index 616c66b0748d..3684a1d0db68 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestLoadBalancingKMSClientProvider.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/kms/TestLoadBalancingKMSClientProvider.java
@@ -39,6 +39,7 @@
 import java.security.PrivilegedExceptionAction;
 import java.util.Arrays;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import javax.net.ssl.SSLHandshakeException;
 
@@ -67,7 +68,7 @@
 public class TestLoadBalancingKMSClientProvider {
 
   @Rule
-  public Timeout testTimeout = new Timeout(30 * 1000);
+  public Timeout testTimeout = new Timeout(30, TimeUnit.SECONDS);
 
   @BeforeClass
   public static void setup() throws IOException {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
index 8065b3f61f52..3a8b1e6ed085 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
@@ -21,6 +21,7 @@
 import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.concurrent.TimeUnit;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -36,7 +37,6 @@
 import org.junit.After;
 import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 import org.junit.rules.Timeout;
 
 /**
@@ -61,7 +61,8 @@ public abstract class FileSystemContractBaseTest {
   protected byte[] data = dataset(getBlockSize() * 2, 0, 255);
 
   @Rule
-  public Timeout globalTimeout = new Timeout(getGlobalTimeout());
+  public Timeout globalTimeout =
+      new Timeout(getGlobalTimeout(), TimeUnit.MILLISECONDS);
 
   /**
    * Get the timeout in milliseconds for each test case.
@@ -71,9 +72,6 @@ protected int getGlobalTimeout() {
     return 30 * 1000;
   }
 
-  @Rule
-  public ExpectedException thrown = ExpectedException.none();
-
   @After
   public void tearDown() throws Exception {
     if (fs != null) {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDefaultUri.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDefaultUri.java
index b84d66aa4ce2..9572bed4098f 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDefaultUri.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDefaultUri.java
@@ -18,9 +18,7 @@
 package org.apache.hadoop.fs;
 
 import static org.apache.hadoop.fs.FileSystem.FS_DEFAULT_NAME_KEY;
-import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.CoreMatchers.is;
-import static org.junit.Assert.assertThat;
+import static org.assertj.core.api.Assertions.assertThat;
 
 import java.io.IOException;
 import java.net.URI;
@@ -40,32 +38,32 @@ public class TestDefaultUri {
   public void tetGetDefaultUri() {
     conf.set(FS_DEFAULT_NAME_KEY, "hdfs://nn_host");
     URI uri = FileSystem.getDefaultUri(conf);
-    assertThat(uri.getScheme(), is("hdfs"));
-    assertThat(uri.getAuthority(), is("nn_host"));
+    assertThat(uri.getScheme()).isEqualTo("hdfs");
+    assertThat(uri.getAuthority()).isEqualTo("nn_host");
   }
 
   @Test
   public void tetGetDefaultUriWithPort() {
     conf.set(FS_DEFAULT_NAME_KEY, "hdfs://nn_host:5432");
     URI uri = FileSystem.getDefaultUri(conf);
-    assertThat(uri.getScheme(), is("hdfs"));
-    assertThat(uri.getAuthority(), is("nn_host:5432"));
+    assertThat(uri.getScheme()).isEqualTo("hdfs");
+    assertThat(uri.getAuthority()).isEqualTo("nn_host:5432");
   }
 
   @Test
   public void tetGetDefaultUriTrailingSlash() {
     conf.set(FS_DEFAULT_NAME_KEY, "hdfs://nn_host/");
     URI uri = FileSystem.getDefaultUri(conf);
-    assertThat(uri.getScheme(), is("hdfs"));
-    assertThat(uri.getAuthority(), is("nn_host"));
+    assertThat(uri.getScheme()).isEqualTo("hdfs");
+    assertThat(uri.getAuthority()).isEqualTo("nn_host");
   }
 
   @Test
   public void tetGetDefaultUriNoScheme() {
     conf.set(FS_DEFAULT_NAME_KEY, "nn_host");
     URI uri = FileSystem.getDefaultUri(conf);
-    assertThat(uri.getScheme(), is("hdfs"));
-    assertThat(uri.getAuthority(), is("nn_host"));
+    assertThat(uri.getScheme()).isEqualTo("hdfs");
+    assertThat(uri.getAuthority()).isEqualTo("nn_host");
   }
 
   @Test
@@ -81,7 +79,7 @@ public void tetGetDefaultUriNoSchemeTrailingSlash() throws Exception {
   public void tetFsGet() throws IOException {
     conf.set(FS_DEFAULT_NAME_KEY, "file:///");
     FileSystem fs = FileSystem.get(conf);
-    assertThat(fs, instanceOf(LocalFileSystem.class));
+    assertThat(fs).isInstanceOf(LocalFileSystem.class);
   }
 
   @Test
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemStorageStatistics.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemStorageStatistics.java
index fa682649a021..2b4e686e5929 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemStorageStatistics.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileSystemStorageStatistics.java
@@ -25,12 +25,12 @@
 import org.junit.Rule;
 import org.junit.Test;
 
-import org.junit.rules.ExpectedException;
 import org.junit.rules.Timeout;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.util.Iterator;
+import java.util.concurrent.TimeUnit;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
@@ -61,9 +61,7 @@ public class TestFileSystemStorageStatistics {
       new FileSystemStorageStatistics(FS_STORAGE_STATISTICS_NAME, statistics);
 
   @Rule
-  public final Timeout globalTimeout = new Timeout(10 * 1000);
-  @Rule
-  public final ExpectedException exception = ExpectedException.none();
+  public final Timeout globalTimeout = new Timeout(10, TimeUnit.SECONDS);
 
   @Before
   public void setup() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShell.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShell.java
index 1c9781881b4b..67906d526bc8 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShell.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShell.java
@@ -22,8 +22,7 @@
 import org.apache.hadoop.fs.shell.CommandFactory;
 import org.apache.hadoop.test.GenericTestUtils;
 import org.apache.hadoop.util.ToolRunner;
-import org.hamcrest.core.StringContains;
-import org.junit.Assert;
+import org.assertj.core.api.Assertions;
 import org.junit.Test;
 import org.mockito.Mockito;
 
@@ -66,14 +65,14 @@ public void testDFSWithInvalidCommmand() throws Throwable {
     try (GenericTestUtils.SystemErrCapturer capture =
              new GenericTestUtils.SystemErrCapturer()) {
       ToolRunner.run(shell, new String[]{"dfs -mkdirs"});
-      Assert.assertThat("FSShell dfs command did not print the error " +
-              "message when invalid command is passed",
-          capture.getOutput(), StringContains.containsString(
-              "-mkdirs: Unknown command"));
-      Assert.assertThat("FSShell dfs command did not print help " +
-              "message when invalid command is passed",
-          capture.getOutput(), StringContains.containsString(
-              "Usage: hadoop fs [generic options]"));
+      Assertions.assertThat(capture.getOutput())
+          .as("FSShell dfs command did not print the error " +
+              "message when invalid command is passed")
+          .contains("-mkdirs: Unknown command");
+      Assertions.assertThat(capture.getOutput())
+          .as("FSShell dfs command did not print help " +
+              "message when invalid command is passed")
+          .contains("Usage: hadoop fs [generic options]");
     }
   }
 
@@ -95,9 +94,8 @@ public void testExceptionNullMessage() throws Exception {
     try (GenericTestUtils.SystemErrCapturer capture =
              new GenericTestUtils.SystemErrCapturer()) {
       ToolRunner.run(shell, new String[]{cmdName});
-      Assert.assertThat(capture.getOutput(),
-          StringContains.containsString(cmdName
-              + ": Null exception message"));
+      Assertions.assertThat(capture.getOutput())
+          .contains(cmdName + ": Null exception message");
     }
   }
 }
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java
index e3c4ee05c8c8..62c1b73227a2 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellCopy.java
@@ -19,12 +19,10 @@
 package org.apache.hadoop.fs;
 
 import static org.apache.hadoop.test.PlatformAssumptions.assumeWindows;
-import static org.hamcrest.CoreMatchers.is;
-import static org.hamcrest.CoreMatchers.not;
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotEquals;
-import static org.junit.Assert.assertThat;
 import static org.junit.Assert.assertTrue;
 
 import java.io.ByteArrayOutputStream;
@@ -640,15 +638,16 @@ public void testCopyNoParent() throws Exception {
     final String noDirName = "noDir";
     final Path noDir = new Path(noDirName);
     lfs.delete(noDir, true);
-    assertThat(lfs.exists(noDir), is(false));
+    assertThat(lfs.exists(noDir)).isFalse();
 
-    assertThat("Expected failed put to a path without parent directory",
-        shellRun("-put", srcPath.toString(), noDirName + "/foo"), is(not(0)));
+    assertThat(shellRun("-put", srcPath.toString(), noDirName + "/foo"))
+        .as("Expected failed put to a path without parent directory")
+        .isNotEqualTo(0);
 
     // Note the trailing '/' in the target path.
-    assertThat("Expected failed copyFromLocal to a non-existent directory",
-        shellRun("-copyFromLocal", srcPath.toString(), noDirName + "/"),
-        is(not(0)));
+    assertThat(shellRun("-copyFromLocal", srcPath.toString(), noDirName + "/"))
+        .as("Expected failed copyFromLocal to a non-existent directory")
+        .isNotEqualTo(0);
   }
 
   @Test
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellList.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellList.java
index c780f4105358..05ad5c23e654 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellList.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellList.java
@@ -18,14 +18,13 @@
 
 package org.apache.hadoop.fs;
 
-import static org.hamcrest.core.Is.is;
-import static org.junit.Assert.assertThat;
-
 import org.apache.hadoop.conf.Configuration;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
+import static org.assertj.core.api.Assertions.assertThat;
+
 /**
  * Test FsShell -ls command.
  */
@@ -45,7 +44,7 @@ public static void setup() throws Exception {
 
     String root = System.getProperty("test.build.data", "test/build/data");
     testRootDir = lfs.makeQualified(new Path(root, "testFsShellList"));
-    assertThat(lfs.mkdirs(testRootDir), is(true));
+    assertThat(lfs.mkdirs(testRootDir)).isTrue();
   }
 
   @AfterClass
@@ -57,23 +56,23 @@ private void createFile(Path filePath) throws Exception {
     FSDataOutputStream out = lfs.create(filePath);
     out.writeChars("I am " + filePath);
     out.close();
-    assertThat(lfs.exists(lfs.getChecksumFile(filePath)), is(true));
+    assertThat(lfs.exists(lfs.getChecksumFile(filePath))).isTrue();
   }
 
   @Test
   public void testList() throws Exception {
     createFile(new Path(testRootDir, "abc"));
     String[] lsArgv = new String[]{"-ls", testRootDir.toString()};
-    assertThat(shell.run(lsArgv), is(0));
+    assertThat(shell.run(lsArgv)).isEqualTo(0);
 
     createFile(new Path(testRootDir, "abc\bd\tef"));
     createFile(new Path(testRootDir, "ghi"));
     createFile(new Path(testRootDir, "qq\r123"));
     lsArgv = new String[]{"-ls", testRootDir.toString()};
-    assertThat(shell.run(lsArgv), is(0));
+    assertThat(shell.run(lsArgv)).isEqualTo(0);
 
     lsArgv = new String[]{"-ls", "-q", testRootDir.toString()};
-    assertThat(shell.run(lsArgv), is(0));
+    assertThat(shell.run(lsArgv)).isEqualTo(0);
   }
 
   /*
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellTouch.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellTouch.java
index 62e7990674d3..49bbd5af04f2 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellTouch.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFsShellTouch.java
@@ -17,10 +17,6 @@
  */
 package org.apache.hadoop.fs;
 
-import static org.hamcrest.CoreMatchers.is;
-import static org.hamcrest.CoreMatchers.not;
-import static org.junit.Assert.assertThat;
-
 import java.text.ParseException;
 import java.util.Date;
 
@@ -34,6 +30,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import static org.assertj.core.api.Assertions.assertThat;
+
 public class TestFsShellTouch {
   static final Logger LOG = LoggerFactory.getLogger(TestFsShellTouch.class);
 
@@ -71,23 +69,25 @@ public void testTouchz() throws Exception {
     final String newFileName = "newFile";
     final Path newFile = new Path(newFileName);
     lfs.delete(newFile, true);
-    assertThat(lfs.exists(newFile), is(false));
+    assertThat(lfs.exists(newFile)).isFalse();
 
-    assertThat("Expected successful touchz on a new file",
-        shellRun("-touchz", newFileName), is(0));
+    assertThat(shellRun("-touchz", newFileName))
+        .as("Expected successful touchz on a new file").isEqualTo(0);
     shellRun("-ls", newFileName);
 
-    assertThat("Expected successful touchz on an existing zero-length file",
-        shellRun("-touchz", newFileName), is(0));
+    assertThat(shellRun("-touchz", newFileName))
+        .as("Expected successful touchz on an existing zero-length file")
+        .isEqualTo(0);
 
     // Ensure noDir does not exist
     final String noDirName = "noDir";
     final Path noDir = new Path(noDirName);
     lfs.delete(noDir, true);
-    assertThat(lfs.exists(noDir), is(false));
+    assertThat(lfs.exists(noDir)).isFalse();
 
-    assertThat("Expected failed touchz in a non-existent directory",
-        shellRun("-touchz", noDirName + "/foo"), is(not(0)));
+    assertThat(shellRun("-touchz", noDirName + "/foo"))
+        .as("Expected failed touchz in a non-existent directory")
+        .isNotEqualTo(0);
   }
 
   @Test
@@ -96,25 +96,28 @@ public void testTouch() throws Exception {
     final String newFileName = "newFile2";
     final Path newFile = new Path(newFileName);
     lfs.delete(newFile, true);
-    assertThat(lfs.exists(newFile), is(false));
+    assertThat(lfs.exists(newFile)).isFalse();
 
     {
-      assertThat(
-          "Expected successful touch on a non-existent file with -c option",
-          shellRun("-touch", "-c", newFileName), is(0));
-      assertThat(lfs.exists(newFile), is(false));
+      assertThat(shellRun("-touch", "-c", newFileName))
+          .as("Expected successful touch on a non-existent file" +
+              " with -c option")
+          .isEqualTo(0);
+      assertThat(lfs.exists(newFile)).isFalse();
     }
 
     {
       String strTime = formatTimestamp(System.currentTimeMillis());
       Date dateObj = parseTimestamp(strTime);
 
-      assertThat(
-          "Expected successful touch on a new file with a specified timestamp",
-          shellRun("-touch", "-t", strTime, newFileName), is(0));
+      assertThat(shellRun("-touch", "-t", strTime, newFileName))
+          .as("Expected successful touch on a new file" +
+              " with a specified timestamp")
+          .isEqualTo(0);
       FileStatus new_status = lfs.getFileStatus(newFile);
-      assertThat(new_status.getAccessTime(), is(dateObj.getTime()));
-      assertThat(new_status.getModificationTime(), is(dateObj.getTime()));
+      assertThat(new_status.getAccessTime()).isEqualTo(dateObj.getTime());
+      assertThat(new_status.getModificationTime())
+          .isEqualTo(dateObj.getTime());
     }
 
     FileStatus fstatus = lfs.getFileStatus(newFile);
@@ -123,14 +126,15 @@ public void testTouch() throws Exception {
       String strTime = formatTimestamp(System.currentTimeMillis());
       Date dateObj = parseTimestamp(strTime);
 
-      assertThat("Expected successful touch with a specified access time",
-          shellRun("-touch", "-a", "-t", strTime, newFileName), is(0));
+      assertThat(shellRun("-touch", "-a", "-t", strTime, newFileName))
+          .as("Expected successful touch with a specified access time")
+          .isEqualTo(0);
       FileStatus new_status = lfs.getFileStatus(newFile);
       // Verify if access time is recorded correctly (and modification time
       // remains unchanged).
-      assertThat(new_status.getAccessTime(), is(dateObj.getTime()));
-      assertThat(new_status.getModificationTime(),
-          is(fstatus.getModificationTime()));
+      assertThat(new_status.getAccessTime()).isEqualTo(dateObj.getTime());
+      assertThat(new_status.getModificationTime())
+          .isEqualTo(fstatus.getModificationTime());
     }
 
     fstatus = lfs.getFileStatus(newFile);
@@ -139,56 +143,63 @@ public void testTouch() throws Exception {
       String strTime = formatTimestamp(System.currentTimeMillis());
       Date dateObj = parseTimestamp(strTime);
 
-      assertThat(
-          "Expected successful touch with a specified modification time",
-          shellRun("-touch", "-m", "-t", strTime, newFileName), is(0));
+      assertThat(shellRun("-touch", "-m", "-t", strTime, newFileName))
+          .as("Expected successful touch with a specified modification time")
+          .isEqualTo(0);
       // Verify if modification time is recorded correctly (and access time
       // remains unchanged).
       FileStatus new_status = lfs.getFileStatus(newFile);
-      assertThat(new_status.getAccessTime(), is(fstatus.getAccessTime()));
-      assertThat(new_status.getModificationTime(), is(dateObj.getTime()));
+      assertThat(new_status.getAccessTime())
+          .isEqualTo(fstatus.getAccessTime());
+      assertThat(new_status.getModificationTime())
+          .isEqualTo(dateObj.getTime());
     }
 
     {
       String strTime = formatTimestamp(System.currentTimeMillis());
       Date dateObj = parseTimestamp(strTime);
 
-      assertThat("Expected successful touch with a specified timestamp",
-          shellRun("-touch", "-t", strTime, newFileName), is(0));
+      assertThat(shellRun("-touch", "-t", strTime, newFileName))
+          .as("Expected successful touch with a specified timestamp")
+          .isEqualTo(0);
 
       // Verify if both modification and access times are recorded correctly
       FileStatus new_status = lfs.getFileStatus(newFile);
-      assertThat(new_status.getAccessTime(), is(dateObj.getTime()));
-      assertThat(new_status.getModificationTime(), is(dateObj.getTime()));
+      assertThat(new_status.getAccessTime()).isEqualTo(dateObj.getTime());
+      assertThat(new_status.getModificationTime())
+          .isEqualTo(dateObj.getTime());
     }
 
     {
       String strTime = formatTimestamp(System.currentTimeMillis());
       Date dateObj = parseTimestamp(strTime);
 
-      assertThat("Expected successful touch with a specified timestamp",
-          shellRun("-touch", "-a", "-m", "-t", strTime, newFileName), is(0));
+      assertThat(shellRun("-touch", "-a", "-m", "-t", strTime, newFileName))
+          .as("Expected successful touch with a specified timestamp")
+          .isEqualTo(0);
 
       // Verify if both modification and access times are recorded correctly
       FileStatus new_status = lfs.getFileStatus(newFile);
-      assertThat(new_status.getAccessTime(), is(dateObj.getTime()));
-      assertThat(new_status.getModificationTime(), is(dateObj.getTime()));
+      assertThat(new_status.getAccessTime()).isEqualTo(dateObj.getTime());
+      assertThat(new_status.getModificationTime())
+          .isEqualTo(dateObj.getTime());
     }
 
     {
-      assertThat("Expected failed touch with a missing timestamp",
-          shellRun("-touch", "-t", newFileName), is(not(0)));
+      assertThat(shellRun("-touch", "-t", newFileName))
+          .as("Expected failed touch with a missing timestamp")
+          .isNotEqualTo(0);
     }
 
     // Verify -c option when file exists.
     String strTime = formatTimestamp(System.currentTimeMillis());
     Date dateObj = parseTimestamp(strTime);
-    assertThat(
-        "Expected successful touch on a non-existent file with -c option",
-        shellRun("-touch", "-c", "-t", strTime, newFileName), is(0));
+    assertThat(shellRun("-touch", "-c", "-t", strTime, newFileName))
+        .as("Expected successful touch on a non-existent file with -c option")
+        .isEqualTo(0);
     FileStatus fileStatus = lfs.getFileStatus(newFile);
-    assertThat(fileStatus.getAccessTime(), is(dateObj.getTime()));
-    assertThat(fileStatus.getModificationTime(), is(dateObj.getTime()));
+    assertThat(fileStatus.getAccessTime()).isEqualTo(dateObj.getTime());
+    assertThat(fileStatus.getModificationTime()).isEqualTo(dateObj.getTime());
   }
 
   private String formatTimestamp(long timeInMillis) {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
index e7b72a93f337..c35a37d48d56 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
@@ -40,6 +40,7 @@
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
+import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
 import static org.apache.hadoop.test.PlatformAssumptions.assumeNotWindows;
@@ -74,16 +75,11 @@ public class TestLocalFileSystem {
   private Configuration conf;
   private LocalFileSystem fileSys;
 
-  /**
-   * standard test timeout: {@value}.
-   */
-  public static final int DEFAULT_TEST_TIMEOUT = 60 * 1000;
-
   /**
    * Set the timeout for every test.
    */
   @Rule
-  public Timeout testTimeout = new Timeout(DEFAULT_TEST_TIMEOUT);
+  public Timeout testTimeout = new Timeout(60, TimeUnit.SECONDS);
 
   private void cleanupFile(FileSystem fs, Path name) throws IOException {
     assertTrue(fs.exists(name));
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystemPermission.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystemPermission.java
index 81756f9305f2..8e48035d7bd8 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystemPermission.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystemPermission.java
@@ -21,6 +21,7 @@
 import org.apache.hadoop.fs.permission.FsPermission;
 import org.apache.hadoop.test.GenericTestUtils;
 import org.apache.hadoop.util.Shell;
+import org.assertj.core.api.Assertions;
 import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -32,8 +33,6 @@
 import java.util.StringTokenizer;
 
 import static org.apache.hadoop.test.PlatformAssumptions.assumeNotWindows;
-import static org.hamcrest.CoreMatchers.is;
-import static org.hamcrest.CoreMatchers.not;
 import static org.junit.Assert.*;
 
 /**
@@ -245,9 +244,9 @@ public void testSetUmaskInRealTime() throws Exception {
       assertTrue(localfs.mkdirs(dir2));
       FsPermission finalPermission = localfs.getFileStatus(dir2)
           .getPermission();
-      assertThat("With umask 062 permission should not be 755 since the " +
-          "default permission is 777", new FsPermission("755"),
-          is(not(finalPermission)));
+      Assertions.assertThat(new FsPermission("755")).as(
+          "With umask 062 permission should not be 755 since the " +
+          "default permission is 777").isNotEqualTo(finalPermission);
       assertEquals(
           "With umask 062 we expect 715 since the default permission is 777",
           new FsPermission("715"), finalPermission);
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractFSContractTestBase.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractFSContractTestBase.java
index ac9de6d7bfe8..7b32f28507cb 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractFSContractTestBase.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractFSContractTestBase.java
@@ -27,7 +27,7 @@
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Rule;
-import org.junit.internal.AssumptionViolatedException;
+import org.junit.AssumptionViolatedException;
 import org.junit.rules.TestName;
 import org.junit.rules.Timeout;
 import org.slf4j.Logger;
@@ -35,6 +35,7 @@
 
 import java.io.IOException;
 import java.net.URI;
+import java.util.concurrent.TimeUnit;
 
 import static org.apache.hadoop.fs.contract.ContractTestUtils.cleanup;
 import static org.apache.hadoop.fs.contract.ContractTestUtils.skip;
@@ -164,7 +165,8 @@ protected Configuration createConfiguration() {
    * Set the timeout for every test.
    */
   @Rule
-  public Timeout testTimeout = new Timeout(getTestTimeoutMillis());
+  public Timeout testTimeout =
+      new Timeout(getTestTimeoutMillis(), TimeUnit.MILLISECONDS);
 
   /**
    * Option for tests to override the default timeout value.
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java
index 8155d8e2b2ba..48cdfdd32ecf 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/ftp/TestFTPFileSystem.java
@@ -22,6 +22,7 @@
 import java.nio.charset.StandardCharsets;
 import java.nio.file.Files;
 import java.util.Comparator;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;
 import org.apache.commons.net.ftp.FTP;
@@ -57,7 +58,7 @@ public class TestFTPFileSystem {
   private FtpTestServer server;
   private java.nio.file.Path testDir;
   @Rule
-  public Timeout testTimeout = new Timeout(180000);
+  public Timeout testTimeout = new Timeout(180000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setUp() throws Exception {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/sftp/TestSFTPFileSystem.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/sftp/TestSFTPFileSystem.java
index 58452f86f599..e8ba5f211eb8 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/sftp/TestSFTPFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/sftp/TestSFTPFileSystem.java
@@ -44,14 +44,15 @@
 import org.apache.sshd.server.keyprovider.SimpleGeneratorHostKeyProvider;
 import org.apache.sshd.server.session.ServerSession;
 import org.apache.sshd.server.subsystem.sftp.SftpSubsystemFactory;
-import static org.hamcrest.core.Is.is;
+
 import org.junit.After;
 import org.junit.AfterClass;
+
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertThat;
 import static org.junit.Assert.assertTrue;
 import org.junit.Before;
 import org.junit.BeforeClass;
@@ -193,8 +194,9 @@ public void testCreateFile() throws Exception {
     assertTrue(localFs.exists(file));
     assertTrue(sftpFs.delete(file, false));
     assertFalse(localFs.exists(file));
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -210,8 +212,9 @@ public void testFileExists() throws Exception {
     assertTrue(sftpFs.delete(file, false));
     assertFalse(sftpFs.exists(file));
     assertFalse(localFs.exists(file));
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -235,8 +238,9 @@ public void testReadFile() throws Exception {
       }
     }
     assertTrue(sftpFs.delete(file, false));
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -258,8 +262,9 @@ public void testStatFile() throws Exception {
     assertEquals(data.length, sstat.getLen());
     assertEquals(lstat.getLen(), sstat.getLen());
     assertTrue(sftpFs.delete(file, false));
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -271,8 +276,9 @@ public void testStatFile() throws Exception {
   public void testDeleteNonEmptyDir() throws Exception {
     Path file = touch(localFs, name.getMethodName().toLowerCase());
     sftpFs.delete(localDir, false);
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -284,8 +290,9 @@ public void testDeleteNonEmptyDir() throws Exception {
   public void testDeleteNonExistFile() throws Exception {
     Path file = new Path(localDir, name.getMethodName().toLowerCase());
     assertFalse(sftpFs.delete(file, false));
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -308,8 +315,9 @@ public void testRenameFile() throws Exception {
     assertFalse(localFs.exists(file1));
 
     assertTrue(sftpFs.delete(file2, false));
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   /**
@@ -347,8 +355,9 @@ public void testGetAccessTime() throws IOException {
     accessTime1 = (accessTime1 / 1000) * 1000;
     long accessTime2 = sftpFs.getFileStatus(file).getAccessTime();
     assertEquals(accessTime1, accessTime2);
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   @Test
@@ -360,8 +369,9 @@ public void testGetModifyTime() throws IOException {
     modifyTime1 = (modifyTime1 / 1000) * 1000;
     long modifyTime2 = sftpFs.getFileStatus(file).getModificationTime();
     assertEquals(modifyTime1, modifyTime2);
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   @Test
@@ -371,17 +381,18 @@ public void testMkDirs() throws IOException {
     sftpFs.mkdirs(path);
     assertTrue(localFs.exists(path));
     assertTrue(localFs.getFileStatus(path).isDirectory());
-    assertThat(((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount(),
-        is(1));
+    assertThat(
+        ((SFTPFileSystem) sftpFs).getConnectionPool().getLiveConnCount())
+        .isEqualTo(1);
   }
 
   @Test
   public void testCloseFileSystemClosesConnectionPool() throws Exception {
     SFTPFileSystem fs = (SFTPFileSystem) sftpFs;
     fs.getHomeDirectory();
-    assertThat(fs.getConnectionPool().getLiveConnCount(), is(1));
+    assertThat(fs.getConnectionPool().getLiveConnCount()).isEqualTo(1);
     fs.close();
-    assertThat(fs.getConnectionPool().getLiveConnCount(), is(0));
+    assertThat(fs.getConnectionPool().getLiveConnCount()).isEqualTo(0);
     ///making sure that re-entrant close calls are safe
     fs.close();
   }
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestPrintableString.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestPrintableString.java
index 91bfdd6d3948..bb325b4832c1 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestPrintableString.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestPrintableString.java
@@ -18,18 +18,18 @@
 
 package org.apache.hadoop.fs.shell;
 
-import static org.hamcrest.CoreMatchers.is;
-import static org.junit.Assert.assertThat;
-
 import org.junit.Test;
 
+import static org.assertj.core.api.Assertions.assertThat;
+
 /**
  * Test {@code PrintableString} class.
  */
 public class TestPrintableString {
 
   private void expect(String reason, String raw, String expected) {
-    assertThat(reason, new PrintableString(raw).toString(), is(expected));
+    assertThat(new PrintableString(raw).toString()).as(reason)
+        .isEqualTo(expected);
   }
 
   /**
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestAnd.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestAnd.java
index bb5ca4ca1c59..9111062ef00a 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestAnd.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestAnd.java
@@ -24,6 +24,7 @@
 import java.io.IOException;
 import java.util.Deque;
 import java.util.LinkedList;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.shell.PathData;
 import org.junit.Rule;
@@ -33,7 +34,7 @@
 public class TestAnd {
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   // test all expressions passing
   @Test
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFilterExpression.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFilterExpression.java
index 7ad0574e183c..b03be79b0316 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFilterExpression.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFilterExpression.java
@@ -22,6 +22,7 @@
 
 import java.io.IOException;
 import java.util.Deque;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.shell.PathData;
 
@@ -35,7 +36,7 @@ public class TestFilterExpression {
   private FilterExpression test;
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setup() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFind.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFind.java
index de0e512618b4..959dc59a270b 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFind.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestFind.java
@@ -26,6 +26,7 @@
 import java.util.Collections;
 import java.util.LinkedList;
 import java.util.NoSuchElementException;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileStatus;
@@ -50,7 +51,7 @@
 public class TestFind {
 
   @Rule
-  public Timeout timeout = new Timeout(10000);
+  public Timeout timeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   private static FileSystem mockFs;
   private static Configuration conf;
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestIname.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestIname.java
index c204322f1e93..f6eafd77b5d2 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestIname.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestIname.java
@@ -21,6 +21,7 @@
 import static org.apache.hadoop.fs.shell.find.TestHelper.*;
 
 import java.io.IOException;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.shell.PathData;
@@ -34,7 +35,7 @@ public class TestIname {
   private Name.Iname name;
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   @Before
   public void resetMock() throws IOException {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestName.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestName.java
index 81a405f4cfd4..8217655b523b 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestName.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestName.java
@@ -21,6 +21,7 @@
 import static org.apache.hadoop.fs.shell.find.TestHelper.*;
 
 import java.io.IOException;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.shell.PathData;
@@ -34,7 +35,7 @@ public class TestName {
   private Name name;
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   @Before
   public void resetMock() throws IOException {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint.java
index a5cacc7defb7..5e861fc35f08 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint.java
@@ -25,6 +25,7 @@
 import org.apache.hadoop.fs.shell.PathData;
 
 import java.io.PrintStream;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.FileSystem;
 import org.junit.Before;
@@ -36,7 +37,7 @@ public class TestPrint {
   private FileSystem mockFs;
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   @Before
   public void resetMock() throws IOException {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint0.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint0.java
index 20c9bd69470f..94c5c403bec3 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint0.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestPrint0.java
@@ -25,6 +25,7 @@
 import org.apache.hadoop.fs.shell.PathData;
 
 import java.io.PrintStream;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.FileSystem;
 import org.junit.Before;
@@ -36,7 +37,7 @@ public class TestPrint0 {
   private FileSystem mockFs;
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   @Before
   public void resetMock() throws IOException {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestResult.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestResult.java
index 999ff598d771..058a0923a43a 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestResult.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/find/TestResult.java
@@ -23,10 +23,12 @@
 import org.junit.rules.Timeout;
 import org.junit.Test;
 
+import java.util.concurrent.TimeUnit;
+
 public class TestResult {
 
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   // test the PASS value
   @Test
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
index 05d797439501..037ea798c9ca 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
@@ -60,6 +60,7 @@
 import org.apache.hadoop.security.UserGroupInformation;
 import org.apache.hadoop.security.token.Token;
 import org.apache.hadoop.test.GenericTestUtils;
+import org.assertj.core.api.Assertions;
 import org.junit.Assume;
 import org.junit.Rule;
 import org.junit.rules.TemporaryFolder;
@@ -74,8 +75,6 @@
 import org.junit.Test;
 
 import static org.apache.hadoop.test.GenericTestUtils.assertExceptionContains;
-import static org.hamcrest.CoreMatchers.containsString;
-import static org.hamcrest.CoreMatchers.equalTo;
 import static org.junit.Assert.*;
 
 /**
@@ -486,11 +485,13 @@ void compareBLs(BlockLocation[] viewBL, BlockLocation[] targetBL) {
     Assert.assertEquals(targetBL.length, viewBL.length);
     int i = 0;
     for (BlockLocation vbl : viewBL) {
-      assertThat(vbl.toString(), equalTo(targetBL[i].toString()));
-      assertThat(vbl.getOffset(), equalTo(targetBL[i].getOffset()));
-      assertThat(vbl.getLength(), equalTo(targetBL[i].getLength()));
+      Assertions.assertThat(vbl.toString()).isEqualTo(targetBL[i].toString());
+      Assertions.assertThat(vbl.getOffset())
+          .isEqualTo(targetBL[i].getOffset());
+      Assertions.assertThat(vbl.getLength())
+          .isEqualTo(targetBL[i].getLength());
       i++;
-    } 
+    }
   }
 
   @Test
@@ -1025,7 +1026,7 @@ public void testConfLinkSlash() throws Exception {
       if (e instanceof UnsupportedFileSystemException) {
         String msg = " Use " + Constants.CONFIG_VIEWFS_LINK_MERGE_SLASH +
             " instead";
-        assertThat(e.getMessage(), containsString(msg));
+        GenericTestUtils.assertExceptionContains(msg, e);
       } else {
         fail("Unexpected exception: " + e.getMessage());
       }
@@ -1262,8 +1263,7 @@ public void testLinkTarget() throws Exception {
       fail("Resolving link target for a ViewFs mount link should fail!");
     } catch (Exception e) {
       LOG.info("Expected exception: " + e);
-      assertThat(e.getMessage(),
-          containsString("not a symbolic link"));
+      GenericTestUtils.assertExceptionContains("not a symbolic link", e);
     }
 
     try {
@@ -1272,8 +1272,7 @@ public void testLinkTarget() throws Exception {
       fail("Resolving link target for a non sym link should fail!");
     } catch (Exception e) {
       LOG.info("Expected exception: " + e);
-      assertThat(e.getMessage(),
-          containsString("not a symbolic link"));
+      GenericTestUtils.assertExceptionContains("not a symbolic link", e);
     }
 
     try {
@@ -1281,8 +1280,7 @@ public void testLinkTarget() throws Exception {
       fail("Resolving link target for a non existing link should fail!");
     } catch (Exception e) {
       LOG.info("Expected exception: " + e);
-      assertThat(e.getMessage(),
-          containsString("File does not exist:"));
+      GenericTestUtils.assertExceptionContains("File does not exist:", e);
     }
   }
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
index d4f548c88b9d..d90702380178 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
@@ -22,6 +22,7 @@
 import java.net.InetSocketAddress;
 import java.security.NoSuchAlgorithmException;
 
+import java.util.concurrent.TimeUnit;
 import java.util.function.Supplier;
 import org.apache.hadoop.HadoopIllegalArgumentException;
 import org.apache.hadoop.conf.Configuration;
@@ -56,7 +57,7 @@ public class TestZKFailoverController extends ClientBaseWithFixes {
    * Set the timeout for every test
    */
   @Rule
-  public Timeout testTimeout = new Timeout(3 * 60 * 1000);
+  public Timeout testTimeout = new Timeout(3, TimeUnit.MINUTES);
 
   // Set up ZK digest-based credentials for the purposes of the tests,
   // to make sure all of our functionality works with auth and ACLs
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java
index e3cb028f5f55..b1255d19d908 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java
@@ -38,9 +38,7 @@
 import org.junit.AfterClass;
 import org.junit.Assert;
 import org.junit.BeforeClass;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 import org.mockito.Mockito;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -81,9 +79,6 @@ public class TestHttpServer extends HttpServerFunctionalTest {
   private static HttpServer2 server;
   private static final int MAX_THREADS = 10;
 
-  @Rule
-  public ExpectedException exception = ExpectedException.none();
-  
   @SuppressWarnings("serial")
   public static class EchoMapServlet extends HttpServlet {
     @SuppressWarnings("unchecked")
@@ -368,11 +363,11 @@ private HttpURLConnection getHttpURLConnection(HttpServer2 httpServer)
   }
 
   @Test
-  public void testHttpResonseInvalidValueType() throws Exception {
+  public void testHttpResonseInvalidValueType() {
     Configuration conf = new Configuration();
     boolean xFrameEnabled = true;
-    exception.expect(IllegalArgumentException.class);
-    createServer(xFrameEnabled, "Hadoop", conf);
+    assertThrows(IllegalArgumentException.class, () ->
+        createServer(xFrameEnabled, "Hadoop", conf));
   }
 
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestDecompressorStream.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestDecompressorStream.java
index 5a41e7ffb2f1..1e9f59b7a51e 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestDecompressorStream.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestDecompressorStream.java
@@ -17,8 +17,7 @@
  */
 package org.apache.hadoop.io.compress;
 
-import static org.hamcrest.CoreMatchers.is;
-import static org.junit.Assert.assertThat;
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -48,7 +47,7 @@ public void setUp() throws IOException {
   @Test
   public void testReadOneByte() throws IOException {
     for (int i = 0; i < TEST_STRING.length(); ++i) {
-      assertThat(decompressorStream.read(), is((int) TEST_STRING.charAt(i)));
+      assertThat(decompressorStream.read()).isEqualTo(TEST_STRING.charAt(i));
     }
     try {
       int ret = decompressorStream.read();
@@ -68,8 +67,8 @@ public void testReadBuffer() throws IOException {
       int n = Math.min(bytesToRead, buf.length);
       int bytesRead = decompressorStream.read(buf, 0, n);
       assertTrue(bytesRead > 0 && bytesRead <= n);
-      assertThat(new String(buf, 0, bytesRead),
-          is(TEST_STRING.substring(i, i + bytesRead)));
+      assertThat(new String(buf, 0, bytesRead))
+          .isEqualTo(TEST_STRING.substring(i, i + bytesRead));
       bytesToRead = bytesToRead - bytesRead;
       i = i + bytesRead;
     }
@@ -83,12 +82,12 @@ public void testReadBuffer() throws IOException {
 
   @Test
   public void testSkip() throws IOException {
-    assertThat(decompressorStream.skip(12), is(12L));
-    assertThat(decompressorStream.read(), is((int)TEST_STRING.charAt(12)));
-    assertThat(decompressorStream.read(), is((int)TEST_STRING.charAt(13)));
-    assertThat(decompressorStream.read(), is((int)TEST_STRING.charAt(14)));
-    assertThat(decompressorStream.skip(10), is(10L));
-    assertThat(decompressorStream.read(), is((int)TEST_STRING.charAt(25)));
+    assertThat(decompressorStream.skip(12)).isEqualTo(12L);
+    assertThat(decompressorStream.read()).isEqualTo(TEST_STRING.charAt(12));
+    assertThat(decompressorStream.read()).isEqualTo(TEST_STRING.charAt(13));
+    assertThat(decompressorStream.read()).isEqualTo(TEST_STRING.charAt(14));
+    assertThat(decompressorStream.skip(10)).isEqualTo(10L);
+    assertThat(decompressorStream.read()).isEqualTo(TEST_STRING.charAt(25));
     try {
       long ret = decompressorStream.skip(1000);
       fail("Not reachable but got ret " + ret);
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/TestECSchema.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/TestECSchema.java
index ae03835571fc..2a3c590ae233 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/TestECSchema.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/TestECSchema.java
@@ -27,11 +27,12 @@
 import java.util.HashMap;
 import java.util.Map;
 import java.util.TreeMap;
+import java.util.concurrent.TimeUnit;
 
 public class TestECSchema {
 
   @Rule
-  public Timeout globalTimeout = new Timeout(300000);
+  public Timeout globalTimeout = new Timeout(300000, TimeUnit.MILLISECONDS);
 
   @Test
   public void testGoodSchema() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestRSErasureCoder.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestRSErasureCoder.java
index 19054cecff01..726d2c1284e6 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestRSErasureCoder.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestRSErasureCoder.java
@@ -25,12 +25,14 @@
 import org.junit.Test;
 import org.junit.rules.Timeout;
 
+import java.util.concurrent.TimeUnit;
+
 /**
  * Test Reed-Solomon encoding and decoding.
  */
 public class TestRSErasureCoder extends TestErasureCoderBase {
   @Rule
-  public Timeout globalTimeout = new Timeout(300000);
+  public Timeout globalTimeout = new Timeout(300000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setup() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestXORCoder.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestXORCoder.java
index a44de1e08984..d1ceec8121ac 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestXORCoder.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/erasurecode/coder/TestXORCoder.java
@@ -22,13 +22,15 @@
 import org.junit.Test;
 import org.junit.rules.Timeout;
 
+import java.util.concurrent.TimeUnit;
+
 /**
  * Test XOR encoding and decoding.
  */
 public class TestXORCoder extends TestErasureCoderBase {
 
   @Rule
-  public Timeout globalTimeout = new Timeout(300000);
+  public Timeout globalTimeout = new Timeout(300000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setup() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/retry/TestDefaultRetryPolicy.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/retry/TestDefaultRetryPolicy.java
index 6b82077e8df9..1a934f4ed86e 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/retry/TestDefaultRetryPolicy.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/retry/TestDefaultRetryPolicy.java
@@ -27,16 +27,16 @@
 import org.junit.rules.Timeout;
 
 import java.io.IOException;
+import java.util.concurrent.TimeUnit;
 
-import static org.hamcrest.core.Is.is;
-import static org.junit.Assert.assertThat;
+import static org.assertj.core.api.Assertions.assertThat;
 
 /**
  * Test the behavior of the default retry policy.
  */
 public class TestDefaultRetryPolicy {
   @Rule
-  public Timeout timeout = new Timeout(30000);
+  public Timeout timeout = new Timeout(30000, TimeUnit.MILLISECONDS);
 
   /** Verify FAIL < RETRY < FAILOVER_AND_RETRY. */
   @Test
@@ -65,8 +65,8 @@ public void testWithRetriable() throws Exception {
         null);
     RetryPolicy.RetryAction action = policy.shouldRetry(
         new RetriableException("Dummy exception"), 0, 0, true);
-    assertThat(action.action,
-        is(RetryPolicy.RetryAction.RetryDecision.RETRY));
+    assertThat(action.action)
+        .isEqualTo(RetryPolicy.RetryAction.RetryDecision.RETRY);
   }
 
   /**
@@ -87,8 +87,8 @@ public void testWithWrappedRetriable() throws Exception {
     RetryPolicy.RetryAction action = policy.shouldRetry(
         new RemoteException(RetriableException.class.getName(),
             "Dummy exception"), 0, 0, true);
-    assertThat(action.action,
-        is(RetryPolicy.RetryAction.RetryDecision.RETRY));
+    assertThat(action.action)
+        .isEqualTo(RetryPolicy.RetryAction.RetryDecision.RETRY);
   }
 
   /**
@@ -107,7 +107,7 @@ public void testWithRetriableAndRetryDisabled() throws Exception {
         null);
     RetryPolicy.RetryAction action = policy.shouldRetry(
         new RetriableException("Dummy exception"), 0, 0, true);
-    assertThat(action.action,
-        is(RetryPolicy.RetryAction.RetryDecision.FAIL));
+    assertThat(action.action).isEqualTo(
+        RetryPolicy.RetryAction.RetryDecision.FAIL);
   }
 }
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/source/TestJvmMetrics.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/source/TestJvmMetrics.java
index ea86fc14c797..5eca1296994c 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/source/TestJvmMetrics.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/source/TestJvmMetrics.java
@@ -40,6 +40,7 @@
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import static org.apache.hadoop.metrics2.source.JvmMetricsInfo.*;
 import static org.apache.hadoop.metrics2.impl.MsInfo.*;
@@ -47,7 +48,7 @@
 public class TestJvmMetrics {
 
   @Rule
-  public Timeout timeout = new Timeout(30000);
+  public Timeout timeout = new Timeout(30000, TimeUnit.MILLISECONDS);
   private JvmPauseMonitor pauseMonitor;
   private GcTimeMonitor gcTimeMonitor;
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestDNS.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestDNS.java
index 3aa0acdcf4c4..c114c356516f 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestDNS.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestDNS.java
@@ -30,13 +30,12 @@
 
 import org.apache.hadoop.util.Time;
 
+import org.assertj.core.api.Assertions;
 import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import static org.apache.hadoop.test.PlatformAssumptions.assumeNotWindows;
-import static org.hamcrest.CoreMatchers.not;
-import static org.hamcrest.core.Is.is;
 import static org.junit.Assert.*;
 
 /**
@@ -104,7 +103,7 @@ private InetAddress getLocalIPAddr() throws UnknownHostException {
   @Test
   public void testNullInterface() throws Exception {
     String host = DNS.getDefaultHost(null);  // should work.
-    assertThat(host, is(DNS.getDefaultHost(DEFAULT)));
+    Assertions.assertThat(host).isEqualTo(DNS.getDefaultHost(DEFAULT));
     try {
       String ip = DNS.getDefaultIP(null);
       fail("Expected a NullPointerException, got " + ip);
@@ -120,7 +119,8 @@ public void testNullInterface() throws Exception {
   @Test
   public void testNullDnsServer() throws Exception {
     String host = DNS.getDefaultHost(getLoopbackInterface(), null);
-    assertThat(host, is(DNS.getDefaultHost(getLoopbackInterface())));
+    Assertions.assertThat(host)
+        .isEqualTo(DNS.getDefaultHost(getLoopbackInterface()));
   }
 
   /**
@@ -130,7 +130,8 @@ public void testNullDnsServer() throws Exception {
   @Test
   public void testDefaultDnsServer() throws Exception {
     String host = DNS.getDefaultHost(getLoopbackInterface(), DEFAULT);
-    assertThat(host, is(DNS.getDefaultHost(getLoopbackInterface())));
+    Assertions.assertThat(host)
+        .isEqualTo(DNS.getDefaultHost(getLoopbackInterface()));
   }
 
   /**
@@ -204,7 +205,7 @@ public void testLookupWithHostsFallback() throws Exception {
           getLoopbackInterface(), INVALID_DNS_SERVER, true);
 
       // Expect to get back something other than the cached host name.
-      assertThat(hostname, not(DUMMY_HOSTNAME));
+      Assertions.assertThat(hostname).isNotEqualTo(DUMMY_HOSTNAME);
     } finally {
       // Restore DNS#cachedHostname for subsequent tests.
       changeDnsCachedHostname(oldHostname);
@@ -227,7 +228,7 @@ public void testLookupWithoutHostsFallback() throws Exception {
 
       // Expect to get back the cached host name since there was no hosts
       // file lookup.
-      assertThat(hostname, is(DUMMY_HOSTNAME));
+      Assertions.assertThat(hostname).isEqualTo(DUMMY_HOSTNAME);
     } finally {
       // Restore DNS#cachedHostname for subsequent tests.
       changeDnsCachedHostname(oldHostname);
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestMockDomainNameResolver.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestMockDomainNameResolver.java
index 5d8f014c72b8..21c6c7279fb8 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestMockDomainNameResolver.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestMockDomainNameResolver.java
@@ -20,15 +20,14 @@
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.CommonConfigurationKeys;
 import org.junit.Before;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 import java.io.IOException;
 import java.net.InetAddress;
 import java.net.UnknownHostException;
 
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertThrows;
 
 /**
  * This class mainly test the MockDomainNameResolver comes working as expected.
@@ -37,9 +36,6 @@ public class TestMockDomainNameResolver {
 
   private Configuration conf;
 
-  @Rule
-  public final ExpectedException exception = ExpectedException.none();
-
   @Before
   public void setup() {
     conf = new Configuration();
@@ -60,12 +56,10 @@ public void testMockDomainNameResolverCanBeCreated() throws IOException {
   }
 
   @Test
-  public void testMockDomainNameResolverCanNotBeCreated()
-      throws UnknownHostException {
+  public void testMockDomainNameResolverCanNotBeCreated() {
     DomainNameResolver resolver = DomainNameResolverFactory.newInstance(
         conf, CommonConfigurationKeys.HADOOP_DOMAINNAME_RESOLVER_IMPL);
-    exception.expect(UnknownHostException.class);
-    resolver.getAllByDomainName(
-        MockDomainNameResolver.UNKNOW_DOMAIN);
+    assertThrows(UnknownHostException.class, () ->
+        resolver.getAllByDomainName(MockDomainNameResolver.UNKNOW_DOMAIN));
   }
 }
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiag.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiag.java
index e395566dae73..297d240d3007 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiag.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiag.java
@@ -37,6 +37,7 @@
 import java.io.FileInputStream;
 import java.io.IOException;
 import java.util.Properties;
+import java.util.concurrent.TimeUnit;
 
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION;
 import static org.apache.hadoop.security.KDiag.*;
@@ -52,7 +53,7 @@ public class TestKDiag extends Assert {
   public TestName methodName = new TestName();
 
   @Rule
-  public Timeout testTimeout = new Timeout(30000);
+  public Timeout testTimeout = new Timeout(30000, TimeUnit.MILLISECONDS);
 
   @BeforeClass
   public static void nameThread() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiagNoKDC.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiagNoKDC.java
index dbc40c52e513..2e266bba1f97 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiagNoKDC.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestKDiagNoKDC.java
@@ -33,6 +33,7 @@
 
 import java.io.File;
 import java.util.Properties;
+import java.util.concurrent.TimeUnit;
 
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.HADOOP_TOKEN_FILES;
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION;
@@ -58,7 +59,7 @@ public class TestKDiagNoKDC extends Assert {
   public TestName methodName = new TestName();
 
   @Rule
-  public Timeout testTimeout = new Timeout(30000);
+  public Timeout testTimeout = new Timeout(30000, TimeUnit.MILLISECONDS);
 
   @BeforeClass
   public static void nameThread() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredentialProviderFactory.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredentialProviderFactory.java
index f7bb8ec4a964..fb17977aa2e7 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredentialProviderFactory.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredentialProviderFactory.java
@@ -36,13 +36,13 @@
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 import org.junit.rules.TestName;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertThrows;
 import static org.junit.Assert.assertTrue;
 
 public class TestCredentialProviderFactory {
@@ -52,9 +52,6 @@ public class TestCredentialProviderFactory {
   @Rule
   public final TestName test = new TestName();
 
-  @Rule
-  public ExpectedException exception = ExpectedException.none();
-
   @Before
   public void announce() {
     LOG.info("Running test " + test.getMethodName());
@@ -250,18 +247,15 @@ public void testLocalJksProvider() throws Exception {
   }
 
   @Test
-  public void testLocalBCFKSProvider() throws Exception {
+  public void testLocalBCFKSProvider() {
     Configuration conf = new Configuration();
     final Path ksPath = new Path(tmpDir.toString(), "test.bcfks");
     final String ourUrl = LocalBouncyCastleFipsKeyStoreProvider.SCHEME_NAME +
         "://file" + ksPath.toUri();
     conf.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, ourUrl);
-
-    exception.expect(IOException.class);
-    exception.expectMessage("Can't create keystore");
-    List<CredentialProvider> providers =
-        CredentialProviderFactory.getProviders(conf);
-    assertTrue("BCFKS needs additional JDK setup", providers.isEmpty());
+    Exception exception = assertThrows(IOException.class,
+        () -> CredentialProviderFactory.getProviders(conf));
+    assertEquals("Can't create keystore", exception.getMessage());
   }
 
   public void checkPermissionRetention(Configuration conf, String ourUrl,
@@ -290,4 +284,3 @@ public void checkPermissionRetention(Configuration conf, String ourUrl,
         "keystore.", "rwxrwxrwx", s.getPermission().toString());
   }
 }
-
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/authorize/TestDefaultImpersonationProvider.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/authorize/TestDefaultImpersonationProvider.java
index ef86697ab14b..9c9618ce5b3c 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/authorize/TestDefaultImpersonationProvider.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/authorize/TestDefaultImpersonationProvider.java
@@ -29,6 +29,8 @@
 import org.junit.rules.Timeout;
 import org.mockito.Mockito;
 
+import java.util.concurrent.TimeUnit;
+
 /**
  * Test class for @DefaultImpersonationProvider
  */
@@ -43,7 +45,7 @@ public class TestDefaultImpersonationProvider {
       .mock(UserGroupInformation.class);
   private Configuration conf;
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setup() {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/TestZKDelegationTokenSecretManager.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/TestZKDelegationTokenSecretManager.java
index 53973055336f..928768d601af 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/TestZKDelegationTokenSecretManager.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/TestZKDelegationTokenSecretManager.java
@@ -24,6 +24,7 @@
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
 
+import java.util.concurrent.TimeUnit;
 import java.util.function.Supplier;
 import org.apache.curator.RetryPolicy;
 import org.apache.curator.framework.CuratorFramework;
@@ -70,7 +71,7 @@ public class TestZKDelegationTokenSecretManager {
   protected TestingServer zkServer;
 
   @Rule
-  public Timeout globalTimeout = new Timeout(300000);
+  public Timeout globalTimeout = new Timeout(300000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setup() throws Exception {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestDelegationTokenAuthenticationHandlerWithMocks.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestDelegationTokenAuthenticationHandlerWithMocks.java
index 0f8f1e45c900..bc140fa7b107 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestDelegationTokenAuthenticationHandlerWithMocks.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/delegation/web/TestDelegationTokenAuthenticationHandlerWithMocks.java
@@ -47,6 +47,7 @@
 import java.io.StringWriter;
 import java.util.Map;
 import java.util.Properties;
+import java.util.concurrent.TimeUnit;
 
 public class TestDelegationTokenAuthenticationHandlerWithMocks {
 
@@ -93,7 +94,7 @@ public AuthenticationToken authenticate(HttpServletRequest request,
   private DelegationTokenAuthenticationHandler handler;
 
   @Rule
-  public Timeout testTimeout = new Timeout(120000);
+  public Timeout testTimeout = new Timeout(120000, TimeUnit.MILLISECONDS);
 
   @Before
   public void setUp() throws Exception {
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/TestServiceOperations.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/TestServiceOperations.java
index 9794c5499802..b7b86b7aa0dc 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/TestServiceOperations.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/TestServiceOperations.java
@@ -30,8 +30,7 @@
 import java.io.PrintWriter;
 
 import static org.apache.hadoop.test.GenericTestUtils.LogCapturer.captureLogs;
-import static org.hamcrest.CoreMatchers.containsString;
-import static org.junit.Assert.assertThat;
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.mockito.Mockito.doThrow;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;
@@ -56,8 +55,8 @@ public void testStopQuietlyWhenServiceStopThrowsException() throws Exception {
 
     ServiceOperations.stopQuietly(logger, service);
 
-    assertThat(logCapturer.getOutput(),
-        containsString("When stopping the service " + service.getName()));
+    assertThat(logCapturer.getOutput())
+        .contains("When stopping the service " + service.getName());
     verify(e, times(1)).printStackTrace(Mockito.any(PrintWriter.class));
   }
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/launcher/AbstractServiceLauncherTestBase.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/launcher/AbstractServiceLauncherTestBase.java
index d7c86316ef62..4be670d4638d 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/launcher/AbstractServiceLauncherTestBase.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/service/launcher/AbstractServiceLauncherTestBase.java
@@ -41,6 +41,7 @@
 import java.io.OutputStream;
 import java.util.Arrays;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 public class AbstractServiceLauncherTestBase extends Assert implements
     LauncherExitCodes {
@@ -57,7 +58,7 @@ public class AbstractServiceLauncherTestBase extends Assert implements
    * All tests have a short life.
    */
   @Rule
-  public Timeout testTimeout = new Timeout(15000);
+  public Timeout testTimeout = new Timeout(15000, TimeUnit.MILLISECONDS);
 
   /**
    * Rule to provide the method name.
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/PlatformAssumptions.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/PlatformAssumptions.java
index 4e8316250236..653cb38c49a6 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/PlatformAssumptions.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/PlatformAssumptions.java
@@ -17,7 +17,7 @@
  */
 package org.apache.hadoop.test;
 
-import org.junit.internal.AssumptionViolatedException;
+import org.junit.AssumptionViolatedException;
 
 /**
  * JUnit assumptions for the environment (OS).
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/UnitTestcaseTimeLimit.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/UnitTestcaseTimeLimit.java
index e992fea0f341..722d0072439a 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/UnitTestcaseTimeLimit.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/UnitTestcaseTimeLimit.java
@@ -21,6 +21,8 @@
 import org.junit.rules.TestRule;
 import org.junit.rules.Timeout;
 
+import java.util.concurrent.TimeUnit;
+
 /**
  * Class for test units to extend in order that their individual tests will
  * be timed out and fail automatically should they run more than 10 seconds.
@@ -30,5 +32,6 @@
 public class UnitTestcaseTimeLimit {
   public final int timeOutSecs = 10;
   
-  @Rule public TestRule globalTimeout = new Timeout(timeOutSecs * 1000);
+  @Rule public TestRule globalTimeout =
+      new Timeout(timeOutSecs, TimeUnit.SECONDS);
 }
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcComposer.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcComposer.java
index f08702e35e59..5d8dcfb1be75 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcComposer.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcComposer.java
@@ -21,6 +21,7 @@
 import java.io.DataInputStream;
 import java.io.IOException;
 import java.util.Random;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.test.LambdaTestUtils;
 import org.junit.Before;
@@ -35,7 +36,7 @@
  */
 public class TestCrcComposer {
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   private Random rand = new Random(1234);
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcUtil.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcUtil.java
index a98cb8a6757d..b4355b1513f4 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcUtil.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCrcUtil.java
@@ -19,6 +19,7 @@
 
 import java.io.IOException;
 import java.util.Random;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.test.LambdaTestUtils;
 import org.junit.Rule;
@@ -32,7 +33,7 @@
  */
 public class TestCrcUtil {
   @Rule
-  public Timeout globalTimeout = new Timeout(10000);
+  public Timeout globalTimeout = new Timeout(10000, TimeUnit.MILLISECONDS);
 
   private Random rand = new Random(1234);
 
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestDiskCheckerWithDiskIo.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestDiskCheckerWithDiskIo.java
index 94462732a5d6..082672ccd33d 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestDiskCheckerWithDiskIo.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestDiskCheckerWithDiskIo.java
@@ -33,6 +33,7 @@
 import java.nio.file.Files;
 import java.nio.file.attribute.PosixFilePermission;
 import java.nio.file.attribute.PosixFilePermissions;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import static org.junit.Assert.assertTrue;
@@ -44,8 +45,8 @@
  */
 public final class TestDiskCheckerWithDiskIo {
   @Rule
-  public Timeout testTimeout = new Timeout(30_000);
-  
+  public Timeout testTimeout = new Timeout(30_000, TimeUnit.MILLISECONDS);
+
   /**
    * Verify DiskChecker ignores at least 2 transient file creation errors.
    */
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestNativeCrc32.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestNativeCrc32.java
index ecc6c906ab90..b2d9e7420649 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestNativeCrc32.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestNativeCrc32.java
@@ -28,9 +28,7 @@
 import org.apache.hadoop.fs.ChecksumException;
 
 import org.junit.Before;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 import org.junit.runners.Parameterized.Parameters;
@@ -51,9 +49,6 @@ public class TestNativeCrc32 {
   private ByteBuffer data, checksums;
   private DataChecksum checksum;
 
-  @Rule
-  public ExpectedException exception = ExpectedException.none();
-
   @Parameters
   public static Collection<Object[]> data() {
     Collection<Object[]> params = new ArrayList<Object[]>(2);
@@ -88,12 +83,12 @@ public void testVerifyChunkedSumsSuccess() throws ChecksumException {
   }
 
   @Test
-  public void testVerifyChunkedSumsFail() throws ChecksumException {
+  public void testVerifyChunkedSumsFail() {
     allocateDirectByteBuffers();
     fillDataAndInvalidChecksums();
-    exception.expect(ChecksumException.class);
-    NativeCrc32.verifyChunkedSums(bytesPerChecksum, checksumType.id,
-      checksums, data, fileName, BASE_POSITION);
+    assertThrows(ChecksumException.class,
+        () -> NativeCrc32.verifyChunkedSums(bytesPerChecksum, checksumType.id,
+            checksums, data, fileName, BASE_POSITION));
   }
 
   @Test
@@ -122,13 +117,14 @@ public void testVerifyChunkedSumsByteArraySuccess() throws ChecksumException {
   }
 
   @Test
-  public void testVerifyChunkedSumsByteArrayFail() throws ChecksumException {
+  public void testVerifyChunkedSumsByteArrayFail() {
     allocateArrayByteBuffers();
     fillDataAndInvalidChecksums();
-    exception.expect(ChecksumException.class);
-    NativeCrc32.verifyChunkedSumsByteArray(bytesPerChecksum, checksumType.id,
-      checksums.array(), checksums.position(), data.array(), data.position(),
-      data.remaining(), fileName, BASE_POSITION);
+    assertThrows(ChecksumException.class,
+        () -> NativeCrc32.verifyChunkedSumsByteArray(bytesPerChecksum,
+            checksumType.id, checksums.array(), checksums.position(),
+            data.array(), data.position(), data.remaining(), fileName,
+            BASE_POSITION));
   }
 
   @Test
@@ -177,13 +173,13 @@ public void testNativeVerifyChunkedSumsSuccess() throws ChecksumException {
 
   @Test
   @SuppressWarnings("deprecation")
-  public void testNativeVerifyChunkedSumsFail() throws ChecksumException {
+  public void testNativeVerifyChunkedSumsFail() {
     allocateDirectByteBuffers();
     fillDataAndInvalidChecksums();
-    exception.expect(ChecksumException.class);
-    NativeCrc32.nativeVerifyChunkedSums(bytesPerChecksum, checksumType.id,
-      checksums, checksums.position(), data, data.position(), data.remaining(),
-      fileName, BASE_POSITION);
+    assertThrows(ChecksumException.class,
+        () -> NativeCrc32.nativeVerifyChunkedSums(bytesPerChecksum,
+            checksumType.id, checksums, checksums.position(), data,
+            data.position(), data.remaining(), fileName, BASE_POSITION));
   }
 
   /**
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestReflectionUtils.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestReflectionUtils.java
index 03c67c826393..1d1ce893a97a 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestReflectionUtils.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestReflectionUtils.java
@@ -25,11 +25,11 @@
 import java.util.HashMap;
 import java.util.List;
 
-import static org.hamcrest.CoreMatchers.containsString;
 import static org.junit.Assert.*;
 
 import org.apache.hadoop.test.GenericTestUtils;
 import org.apache.hadoop.test.GenericTestUtils.LogCapturer;
+import org.assertj.core.api.Assertions;
 import org.junit.Before;
 import org.junit.Test;
 import org.slf4j.Logger;
@@ -165,8 +165,8 @@ public void testLogThreadInfo() throws Exception {
     final String title = "title";
     ReflectionUtils.logThreadInfo(logger, title, 0L);
 
-    assertThat(logCapturer.getOutput(),
-        containsString("Process Thread Dump: " + title));
+    Assertions.assertThat(logCapturer.getOutput())
+        .contains("Process Thread Dump: " + title);
   }
 
   @Test
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestShell.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestShell.java
index c9f398da563e..6b7154b83b52 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestShell.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestShell.java
@@ -17,6 +17,7 @@
  */
 package org.apache.hadoop.util;
 
+import java.util.concurrent.TimeUnit;
 import java.util.function.Supplier;
 import org.apache.commons.io.FileUtils;
 import org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider;
@@ -53,7 +54,7 @@ public class TestShell extends Assert {
    * Set the timeout for every test
    */
   @Rule
-  public Timeout testTimeout = new Timeout(30000);
+  public Timeout testTimeout = new Timeout(30000, TimeUnit.MILLISECONDS);
 
   @Rule
   public TestName methodName = new TestName();
diff --git a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
index baf4251c3e50..00e36ee8fa94 100644
--- a/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
+++ b/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
@@ -20,7 +20,6 @@
 
 import static org.apache.hadoop.test.PlatformAssumptions.assumeWindows;
 import static org.junit.Assert.*;
-import static org.junit.matchers.JUnitMatchers.containsString;
 
 import java.io.File;
 import java.io.FileInputStream;
@@ -31,14 +30,13 @@
 import org.apache.commons.io.FileUtils;
 import org.apache.hadoop.fs.FileUtil;
 import org.apache.hadoop.test.GenericTestUtils;
+import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import static org.hamcrest.CoreMatchers.*;
-
 /**
  * Test cases for helper Windows winutils.exe utility.
  */
@@ -496,12 +494,12 @@ public void testReadLink() throws IOException {
     String readLinkOutput = Shell.execCommand(winutils,
         "readlink",
         dirLink.toString());
-    assertThat(readLinkOutput, equalTo(dir1.toString()));
+    Assertions.assertThat(readLinkOutput).isEqualTo(dir1.toString());
 
     readLinkOutput = Shell.execCommand(winutils,
         "readlink",
         fileLink.toString());
-    assertThat(readLinkOutput, equalTo(file1.toString()));
+    Assertions.assertThat(readLinkOutput).isEqualTo(file1.toString());
 
     // Try a few invalid inputs and verify we get an ExitCodeException for each.
     //
@@ -511,7 +509,7 @@ public void testReadLink() throws IOException {
       Shell.execCommand(winutils, "readlink", "");
       fail("Failed to get Shell.ExitCodeException when reading bad symlink");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1);
     }
 
     try {
@@ -520,7 +518,7 @@ public void testReadLink() throws IOException {
       Shell.execCommand(winutils, "readlink", "ThereIsNoSuchLink");
       fail("Failed to get Shell.ExitCodeException when reading bad symlink");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1);
     }
 
     try {
@@ -529,7 +527,7 @@ public void testReadLink() throws IOException {
       Shell.execCommand(winutils, "readlink", dir1.toString());
       fail("Failed to get Shell.ExitCodeException when reading bad symlink");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1);
     }
 
     try {
@@ -538,7 +536,7 @@ public void testReadLink() throws IOException {
       Shell.execCommand(winutils, "readlink", file1.toString());
       fail("Failed to get Shell.ExitCodeException when reading bad symlink");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1);
     }
 
     try {
@@ -547,11 +545,10 @@ public void testReadLink() throws IOException {
       Shell.execCommand(winutils, "readlink", "a", "b");
       fail("Failed to get Shell.ExitCodeException with bad parameters");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1);
     }
   }
   
-  @SuppressWarnings("deprecation")
   @Test(timeout=10000)
   public void testTaskCreate() throws IOException {
     requireWinutils();
@@ -570,8 +567,8 @@ public void testTaskCreate() throws IOException {
     assertTrue(proof.exists());
     
     String outNumber = FileUtils.readFileToString(proof);
-    
-    assertThat(outNumber, containsString(testNumber));
+
+    Assertions.assertThat(outNumber).contains(testNumber);
   }
 
   @Test (timeout = 30000)
@@ -604,7 +601,7 @@ public void testTaskCreateWithLimits() throws IOException {
           + jobId, "java -Xmx256m -version");
       fail("Failed to get Shell.ExitCodeException with insufficient memory");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1);
     }
 
     // Run tasks with wrong parameters
@@ -615,7 +612,7 @@ public void testTaskCreateWithLimits() throws IOException {
           "-1", "foo", "job" + jobId, "cmd /c echo job" + jobId);
       fail("Failed to get Shell.ExitCodeException with bad parameters");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1639));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1639);
     }
 
     try {
@@ -624,7 +621,7 @@ public void testTaskCreateWithLimits() throws IOException {
           "job" + jobId, "cmd /c echo job" + jobId);
       fail("Failed to get Shell.ExitCodeException with bad parameters");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1639));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1639);
     }
 
     try {
@@ -633,7 +630,7 @@ public void testTaskCreateWithLimits() throws IOException {
           "job" + jobId, "cmd /c echo job" + jobId);
       fail("Failed to get Shell.ExitCodeException with bad parameters");
     } catch (Shell.ExitCodeException ece) {
-      assertThat(ece.getExitCode(), is(1639));
+      Assertions.assertThat(ece.getExitCode()).isEqualTo(1639);
     }
   }
 }
