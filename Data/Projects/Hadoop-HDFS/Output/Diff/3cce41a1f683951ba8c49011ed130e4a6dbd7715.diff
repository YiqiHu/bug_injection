diff --git a/hadoop-common-project/hadoop-common/src/site/markdown/release/3.2.4/CHANGELOG.3.2.4.md b/hadoop-common-project/hadoop-common/src/site/markdown/release/3.2.4/CHANGELOG.3.2.4.md
new file mode 100644
index 000000000000..fc0079d1c9bd
--- /dev/null
+++ b/hadoop-common-project/hadoop-common/src/site/markdown/release/3.2.4/CHANGELOG.3.2.4.md
@@ -0,0 +1,213 @@
+
+<!---
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+-->
+# Apache Hadoop Changelog
+
+## Release 3.2.4 - 2022-07-12
+
+
+
+### NEW FEATURES:
+
+| JIRA | Summary | Priority | Component | Reporter | Contributor |
+|:---- |:---- | :--- |:---- |:---- |:---- |
+| [HDFS-16337](https://issues.apache.org/jira/browse/HDFS-16337) | Show start time of Datanode on Web |  Minor | . | Tao Li | Tao Li |
+
+
+### IMPROVEMENTS:
+
+| JIRA | Summary | Priority | Component | Reporter | Contributor |
+|:---- |:---- | :--- |:---- |:---- |:---- |
+| [HDFS-15075](https://issues.apache.org/jira/browse/HDFS-15075) | Remove process command timing from BPServiceActor |  Major | . | Íñigo Goiri | Xiaoqiao He |
+| [HDFS-15150](https://issues.apache.org/jira/browse/HDFS-15150) | Introduce read write lock to Datanode |  Major | datanode | Stephen O'Donnell | Stephen O'Donnell |
+| [HDFS-16175](https://issues.apache.org/jira/browse/HDFS-16175) | Improve the configurable value of Server #PURGE\_INTERVAL\_NANOS |  Major | ipc | JiangHua Zhu | JiangHua Zhu |
+| [HDFS-16173](https://issues.apache.org/jira/browse/HDFS-16173) | Improve CopyCommands#Put#executor queue configurability |  Major | fs | JiangHua Zhu | JiangHua Zhu |
+| [HADOOP-17897](https://issues.apache.org/jira/browse/HADOOP-17897) | Allow nested blocks in switch case in checkstyle settings |  Minor | build | Masatake Iwasaki | Masatake Iwasaki |
+| [HADOOP-17857](https://issues.apache.org/jira/browse/HADOOP-17857) | Check real user ACLs in addition to proxied user ACLs |  Major | . | Eric Payne | Eric Payne |
+| [HDFS-14997](https://issues.apache.org/jira/browse/HDFS-14997) | BPServiceActor processes commands from NameNode asynchronously |  Major | datanode | Xiaoqiao He | Xiaoqiao He |
+| [HADOOP-17926](https://issues.apache.org/jira/browse/HADOOP-17926) | Maven-eclipse-plugin is no longer needed since Eclipse can import Maven projects by itself. |  Minor | documentation | Rintaro Ikeda | Rintaro Ikeda |
+| [YARN-10935](https://issues.apache.org/jira/browse/YARN-10935) | AM Total Queue Limit goes below per-user AM Limit if parent is full. |  Major | capacity scheduler, capacityscheduler | Eric Payne | Eric Payne |
+| [HDFS-16241](https://issues.apache.org/jira/browse/HDFS-16241) | Standby close reconstruction thread |  Major | . | zhanghuazong | zhanghuazong |
+| [YARN-1115](https://issues.apache.org/jira/browse/YARN-1115) | Provide optional means for a scheduler to check real user ACLs |  Major | capacity scheduler, scheduler | Eric Payne |  |
+| [HDFS-16279](https://issues.apache.org/jira/browse/HDFS-16279) | Print detail datanode info when process first storage report |  Minor | . | Tao Li | Tao Li |
+| [HDFS-16294](https://issues.apache.org/jira/browse/HDFS-16294) | Remove invalid DataNode#CONFIG\_PROPERTY\_SIMULATED |  Major | datanode | JiangHua Zhu | JiangHua Zhu |
+| [HDFS-16299](https://issues.apache.org/jira/browse/HDFS-16299) | Fix bug for TestDataNodeVolumeMetrics#verifyDataNodeVolumeMetrics |  Minor | . | Tao Li | Tao Li |
+| [HDFS-16301](https://issues.apache.org/jira/browse/HDFS-16301) | Improve BenchmarkThroughput#SIZE naming standardization |  Minor | benchmarks, test | JiangHua Zhu | JiangHua Zhu |
+| [YARN-10997](https://issues.apache.org/jira/browse/YARN-10997) | Revisit allocation and reservation logging |  Major | . | Andras Gyori | Andras Gyori |
+| [HDFS-16315](https://issues.apache.org/jira/browse/HDFS-16315) | Add metrics related to Transfer and NativeCopy for DataNode |  Major | . | Tao Li | Tao Li |
+| [HADOOP-17998](https://issues.apache.org/jira/browse/HADOOP-17998) | Allow get command to run with multi threads. |  Major | fs | Chengwei Wang | Chengwei Wang |
+| [HDFS-16345](https://issues.apache.org/jira/browse/HDFS-16345) | Fix test cases fail in TestBlockStoragePolicy |  Major | build | guophilipse | guophilipse |
+| [HADOOP-18035](https://issues.apache.org/jira/browse/HADOOP-18035) | Skip unit test failures to run all the unit tests |  Major | build | Akira Ajisaka | Akira Ajisaka |
+| [HADOOP-18040](https://issues.apache.org/jira/browse/HADOOP-18040) | Use maven.test.failure.ignore instead of ignoreTestFailure |  Major | build | Akira Ajisaka | Akira Ajisaka |
+| [HDFS-16352](https://issues.apache.org/jira/browse/HDFS-16352) | return the real datanode numBlocks in #getDatanodeStorageReport |  Major | . | qinyuren | qinyuren |
+| [HDFS-16386](https://issues.apache.org/jira/browse/HDFS-16386) | Reduce DataNode load when FsDatasetAsyncDiskService is working |  Major | datanode | JiangHua Zhu | JiangHua Zhu |
+| [HDFS-16391](https://issues.apache.org/jira/browse/HDFS-16391) | Avoid evaluation of LOG.debug statement in NameNodeHeartbeatService |  Trivial | . | wangzhaohui | wangzhaohui |
+| [YARN-8234](https://issues.apache.org/jira/browse/YARN-8234) | Improve RM system metrics publisher's performance by pushing events to timeline server in batch |  Critical | resourcemanager, timelineserver | Hu Ziqian | Ashutosh Gupta |
+| [HDFS-16430](https://issues.apache.org/jira/browse/HDFS-16430) | Validate maximum blocks in EC group when adding an EC policy |  Minor | ec, erasure-coding | daimin | daimin |
+| [HDFS-16403](https://issues.apache.org/jira/browse/HDFS-16403) | Improve FUSE IO performance by supporting FUSE parameter max\_background |  Minor | fuse-dfs | daimin | daimin |
+| [HADOOP-18136](https://issues.apache.org/jira/browse/HADOOP-18136) | Verify FileUtils.unTar() handling of missing .tar files |  Minor | test, util | Steve Loughran | Steve Loughran |
+| [HDFS-16529](https://issues.apache.org/jira/browse/HDFS-16529) | Remove unnecessary setObserverRead in TestConsistentReadsObserver |  Trivial | test | wangzhaohui | wangzhaohui |
+| [HDFS-16530](https://issues.apache.org/jira/browse/HDFS-16530) | setReplication debug log creates a new string even if debug is disabled |  Major | namenode | Stephen O'Donnell | Stephen O'Donnell |
+| [HDFS-16427](https://issues.apache.org/jira/browse/HDFS-16427) | Add debug log for BlockManager#chooseExcessRedundancyStriped |  Minor | erasure-coding | Tao Li | Tao Li |
+| [HDFS-16389](https://issues.apache.org/jira/browse/HDFS-16389) | Improve NNThroughputBenchmark test mkdirs |  Major | benchmarks, namenode | JiangHua Zhu | JiangHua Zhu |
+| [MAPREDUCE-7373](https://issues.apache.org/jira/browse/MAPREDUCE-7373) | Building MapReduce NativeTask fails on Fedora 34+ |  Major | build, nativetask | Kengo Seki | Kengo Seki |
+| [HDFS-16355](https://issues.apache.org/jira/browse/HDFS-16355) | Improve the description of dfs.block.scanner.volume.bytes.per.second |  Minor | documentation, hdfs | guophilipse | guophilipse |
+| [HADOOP-18088](https://issues.apache.org/jira/browse/HADOOP-18088) | Replace log4j 1.x with reload4j |  Major | . | Wei-Chiu Chuang | Wei-Chiu Chuang |
+| [HDFS-16501](https://issues.apache.org/jira/browse/HDFS-16501) | Print the exception when reporting a bad block |  Major | datanode | qinyuren | qinyuren |
+| [YARN-11116](https://issues.apache.org/jira/browse/YARN-11116) | Migrate Times util from SimpleDateFormat to thread-safe DateTimeFormatter class |  Minor | . | Jonathan Turner Eagles | Jonathan Turner Eagles |
+| [YARN-10080](https://issues.apache.org/jira/browse/YARN-10080) | Support show app id on localizer thread pool |  Major | nodemanager | zhoukang | Ashutosh Gupta |
+| [HADOOP-18240](https://issues.apache.org/jira/browse/HADOOP-18240) | Upgrade Yetus to 0.14.0 |  Major | build | Akira Ajisaka | Ashutosh Gupta |
+| [HDFS-16585](https://issues.apache.org/jira/browse/HDFS-16585) | Add @VisibleForTesting in Dispatcher.java after HDFS-16268 |  Trivial | . | Wei-Chiu Chuang | Ashutosh Gupta |
+| [HDFS-16610](https://issues.apache.org/jira/browse/HDFS-16610) | Make fsck read timeout configurable |  Major | hdfs-client | Stephen O'Donnell | Stephen O'Donnell |
+
+
+### BUG FIXES:
+
+| JIRA | Summary | Priority | Component | Reporter | Contributor |
+|:---- |:---- | :--- |:---- |:---- |:---- |
+| [HDFS-13983](https://issues.apache.org/jira/browse/HDFS-13983) | TestOfflineImageViewer crashes in windows |  Major | . | Vinayakumar B | Vinayakumar B |
+| [YARN-9744](https://issues.apache.org/jira/browse/YARN-9744) | RollingLevelDBTimelineStore.getEntityByTime fails with NPE |  Major | timelineserver | Prabhu Joseph | Prabhu Joseph |
+| [HDFS-15113](https://issues.apache.org/jira/browse/HDFS-15113) | Missing IBR when NameNode restart if open processCommand async feature |  Blocker | datanode | Xiaoqiao He | Xiaoqiao He |
+| [HADOOP-16985](https://issues.apache.org/jira/browse/HADOOP-16985) | Handle release package related issues |  Major | . | Vinayakumar B | Vinayakumar B |
+| [HADOOP-17116](https://issues.apache.org/jira/browse/HADOOP-17116) | Skip Retry INFO logging on first failover from a proxy |  Major | ha | Hanisha Koneru | Hanisha Koneru |
+| [HDFS-15651](https://issues.apache.org/jira/browse/HDFS-15651) | Client could not obtain block when DN CommandProcessingThread exit |  Major | . | Yiqun Lin | Mingxiang Li |
+| [HDFS-15963](https://issues.apache.org/jira/browse/HDFS-15963) | Unreleased volume references cause an infinite loop |  Critical | datanode | Shuyan Zhang | Shuyan Zhang |
+| [HDFS-14575](https://issues.apache.org/jira/browse/HDFS-14575) | LeaseRenewer#daemon threads leak in DFSClient |  Major | . | Tao Yang | Renukaprasad C |
+| [HADOOP-17796](https://issues.apache.org/jira/browse/HADOOP-17796) | Upgrade jetty version to 9.4.43 |  Major | . | Wei-Chiu Chuang | Renukaprasad C |
+| [HDFS-15175](https://issues.apache.org/jira/browse/HDFS-15175) | Multiple CloseOp shared block instance causes the standby namenode to crash when rolling editlog |  Critical | . | Yicong Cai | Wan Chang |
+| [HDFS-16177](https://issues.apache.org/jira/browse/HDFS-16177) | Bug fix for Util#receiveFile |  Minor | . | Tao Li | Tao Li |
+| [YARN-10814](https://issues.apache.org/jira/browse/YARN-10814) | YARN shouldn't start with empty hadoop.http.authentication.signature.secret.file |  Major | . | Benjamin Teke | Tamas Domok |
+| [HADOOP-17874](https://issues.apache.org/jira/browse/HADOOP-17874) | ExceptionsHandler to add terse/suppressed Exceptions in thread-safe manner |  Major | . | Viraj Jasani | Viraj Jasani |
+| [HADOOP-15129](https://issues.apache.org/jira/browse/HADOOP-15129) | Datanode caches namenode DNS lookup failure and cannot startup |  Minor | ipc | Karthik Palaniappan | Chris Nauroth |
+| [YARN-10901](https://issues.apache.org/jira/browse/YARN-10901) | Permission checking error on an existing directory in LogAggregationFileController#verifyAndCreateRemoteLogDir |  Major | nodemanager | Tamas Domok | Tamas Domok |
+| [HDFS-16207](https://issues.apache.org/jira/browse/HDFS-16207) | Remove NN logs stack trace for non-existent xattr query |  Major | namenode | Ahmed Hussein | Ahmed Hussein |
+| [HDFS-16187](https://issues.apache.org/jira/browse/HDFS-16187) | SnapshotDiff behaviour with Xattrs and Acls is not consistent across NN restarts with checkpointing |  Major | snapshots | Srinivasu Majeti | Shashikant Banerjee |
+| [HDFS-16198](https://issues.apache.org/jira/browse/HDFS-16198) | Short circuit read leaks Slot objects when InvalidToken exception is thrown |  Major | . | Eungsop Yoo | Eungsop Yoo |
+| [YARN-10870](https://issues.apache.org/jira/browse/YARN-10870) | Missing user filtering check -\> yarn.webapp.filter-entity-list-by-user for RM Scheduler page |  Major | yarn | Siddharth Ahuja | Gergely Pollák |
+| [HADOOP-17919](https://issues.apache.org/jira/browse/HADOOP-17919) | Fix command line example in Hadoop Cluster Setup documentation |  Minor | documentation | Rintaro Ikeda | Rintaro Ikeda |
+| [HDFS-16235](https://issues.apache.org/jira/browse/HDFS-16235) | Deadlock in LeaseRenewer for static remove method |  Major | hdfs | angerszhu | angerszhu |
+| [HDFS-16181](https://issues.apache.org/jira/browse/HDFS-16181) | [SBN Read] Fix metric of RpcRequestCacheMissAmount can't display when tailEditLog form JN |  Critical | . | wangzhaohui | wangzhaohui |
+| [HADOOP-17925](https://issues.apache.org/jira/browse/HADOOP-17925) | BUILDING.txt should not encourage to activate docs profile on building binary artifacts |  Minor | documentation | Rintaro Ikeda | Masatake Iwasaki |
+| [HADOOP-16532](https://issues.apache.org/jira/browse/HADOOP-16532) | Fix TestViewFsTrash to use the correct homeDir. |  Minor | test, viewfs | Steve Loughran | Xing Lin |
+| [HDFS-16268](https://issues.apache.org/jira/browse/HDFS-16268) | Balancer stuck when moving striped blocks due to NPE |  Major | balancer & mover, erasure-coding | Leon Gao | Leon Gao |
+| [HDFS-7612](https://issues.apache.org/jira/browse/HDFS-7612) | TestOfflineEditsViewer.testStored() uses incorrect default value for cacheDir |  Major | test | Konstantin Shvachko | Michael Kuchenbecker |
+| [HDFS-16311](https://issues.apache.org/jira/browse/HDFS-16311) | Metric metadataOperationRate calculation error in DataNodeVolumeMetrics |  Major | . | Tao Li | Tao Li |
+| [HDFS-16182](https://issues.apache.org/jira/browse/HDFS-16182) | numOfReplicas is given the wrong value in  BlockPlacementPolicyDefault$chooseTarget can cause DataStreamer to fail with Heterogeneous Storage |  Major | namanode | Max  Xie | Max  Xie |
+| [HADOOP-17999](https://issues.apache.org/jira/browse/HADOOP-17999) | No-op implementation of setWriteChecksum and setVerifyChecksum in ViewFileSystem |  Major | . | Abhishek Das | Abhishek Das |
+| [HDFS-16329](https://issues.apache.org/jira/browse/HDFS-16329) | Fix log format for BlockManager |  Minor | . | Tao Li | Tao Li |
+| [HDFS-16330](https://issues.apache.org/jira/browse/HDFS-16330) | Fix incorrect placeholder for Exception logs in DiskBalancer |  Major | . | Viraj Jasani | Viraj Jasani |
+| [HDFS-16328](https://issues.apache.org/jira/browse/HDFS-16328) | Correct disk balancer param desc |  Minor | documentation, hdfs | guophilipse | guophilipse |
+| [HDFS-16343](https://issues.apache.org/jira/browse/HDFS-16343) | Add some debug logs when the dfsUsed are not used during Datanode startup |  Major | datanode | Mukul Kumar Singh | Mukul Kumar Singh |
+| [YARN-10991](https://issues.apache.org/jira/browse/YARN-10991) | Fix to ignore the grouping "[]" for resourcesStr in parseResourcesString method |  Minor | distributed-shell | Ashutosh Gupta | Ashutosh Gupta |
+| [HADOOP-17975](https://issues.apache.org/jira/browse/HADOOP-17975) | Fallback to simple auth does not work for a secondary DistributedFileSystem instance |  Major | ipc | István Fajth | István Fajth |
+| [HDFS-16350](https://issues.apache.org/jira/browse/HDFS-16350) | Datanode start time should be set after RPC server starts successfully |  Minor | . | Viraj Jasani | Viraj Jasani |
+| [YARN-11007](https://issues.apache.org/jira/browse/YARN-11007) | Correct words in YARN documents |  Minor | documentation | guophilipse | guophilipse |
+| [HDFS-16332](https://issues.apache.org/jira/browse/HDFS-16332) | Expired block token causes slow read due to missing handling in sasl handshake |  Major | datanode, dfs, dfsclient | Shinya Yoshida | Shinya Yoshida |
+| [YARN-9063](https://issues.apache.org/jira/browse/YARN-9063) | ATS 1.5 fails to start if RollingLevelDb files are corrupt or missing |  Major | timelineserver, timelineservice | Tarun Parimi | Ashutosh Gupta |
+| [HDFS-16333](https://issues.apache.org/jira/browse/HDFS-16333) | fix balancer bug when transfer an EC block |  Major | balancer & mover, erasure-coding | qinyuren | qinyuren |
+| [HDFS-16373](https://issues.apache.org/jira/browse/HDFS-16373) | Fix MiniDFSCluster restart in case of multiple namenodes |  Major | . | Ayush Saxena | Ayush Saxena |
+| [HDFS-16377](https://issues.apache.org/jira/browse/HDFS-16377) | Should CheckNotNull before access FsDatasetSpi |  Major | . | Tao Li | Tao Li |
+| [YARN-6862](https://issues.apache.org/jira/browse/YARN-6862) | Nodemanager resource usage metrics sometimes are negative |  Major | nodemanager | YunFan Zhou | Benjamin Teke |
+| [YARN-10178](https://issues.apache.org/jira/browse/YARN-10178) | Global Scheduler async thread crash caused by 'Comparison method violates its general contract |  Major | capacity scheduler | tuyu | Andras Gyori |
+| [HDFS-16395](https://issues.apache.org/jira/browse/HDFS-16395) | Remove useless NNThroughputBenchmark#dummyActionNoSynch() |  Major | benchmarks, namenode | JiangHua Zhu | JiangHua Zhu |
+| [HADOOP-18063](https://issues.apache.org/jira/browse/HADOOP-18063) | Remove unused import AbstractJavaKeyStoreProvider in Shell class |  Minor | . | JiangHua Zhu | JiangHua Zhu |
+| [HDFS-16409](https://issues.apache.org/jira/browse/HDFS-16409) | Fix typo: testHasExeceptionsReturnsCorrectValue -\> testHasExceptionsReturnsCorrectValue |  Trivial | . | Ashutosh Gupta | Ashutosh Gupta |
+| [HDFS-16408](https://issues.apache.org/jira/browse/HDFS-16408) | Ensure LeaseRecheckIntervalMs is greater than zero |  Major | namenode | Jingxuan Fu | Jingxuan Fu |
+| [YARN-11055](https://issues.apache.org/jira/browse/YARN-11055) | In cgroups-operations.c some fprintf format strings don't end with "\\n" |  Minor | nodemanager | Gera Shegalov | Gera Shegalov |
+| [HDFS-16303](https://issues.apache.org/jira/browse/HDFS-16303) | Losing over 100 datanodes in state decommissioning results in full blockage of all datanode decommissioning |  Major | . | Kevin Wikant | Kevin Wikant |
+| [HDFS-16443](https://issues.apache.org/jira/browse/HDFS-16443) | Fix edge case where DatanodeAdminDefaultMonitor doubly enqueues a DatanodeDescriptor on exception |  Major | hdfs | Kevin Wikant | Kevin Wikant |
+| [HDFS-16449](https://issues.apache.org/jira/browse/HDFS-16449) | Fix hadoop web site release notes and changelog not available |  Minor | documentation | guophilipse | guophilipse |
+| [HADOOP-18192](https://issues.apache.org/jira/browse/HADOOP-18192) | Fix multiple\_bindings warning about slf4j-reload4j |  Major | . | Masatake Iwasaki | Masatake Iwasaki |
+| [HDFS-16479](https://issues.apache.org/jira/browse/HDFS-16479) | EC: NameNode should not send a reconstruction work when the source datanodes are insufficient |  Critical | ec, erasure-coding | Yuanbo Liu | Takanobu Asanuma |
+| [HDFS-16509](https://issues.apache.org/jira/browse/HDFS-16509) | Fix decommission UnsupportedOperationException: Remove unsupported |  Major | namenode | daimin | daimin |
+| [HDFS-16456](https://issues.apache.org/jira/browse/HDFS-16456) | EC: Decommission a rack with only on dn will fail when the rack number is equal with replication |  Critical | ec, namenode | caozhiqiang | caozhiqiang |
+| [HDFS-16437](https://issues.apache.org/jira/browse/HDFS-16437) | ReverseXML processor doesn't accept XML files without the SnapshotDiffSection. |  Critical | hdfs | yanbin.zhang | yanbin.zhang |
+| [HDFS-16507](https://issues.apache.org/jira/browse/HDFS-16507) | [SBN read] Avoid purging edit log which is in progress |  Critical | . | Tao Li | Tao Li |
+| [YARN-10720](https://issues.apache.org/jira/browse/YARN-10720) | YARN WebAppProxyServlet should support connection timeout to prevent proxy server from hanging |  Critical | . | Qi Zhu | Qi Zhu |
+| [HDFS-16428](https://issues.apache.org/jira/browse/HDFS-16428) | Source path with storagePolicy cause wrong typeConsumed while rename |  Major | hdfs, namenode | lei w | lei w |
+| [YARN-11014](https://issues.apache.org/jira/browse/YARN-11014) | YARN incorrectly validates maximum capacity resources on the validation API |  Major | . | Benjamin Teke | Benjamin Teke |
+| [YARN-11075](https://issues.apache.org/jira/browse/YARN-11075) | Explicitly declare serialVersionUID in LogMutation class |  Major | . | Benjamin Teke | Benjamin Teke |
+| [HDFS-11041](https://issues.apache.org/jira/browse/HDFS-11041) | Unable to unregister FsDatasetState MBean if DataNode is shutdown twice |  Trivial | datanode | Wei-Chiu Chuang | Wei-Chiu Chuang |
+| [HDFS-16538](https://issues.apache.org/jira/browse/HDFS-16538) |  EC decoding failed due to not enough valid inputs |  Major | erasure-coding | qinyuren | qinyuren |
+| [HDFS-16544](https://issues.apache.org/jira/browse/HDFS-16544) | EC decoding failed due to invalid buffer |  Major | erasure-coding | qinyuren | qinyuren |
+| [HDFS-16546](https://issues.apache.org/jira/browse/HDFS-16546) | Fix UT TestOfflineImageViewer#testReverseXmlWithoutSnapshotDiffSection to branch branch-3.2 |  Major | test | daimin | daimin |
+| [HDFS-16552](https://issues.apache.org/jira/browse/HDFS-16552) | Fix NPE for TestBlockManager |  Major | . | Tao Li | Tao Li |
+| [MAPREDUCE-7246](https://issues.apache.org/jira/browse/MAPREDUCE-7246) |  In MapredAppMasterRest#Mapreduce\_Application\_Master\_Info\_API, the datatype of appId should be "string". |  Major | documentation | jenny | Ashutosh Gupta |
+| [YARN-10187](https://issues.apache.org/jira/browse/YARN-10187) | Removing hadoop-yarn-project/hadoop-yarn/README as it is no longer maintained. |  Minor | documentation | N Sanketh Reddy | Ashutosh Gupta |
+| [HDFS-16185](https://issues.apache.org/jira/browse/HDFS-16185) | Fix comment in LowRedundancyBlocks.java |  Minor | documentation | Akira Ajisaka | Ashutosh Gupta |
+| [HADOOP-17479](https://issues.apache.org/jira/browse/HADOOP-17479) | Fix the examples of hadoop config prefix |  Minor | documentation | Akira Ajisaka | Ashutosh Gupta |
+| [HDFS-16579](https://issues.apache.org/jira/browse/HDFS-16579) | Fix build failure for TestBlockManager on branch-3.2 |  Major | . | Tao Li | Tao Li |
+| [YARN-11092](https://issues.apache.org/jira/browse/YARN-11092) | Upgrade jquery ui to 1.13.1 |  Major | . | D M Murali Krishna Reddy | Ashutosh Gupta |
+| [YARN-11133](https://issues.apache.org/jira/browse/YARN-11133) | YarnClient gets the wrong EffectiveMinCapacity value |  Major | api | Zilong Zhu | Zilong Zhu |
+| [YARN-10850](https://issues.apache.org/jira/browse/YARN-10850) | TimelineService v2 lists containers for all attempts when filtering for one |  Major | timelinereader | Benjamin Teke | Benjamin Teke |
+| [YARN-11126](https://issues.apache.org/jira/browse/YARN-11126) | ZKConfigurationStore Java deserialisation vulnerability |  Major | yarn | Tamas Domok | Tamas Domok |
+| [YARN-11162](https://issues.apache.org/jira/browse/YARN-11162) | Set the zk acl for nodes created by ZKConfigurationStore. |  Major | resourcemanager | Owen O'Malley | Owen O'Malley |
+| [HDFS-16586](https://issues.apache.org/jira/browse/HDFS-16586) | Purge FsDatasetAsyncDiskService threadgroup; it causes BPServiceActor$CommandProcessingThread IllegalThreadStateException 'fatal exception and exit' |  Major | datanode | Michael Stack | Michael Stack |
+| [HADOOP-18251](https://issues.apache.org/jira/browse/HADOOP-18251) | Fix failure of extracting JIRA id from commit message in git\_jira\_fix\_version\_check.py |  Minor | build | Masatake Iwasaki | Masatake Iwasaki |
+| [HDFS-16583](https://issues.apache.org/jira/browse/HDFS-16583) | DatanodeAdminDefaultMonitor can get stuck in an infinite loop |  Major | . | Stephen O'Donnell | Stephen O'Donnell |
+| [HDFS-16623](https://issues.apache.org/jira/browse/HDFS-16623) | IllegalArgumentException in LifelineSender |  Major | . | ZanderXu | ZanderXu |
+| [HDFS-16064](https://issues.apache.org/jira/browse/HDFS-16064) | Determine when to invalidate corrupt replicas based on number of usable replicas |  Major | datanode, namenode | Kevin Wikant | Kevin Wikant |
+| [HADOOP-18100](https://issues.apache.org/jira/browse/HADOOP-18100) | Change scope of inner classes in InodeTree to make them accessible outside package |  Major | . | Abhishek Das | Abhishek Das |
+| [HADOOP-18334](https://issues.apache.org/jira/browse/HADOOP-18334) | Fix create-release to address removal of GPG\_AGENT\_INFO in branch-3.2 |  Major | build | Masatake Iwasaki | Masatake Iwasaki |
+
+
+### TESTS:
+
+| JIRA | Summary | Priority | Component | Reporter | Contributor |
+|:---- |:---- | :--- |:---- |:---- |:---- |
+| [MAPREDUCE-7342](https://issues.apache.org/jira/browse/MAPREDUCE-7342) | Stop RMService in TestClientRedirect.testRedirect() |  Minor | . | Zhengxi Li | Zhengxi Li |
+| [MAPREDUCE-7311](https://issues.apache.org/jira/browse/MAPREDUCE-7311) | Fix non-idempotent test in TestTaskProgressReporter |  Minor | . | Zhengxi Li | Zhengxi Li |
+| [HDFS-15862](https://issues.apache.org/jira/browse/HDFS-15862) | Make TestViewfsWithNfs3.testNfsRenameSingleNN() idempotent |  Minor | nfs | Zhengxi Li | Zhengxi Li |
+
+
+### SUB-TASKS:
+
+| JIRA | Summary | Priority | Component | Reporter | Contributor |
+|:---- |:---- | :--- |:---- |:---- |:---- |
+| [HDFS-15457](https://issues.apache.org/jira/browse/HDFS-15457) | TestFsDatasetImpl fails intermittently |  Major | hdfs | Ahmed Hussein | Ahmed Hussein |
+| [HDFS-15818](https://issues.apache.org/jira/browse/HDFS-15818) | Fix TestFsDatasetImpl.testReadLockCanBeDisabledByConfig |  Minor | test | Leon Gao | Leon Gao |
+| [YARN-10503](https://issues.apache.org/jira/browse/YARN-10503) | Support queue capacity in terms of absolute resources with custom resourceType. |  Critical | . | Qi Zhu | Qi Zhu |
+| [HADOOP-17126](https://issues.apache.org/jira/browse/HADOOP-17126) | implement non-guava Precondition checkNotNull |  Major | . | Ahmed Hussein | Ahmed Hussein |
+| [HADOOP-17929](https://issues.apache.org/jira/browse/HADOOP-17929) | implement non-guava Precondition checkArgument |  Major | . | Ahmed Hussein | Ahmed Hussein |
+| [HADOOP-17947](https://issues.apache.org/jira/browse/HADOOP-17947) | Provide alternative to Guava VisibleForTesting |  Major | . | Viraj Jasani | Viraj Jasani |
+| [HADOOP-17930](https://issues.apache.org/jira/browse/HADOOP-17930) | implement non-guava Precondition checkState |  Major | . | Ahmed Hussein | Ahmed Hussein |
+| [HADOOP-17374](https://issues.apache.org/jira/browse/HADOOP-17374) | AliyunOSS: support ListObjectsV2 |  Major | fs/oss | wujinhu | wujinhu |
+| [HDFS-16336](https://issues.apache.org/jira/browse/HDFS-16336) | De-flake TestRollingUpgrade#testRollback |  Minor | hdfs, test | Kevin Wikant | Viraj Jasani |
+| [HDFS-16171](https://issues.apache.org/jira/browse/HDFS-16171) | De-flake testDecommissionStatus |  Major | . | Viraj Jasani | Viraj Jasani |
+| [HDFS-16169](https://issues.apache.org/jira/browse/HDFS-16169) | Fix TestBlockTokenWithDFSStriped#testEnd2End failure |  Major | test | Hui Fei | secfree |
+| [HDFS-16484](https://issues.apache.org/jira/browse/HDFS-16484) | [SPS]: Fix an infinite loop bug in SPSPathIdProcessor thread |  Major | . | qinyuren | qinyuren |
+| [HADOOP-16663](https://issues.apache.org/jira/browse/HADOOP-16663) | Backport "HADOOP-16560 [YARN] use protobuf-maven-plugin to generate protobuf classes" to all active branches |  Major | . | Duo Zhang | Duo Zhang |
+| [HADOOP-16664](https://issues.apache.org/jira/browse/HADOOP-16664) | Backport "HADOOP-16561 [MAPREDUCE] use protobuf-maven-plugin to generate protobuf classes" to all active branches |  Major | . | Duo Zhang | Duo Zhang |
+
+
+### OTHER:
+
+| JIRA | Summary | Priority | Component | Reporter | Contributor |
+|:---- |:---- | :--- |:---- |:---- |:---- |
+| [HDFS-16298](https://issues.apache.org/jira/browse/HDFS-16298) | Improve error msg for BlockMissingException |  Minor | . | Tao Li | Tao Li |
+| [HDFS-16312](https://issues.apache.org/jira/browse/HDFS-16312) | Fix typo for DataNodeVolumeMetrics and ProfilingFileIoEvents |  Minor | . | Tao Li | Tao Li |
+| [HDFS-16326](https://issues.apache.org/jira/browse/HDFS-16326) | Simplify the code for DiskBalancer |  Minor | . | Tao Li | Tao Li |
+| [HDFS-16339](https://issues.apache.org/jira/browse/HDFS-16339) | Show the threshold when mover threads quota is exceeded |  Minor | . | Tao Li | Tao Li |
+| [YARN-10820](https://issues.apache.org/jira/browse/YARN-10820) | Make GetClusterNodesRequestPBImpl thread safe |  Major | client | Prabhu Joseph | SwathiChandrashekar |
+| [HADOOP-13464](https://issues.apache.org/jira/browse/HADOOP-13464) | update GSON to 2.7+ |  Minor | build | Sean Busbey | Igor Dvorzhak |
+| [HADOOP-18191](https://issues.apache.org/jira/browse/HADOOP-18191) | Log retry count while handling exceptions in RetryInvocationHandler |  Minor | . | Viraj Jasani | Viraj Jasani |
+| [HDFS-16551](https://issues.apache.org/jira/browse/HDFS-16551) | Backport HADOOP-17588 to 3.3 and other active old branches. |  Major | . | Renukaprasad C | Renukaprasad C |
+| [HDFS-16618](https://issues.apache.org/jira/browse/HDFS-16618) | sync\_file\_range error should include more volume and file info |  Minor | . | Viraj Jasani | Viraj Jasani |
+| [HADOOP-18300](https://issues.apache.org/jira/browse/HADOOP-18300) | Update Gson to 2.9.0 |  Minor | build | Igor Dvorzhak | Igor Dvorzhak |
+
+
diff --git a/hadoop-common-project/hadoop-common/src/site/markdown/release/3.2.4/RELEASENOTES.3.2.4.md b/hadoop-common-project/hadoop-common/src/site/markdown/release/3.2.4/RELEASENOTES.3.2.4.md
new file mode 100644
index 000000000000..fac976d655da
--- /dev/null
+++ b/hadoop-common-project/hadoop-common/src/site/markdown/release/3.2.4/RELEASENOTES.3.2.4.md
@@ -0,0 +1,55 @@
+
+<!---
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# "License"); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+-->
+# Apache Hadoop  3.2.4 Release Notes
+
+These release notes cover new developer and user-facing incompatibilities, important issues, features, and major improvements.
+
+
+---
+
+* [YARN-10820](https://issues.apache.org/jira/browse/YARN-10820) | *Major* | **Make GetClusterNodesRequestPBImpl thread safe**
+
+Added syncronization so that the "yarn node list" command does not fail intermittently
+
+
+---
+
+* [YARN-8234](https://issues.apache.org/jira/browse/YARN-8234) | *Critical* | **Improve RM system metrics publisher's performance by pushing events to timeline server in batch**
+
+When Timeline Service V1 or V1.5 is used, if "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch" is set to true, ResourceManager sends timeline events in batch. The default value is false. If this functionality is enabled, the maximum number that events published in batch is configured by "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size". The default value is 1000. The interval of publishing events can be configured by "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds". By default, it is set to 60 seconds.
+
+
+---
+
+* [HADOOP-18088](https://issues.apache.org/jira/browse/HADOOP-18088) | *Major* | **Replace log4j 1.x with reload4j**
+
+log4j 1 was replaced with reload4j which is fork of log4j 1.2.17 with the goal of fixing pressing security issues.
+
+If you are depending on the hadoop artifacts in your build were explicitly excluding log4 artifacts, and now want to exclude the reload4j files, you will need to update your exclusion lists
+\<exclusion\>
+  \<groupId\>org.slf4j\</groupId\>
+  \<artifactId\>slf4j-reload4j\</artifactId\>
+\</exclusion\>
+\<exclusion\>
+  \<groupId\>ch.qos.reload4j\</groupId\>
+  \<artifactId\>reload4j\</artifactId\>
+\</exclusion\>
+
+
+
diff --git a/hadoop-hdfs-project/hadoop-hdfs/dev-support/jdiff/Apache_Hadoop_HDFS_3.2.4.xml b/hadoop-hdfs-project/hadoop-hdfs/dev-support/jdiff/Apache_Hadoop_HDFS_3.2.4.xml
new file mode 100644
index 000000000000..2aa6ef1cdb5b
--- /dev/null
+++ b/hadoop-hdfs-project/hadoop-hdfs/dev-support/jdiff/Apache_Hadoop_HDFS_3.2.4.xml
@@ -0,0 +1,674 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:52:30 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop HDFS 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-annotations.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs/target/jdiff.jar -verbose -classpath /build/source/hadoop-hdfs-project/hadoop-hdfs/target/classes:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-hdfs-client-3.2.4.jar:/maven/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/maven/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/org/slf4j/slf4j-reload4j/1.7.35/slf4j-reload4j-1.7.35.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/io/netty/netty-all/4.1.68.Final/netty-all-4.1.68.Final.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-hdfs-project/hadoop-hdfs/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-annotations.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs/target/jdiff.jar -apidir /build/source/hadoop-hdfs-project/hadoop-hdfs/target/site/jdiff/xml -apiname Apache Hadoop HDFS 3.2.4 -->
+<package name="org.apache.hadoop.hdfs">
+  <doc>
+  <![CDATA[<p>A distributed implementation of {@link
+org.apache.hadoop.fs.FileSystem}.  This is loosely modelled after
+Google's <a href="http://research.google.com/archive/gfs.html">GFS</a>.</p>
+
+<p>The most important difference is that unlike GFS, Hadoop DFS files 
+have strictly one writer at any one time.  Bytes are always appended 
+to the end of the writer's stream.  There is no notion of "record appends"
+or "mutations" that are then checked or reordered.  Writers simply emit 
+a byte stream.  That byte stream is guaranteed to be stored in the 
+order written.</p>]]>
+  </doc>
+</package>
+<package name="org.apache.hadoop.hdfs.net">
+</package>
+<package name="org.apache.hadoop.hdfs.protocol">
+</package>
+<package name="org.apache.hadoop.hdfs.protocol.datatransfer">
+</package>
+<package name="org.apache.hadoop.hdfs.protocol.datatransfer.sasl">
+</package>
+<package name="org.apache.hadoop.hdfs.protocolPB">
+</package>
+<package name="org.apache.hadoop.hdfs.qjournal.client">
+</package>
+<package name="org.apache.hadoop.hdfs.qjournal.protocol">
+</package>
+<package name="org.apache.hadoop.hdfs.qjournal.protocolPB">
+</package>
+<package name="org.apache.hadoop.hdfs.qjournal.server">
+  <!-- start interface org.apache.hadoop.hdfs.qjournal.server.JournalNodeMXBean -->
+  <interface name="JournalNodeMXBean"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getJournalsStatus" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get status information (e.g., whether formatted) of JournalNode's journals.
+ 
+ @return A string presenting status for each journal]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This is the JMX management interface for JournalNode information]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.hdfs.qjournal.server.JournalNodeMXBean -->
+</package>
+<package name="org.apache.hadoop.hdfs.security.token.block">
+</package>
+<package name="org.apache.hadoop.hdfs.security.token.delegation">
+</package>
+<package name="org.apache.hadoop.hdfs.server.aliasmap">
+  <!-- start class org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap -->
+  <class name="InMemoryAliasMap" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol"/>
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="init" return="org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="list" return="org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMapProtocol.IterationResult"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="marker" type="java.util.Optional"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="read" return="java.util.Optional"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
+      <param name="providedStorageLocation" type="org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getBlockPoolId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="fromProvidedStorageLocationBytes" return="org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="providedStorageLocationDbFormat" type="byte[]"/>
+      <exception name="InvalidProtocolBufferException" type="com.google.protobuf.InvalidProtocolBufferException"/>
+    </method>
+    <method name="fromBlockBytes" return="org.apache.hadoop.hdfs.protocol.Block"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="blockDbFormat" type="byte[]"/>
+      <exception name="InvalidProtocolBufferException" type="com.google.protobuf.InvalidProtocolBufferException"/>
+    </method>
+    <method name="toProtoBufBytes" return="byte[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="providedStorageLocation" type="org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="toProtoBufBytes" return="byte[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="block" type="org.apache.hadoop.hdfs.protocol.Block"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[InMemoryAliasMap is an implementation of the InMemoryAliasMapProtocol for
+ use with LevelDB.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap -->
+</package>
+<package name="org.apache.hadoop.hdfs.server.balancer">
+</package>
+<package name="org.apache.hadoop.hdfs.server.blockmanagement">
+</package>
+<package name="org.apache.hadoop.hdfs.server.common">
+  <!-- start interface org.apache.hadoop.hdfs.server.common.BlockAlias -->
+  <interface name="BlockAlias"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getBlock" return="org.apache.hadoop.hdfs.protocol.Block"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Interface used to load provided blocks.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.hdfs.server.common.BlockAlias -->
+  <!-- start class org.apache.hadoop.hdfs.server.common.FileRegion -->
+  <class name="FileRegion" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.hdfs.server.common.BlockAlias"/>
+    <constructor name="FileRegion" type="long, org.apache.hadoop.fs.Path, long, long, long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FileRegion" type="long, org.apache.hadoop.fs.Path, long, long, long, byte[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FileRegion" type="long, org.apache.hadoop.fs.Path, long, long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FileRegion" type="org.apache.hadoop.hdfs.protocol.Block, org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getBlock" return="org.apache.hadoop.hdfs.protocol.Block"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProvidedStorageLocation" return="org.apache.hadoop.hdfs.protocol.ProvidedStorageLocation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[This class is used to represent provided blocks that are file regions,
+ i.e., can be described using (path, offset, length).]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.common.FileRegion -->
+</package>
+<package name="org.apache.hadoop.hdfs.server.common.blockaliasmap">
+  <!-- start class org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap -->
+  <class name="BlockAliasMap" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="BlockAliasMap"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getReader" return="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Reader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="opts" type="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Reader.Options"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns a reader to the alias map.
+ @param opts reader options
+ @param blockPoolID block pool id to use
+ @return {@link Reader} to the alias map. If a Reader for the blockPoolID
+ cannot be created, this will return null.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getWriter" return="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Writer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="opts" type="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Writer.Options"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns the writer for the alias map.
+ @param opts writer options.
+ @param blockPoolID block pool id to use
+ @return {@link Writer} to the alias map.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="refresh"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Refresh the alias map.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An abstract class used to read and write block maps for provided blocks.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap -->
+</package>
+<package name="org.apache.hadoop.hdfs.server.common.blockaliasmap.impl">
+  <!-- start class org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.LevelDBFileRegionAliasMap -->
+  <class name="LevelDBFileRegionAliasMap" extends="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="LevelDBFileRegionAliasMap"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getReader" return="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Reader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="opts" type="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Reader.Options"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getWriter" return="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Writer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="opts" type="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Writer.Options"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="refresh"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A LevelDB based implementation of {@link BlockAliasMap}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.LevelDBFileRegionAliasMap -->
+  <!-- start class org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap -->
+  <class name="TextFileRegionAliasMap" extends="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="TextFileRegionAliasMap"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getReader" return="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Reader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="opts" type="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Reader.Options"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getWriter" return="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Writer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="opts" type="org.apache.hadoop.hdfs.server.common.blockaliasmap.BlockAliasMap.Writer.Options"/>
+      <param name="blockPoolID" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="refresh"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="blockPoolIDFromFileName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="fileNameFromBlockPoolID" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="blockPoolID" type="java.lang.String"/>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class is used for block maps stored as text files,
+ with a specified delimiter.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.common.blockaliasmap.impl.TextFileRegionAliasMap -->
+</package>
+<package name="org.apache.hadoop.hdfs.server.datanode">
+</package>
+<package name="org.apache.hadoop.hdfs.server.datanode.fsdataset">
+</package>
+<package name="org.apache.hadoop.hdfs.server.datanode.fsdataset.impl">
+</package>
+<package name="org.apache.hadoop.hdfs.server.datanode.metrics">
+</package>
+<package name="org.apache.hadoop.hdfs.server.datanode.web">
+</package>
+<package name="org.apache.hadoop.hdfs.server.datanode.web.webhdfs">
+</package>
+<package name="org.apache.hadoop.hdfs.server.diskbalancer">
+</package>
+<package name="org.apache.hadoop.hdfs.server.diskbalancer.command">
+</package>
+<package name="org.apache.hadoop.hdfs.server.diskbalancer.connectors">
+</package>
+<package name="org.apache.hadoop.hdfs.server.diskbalancer.datamodel">
+</package>
+<package name="org.apache.hadoop.hdfs.server.diskbalancer.planner">
+</package>
+<package name="org.apache.hadoop.hdfs.server.mover">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode">
+  <!-- start interface org.apache.hadoop.hdfs.server.namenode.AuditLogger -->
+  <interface name="AuditLogger"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="initialize"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Called during initialization of the logger.
+
+ @param conf The configuration object.]]>
+      </doc>
+    </method>
+    <method name="logAuditEvent"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="succeeded" type="boolean"/>
+      <param name="userName" type="java.lang.String"/>
+      <param name="addr" type="java.net.InetAddress"/>
+      <param name="cmd" type="java.lang.String"/>
+      <param name="src" type="java.lang.String"/>
+      <param name="dst" type="java.lang.String"/>
+      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
+      <doc>
+      <![CDATA[Called to log an audit event.
+ <p>
+ This method must return as quickly as possible, since it's called
+ in a critical section of the NameNode's operation.
+
+ @param succeeded Whether authorization succeeded.
+ @param userName Name of the user executing the request.
+ @param addr Remote address of the request.
+ @param cmd The requested command.
+ @param src Path of affected source file.
+ @param dst Path of affected destination file (if any).
+ @param stat File information for operations that change the file's
+             metadata (permissions, owner, times, etc).]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Interface defining an audit logger.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.hdfs.server.namenode.AuditLogger -->
+  <!-- start class org.apache.hadoop.hdfs.server.namenode.HdfsAuditLogger -->
+  <class name="HdfsAuditLogger" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.hdfs.server.namenode.AuditLogger"/>
+    <constructor name="HdfsAuditLogger"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="logAuditEvent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="succeeded" type="boolean"/>
+      <param name="userName" type="java.lang.String"/>
+      <param name="addr" type="java.net.InetAddress"/>
+      <param name="cmd" type="java.lang.String"/>
+      <param name="src" type="java.lang.String"/>
+      <param name="dst" type="java.lang.String"/>
+      <param name="status" type="org.apache.hadoop.fs.FileStatus"/>
+    </method>
+    <method name="logAuditEvent"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="succeeded" type="boolean"/>
+      <param name="userName" type="java.lang.String"/>
+      <param name="addr" type="java.net.InetAddress"/>
+      <param name="cmd" type="java.lang.String"/>
+      <param name="src" type="java.lang.String"/>
+      <param name="dst" type="java.lang.String"/>
+      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
+      <param name="callerContext" type="org.apache.hadoop.ipc.CallerContext"/>
+      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
+      <param name="dtSecretManager" type="org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager"/>
+      <doc>
+      <![CDATA[Same as
+ {@link #logAuditEvent(boolean, String, InetAddress, String, String, String,
+ FileStatus)} with additional parameters related to logging delegation token
+ tracking IDs.
+ 
+ @param succeeded Whether authorization succeeded.
+ @param userName Name of the user executing the request.
+ @param addr Remote address of the request.
+ @param cmd The requested command.
+ @param src Path of affected source file.
+ @param dst Path of affected destination file (if any).
+ @param stat File information for operations that change the file's metadata
+          (permissions, owner, times, etc).
+ @param callerContext Context information of the caller
+ @param ugi UserGroupInformation of the current user, or null if not logging
+          token tracking information
+ @param dtSecretManager The token secret manager, or null if not logging
+          token tracking information]]>
+      </doc>
+    </method>
+    <method name="logAuditEvent"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="succeeded" type="boolean"/>
+      <param name="userName" type="java.lang.String"/>
+      <param name="addr" type="java.net.InetAddress"/>
+      <param name="cmd" type="java.lang.String"/>
+      <param name="src" type="java.lang.String"/>
+      <param name="dst" type="java.lang.String"/>
+      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
+      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
+      <param name="dtSecretManager" type="org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenSecretManager"/>
+      <doc>
+      <![CDATA[Same as
+ {@link #logAuditEvent(boolean, String, InetAddress, String, String,
+ String, FileStatus, CallerContext, UserGroupInformation,
+ DelegationTokenSecretManager)} without {@link CallerContext} information.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Extension of {@link AuditLogger}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.namenode.HdfsAuditLogger -->
+  <!-- start class org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider -->
+  <class name="INodeAttributeProvider" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="INodeAttributeProvider"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="start"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Initialize the provider. This method is called at NameNode startup
+ time.]]>
+      </doc>
+    </method>
+    <method name="stop"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Shutdown the provider. This method is called at NameNode shutdown time.]]>
+      </doc>
+    </method>
+    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fullPath" type="java.lang.String"/>
+      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
+    </method>
+    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pathElements" type="java.lang.String[]"/>
+      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
+    </method>
+    <method name="getAttributes" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="components" type="byte[][]"/>
+      <param name="inode" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributes"/>
+    </method>
+    <method name="getExternalAccessControlEnforcer" return="org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider.AccessControlEnforcer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="defaultEnforcer" type="org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider.AccessControlEnforcer"/>
+      <doc>
+      <![CDATA[Can be over-ridden by implementations to provide a custom Access Control
+ Enforcer that can provide an alternate implementation of the
+ default permission checking logic.
+ @param defaultEnforcer The Default AccessControlEnforcer
+ @return The AccessControlEnforcer to use]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.hdfs.server.namenode.INodeAttributeProvider -->
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.ha">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.metrics">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.snapshot">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.top">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.top.metrics">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.top.window">
+</package>
+<package name="org.apache.hadoop.hdfs.server.namenode.web.resources">
+</package>
+<package name="org.apache.hadoop.hdfs.tools">
+</package>
+<package name="org.apache.hadoop.hdfs.tools.offlineEditsViewer">
+</package>
+<package name="org.apache.hadoop.hdfs.tools.offlineImageViewer">
+</package>
+<package name="org.apache.hadoop.hdfs.tools.snapshot">
+</package>
+<package name="org.apache.hadoop.hdfs.util">
+</package>
+<package name="org.apache.hadoop.hdfs.web">
+</package>
+<package name="org.apache.hadoop.hdfs.web.resources">
+</package>
+
+</api>
diff --git a/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_Common_3.2.4.xml b/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_Common_3.2.4.xml
new file mode 100644
index 000000000000..ff74bb7afb25
--- /dev/null
+++ b/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_Common_3.2.4.xml
@@ -0,0 +1,113 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:57:31 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop MapReduce Common 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/hadoop-annotations.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/jdiff.jar -verbose -classpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/classes:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-3.2.4.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.2.4.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/com/google/inject/guice/4.0/guice-4.0.jar:/maven/javax/inject/javax.inject/1/javax.inject-1.jar:/maven/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.5/jackson-module-jaxb-annotations-2.10.5.jar:/maven/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/maven/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.5/jackson-jaxrs-json-provider-2.10.5.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.5/jackson-jaxrs-base-2.10.5.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/hadoop-yarn-client-3.2.4.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/hadoop-mapreduce-client-core-3.2.4.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/slf4j/slf4j-reload4j/1.7.35/slf4j-reload4j-1.7.35.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/maven/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/hadoop-annotations.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/jdiff.jar -apidir /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/site/jdiff/xml -apiname Apache Hadoop MapReduce Common 3.2.4 -->
+<package name="org.apache.hadoop.mapred">
+</package>
+<package name="org.apache.hadoop.mapreduce">
+</package>
+<package name="org.apache.hadoop.mapreduce.v2.api.protocolrecords">
+  <!-- start interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.CancelDelegationTokenRequest -->
+  <interface name="CancelDelegationTokenRequest"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getDelegationToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setDelegationToken"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dToken" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <doc>
+    <![CDATA[The request issued by the client to the {@code ResourceManager} to cancel a
+ delegation token.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.CancelDelegationTokenRequest -->
+  <!-- start interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.CancelDelegationTokenResponse -->
+  <interface name="CancelDelegationTokenResponse"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <doc>
+    <![CDATA[The response from the {@code ResourceManager} to a cancelDelegationToken
+ request.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.CancelDelegationTokenResponse -->
+  <!-- start interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetDelegationTokenRequest -->
+  <interface name="GetDelegationTokenRequest"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getRenewer" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setRenewer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="java.lang.String"/>
+    </method>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.GetDelegationTokenRequest -->
+  <!-- start interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.RenewDelegationTokenRequest -->
+  <interface name="RenewDelegationTokenRequest"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getDelegationToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setDelegationToken"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dToken" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <doc>
+    <![CDATA[The request issued by the client to renew a delegation token from
+ the {@code ResourceManager}.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.RenewDelegationTokenRequest -->
+  <!-- start interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.RenewDelegationTokenResponse -->
+  <interface name="RenewDelegationTokenResponse"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getNextExpirationTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setNextExpirationTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="expTime" type="long"/>
+    </method>
+    <doc>
+    <![CDATA[The response to a renewDelegationToken call to the {@code ResourceManager}.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.v2.api.protocolrecords.RenewDelegationTokenResponse -->
+</package>
+<package name="org.apache.hadoop.mapreduce.v2.security">
+</package>
+<package name="org.apache.hadoop.yarn.proto">
+</package>
+
+</api>
diff --git a/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_Core_3.2.4.xml b/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_Core_3.2.4.xml
new file mode 100644
index 000000000000..239b01b46126
--- /dev/null
+++ b/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_Core_3.2.4.xml
@@ -0,0 +1,28073 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:57:12 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop MapReduce Core 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/hadoop-annotations.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/jdiff.jar -verbose -classpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/classes:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/hadoop-yarn-client-3.2.4.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.2.4.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-3.2.4.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/com/google/inject/guice/4.0/guice-4.0.jar:/maven/javax/inject/javax.inject/1/javax.inject-1.jar:/maven/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.5/jackson-module-jaxb-annotations-2.10.5.jar:/maven/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/maven/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.5/jackson-jaxrs-json-provider-2.10.5.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.5/jackson-jaxrs-base-2.10.5.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-hdfs-client-3.2.4.jar:/maven/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/maven/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/slf4j/slf4j-reload4j/1.7.35/slf4j-reload4j-1.7.35.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/hadoop-annotations.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/jdiff.jar -apidir /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/site/jdiff/xml -apiname Apache Hadoop MapReduce Core 3.2.4 -->
+<package name="org.apache.hadoop.filecache">
+  <!-- start class org.apache.hadoop.filecache.DistributedCache -->
+  <class name="DistributedCache" extends="org.apache.hadoop.mapreduce.filecache.DistributedCache"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="DistributedCache"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addLocalArchives"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="str" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Add a archive that has been localized to the conf.  Used
+ by internal DistributedCache code.
+ @param conf The conf to modify to contain the localized caches
+ @param str a comma separated list of local archives]]>
+      </doc>
+    </method>
+    <method name="addLocalFiles"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="str" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Add a file that has been localized to the conf..  Used
+ by internal DistributedCache code.
+ @param conf The conf to modify to contain the localized caches
+ @param str a comma separated list of local files]]>
+      </doc>
+    </method>
+    <method name="createAllSymlink"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Internal to MapReduce framework.  Use DistributedCacheManager
+ instead.">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="jobCacheDir" type="java.io.File"/>
+      <param name="workDir" type="java.io.File"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method create symlinks for all files in a given dir in another
+ directory. Currently symlinks cannot be disabled. This is a NO-OP.
+
+ @param conf the configuration
+ @param jobCacheDir the target directory for creating symlinks
+ @param workDir the directory in which the symlinks are created
+ @throws IOException
+ @deprecated Internal to MapReduce framework.  Use DistributedCacheManager
+ instead.]]>
+      </doc>
+    </method>
+    <method name="getFileStatus" return="org.apache.hadoop.fs.FileStatus"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="cache" type="java.net.URI"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns {@link FileStatus} of a given cache file on hdfs. Internal to
+ MapReduce.
+ @param conf configuration
+ @param cache cache file
+ @return <code>FileStatus</code> of a given cache file on hdfs
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getTimestamp" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="cache" type="java.net.URI"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns mtime of a given cache file on hdfs. Internal to MapReduce.
+ @param conf configuration
+ @param cache cache file
+ @return mtime of a given cache file on hdfs
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setArchiveTimestamps"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="timestamps" type="java.lang.String"/>
+      <doc>
+      <![CDATA[This is to check the timestamp of the archives to be localized.
+ Used by internal MapReduce code.
+ @param conf Configuration which stores the timestamp's
+ @param timestamps comma separated list of timestamps of archives.
+ The order should be the same as the order in which the archives are added.]]>
+      </doc>
+    </method>
+    <method name="setFileTimestamps"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="timestamps" type="java.lang.String"/>
+      <doc>
+      <![CDATA[This is to check the timestamp of the files to be localized.
+ Used by internal MapReduce code.
+ @param conf Configuration which stores the timestamp's
+ @param timestamps comma separated list of timestamps of files.
+ The order should be the same as the order in which the files are added.]]>
+      </doc>
+    </method>
+    <method name="setLocalArchives"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="str" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the conf to contain the location for localized archives.  Used
+ by internal DistributedCache code.
+ @param conf The conf to modify to contain the localized caches
+ @param str a comma separated list of local archives]]>
+      </doc>
+    </method>
+    <method name="setLocalFiles"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="str" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the conf to contain the location for localized files.  Used
+ by internal DistributedCache code.
+ @param conf The conf to modify to contain the localized caches
+ @param str a comma separated list of local files]]>
+      </doc>
+    </method>
+    <field name="CACHE_FILES_SIZES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_FILES_SIZES} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_FILES_SIZES}]]>
+      </doc>
+    </field>
+    <field name="CACHE_ARCHIVES_SIZES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_ARCHIVES_SIZES} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_ARCHIVES_SIZES}]]>
+      </doc>
+    </field>
+    <field name="CACHE_ARCHIVES_TIMESTAMPS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_ARCHIVES_TIMESTAMPS} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_ARCHIVES_TIMESTAMPS}]]>
+      </doc>
+    </field>
+    <field name="CACHE_FILES_TIMESTAMPS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_FILES_TIMESTAMPS} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_FILE_TIMESTAMPS}]]>
+      </doc>
+    </field>
+    <field name="CACHE_ARCHIVES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_ARCHIVES} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_ARCHIVES}]]>
+      </doc>
+    </field>
+    <field name="CACHE_FILES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_FILES} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_FILES}]]>
+      </doc>
+    </field>
+    <field name="CACHE_LOCALARCHIVES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_LOCALARCHIVES} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_LOCALARCHIVES}]]>
+      </doc>
+    </field>
+    <field name="CACHE_LOCALFILES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_LOCALFILES} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_LOCALFILES}]]>
+      </doc>
+    </field>
+    <field name="CACHE_SYMLINK" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Warning: {@link #CACHE_SYMLINK} is not a *public* constant.
+ The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#CACHE_SYMLINK}]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[Distribute application-specific large, read-only files efficiently.
+
+ <p><code>DistributedCache</code> is a facility provided by the Map-Reduce
+ framework to cache files (text, archives, jars etc.) needed by applications.
+ </p>
+
+ <p>Applications specify the files, via urls (hdfs:// or http://) to be cached
+ via the {@link org.apache.hadoop.mapred.JobConf}. The
+ <code>DistributedCache</code> assumes that the files specified via urls are
+ already present on the {@link FileSystem} at the path specified by the url
+ and are accessible by every machine in the cluster.</p>
+
+ <p>The framework will copy the necessary files on to the worker node before
+ any tasks for the job are executed on that node. Its efficiency stems from
+ the fact that the files are only copied once per job and the ability to
+ cache archives which are un-archived on the workers.</p>
+
+ <p><code>DistributedCache</code> can be used to distribute simple, read-only
+ data/text files and/or more complex types such as archives, jars etc.
+ Archives (zip, tar and tgz/tar.gz files) are un-archived at the worker nodes.
+ Jars may be optionally added to the classpath of the tasks, a rudimentary
+ software distribution mechanism.  Files have execution permissions.
+ In older version of Hadoop Map/Reduce users could optionally ask for symlinks
+ to be created in the working directory of the child task.  In the current
+ version symlinks are always created.  If the URL does not have a fragment
+ the name of the file or directory will be used. If multiple files or
+ directories map to the same link name, the last one added, will be used.  All
+ others will not even be downloaded.</p>
+
+ <p><code>DistributedCache</code> tracks modification timestamps of the cache
+ files. Clearly the cache files should not be modified by the application
+ or externally while the job is executing.</p>
+
+ <p>Here is an illustrative example on how to use the
+ <code>DistributedCache</code>:</p>
+ <p><blockquote><pre>
+     // Setting up the cache for the application
+
+     1. Copy the requisite files to the <code>FileSystem</code>:
+
+     $ bin/hadoop fs -copyFromLocal lookup.dat /myapp/lookup.dat
+     $ bin/hadoop fs -copyFromLocal map.zip /myapp/map.zip
+     $ bin/hadoop fs -copyFromLocal mylib.jar /myapp/mylib.jar
+     $ bin/hadoop fs -copyFromLocal mytar.tar /myapp/mytar.tar
+     $ bin/hadoop fs -copyFromLocal mytgz.tgz /myapp/mytgz.tgz
+     $ bin/hadoop fs -copyFromLocal mytargz.tar.gz /myapp/mytargz.tar.gz
+
+     2. Setup the application's <code>JobConf</code>:
+
+     JobConf job = new JobConf();
+     DistributedCache.addCacheFile(new URI("/myapp/lookup.dat#lookup.dat"),
+                                   job);
+     DistributedCache.addCacheArchive(new URI("/myapp/map.zip"), job);
+     DistributedCache.addFileToClassPath(new Path("/myapp/mylib.jar"), job);
+     DistributedCache.addCacheArchive(new URI("/myapp/mytar.tar"), job);
+     DistributedCache.addCacheArchive(new URI("/myapp/mytgz.tgz"), job);
+     DistributedCache.addCacheArchive(new URI("/myapp/mytargz.tar.gz"), job);
+
+     3. Use the cached files in the {@link org.apache.hadoop.mapred.Mapper}
+     or {@link org.apache.hadoop.mapred.Reducer}:
+
+     public static class MapClass extends MapReduceBase
+     implements Mapper&lt;K, V, K, V&gt; {
+
+       private Path[] localArchives;
+       private Path[] localFiles;
+
+       public void configure(JobConf job) {
+         // Get the cached archives/files
+         File f = new File("./map.zip/some/file/in/zip.txt");
+       }
+
+       public void map(K key, V value,
+                       OutputCollector&lt;K, V&gt; output, Reporter reporter)
+       throws IOException {
+         // Use data from the cached archives/files here
+         // ...
+         // ...
+         output.collect(k, v);
+       }
+     }
+
+ </pre></blockquote>
+
+ It is also very common to use the DistributedCache by using
+ {@link org.apache.hadoop.util.GenericOptionsParser}.
+
+ This class includes methods that should be used by users
+ (specifically those mentioned in the example above, as well
+ as {@link DistributedCache#addArchiveToClassPath(Path, Configuration)}),
+ as well as methods intended for use by the MapReduce framework
+ (e.g., {@link org.apache.hadoop.mapred.JobClient}).
+
+ @see org.apache.hadoop.mapred.JobConf
+ @see org.apache.hadoop.mapred.JobClient
+ @see org.apache.hadoop.mapreduce.Job]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.filecache.DistributedCache -->
+</package>
+<package name="org.apache.hadoop.mapred">
+  <!-- start class org.apache.hadoop.mapred.ClusterStatus -->
+  <class name="ClusterStatus" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <method name="getTaskTrackers" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of task trackers in the cluster.
+ 
+ @return the number of task trackers in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getActiveTrackerNames" return="java.util.Collection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the names of task trackers in the cluster.
+ 
+ @return the active task trackers in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getBlacklistedTrackerNames" return="java.util.Collection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the names of task trackers in the cluster.
+ 
+ @return the blacklisted task trackers in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getGraylistedTrackerNames" return="java.util.Collection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the names of graylisted task trackers in the cluster.
+
+ The gray list of trackers is no longer available on M/R 2.x. The function
+ is kept to be compatible with M/R 1.x applications.
+
+ @return an empty graylisted task trackers in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getGraylistedTrackers" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of graylisted task trackers in the cluster.
+
+ The gray list of trackers is no longer available on M/R 2.x. The function
+ is kept to be compatible with M/R 1.x applications.
+
+ @return 0 graylisted task trackers in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getBlacklistedTrackers" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of blacklisted task trackers in the cluster.
+ 
+ @return the number of blacklisted task trackers in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getNumExcludedNodes" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of excluded hosts in the cluster.
+ @return the number of excluded hosts in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getTTExpiryInterval" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the tasktracker expiry interval for the cluster
+ @return the expiry interval in msec]]>
+      </doc>
+    </method>
+    <method name="getMapTasks" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of currently running map tasks in the cluster.
+ 
+ @return the number of currently running map tasks in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getReduceTasks" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of currently running reduce tasks in the cluster.
+ 
+ @return the number of currently running reduce tasks in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getMaxMapTasks" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the maximum capacity for running map tasks in the cluster.
+ 
+ @return the maximum capacity for running map tasks in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getMaxReduceTasks" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the maximum capacity for running reduce tasks in the cluster.
+ 
+ @return the maximum capacity for running reduce tasks in the cluster.]]>
+      </doc>
+    </method>
+    <method name="getJobTrackerStatus" return="org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the JobTracker's status.
+ 
+ @return {@link JobTrackerStatus} of the JobTracker]]>
+      </doc>
+    </method>
+    <method name="getMaxMemory" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns UNINITIALIZED_MEMORY_VALUE (-1)]]>
+      </doc>
+    </method>
+    <method name="getUsedMemory" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns UNINITIALIZED_MEMORY_VALUE (-1)]]>
+      </doc>
+    </method>
+    <method name="getBlackListedTrackersInfo" return="java.util.Collection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets the list of blacklisted trackers along with reasons for blacklisting.
+ 
+ @return the collection of {@link BlackListInfo} objects.]]>
+      </doc>
+    </method>
+    <method name="getJobTrackerState" return="org.apache.hadoop.mapred.JobTracker.State"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the current state of the <code>JobTracker</code>,
+ as {@link JobTracker.State}
+
+ {@link JobTracker.State} should no longer be used on M/R 2.x. The function
+ is kept to be compatible with M/R 1.x applications.
+
+ @return the invalid state of the <code>JobTracker</code>.]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="UNINITIALIZED_MEMORY_VALUE" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Status information on the current state of the Map-Reduce cluster.
+ 
+ <p><code>ClusterStatus</code> provides clients with information such as:
+ <ol>
+   <li>
+   Size of the cluster. 
+   </li>
+   <li>
+   Name of the trackers. 
+   </li>
+   <li>
+   Task capacity of the cluster. 
+   </li>
+   <li>
+   The number of currently running map and reduce tasks.
+   </li>
+   <li>
+   State of the <code>JobTracker</code>.
+   </li>
+   <li>
+   Details regarding black listed trackers.
+   </li>
+ </ol>
+ 
+ <p>Clients can query for the latest <code>ClusterStatus</code>, via 
+ {@link JobClient#getClusterStatus()}.</p>
+ 
+ @see JobClient]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.ClusterStatus -->
+  <!-- start class org.apache.hadoop.mapred.Counters -->
+  <class name="Counters" extends="org.apache.hadoop.mapreduce.counters.AbstractCounters"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Counters"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="Counters" type="org.apache.hadoop.mapreduce.Counters"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getGroup" return="org.apache.hadoop.mapred.Counters.Group"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="groupName" type="java.lang.String"/>
+    </method>
+    <method name="getGroupNames" return="java.util.Collection"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="makeCompactString" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="findCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="group" type="java.lang.String"/>
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <method name="findCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use {@link #findCounter(String, String)} instead">
+      <param name="group" type="java.lang.String"/>
+      <param name="id" type="int"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Find a counter by using strings
+ @param group the name of the group
+ @param id the id of the counter within the group (0 to N-1)
+ @param name the internal name of the counter
+ @return the counter for that name
+ @deprecated use {@link #findCounter(String, String)} instead]]>
+      </doc>
+    </method>
+    <method name="incrCounter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Enum"/>
+      <param name="amount" type="long"/>
+      <doc>
+      <![CDATA[Increments the specified counter by the specified amount, creating it if
+ it didn't already exist.
+ @param key identifies a counter
+ @param amount amount by which counter is to be incremented]]>
+      </doc>
+    </method>
+    <method name="incrCounter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="group" type="java.lang.String"/>
+      <param name="counter" type="java.lang.String"/>
+      <param name="amount" type="long"/>
+      <doc>
+      <![CDATA[Increments the specified counter by the specified amount, creating it if
+ it didn't already exist.
+ @param group the name of the group
+ @param counter the internal name of the counter
+ @param amount amount by which counter is to be incremented]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="long"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Enum"/>
+      <doc>
+      <![CDATA[Returns current value of the specified counter, or 0 if the counter
+ does not exist.
+ @param key the counter enum to lookup
+ @return the counter value or 0 if counter not found]]>
+      </doc>
+    </method>
+    <method name="incrAllCounters"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.mapred.Counters"/>
+      <doc>
+      <![CDATA[Increments multiple counters by their amounts in another Counters
+ instance.
+ @param other the other Counters instance]]>
+      </doc>
+    </method>
+    <method name="size" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use {@link #countCounters()} instead">
+      <doc>
+      <![CDATA[@return the total number of counters
+ @deprecated use {@link #countCounters()} instead]]>
+      </doc>
+    </method>
+    <method name="sum" return="org.apache.hadoop.mapred.Counters"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="a" type="org.apache.hadoop.mapred.Counters"/>
+      <param name="b" type="org.apache.hadoop.mapred.Counters"/>
+      <doc>
+      <![CDATA[Convenience method for computing the sum of two sets of counters.
+ @param a the first counters
+ @param b the second counters
+ @return a new summed counters object]]>
+      </doc>
+    </method>
+    <method name="log"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="log" type="org.slf4j.Logger"/>
+      <doc>
+      <![CDATA[Logs the current counter values.
+ @param log The log to use.]]>
+      </doc>
+    </method>
+    <method name="makeEscapedCompactString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Represent the counter in a textual format that can be converted back to
+ its object form
+ @return the string in the following format
+ {(groupName)(group-displayName)[(counterName)(displayName)(value)][]*}*]]>
+      </doc>
+    </method>
+    <method name="fromEscapedCompactString" return="org.apache.hadoop.mapred.Counters"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="compactString" type="java.lang.String"/>
+      <exception name="ParseException" type="java.text.ParseException"/>
+      <doc>
+      <![CDATA[Convert a stringified (by {@link #makeEscapedCompactString()} counter
+ representation into a counter object.
+ @param compactString to parse
+ @return a new counters object
+ @throws ParseException]]>
+      </doc>
+    </method>
+    <field name="MAX_COUNTER_LIMIT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAX_GROUP_LIMIT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A set of named counters.
+
+ <p><code>Counters</code> represent global counters, defined either by the
+ Map-Reduce framework or applications. Each <code>Counter</code> can be of
+ any {@link Enum} type.</p>
+
+ <p><code>Counters</code> are bunched into {@link Group}s, each comprising of
+ counters from a particular <code>Enum</code> class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.Counters -->
+  <!-- start class org.apache.hadoop.mapred.Counters.Counter -->
+  <class name="Counters.Counter" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.Counter"/>
+    <constructor name="Counter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setDisplayName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="displayName" type="java.lang.String"/>
+    </method>
+    <method name="getName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDisplayName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getValue" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="value" type="long"/>
+    </method>
+    <method name="increment"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="incr" type="long"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="makeEscapedCompactString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the compact stringified version of the counter in the format
+ [(actual-name)(display-name)(value)]
+ @return the stringified result]]>
+      </doc>
+    </method>
+    <method name="contentEquals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="deprecated, no comment">
+      <param name="counter" type="org.apache.hadoop.mapred.Counters.Counter"/>
+      <doc>
+      <![CDATA[Checks for (content) equality of two (basic) counters
+ @param counter to compare
+ @return true if content equals
+ @deprecated]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the value of the counter]]>
+      </doc>
+    </method>
+    <method name="getUnderlyingCounter" return="org.apache.hadoop.mapreduce.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericRight" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[A counter record, comprising its name and value.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.Counters.Counter -->
+  <!-- start class org.apache.hadoop.mapred.Counters.Group -->
+  <class name="Counters.Group" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.counters.CounterGroupBase"/>
+    <constructor name="Group"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getCounter" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[@param counterName the name of the counter
+ @return the value of the specified counter, or 0 if the counter does
+ not exist.]]>
+      </doc>
+    </method>
+    <method name="makeEscapedCompactString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the compact stringified version of the group in the format
+ {(actual-name)(display-name)(value)[][][]} where [] are compact strings
+ for the counters within.]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use {@link #findCounter(String)} instead">
+      <param name="id" type="int"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get the counter for the given id and create it if it doesn't exist.
+ @param id the numeric id of the counter within the group
+ @param name the internal counter name
+ @return the counter
+ @deprecated use {@link #findCounter(String)} instead]]>
+      </doc>
+    </method>
+    <method name="getCounterForName" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get the counter for the given name and create it if it doesn't exist.
+ @param name the internal counter name
+ @return the counter]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="iterator" return="java.util.Iterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDisplayName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setDisplayName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="displayName" type="java.lang.String"/>
+    </method>
+    <method name="addCounter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counter" type="org.apache.hadoop.mapred.Counters.Counter"/>
+    </method>
+    <method name="addCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <param name="displayName" type="java.lang.String"/>
+      <param name="value" type="long"/>
+    </method>
+    <method name="findCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+      <param name="displayName" type="java.lang.String"/>
+    </method>
+    <method name="findCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+      <param name="create" type="boolean"/>
+    </method>
+    <method name="findCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+    </method>
+    <method name="size" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="incrAllCounters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rightGroup" type="org.apache.hadoop.mapreduce.counters.CounterGroupBase"/>
+    </method>
+    <method name="getUnderlyingGroup" return="org.apache.hadoop.mapreduce.counters.CounterGroupBase"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericRight" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<code>Group</code> of counters, comprising of counters from a particular
+  counter {@link Enum} class.
+
+  <p><code>Group</code>handles localization of the class name and the
+  counter names.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.Counters.Group -->
+  <!-- start class org.apache.hadoop.mapred.FileAlreadyExistsException -->
+  <class name="FileAlreadyExistsException" extends="java.io.IOException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FileAlreadyExistsException"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FileAlreadyExistsException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Used when target file already exists for any operation and 
+ is not configured to be overwritten.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.FileAlreadyExistsException -->
+  <!-- start class org.apache.hadoop.mapred.FileInputFormat -->
+  <class name="FileInputFormat" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputFormat"/>
+    <constructor name="FileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setMinSplitSize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="minSplitSize" type="long"/>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="filename" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Is the given filename splittable? Usually, true, but if the file is
+ stream compressed, it will not be.
+
+ The default implementation in <code>FileInputFormat</code> always returns
+ true. Implementations that may deal with non-splittable files <i>must</i>
+ override this method.
+
+ <code>FileInputFormat</code> implementations can override this and return
+ <code>false</code> to ensure that individual input files are never split-up
+ so that {@link Mapper}s process entire files.
+ 
+ @param fs the file system that the file is on
+ @param filename the file name to check
+ @return is this file splitable?]]>
+      </doc>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setInputPathFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="filter" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set a PathFilter to be applied to the input paths for the map-reduce job.
+
+ @param filter the PathFilter class use for filtering the input paths.]]>
+      </doc>
+    </method>
+    <method name="getInputPathFilter" return="org.apache.hadoop.fs.PathFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get a PathFilter instance of the filter set for the input paths.
+
+ @return the PathFilter instance set for the job, NULL if none has been set.]]>
+      </doc>
+    </method>
+    <method name="addInputPathRecursively"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="result" type="java.util.List"/>
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="inputFilter" type="org.apache.hadoop.fs.PathFilter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add files in the input path recursively into the results.
+ @param result
+          The List to store all files.
+ @param fs
+          The FileSystem.
+ @param path
+          The input path.
+ @param inputFilter
+          The input filter that can be used to filter files/dirs. 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="listStatus" return="org.apache.hadoop.fs.FileStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[List input directories.
+ Subclasses may override to, e.g., select only files matching a regular
+ expression. 
+ 
+ @param job the job to list input paths for
+ @return array of FileStatus objects
+ @throws IOException if zero items.]]>
+      </doc>
+    </method>
+    <method name="makeSplit" return="org.apache.hadoop.mapred.FileSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+      <param name="start" type="long"/>
+      <param name="length" type="long"/>
+      <param name="hosts" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[A factory that makes the split for this class. It can be overridden
+ by sub-classes to make sub-types]]>
+      </doc>
+    </method>
+    <method name="makeSplit" return="org.apache.hadoop.mapred.FileSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+      <param name="start" type="long"/>
+      <param name="length" type="long"/>
+      <param name="hosts" type="java.lang.String[]"/>
+      <param name="inMemoryHosts" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[A factory that makes the split for this class. It can be overridden
+ by sub-classes to make sub-types]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="numSplits" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Splits files returned by {@link #listStatus(JobConf)} when
+ they're too big.]]>
+      </doc>
+    </method>
+    <method name="computeSplitSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="goalSize" type="long"/>
+      <param name="minSize" type="long"/>
+      <param name="blockSize" type="long"/>
+    </method>
+    <method name="getBlockIndex" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="blkLocations" type="org.apache.hadoop.fs.BlockLocation[]"/>
+      <param name="offset" type="long"/>
+    </method>
+    <method name="setInputPaths"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="commaSeparatedPaths" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets the given comma separated paths as the list of inputs 
+ for the map-reduce job.
+ 
+ @param conf Configuration of the job
+ @param commaSeparatedPaths Comma separated paths to be set as 
+        the list of inputs for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="addInputPaths"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="commaSeparatedPaths" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Add the given comma separated paths to the list of inputs for
+  the map-reduce job.
+ 
+ @param conf The configuration of the job 
+ @param commaSeparatedPaths Comma separated paths to be added to
+        the list of inputs for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="setInputPaths"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="inputPaths" type="org.apache.hadoop.fs.Path[]"/>
+      <doc>
+      <![CDATA[Set the array of {@link Path}s as the list of inputs
+ for the map-reduce job.
+ 
+ @param conf Configuration of the job. 
+ @param inputPaths the {@link Path}s of the input directories/files 
+ for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="addInputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Add a {@link Path} to the list of inputs for the map-reduce job.
+ 
+ @param conf The configuration of the job 
+ @param path {@link Path} to be added to the list of inputs for 
+            the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getInputPaths" return="org.apache.hadoop.fs.Path[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the list of input {@link Path}s for the map-reduce job.
+ 
+ @param conf The configuration of the job 
+ @return the list of input {@link Path}s for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getSplitHosts" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="blkLocations" type="org.apache.hadoop.fs.BlockLocation[]"/>
+      <param name="offset" type="long"/>
+      <param name="splitSize" type="long"/>
+      <param name="clusterMap" type="org.apache.hadoop.net.NetworkTopology"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This function identifies and returns the hosts that contribute 
+ most for a given split. For calculating the contribution, rack
+ locality is treated on par with host locality, so hosts from racks
+ that contribute the most are preferred over hosts on racks that 
+ contribute less
+ @param blkLocations The list of block locations
+ @param offset 
+ @param splitSize 
+ @return an array of hosts that contribute most to this split
+ @throws IOException]]>
+      </doc>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NUM_INPUT_FILES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INPUT_DIR_RECURSIVE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INPUT_DIR_NONRECURSIVE_IGNORE_SUBDIRS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A base class for file-based {@link InputFormat}.
+ 
+ <p><code>FileInputFormat</code> is the base class for all file-based 
+ <code>InputFormat</code>s. This provides a generic implementation of
+ {@link #getSplits(JobConf, int)}.
+
+ Implementations of <code>FileInputFormat</code> can also override the
+ {@link #isSplitable(FileSystem, Path)} method to prevent input files
+ from being split-up in certain situations. Implementations that may
+ deal with non-splittable files <i>must</i> override this method, since
+ the default implementation assumes splitting is always possible.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.FileInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.FileOutputCommitter -->
+  <class name="FileOutputCommitter" extends="org.apache.hadoop.mapred.OutputCommitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FileOutputCommitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getWorkPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <param name="outputPath" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="commitJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="cleanupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="abortJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.JobContext"/>
+      <param name="runState" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setupTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="commitTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="abortTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="needsTaskCommit" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isCommitJobRepeatable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="recoverTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TEMP_DIR_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Temporary directory name]]>
+      </doc>
+    </field>
+    <field name="SUCCEEDED_FILE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An {@link OutputCommitter} that commits files specified 
+ in job output directory i.e. ${mapreduce.output.fileoutputformat.outputdir}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.FileOutputCommitter -->
+  <!-- start class org.apache.hadoop.mapred.FileOutputFormat -->
+  <class name="FileOutputFormat" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.OutputFormat"/>
+    <constructor name="FileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setCompressOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="compress" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the output of the job is compressed.
+ @param conf the {@link JobConf} to modify
+ @param compress should the output of the job be compressed?]]>
+      </doc>
+    </method>
+    <method name="getCompressOutput" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Is the job output compressed?
+ @param conf the {@link JobConf} to look in
+ @return <code>true</code> if the job output should be compressed,
+         <code>false</code> otherwise]]>
+      </doc>
+    </method>
+    <method name="setOutputCompressorClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="codecClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link CompressionCodec} to be used to compress job outputs.
+ @param conf the {@link JobConf} to modify
+ @param codecClass the {@link CompressionCodec} to be used to
+                   compress the job outputs]]>
+      </doc>
+    </method>
+    <method name="getOutputCompressorClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="defaultValue" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Get the {@link CompressionCodec} for compressing the job outputs.
+ @param conf the {@link JobConf} to look in
+ @param defaultValue the {@link CompressionCodec} to return if not set
+ @return the {@link CompressionCodec} to be used to compress the 
+         job outputs
+ @throws IllegalArgumentException if the class was specified, but not found]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="FileAlreadyExistsException" type="org.apache.hadoop.mapred.FileAlreadyExistsException"/>
+      <exception name="InvalidJobConfException" type="org.apache.hadoop.mapred.InvalidJobConfException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setOutputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="outputDir" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the {@link Path} of the output directory for the map-reduce job.
+
+ @param conf The configuration of the job.
+ @param outputDir the {@link Path} of the output directory for 
+ the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the {@link Path} to the output directory for the map-reduce job.
+ 
+ @return the {@link Path} to the output directory for the map-reduce job.
+ @see FileOutputFormat#getWorkOutputPath(JobConf)]]>
+      </doc>
+    </method>
+    <method name="getWorkOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the {@link Path} to the task's temporary output directory 
+  for the map-reduce job
+  
+ <b id="SideEffectFiles">Tasks' Side-Effect Files</b>
+ 
+ <p><i>Note:</i> The following is valid only if the {@link OutputCommitter}
+  is {@link FileOutputCommitter}. If <code>OutputCommitter</code> is not 
+  a <code>FileOutputCommitter</code>, the task's temporary output
+  directory is same as {@link #getOutputPath(JobConf)} i.e.
+  <tt>${mapreduce.output.fileoutputformat.outputdir}$</tt></p>
+  
+ <p>Some applications need to create/write-to side-files, which differ from
+ the actual job-outputs.
+ 
+ <p>In such cases there could be issues with 2 instances of the same TIP 
+ (running simultaneously e.g. speculative tasks) trying to open/write-to the
+ same file (path) on HDFS. Hence the application-writer will have to pick 
+ unique names per task-attempt (e.g. using the attemptid, say 
+ <tt>attempt_200709221812_0001_m_000000_0</tt>), not just per TIP.</p> 
+ 
+ <p>To get around this the Map-Reduce framework helps the application-writer 
+ out by maintaining a special 
+ <tt>${mapreduce.output.fileoutputformat.outputdir}/_temporary/_${taskid}</tt> 
+ sub-directory for each task-attempt on HDFS where the output of the 
+ task-attempt goes. On successful completion of the task-attempt the files 
+ in the <tt>${mapreduce.output.fileoutputformat.outputdir}/_temporary/_${taskid}</tt> (only) 
+ are <i>promoted</i> to <tt>${mapreduce.output.fileoutputformat.outputdir}</tt>. Of course, the 
+ framework discards the sub-directory of unsuccessful task-attempts. This 
+ is completely transparent to the application.</p>
+ 
+ <p>The application-writer can take advantage of this by creating any 
+ side-files required in <tt>${mapreduce.task.output.dir}</tt> during execution 
+ of his reduce-task i.e. via {@link #getWorkOutputPath(JobConf)}, and the 
+ framework will move them out similarly - thus she doesn't have to pick 
+ unique paths per task-attempt.</p>
+ 
+ <p><i>Note</i>: the value of <tt>${mapreduce.task.output.dir}</tt> during 
+ execution of a particular task-attempt is actually 
+ <tt>${mapreduce.output.fileoutputformat.outputdir}/_temporary/_{$taskid}</tt>, and this value is 
+ set by the map-reduce framework. So, just create any side-files in the 
+ path  returned by {@link #getWorkOutputPath(JobConf)} from map/reduce 
+ task to take advantage of this feature.</p>
+ 
+ <p>The entire discussion holds true for maps of jobs with 
+ reducer=NONE (i.e. 0 reduces) since output of the map, in that case, 
+ goes directly to HDFS.</p> 
+ 
+ @return the {@link Path} to the task's temporary output directory 
+ for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getTaskOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Helper function to create the task's temporary output directory and 
+ return the path to the task's output file.
+ 
+ @param conf job-configuration
+ @param name temporary task-output filename
+ @return path to the task's temporary output file
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getUniqueName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Helper function to generate a name that is unique for the task.
+
+ <p>The generated name can be used to create custom files from within the
+ different tasks for the job, the names for different tasks will not collide
+ with each other.</p>
+
+ <p>The given name is postfixed with the task type, 'm' for maps, 'r' for
+ reduces and the task partition number. For example, give a name 'test'
+ running on the first map o the job the generated name will be
+ 'test-m-00000'.</p>
+
+ @param conf the configuration for the job.
+ @param name the name to make unique.
+ @return a unique name accross all tasks of the job.]]>
+      </doc>
+    </method>
+    <method name="getPathForCustomFile" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Helper function to generate a {@link Path} for a file that is unique for
+ the task within the job output directory.
+
+ <p>The path can be used to create custom files from within the map and
+ reduce tasks. The path name will be unique for each task. The path parent
+ will be the job output directory.</p>ls
+
+ <p>This method uses the {@link #getUniqueName} method to make the file name
+ unique for the task.</p>
+
+ @param conf the configuration for the job.
+ @param name the name for the file.
+ @return a unique path accross all tasks of the job.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A base class for {@link OutputFormat}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.FileOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.FileSplit -->
+  <class name="FileSplit" extends="org.apache.hadoop.mapreduce.InputSplit"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputSplitWithLocationInfo"/>
+    <constructor name="FileSplit"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FileSplit" type="org.apache.hadoop.fs.Path, long, long, org.apache.hadoop.mapred.JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="deprecated, no comment">
+      <doc>
+      <![CDATA[Constructs a split.
+ @deprecated
+ @param file the file name
+ @param start the position of the first byte in the file to process
+ @param length the number of bytes in the file to process]]>
+      </doc>
+    </constructor>
+    <constructor name="FileSplit" type="org.apache.hadoop.fs.Path, long, long, java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a split with host information
+
+ @param file the file name
+ @param start the position of the first byte in the file to process
+ @param length the number of bytes in the file to process
+ @param hosts the list of hosts containing the block, possibly null]]>
+      </doc>
+    </constructor>
+    <constructor name="FileSplit" type="org.apache.hadoop.fs.Path, long, long, java.lang.String[], java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a split with host information
+
+ @param file the file name
+ @param start the position of the first byte in the file to process
+ @param length the number of bytes in the file to process
+ @param hosts the list of hosts containing the block, possibly null
+ @param inMemoryHosts the list of hosts containing the block in memory]]>
+      </doc>
+    </constructor>
+    <constructor name="FileSplit" type="org.apache.hadoop.mapreduce.lib.input.FileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The file containing this split's data.]]>
+      </doc>
+    </method>
+    <method name="getStart" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The position of the first byte in the file to process.]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of bytes in the file to process.]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getLocationInfo" return="org.apache.hadoop.mapred.SplitLocationInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A section of an input file.  Returned by {@link
+ InputFormat#getSplits(JobConf, int)} and passed to
+ {@link InputFormat#getRecordReader(InputSplit,JobConf,Reporter)}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.FileSplit -->
+  <!-- start class org.apache.hadoop.mapred.FixedLengthInputFormat -->
+  <class name="FixedLengthInputFormat" extends="org.apache.hadoop.mapred.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="FixedLengthInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setRecordLength"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="recordLength" type="int"/>
+      <doc>
+      <![CDATA[Set the length of each record
+ @param conf configuration
+ @param recordLength the length of a record]]>
+      </doc>
+    </method>
+    <method name="getRecordLength" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get record length value
+ @param conf configuration
+ @return the record length, zero means none was set]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <field name="FIXED_RECORD_LENGTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[FixedLengthInputFormat is an input format used to read input files
+ which contain fixed length records.  The content of a record need not be
+ text.  It can be arbitrary binary data.  Users must configure the record
+ length property by calling:
+ FixedLengthInputFormat.setRecordLength(conf, recordLength);<br><br> or
+ conf.setInt(FixedLengthInputFormat.FIXED_RECORD_LENGTH, recordLength);
+ <br><br>
+ @see FixedLengthRecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.FixedLengthInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.ID -->
+  <class name="ID" extends="org.apache.hadoop.mapreduce.ID"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ID" type="int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[constructs an ID object from the given int]]>
+      </doc>
+    </constructor>
+    <constructor name="ID"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[A general identifier, which internally stores the id
+ as an integer. This is the super class of {@link JobID}, 
+ {@link TaskID} and {@link TaskAttemptID}.
+ 
+ @see JobID
+ @see TaskID
+ @see TaskAttemptID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.ID -->
+  <!-- start interface org.apache.hadoop.mapred.InputFormat -->
+  <interface name="InputFormat"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="numSplits" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Logically split the set of input files for the job.  
+ 
+ <p>Each {@link InputSplit} is then assigned to an individual {@link Mapper}
+ for processing.</p>
+
+ <p><i>Note</i>: The split is a <i>logical</i> split of the inputs and the
+ input files are not physically split into chunks. For e.g. a split could
+ be <i>&lt;input-file-path, start, offset&gt;</i> tuple.
+ 
+ @param job job configuration.
+ @param numSplits the desired number of splits, a hint.
+ @return an array of {@link InputSplit}s for the job.]]>
+      </doc>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the {@link RecordReader} for the given {@link InputSplit}.
+
+ <p>It is the responsibility of the <code>RecordReader</code> to respect
+ record boundaries while processing the logical split to present a 
+ record-oriented view to the individual task.</p>
+ 
+ @param split the {@link InputSplit}
+ @param job the job that this split belongs to
+ @return a {@link RecordReader}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>InputFormat</code> describes the input-specification for a 
+ Map-Reduce job. 
+ 
+ <p>The Map-Reduce framework relies on the <code>InputFormat</code> of the
+ job to:<p>
+ <ol>
+   <li>
+   Validate the input-specification of the job. 
+   <li>
+   Split-up the input file(s) into logical {@link InputSplit}s, each of 
+   which is then assigned to an individual {@link Mapper}.
+   </li>
+   <li>
+   Provide the {@link RecordReader} implementation to be used to glean
+   input records from the logical <code>InputSplit</code> for processing by 
+   the {@link Mapper}.
+   </li>
+ </ol>
+ 
+ <p>The default behavior of file-based {@link InputFormat}s, typically 
+ sub-classes of {@link FileInputFormat}, is to split the 
+ input into <i>logical</i> {@link InputSplit}s based on the total size, in 
+ bytes, of the input files. However, the {@link FileSystem} blocksize of  
+ the input files is treated as an upper bound for input splits. A lower bound 
+ on the split size can be set via 
+ <a href="{@docRoot}/../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml#mapreduce.input.fileinputformat.split.minsize">
+ mapreduce.input.fileinputformat.split.minsize</a>.</p>
+ 
+ <p>Clearly, logical splits based on input-size is insufficient for many 
+ applications since record boundaries are to be respected. In such cases, the
+ application has to also implement a {@link RecordReader} on whom lies the
+ responsibilty to respect record-boundaries and present a record-oriented
+ view of the logical <code>InputSplit</code> to the individual task.
+
+ @see InputSplit
+ @see RecordReader
+ @see JobClient
+ @see FileInputFormat]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.InputFormat -->
+  <!-- start interface org.apache.hadoop.mapred.InputSplit -->
+  <interface name="InputSplit"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <method name="getLength" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the total number of bytes in the data of the <code>InputSplit</code>.
+ 
+ @return the number of bytes in the input split.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the list of hostnames where the input split is located.
+ 
+ @return list of hostnames where data of the <code>InputSplit</code> is
+         located as an array of <code>String</code>s.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>InputSplit</code> represents the data to be processed by an 
+ individual {@link Mapper}. 
+
+ <p>Typically, it presents a byte-oriented view on the input and is the 
+ responsibility of {@link RecordReader} of the job to process this and present
+ a record-oriented view.
+ 
+ @see InputFormat
+ @see RecordReader]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.InputSplit -->
+  <!-- start interface org.apache.hadoop.mapred.InputSplitWithLocationInfo -->
+  <interface name="InputSplitWithLocationInfo"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputSplit"/>
+    <method name="getLocationInfo" return="org.apache.hadoop.mapred.SplitLocationInfo[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets info about which nodes the input split is stored on and how it is
+ stored at each location.
+ 
+ @return list of <code>SplitLocationInfo</code>s describing how the split
+    data is stored at each location. A null value indicates that all the
+    locations have the data stored on disk.
+ @throws IOException]]>
+      </doc>
+    </method>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.InputSplitWithLocationInfo -->
+  <!-- start class org.apache.hadoop.mapred.InvalidFileTypeException -->
+  <class name="InvalidFileTypeException" extends="java.io.IOException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InvalidFileTypeException"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="InvalidFileTypeException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Used when file type differs from the desired file type. like 
+ getting a file when a directory is expected. Or a wrong file type.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.InvalidFileTypeException -->
+  <!-- start class org.apache.hadoop.mapred.InvalidInputException -->
+  <class name="InvalidInputException" extends="java.io.IOException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InvalidInputException" type="java.util.List"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create the exception with the given list.
+ @param probs the list of problems to report. this list is not copied.]]>
+      </doc>
+    </constructor>
+    <method name="getProblems" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the complete list of the problems reported.
+ @return the list of problems, which must not be modified]]>
+      </doc>
+    </method>
+    <method name="getMessage" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a summary message of the problems found.
+ @return the concatenated messages from all of the problems.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class wraps a list of problems with the input, so that the user
+ can get a list of problems together instead of finding and fixing them one 
+ by one.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.InvalidInputException -->
+  <!-- start class org.apache.hadoop.mapred.InvalidJobConfException -->
+  <class name="InvalidJobConfException" extends="java.io.IOException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InvalidJobConfException"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="InvalidJobConfException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="InvalidJobConfException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="InvalidJobConfException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown when jobconf misses some mendatory attributes
+ or value of some attributes is invalid.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.InvalidJobConfException -->
+  <!-- start class org.apache.hadoop.mapred.JobClient -->
+  <class name="JobClient" extends="org.apache.hadoop.mapreduce.tools.CLI"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.AutoCloseable"/>
+    <constructor name="JobClient"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job client.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobClient" type="org.apache.hadoop.mapred.JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Build a job client with the given {@link JobConf}, and connect to the 
+ default cluster
+ 
+ @param conf the job configuration.
+ @throws IOException]]>
+      </doc>
+    </constructor>
+    <constructor name="JobClient" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Build a job client with the given {@link Configuration}, 
+ and connect to the default cluster
+ 
+ @param conf the configuration.
+ @throws IOException]]>
+      </doc>
+    </constructor>
+    <constructor name="JobClient" type="java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Build a job client, connect to the indicated job tracker.
+ 
+ @param jobTrackAddr the job tracker to connect to.
+ @param conf configuration.]]>
+      </doc>
+    </constructor>
+    <method name="init"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Connect to the default cluster
+ @param conf the job configuration.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close the <code>JobClient</code>.]]>
+      </doc>
+    </method>
+    <method name="getFs" return="org.apache.hadoop.fs.FileSystem"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get a filesystem handle.  We need this to prepare jobs
+ for submission to the MapReduce system.
+ 
+ @return the filesystem handle.]]>
+      </doc>
+    </method>
+    <method name="getClusterHandle" return="org.apache.hadoop.mapreduce.Cluster"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a handle to the Cluster]]>
+      </doc>
+    </method>
+    <method name="submitJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobFile" type="java.lang.String"/>
+      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
+      <exception name="InvalidJobConfException" type="org.apache.hadoop.mapred.InvalidJobConfException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Submit a job to the MR system.
+ 
+ This returns a handle to the {@link RunningJob} which can be used to track
+ the running-job.
+ 
+ @param jobFile the job configuration.
+ @return a handle to the {@link RunningJob} which can be used to track the
+         running-job.
+ @throws FileNotFoundException
+ @throws InvalidJobConfException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="submitJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="FileNotFoundException" type="java.io.FileNotFoundException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Submit a job to the MR system.
+ This returns a handle to the {@link RunningJob} which can be used to track
+ the running-job.
+ 
+ @param conf the job configuration.
+ @return a handle to the {@link RunningJob} which can be used to track the
+         running-job.
+ @throws FileNotFoundException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getJobInner" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="jobid" type="org.apache.hadoop.mapred.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobid" type="org.apache.hadoop.mapred.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get an {@link RunningJob} object to track an ongoing job.  Returns
+ null if the id does not correspond to any known job.
+
+ @param jobid the jobid of the job.
+ @return the {@link RunningJob} handle to track the job, null if the
+         <code>jobid</code> doesn't correspond to any known job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Applications should rather use {@link #getJob(JobID)}.">
+      <param name="jobid" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Applications should rather use {@link #getJob(JobID)}.]]>
+      </doc>
+    </method>
+    <method name="getMapTaskReports" return="org.apache.hadoop.mapred.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapred.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the information of the current state of the map tasks of a job.
+ 
+ @param jobId the job to query.
+ @return the list of all of the map tips.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getMapTaskReports" return="org.apache.hadoop.mapred.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Applications should rather use {@link #getMapTaskReports(JobID)}">
+      <param name="jobId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Applications should rather use {@link #getMapTaskReports(JobID)}]]>
+      </doc>
+    </method>
+    <method name="getReduceTaskReports" return="org.apache.hadoop.mapred.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapred.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the information of the current state of the reduce tasks of a job.
+ 
+ @param jobId the job to query.
+ @return the list of all of the reduce tips.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getCleanupTaskReports" return="org.apache.hadoop.mapred.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapred.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the information of the current state of the cleanup tasks of a job.
+ 
+ @param jobId the job to query.
+ @return the list of all of the cleanup tips.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getSetupTaskReports" return="org.apache.hadoop.mapred.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapred.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the information of the current state of the setup tasks of a job.
+ 
+ @param jobId the job to query.
+ @return the list of all of the setup tips.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getReduceTaskReports" return="org.apache.hadoop.mapred.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Applications should rather use {@link #getReduceTaskReports(JobID)}">
+      <param name="jobId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Applications should rather use {@link #getReduceTaskReports(JobID)}]]>
+      </doc>
+    </method>
+    <method name="displayTasks"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapred.JobID"/>
+      <param name="type" type="java.lang.String"/>
+      <param name="state" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Display the information about a job's tasks, of a particular type and
+ in a particular state
+ 
+ @param jobId the ID of the job
+ @param type the type of the task (map/reduce/setup/cleanup)
+ @param state the state of the task 
+ (pending/running/completed/failed/killed)
+ @throws IOException when there is an error communicating with the master
+ @throws IllegalArgumentException if an invalid type/state is passed]]>
+      </doc>
+    </method>
+    <method name="getClusterStatus" return="org.apache.hadoop.mapred.ClusterStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get status information about the Map-Reduce cluster.
+  
+ @return the status information about the Map-Reduce cluster as an object
+         of {@link ClusterStatus}.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getClusterStatus" return="org.apache.hadoop.mapred.ClusterStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="detailed" type="boolean"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get status information about the Map-Reduce cluster.
+  
+ @param  detailed if true then get a detailed status including the
+         tracker names
+ @return the status information about the Map-Reduce cluster as an object
+         of {@link ClusterStatus}.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="jobsToComplete" return="org.apache.hadoop.mapred.JobStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the jobs that are not completed and not failed.
+ 
+ @return array of {@link JobStatus} for the running/to-be-run jobs.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getAllJobs" return="org.apache.hadoop.mapred.JobStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the jobs that are submitted.
+ 
+ @return array of {@link JobStatus} for the submitted jobs.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="runJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Utility that submits a job, then polls for progress until the job is
+ complete.
+ 
+ @param job the job configuration.
+ @throws IOException if the job fails]]>
+      </doc>
+    </method>
+    <method name="monitorAndPrintJob" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="job" type="org.apache.hadoop.mapred.RunningJob"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Monitor a job and print status in real-time as progress is made and tasks 
+ fail.
+ @param conf the job's configuration
+ @param job the job to track
+ @return true if the job succeeded
+ @throws IOException if communication to the JobTracker fails]]>
+      </doc>
+    </method>
+    <method name="setTaskOutputFilter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="newValue" type="org.apache.hadoop.mapred.JobClient.TaskStatusFilter"/>
+      <doc>
+      <![CDATA[Sets the output filter for tasks. only those tasks are printed whose
+ output matches the filter. 
+ @param newValue task filter.]]>
+      </doc>
+    </method>
+    <method name="getTaskOutputFilter" return="org.apache.hadoop.mapred.JobClient.TaskStatusFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the task output filter out of the JobConf.
+ 
+ @param job the JobConf to examine.
+ @return the filter level.]]>
+      </doc>
+    </method>
+    <method name="setTaskOutputFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="newValue" type="org.apache.hadoop.mapred.JobClient.TaskStatusFilter"/>
+      <doc>
+      <![CDATA[Modify the JobConf to set the task output filter.
+ 
+ @param job the JobConf to modify.
+ @param newValue the value to set.]]>
+      </doc>
+    </method>
+    <method name="getTaskOutputFilter" return="org.apache.hadoop.mapred.JobClient.TaskStatusFilter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns task output filter.
+ @return task filter.]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="cntrs" type="org.apache.hadoop.mapreduce.Counters"/>
+      <param name="counterGroupName" type="java.lang.String"/>
+      <param name="counterName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getDefaultMaps" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get status information about the max available Maps in the cluster.
+  
+ @return the max available Maps in the cluster
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getDefaultReduces" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get status information about the max available Reduces in the cluster.
+  
+ @return the max available Reduces in the cluster
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getSystemDir" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Grab the jobtracker system directory path where job-specific files are to be placed.
+ 
+ @return the system directory where job-specific files are to be placed.]]>
+      </doc>
+    </method>
+    <method name="isJobDirValid" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobDirPath" type="org.apache.hadoop.fs.Path"/>
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Checks if the job directory is clean and has all the required components
+ for (re) starting the job]]>
+      </doc>
+    </method>
+    <method name="getStagingAreaDir" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Fetch the staging area directory for the application
+ 
+ @return path to staging area directory
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getRootQueues" return="org.apache.hadoop.mapred.JobQueueInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns an array of queue information objects about root level queues
+ configured
+
+ @return the array of root level JobQueueInfo objects
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getChildQueues" return="org.apache.hadoop.mapred.JobQueueInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns an array of queue information objects about immediate children
+ of queue queueName.
+ 
+ @param queueName
+ @return the array of immediate children JobQueueInfo objects
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueues" return="org.apache.hadoop.mapred.JobQueueInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return an array of queue information objects about all the Job Queues
+ configured.
+ 
+ @return Array of JobQueueInfo objects
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getJobsFromQueue" return="org.apache.hadoop.mapred.JobStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets all the jobs which were added to particular Job Queue
+ 
+ @param queueName name of the Job Queue
+ @return Array of jobs present in the job queue
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueueInfo" return="org.apache.hadoop.mapred.JobQueueInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the queue information associated to a particular Job Queue
+ 
+ @param queueName name of the job queue.
+ @return Queue information associated to particular queue.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueueAclsForCurrentUser" return="org.apache.hadoop.mapred.QueueAclsInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the Queue ACLs for current user
+ @return array of QueueAclsInfo object for current user.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="org.apache.hadoop.io.Text"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get a delegation token for the user from the JobTracker.
+ @param renewer the user who can renew the token
+ @return the new token
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="renewDelegationToken" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link Token#renew} instead">
+      <param name="token" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Renew a delegation token
+ @param token the token to renew
+ @return true if the renewal went well
+ @throws InvalidToken
+ @throws IOException
+ @deprecated Use {@link Token#renew} instead]]>
+      </doc>
+    </method>
+    <method name="cancelDelegationToken"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link Token#cancel} instead">
+      <param name="token" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Cancel a delegation token from the JobTracker
+ @param token the token to cancel
+ @throws IOException
+ @deprecated Use {@link Token#cancel} instead]]>
+      </doc>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="argv" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <field name="MAPREDUCE_CLIENT_RETRY_POLICY_ENABLED_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAPREDUCE_CLIENT_RETRY_POLICY_ENABLED_DEFAULT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAPREDUCE_CLIENT_RETRY_POLICY_SPEC_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAPREDUCE_CLIENT_RETRY_POLICY_SPEC_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<code>JobClient</code> is the primary interface for the user-job to interact
+ with the cluster.
+ 
+ <code>JobClient</code> provides facilities to submit jobs, track their 
+ progress, access component-tasks' reports/logs, get the Map-Reduce cluster
+ status information etc.
+ 
+ <p>The job submission process involves:
+ <ol>
+   <li>
+   Checking the input and output specifications of the job.
+   </li>
+   <li>
+   Computing the {@link InputSplit}s for the job.
+   </li>
+   <li>
+   Setup the requisite accounting information for the {@link DistributedCache} 
+   of the job, if necessary.
+   </li>
+   <li>
+   Copying the job's jar and configuration to the map-reduce system directory 
+   on the distributed file-system. 
+   </li>
+   <li>
+   Submitting the job to the cluster and optionally monitoring
+   it's status.
+   </li>
+ </ol>
+  
+ Normally the user creates the application, describes various facets of the
+ job via {@link JobConf} and then uses the <code>JobClient</code> to submit 
+ the job and monitor its progress.
+ 
+ <p>Here is an example on how to use <code>JobClient</code>:</p>
+ <p><blockquote><pre>
+     // Create a new JobConf
+     JobConf job = new JobConf(new Configuration(), MyJob.class);
+     
+     // Specify various job-specific parameters     
+     job.setJobName("myjob");
+     
+     job.setInputPath(new Path("in"));
+     job.setOutputPath(new Path("out"));
+     
+     job.setMapperClass(MyJob.MyMapper.class);
+     job.setReducerClass(MyJob.MyReducer.class);
+
+     // Submit the job, then poll for progress until the job is complete
+     JobClient.runJob(job);
+ </pre></blockquote>
+ 
+ <b id="JobControl">Job Control</b>
+ 
+ <p>At times clients would chain map-reduce jobs to accomplish complex tasks 
+ which cannot be done via a single map-reduce job. This is fairly easy since 
+ the output of the job, typically, goes to distributed file-system and that 
+ can be used as the input for the next job.</p>
+ 
+ <p>However, this also means that the onus on ensuring jobs are complete 
+ (success/failure) lies squarely on the clients. In such situations the 
+ various job-control options are:
+ <ol>
+   <li>
+   {@link #runJob(JobConf)} : submits the job and returns only after 
+   the job has completed.
+   </li>
+   <li>
+   {@link #submitJob(JobConf)} : only submits the job, then poll the 
+   returned handle to the {@link RunningJob} to query status and make 
+   scheduling decisions.
+   </li>
+   <li>
+   {@link JobConf#setJobEndNotificationURI(String)} : setup a notification
+   on job-completion, thus avoiding polling.
+   </li>
+ </ol>
+ 
+ @see JobConf
+ @see ClusterStatus
+ @see Tool
+ @see DistributedCache]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.JobClient -->
+  <!-- start class org.apache.hadoop.mapred.JobConf -->
+  <class name="JobConf" extends="org.apache.hadoop.conf.Configuration"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a map/reduce job configuration.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobConf" type="java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a map/reduce job configuration.
+ 
+ @param exampleClass a class whose containing jar is used as the job's jar.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobConf" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a map/reduce job configuration.
+ 
+ @param conf a Configuration whose settings will be inherited.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobConf" type="org.apache.hadoop.conf.Configuration, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a map/reduce job configuration.
+ 
+ @param conf a Configuration whose settings will be inherited.
+ @param exampleClass a class whose containing jar is used as the job's jar.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobConf" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a map/reduce configuration.
+
+ @param config a Configuration-format XML job description file.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobConf" type="org.apache.hadoop.fs.Path"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a map/reduce configuration.
+
+ @param config a Configuration-format XML job description file.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobConf" type="boolean"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[A new map/reduce configuration where the behavior of reading from the
+ default resources can be turned off.
+ <p>
+ If the parameter {@code loadDefaults} is false, the new instance
+ will not load resources from the default files.
+
+ @param loadDefaults specifies whether to load from the default files]]>
+      </doc>
+    </constructor>
+    <method name="getCredentials" return="org.apache.hadoop.security.Credentials"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get credentials for the job.
+ @return credentials for the job]]>
+      </doc>
+    </method>
+    <method name="getJar" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user jar for the map-reduce job.
+ 
+ @return the user jar for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="setJar"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jar" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the user jar for the map-reduce job.
+ 
+ @param jar the user jar for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getJarUnpackPattern" return="java.util.regex.Pattern"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the pattern for jar contents to unpack on the tasktracker]]>
+      </doc>
+    </method>
+    <method name="setJarByClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the job's jar file by finding an example class location.
+ 
+ @param cls the example class.]]>
+      </doc>
+    </method>
+    <method name="getLocalDirs" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="deleteLocalFiles"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Use MRAsyncDiskService.moveAndDeleteAllVolumes instead.]]>
+      </doc>
+    </method>
+    <method name="deleteLocalFiles"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="subdir" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getLocalPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pathString" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Constructs a local file name. Files are distributed among configured
+ local directories.]]>
+      </doc>
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reported username for this job.
+ 
+ @return the username]]>
+      </doc>
+    </method>
+    <method name="setUser"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="user" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the reported username for this job.
+ 
+ @param user the username for this job.]]>
+      </doc>
+    </method>
+    <method name="setKeepFailedTaskFiles"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="keep" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the framework should keep the intermediate files for 
+ failed tasks.
+ 
+ @param keep <code>true</code> if framework should keep the intermediate files 
+             for failed tasks, <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="getKeepFailedTaskFiles" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Should the temporary files for failed tasks be kept?
+ 
+ @return should the files be kept?]]>
+      </doc>
+    </method>
+    <method name="setKeepTaskFilesPattern"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pattern" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set a regular expression for task names that should be kept. 
+ The regular expression ".*_m_000123_0" would keep the files
+ for the first instance of map 123 that ran.
+ 
+ @param pattern the java.util.regex.Pattern to match against the 
+        task names.]]>
+      </doc>
+    </method>
+    <method name="getKeepTaskFilesPattern" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the regular expression that is matched against the task names
+ to see if we need to keep the files.
+ 
+ @return the pattern as a string, if it was set, othewise null.]]>
+      </doc>
+    </method>
+    <method name="setWorkingDirectory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dir" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the current working directory for the default file system.
+ 
+ @param dir the new current working directory.]]>
+      </doc>
+    </method>
+    <method name="getWorkingDirectory" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the current working directory for the default file system.
+ 
+ @return the directory name.]]>
+      </doc>
+    </method>
+    <method name="setNumTasksToExecutePerJvm"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numTasks" type="int"/>
+      <doc>
+      <![CDATA[Sets the number of tasks that a spawned task JVM should run
+ before it exits
+ @param numTasks the number of tasks to execute; defaults to 1;
+ -1 signifies no limit]]>
+      </doc>
+    </method>
+    <method name="getNumTasksToExecutePerJvm" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of tasks that a spawned JVM should execute]]>
+      </doc>
+    </method>
+    <method name="getInputFormat" return="org.apache.hadoop.mapred.InputFormat"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link InputFormat} implementation for the map-reduce job,
+ defaults to {@link TextInputFormat} if not specified explicity.
+ 
+ @return the {@link InputFormat} implementation for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="setInputFormat"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link InputFormat} implementation for the map-reduce job.
+ 
+ @param theClass the {@link InputFormat} implementation for the map-reduce 
+                 job.]]>
+      </doc>
+    </method>
+    <method name="getOutputFormat" return="org.apache.hadoop.mapred.OutputFormat"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link OutputFormat} implementation for the map-reduce job,
+ defaults to {@link TextOutputFormat} if not specified explicity.
+ 
+ @return the {@link OutputFormat} implementation for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapred.OutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link OutputCommitter} implementation for the map-reduce job,
+ defaults to {@link FileOutputCommitter} if not specified explicitly.
+ 
+ @return the {@link OutputCommitter} implementation for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="setOutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link OutputCommitter} implementation for the map-reduce job.
+ 
+ @param theClass the {@link OutputCommitter} implementation for the map-reduce 
+                 job.]]>
+      </doc>
+    </method>
+    <method name="setOutputFormat"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link OutputFormat} implementation for the map-reduce job.
+ 
+ @param theClass the {@link OutputFormat} implementation for the map-reduce 
+                 job.]]>
+      </doc>
+    </method>
+    <method name="setCompressMapOutput"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="compress" type="boolean"/>
+      <doc>
+      <![CDATA[Should the map outputs be compressed before transfer?
+ 
+ @param compress should the map outputs be compressed?]]>
+      </doc>
+    </method>
+    <method name="getCompressMapOutput" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Are the outputs of the maps be compressed?
+ 
+ @return <code>true</code> if the outputs of the maps are to be compressed,
+         <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="setMapOutputCompressorClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="codecClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the given class as the  {@link CompressionCodec} for the map outputs.
+ 
+ @param codecClass the {@link CompressionCodec} class that will compress  
+                   the map outputs.]]>
+      </doc>
+    </method>
+    <method name="getMapOutputCompressorClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="defaultValue" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Get the {@link CompressionCodec} for compressing the map outputs.
+ 
+ @param defaultValue the {@link CompressionCodec} to return if not set
+ @return the {@link CompressionCodec} class that should be used to compress the 
+         map outputs.
+ @throws IllegalArgumentException if the class was specified, but not found]]>
+      </doc>
+    </method>
+    <method name="getMapOutputKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the key class for the map output data. If it is not set, use the
+ (final) output key class. This allows the map output key class to be
+ different than the final output key class.
+  
+ @return the map output key class.]]>
+      </doc>
+    </method>
+    <method name="setMapOutputKeyClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the key class for the map output data. This allows the user to
+ specify the map output key class to be different than the final output
+ value class.
+ 
+ @param theClass the map output key class.]]>
+      </doc>
+    </method>
+    <method name="getMapOutputValueClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the value class for the map output data. If it is not set, use the
+ (final) output value class This allows the map output value class to be
+ different than the final output value class.
+  
+ @return the map output value class.]]>
+      </doc>
+    </method>
+    <method name="setMapOutputValueClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the value class for the map output data. This allows the user to
+ specify the map output value class to be different than the final output
+ value class.
+ 
+ @param theClass the map output value class.]]>
+      </doc>
+    </method>
+    <method name="getOutputKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the key class for the job output data.
+ 
+ @return the key class for the job output data.]]>
+      </doc>
+    </method>
+    <method name="setOutputKeyClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the key class for the job output data.
+ 
+ @param theClass the key class for the job output data.]]>
+      </doc>
+    </method>
+    <method name="getOutputKeyComparator" return="org.apache.hadoop.io.RawComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link RawComparator} comparator used to compare keys.
+ 
+ @return the {@link RawComparator} comparator used to compare keys.]]>
+      </doc>
+    </method>
+    <method name="setOutputKeyComparatorClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link RawComparator} comparator used to compare keys.
+ 
+ @param theClass the {@link RawComparator} comparator used to 
+                 compare keys.
+ @see #setOutputValueGroupingComparator(Class)]]>
+      </doc>
+    </method>
+    <method name="setKeyFieldComparatorOptions"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="keySpec" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the {@link KeyFieldBasedComparator} options used to compare keys.
+ 
+ @param keySpec the key specification of the form -k pos1[,pos2], where,
+  pos is of the form f[.c][opts], where f is the number
+  of the key field to use, and c is the number of the first character from
+  the beginning of the field. Fields and character posns are numbered 
+  starting with 1; a character position of zero in pos2 indicates the
+  field's last character. If '.c' is omitted from pos1, it defaults to 1
+  (the beginning of the field); if omitted from pos2, it defaults to 0 
+  (the end of the field). opts are ordering options. The supported options
+  are:
+    -n, (Sort numerically)
+    -r, (Reverse the result of comparison)]]>
+      </doc>
+    </method>
+    <method name="getKeyFieldComparatorOption" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link KeyFieldBasedComparator} options]]>
+      </doc>
+    </method>
+    <method name="setKeyFieldPartitionerOptions"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="keySpec" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the {@link KeyFieldBasedPartitioner} options used for 
+ {@link Partitioner}
+ 
+ @param keySpec the key specification of the form -k pos1[,pos2], where,
+  pos is of the form f[.c][opts], where f is the number
+  of the key field to use, and c is the number of the first character from
+  the beginning of the field. Fields and character posns are numbered 
+  starting with 1; a character position of zero in pos2 indicates the
+  field's last character. If '.c' is omitted from pos1, it defaults to 1
+  (the beginning of the field); if omitted from pos2, it defaults to 0 
+  (the end of the field).]]>
+      </doc>
+    </method>
+    <method name="getKeyFieldPartitionerOption" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link KeyFieldBasedPartitioner} options]]>
+      </doc>
+    </method>
+    <method name="getCombinerKeyGroupingComparator" return="org.apache.hadoop.io.RawComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user defined {@link WritableComparable} comparator for
+ grouping keys of inputs to the combiner.
+
+ @return comparator set by the user for grouping values.
+ @see #setCombinerKeyGroupingComparator(Class) for details.]]>
+      </doc>
+    </method>
+    <method name="getOutputValueGroupingComparator" return="org.apache.hadoop.io.RawComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user defined {@link WritableComparable} comparator for 
+ grouping keys of inputs to the reduce.
+ 
+ @return comparator set by the user for grouping values.
+ @see #setOutputValueGroupingComparator(Class) for details.]]>
+      </doc>
+    </method>
+    <method name="setCombinerKeyGroupingComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the user defined {@link RawComparator} comparator for
+ grouping keys in the input to the combiner.
+
+ <p>This comparator should be provided if the equivalence rules for keys
+ for sorting the intermediates are different from those for grouping keys
+ before each call to
+ {@link Reducer#reduce(Object, java.util.Iterator, OutputCollector, Reporter)}.</p>
+
+ <p>For key-value pairs (K1,V1) and (K2,V2), the values (V1, V2) are passed
+ in a single call to the reduce function if K1 and K2 compare as equal.</p>
+
+ <p>Since {@link #setOutputKeyComparatorClass(Class)} can be used to control
+ how keys are sorted, this can be used in conjunction to simulate
+ <i>secondary sort on values</i>.</p>
+
+ <p><i>Note</i>: This is not a guarantee of the combiner sort being
+ <i>stable</i> in any sense. (In any case, with the order of available
+ map-outputs to the combiner being non-deterministic, it wouldn't make
+ that much sense.)</p>
+
+ @param theClass the comparator class to be used for grouping keys for the
+ combiner. It should implement <code>RawComparator</code>.
+ @see #setOutputKeyComparatorClass(Class)]]>
+      </doc>
+    </method>
+    <method name="setOutputValueGroupingComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the user defined {@link RawComparator} comparator for 
+ grouping keys in the input to the reduce.
+ 
+ <p>This comparator should be provided if the equivalence rules for keys
+ for sorting the intermediates are different from those for grouping keys
+ before each call to 
+ {@link Reducer#reduce(Object, java.util.Iterator, OutputCollector, Reporter)}.</p>
+  
+ <p>For key-value pairs (K1,V1) and (K2,V2), the values (V1, V2) are passed
+ in a single call to the reduce function if K1 and K2 compare as equal.</p>
+ 
+ <p>Since {@link #setOutputKeyComparatorClass(Class)} can be used to control 
+ how keys are sorted, this can be used in conjunction to simulate 
+ <i>secondary sort on values</i>.</p>
+  
+ <p><i>Note</i>: This is not a guarantee of the reduce sort being 
+ <i>stable</i> in any sense. (In any case, with the order of available 
+ map-outputs to the reduce being non-deterministic, it wouldn't make 
+ that much sense.)</p>
+ 
+ @param theClass the comparator class to be used for grouping keys. 
+                 It should implement <code>RawComparator</code>.
+ @see #setOutputKeyComparatorClass(Class)
+ @see #setCombinerKeyGroupingComparator(Class)]]>
+      </doc>
+    </method>
+    <method name="getUseNewMapper" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Should the framework use the new context-object code for running
+ the mapper?
+ @return true, if the new api should be used]]>
+      </doc>
+    </method>
+    <method name="setUseNewMapper"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flag" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the framework should use the new api for the mapper.
+ This is the default for jobs submitted with the new Job api.
+ @param flag true, if the new api should be used]]>
+      </doc>
+    </method>
+    <method name="getUseNewReducer" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Should the framework use the new context-object code for running
+ the reducer?
+ @return true, if the new api should be used]]>
+      </doc>
+    </method>
+    <method name="setUseNewReducer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flag" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the framework should use the new api for the reducer. 
+ This is the default for jobs submitted with the new Job api.
+ @param flag true, if the new api should be used]]>
+      </doc>
+    </method>
+    <method name="getOutputValueClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the value class for job outputs.
+ 
+ @return the value class for job outputs.]]>
+      </doc>
+    </method>
+    <method name="setOutputValueClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the value class for job outputs.
+ 
+ @param theClass the value class for job outputs.]]>
+      </doc>
+    </method>
+    <method name="getMapperClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link Mapper} class for the job.
+ 
+ @return the {@link Mapper} class for the job.]]>
+      </doc>
+    </method>
+    <method name="setMapperClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link Mapper} class for the job.
+ 
+ @param theClass the {@link Mapper} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getMapRunnerClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link MapRunnable} class for the job.
+ 
+ @return the {@link MapRunnable} class for the job.]]>
+      </doc>
+    </method>
+    <method name="setMapRunnerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Expert: Set the {@link MapRunnable} class for the job.
+ 
+ Typically used to exert greater control on {@link Mapper}s.
+ 
+ @param theClass the {@link MapRunnable} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getPartitionerClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link Partitioner} used to partition {@link Mapper}-outputs 
+ to be sent to the {@link Reducer}s.
+ 
+ @return the {@link Partitioner} used to partition map-outputs.]]>
+      </doc>
+    </method>
+    <method name="setPartitionerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link Partitioner} class used to partition 
+ {@link Mapper}-outputs to be sent to the {@link Reducer}s.
+ 
+ @param theClass the {@link Partitioner} used to partition map-outputs.]]>
+      </doc>
+    </method>
+    <method name="getReducerClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link Reducer} class for the job.
+ 
+ @return the {@link Reducer} class for the job.]]>
+      </doc>
+    </method>
+    <method name="setReducerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link Reducer} class for the job.
+ 
+ @param theClass the {@link Reducer} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getCombinerClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-defined <i>combiner</i> class used to combine map-outputs 
+ before being sent to the reducers. Typically the combiner is same as the
+ the {@link Reducer} for the job i.e. {@link #getReducerClass()}.
+ 
+ @return the user-defined combiner class used to combine map-outputs.]]>
+      </doc>
+    </method>
+    <method name="setCombinerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the user-defined <i>combiner</i> class used to combine map-outputs 
+ before being sent to the reducers. 
+ 
+ <p>The combiner is an application-specified aggregation operation, which
+ can help cut down the amount of data transferred between the 
+ {@link Mapper} and the {@link Reducer}, leading to better performance.</p>
+ 
+ <p>The framework may invoke the combiner 0, 1, or multiple times, in both
+ the mapper and reducer tasks. In general, the combiner is called as the
+ sort/merge result is written to disk. The combiner must:
+ <ul>
+   <li> be side-effect free</li>
+   <li> have the same input and output key types and the same input and 
+        output value types</li>
+ </ul>
+ 
+ <p>Typically the combiner is same as the <code>Reducer</code> for the  
+ job i.e. {@link #setReducerClass(Class)}.</p>
+ 
+ @param theClass the user-defined combiner class used to combine 
+                 map-outputs.]]>
+      </doc>
+    </method>
+    <method name="getSpeculativeExecution" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Should speculative execution be used for this job? 
+ Defaults to <code>true</code>.
+ 
+ @return <code>true</code> if speculative execution be used for this job,
+         <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="setSpeculativeExecution"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="speculativeExecution" type="boolean"/>
+      <doc>
+      <![CDATA[Turn speculative execution on or off for this job. 
+ 
+ @param speculativeExecution <code>true</code> if speculative execution 
+                             should be turned on, else <code>false</code>.]]>
+      </doc>
+    </method>
+    <method name="getMapSpeculativeExecution" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Should speculative execution be used for this job for map tasks? 
+ Defaults to <code>true</code>.
+ 
+ @return <code>true</code> if speculative execution be 
+                           used for this job for map tasks,
+         <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="setMapSpeculativeExecution"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="speculativeExecution" type="boolean"/>
+      <doc>
+      <![CDATA[Turn speculative execution on or off for this job for map tasks. 
+ 
+ @param speculativeExecution <code>true</code> if speculative execution 
+                             should be turned on for map tasks,
+                             else <code>false</code>.]]>
+      </doc>
+    </method>
+    <method name="getReduceSpeculativeExecution" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Should speculative execution be used for this job for reduce tasks? 
+ Defaults to <code>true</code>.
+ 
+ @return <code>true</code> if speculative execution be used 
+                           for reduce tasks for this job,
+         <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="setReduceSpeculativeExecution"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="speculativeExecution" type="boolean"/>
+      <doc>
+      <![CDATA[Turn speculative execution on or off for this job for reduce tasks. 
+ 
+ @param speculativeExecution <code>true</code> if speculative execution 
+                             should be turned on for reduce tasks,
+                             else <code>false</code>.]]>
+      </doc>
+    </method>
+    <method name="getNumMapTasks" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configured number of map tasks for this job.
+ Defaults to <code>1</code>.
+ 
+ @return the number of map tasks for this job.]]>
+      </doc>
+    </method>
+    <method name="setNumMapTasks"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[Set the number of map tasks for this job.
+ 
+ <p><i>Note</i>: This is only a <i>hint</i> to the framework. The actual 
+ number of spawned map tasks depends on the number of {@link InputSplit}s 
+ generated by the job's {@link InputFormat#getSplits(JobConf, int)}.
+  
+ A custom {@link InputFormat} is typically used to accurately control 
+ the number of map tasks for the job.</p>
+ 
+ <b id="NoOfMaps">How many maps?</b>
+ 
+ <p>The number of maps is usually driven by the total size of the inputs 
+ i.e. total number of blocks of the input files.</p>
+  
+ <p>The right level of parallelism for maps seems to be around 10-100 maps 
+ per-node, although it has been set up to 300 or so for very cpu-light map 
+ tasks. Task setup takes awhile, so it is best if the maps take at least a 
+ minute to execute.</p>
+ 
+ <p>The default behavior of file-based {@link InputFormat}s is to split the 
+ input into <i>logical</i> {@link InputSplit}s based on the total size, in 
+ bytes, of input files. However, the {@link FileSystem} blocksize of the 
+ input files is treated as an upper bound for input splits. A lower bound 
+ on the split size can be set via 
+ <a href="{@docRoot}/../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml#mapreduce.input.fileinputformat.split.minsize">
+ mapreduce.input.fileinputformat.split.minsize</a>.</p>
+  
+ <p>Thus, if you expect 10TB of input data and have a blocksize of 128MB, 
+ you'll end up with 82,000 maps, unless {@link #setNumMapTasks(int)} is 
+ used to set it even higher.</p>
+ 
+ @param n the number of map tasks for this job.
+ @see InputFormat#getSplits(JobConf, int)
+ @see FileInputFormat
+ @see FileSystem#getDefaultBlockSize()
+ @see FileStatus#getBlockSize()]]>
+      </doc>
+    </method>
+    <method name="getNumReduceTasks" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configured number of reduce tasks for this job. Defaults to
+ <code>1</code>.
+
+ @return the number of reduce tasks for this job.]]>
+      </doc>
+    </method>
+    <method name="setNumReduceTasks"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[Set the requisite number of reduce tasks for this job.
+ 
+ <b id="NoOfReduces">How many reduces?</b>
+ 
+ <p>The right number of reduces seems to be <code>0.95</code> or 
+ <code>1.75</code> multiplied by (
+ <i>available memory for reduce tasks</i>
+ (The value of this should be smaller than
+ numNodes * yarn.nodemanager.resource.memory-mb
+ since the resource of memory is shared by map tasks and other
+ applications) /
+ <a href="{@docRoot}/../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml#mapreduce.reduce.memory.mb">
+ mapreduce.reduce.memory.mb</a>).
+ </p>
+ 
+ <p>With <code>0.95</code> all of the reduces can launch immediately and 
+ start transfering map outputs as the maps finish. With <code>1.75</code> 
+ the faster nodes will finish their first round of reduces and launch a 
+ second wave of reduces doing a much better job of load balancing.</p>
+ 
+ <p>Increasing the number of reduces increases the framework overhead, but 
+ increases load balancing and lowers the cost of failures.</p>
+ 
+ <p>The scaling factors above are slightly less than whole numbers to 
+ reserve a few reduce slots in the framework for speculative-tasks, failures
+ etc.</p> 
+
+ <b id="ReducerNone">Reducer NONE</b>
+ 
+ <p>It is legal to set the number of reduce-tasks to <code>zero</code>.</p>
+ 
+ <p>In this case the output of the map-tasks directly go to distributed 
+ file-system, to the path set by 
+ {@link FileOutputFormat#setOutputPath(JobConf, Path)}. Also, the 
+ framework doesn't sort the map-outputs before writing it out to HDFS.</p>
+ 
+ @param n the number of reduce tasks for this job.]]>
+      </doc>
+    </method>
+    <method name="getMaxMapAttempts" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configured number of maximum attempts that will be made to run a
+ map task, as specified by the <code>mapreduce.map.maxattempts</code>
+ property. If this property is not already set, the default is 4 attempts.
+  
+ @return the max number of attempts per map task.]]>
+      </doc>
+    </method>
+    <method name="setMaxMapAttempts"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[Expert: Set the number of maximum attempts that will be made to run a
+ map task.
+ 
+ @param n the number of attempts per map task.]]>
+      </doc>
+    </method>
+    <method name="getMaxReduceAttempts" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configured number of maximum attempts  that will be made to run a
+ reduce task, as specified by the <code>mapreduce.reduce.maxattempts</code>
+ property. If this property is not already set, the default is 4 attempts.
+ 
+ @return the max number of attempts per reduce task.]]>
+      </doc>
+    </method>
+    <method name="setMaxReduceAttempts"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[Expert: Set the number of maximum attempts that will be made to run a
+ reduce task.
+ 
+ @param n the number of attempts per reduce task.]]>
+      </doc>
+    </method>
+    <method name="getJobName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-specified job name. This is only used to identify the 
+ job to the user.
+ 
+ @return the job's name, defaulting to "".]]>
+      </doc>
+    </method>
+    <method name="setJobName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the user-specified job name.
+ 
+ @param name the job's new name.]]>
+      </doc>
+    </method>
+    <method name="getSessionId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-specified session identifier. The default is the empty string.
+
+ The session identifier is used to tag metric data that is reported to some
+ performance metrics system via the org.apache.hadoop.metrics API.  The 
+ session identifier is intended, in particular, for use by Hadoop-On-Demand 
+ (HOD) which allocates a virtual Hadoop cluster dynamically and transiently. 
+ HOD will set the session identifier by modifying the mapred-site.xml file 
+ before starting the cluster.
+
+ When not running under HOD, this identifer is expected to remain set to 
+ the empty string.
+
+ @return the session identifier, defaulting to "".]]>
+      </doc>
+    </method>
+    <method name="setSessionId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="sessionId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the user-specified session identifier.  
+
+ @param sessionId the new session id.]]>
+      </doc>
+    </method>
+    <method name="setMaxTaskFailuresPerTracker"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="noFailures" type="int"/>
+      <doc>
+      <![CDATA[Set the maximum no. of failures of a given job per tasktracker.
+ If the no. of task failures exceeds <code>noFailures</code>, the 
+ tasktracker is <i>blacklisted</i> for this job. 
+ 
+ @param noFailures maximum no. of failures of a given job per tasktracker.]]>
+      </doc>
+    </method>
+    <method name="getMaxTaskFailuresPerTracker" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Expert: Get the maximum no. of failures of a given job per tasktracker.
+ If the no. of task failures exceeds this, the tasktracker is
+ <i>blacklisted</i> for this job. 
+ 
+ @return the maximum no. of failures of a given job per tasktracker.]]>
+      </doc>
+    </method>
+    <method name="getMaxMapTaskFailuresPercent" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the maximum percentage of map tasks that can fail without 
+ the job being aborted. 
+ 
+ Each map task is executed a minimum of {@link #getMaxMapAttempts()} 
+ attempts before being declared as <i>failed</i>.
+  
+ Defaults to <code>zero</code>, i.e. <i>any</i> failed map-task results in
+ the job being declared as {@link JobStatus#FAILED}.
+ 
+ @return the maximum percentage of map tasks that can fail without
+         the job being aborted.]]>
+      </doc>
+    </method>
+    <method name="setMaxMapTaskFailuresPercent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="percent" type="int"/>
+      <doc>
+      <![CDATA[Expert: Set the maximum percentage of map tasks that can fail without the
+ job being aborted. 
+ 
+ Each map task is executed a minimum of {@link #getMaxMapAttempts} attempts 
+ before being declared as <i>failed</i>.
+ 
+ @param percent the maximum percentage of map tasks that can fail without 
+                the job being aborted.]]>
+      </doc>
+    </method>
+    <method name="getMaxReduceTaskFailuresPercent" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the maximum percentage of reduce tasks that can fail without 
+ the job being aborted. 
+ 
+ Each reduce task is executed a minimum of {@link #getMaxReduceAttempts()} 
+ attempts before being declared as <i>failed</i>.
+ 
+ Defaults to <code>zero</code>, i.e. <i>any</i> failed reduce-task results 
+ in the job being declared as {@link JobStatus#FAILED}.
+ 
+ @return the maximum percentage of reduce tasks that can fail without
+         the job being aborted.]]>
+      </doc>
+    </method>
+    <method name="setMaxReduceTaskFailuresPercent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="percent" type="int"/>
+      <doc>
+      <![CDATA[Set the maximum percentage of reduce tasks that can fail without the job
+ being aborted.
+ 
+ Each reduce task is executed a minimum of {@link #getMaxReduceAttempts()} 
+ attempts before being declared as <i>failed</i>.
+ 
+ @param percent the maximum percentage of reduce tasks that can fail without 
+                the job being aborted.]]>
+      </doc>
+    </method>
+    <method name="setJobPriority"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="prio" type="org.apache.hadoop.mapred.JobPriority"/>
+      <doc>
+      <![CDATA[Set {@link JobPriority} for this job.
+
+ @param prio the {@link JobPriority} for this job.]]>
+      </doc>
+    </method>
+    <method name="setJobPriorityAsInteger"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="prio" type="int"/>
+      <doc>
+      <![CDATA[Set {@link JobPriority} for this job.
+
+ @param prio the {@link JobPriority} for this job.]]>
+      </doc>
+    </method>
+    <method name="getJobPriority" return="org.apache.hadoop.mapred.JobPriority"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link JobPriority} for this job.
+
+ @return the {@link JobPriority} for this job.]]>
+      </doc>
+    </method>
+    <method name="getJobPriorityAsInteger" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the priority for this job.
+
+ @return the priority for this job.]]>
+      </doc>
+    </method>
+    <method name="getProfileEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether the task profiling is enabled.
+ @return true if some tasks will be profiled]]>
+      </doc>
+    </method>
+    <method name="setProfileEnabled"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="newValue" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the system should collect profiler information for some of 
+ the tasks in this job? The information is stored in the user log 
+ directory.
+ @param newValue true means it should be gathered]]>
+      </doc>
+    </method>
+    <method name="getProfileParams" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the profiler configuration arguments.
+
+ The default value for this property is
+ "-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s"
+ 
+ @return the parameters to pass to the task child to configure profiling]]>
+      </doc>
+    </method>
+    <method name="setProfileParams"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="value" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the profiler configuration arguments. If the string contains a '%s' it
+ will be replaced with the name of the profiling output file when the task
+ runs.
+
+ This value is passed to the task child JVM on the command line.
+
+ @param value the configuration string]]>
+      </doc>
+    </method>
+    <method name="getProfileTaskRange" return="org.apache.hadoop.conf.Configuration.IntegerRanges"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isMap" type="boolean"/>
+      <doc>
+      <![CDATA[Get the range of maps or reduces to profile.
+ @param isMap is the task a map?
+ @return the task ranges]]>
+      </doc>
+    </method>
+    <method name="setProfileTaskRange"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isMap" type="boolean"/>
+      <param name="newValue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the ranges of maps or reduces to profile. setProfileEnabled(true) 
+ must also be called.
+ @param newValue a set of integer ranges of the map ids]]>
+      </doc>
+    </method>
+    <method name="setMapDebugScript"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="mDbgScript" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the debug script to run when the map tasks fail.
+ 
+ <p>The debug script can aid debugging of failed map tasks. The script is 
+ given task's stdout, stderr, syslog, jobconf files as arguments.</p>
+ 
+ <p>The debug command, run on the node where the map failed, is:</p>
+ <p><blockquote><pre>
+ $script $stdout $stderr $syslog $jobconf.
+ </pre></blockquote>
+ 
+ <p> The script file is distributed through {@link DistributedCache} 
+ APIs. The script needs to be symlinked. </p>
+ 
+ <p>Here is an example on how to submit a script 
+ <p><blockquote><pre>
+ job.setMapDebugScript("./myscript");
+ DistributedCache.createSymlink(job);
+ DistributedCache.addCacheFile("/debug/scripts/myscript#myscript");
+ </pre></blockquote>
+ 
+ @param mDbgScript the script name]]>
+      </doc>
+    </method>
+    <method name="getMapDebugScript" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the map task's debug script.
+ 
+ @return the debug Script for the mapred job for failed map tasks.
+ @see #setMapDebugScript(String)]]>
+      </doc>
+    </method>
+    <method name="setReduceDebugScript"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rDbgScript" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the debug script to run when the reduce tasks fail.
+ 
+ <p>The debug script can aid debugging of failed reduce tasks. The script
+ is given task's stdout, stderr, syslog, jobconf files as arguments.</p>
+ 
+ <p>The debug command, run on the node where the map failed, is:</p>
+ <p><blockquote><pre>
+ $script $stdout $stderr $syslog $jobconf.
+ </pre></blockquote>
+ 
+ <p> The script file is distributed through {@link DistributedCache} 
+ APIs. The script file needs to be symlinked </p>
+ 
+ <p>Here is an example on how to submit a script 
+ <p><blockquote><pre>
+ job.setReduceDebugScript("./myscript");
+ DistributedCache.createSymlink(job);
+ DistributedCache.addCacheFile("/debug/scripts/myscript#myscript");
+ </pre></blockquote>
+ 
+ @param rDbgScript the script name]]>
+      </doc>
+    </method>
+    <method name="getReduceDebugScript" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reduce task's debug Script
+ 
+ @return the debug script for the mapred job for failed reduce tasks.
+ @see #setReduceDebugScript(String)]]>
+      </doc>
+    </method>
+    <method name="getJobEndNotificationURI" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the uri to be invoked in-order to send a notification after the job 
+ has completed (success/failure). 
+ 
+ @return the job end notification uri, <code>null</code> if it hasn't
+         been set.
+ @see #setJobEndNotificationURI(String)]]>
+      </doc>
+    </method>
+    <method name="setJobEndNotificationURI"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uri" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the uri to be invoked in-order to send a notification after the job
+ has completed (success/failure).
+ 
+ <p>The uri can contain 2 special parameters: <tt>$jobId</tt> and 
+ <tt>$jobStatus</tt>. Those, if present, are replaced by the job's 
+ identifier and completion-status respectively.</p>
+ 
+ <p>This is typically used by application-writers to implement chaining of 
+ Map-Reduce jobs in an <i>asynchronous manner</i>.</p>
+ 
+ @param uri the job end notification uri
+ @see JobStatus]]>
+      </doc>
+    </method>
+    <method name="getJobEndNotificationCustomNotifierClass" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the class to be invoked in order to send a notification
+ after the job has completed (success/failure).
+
+ @return the fully-qualified name of the class which implements
+ {@link org.apache.hadoop.mapreduce.CustomJobEndNotifier} set through the
+ {@link org.apache.hadoop.mapreduce.MRJobConfig#MR_JOB_END_NOTIFICATION_CUSTOM_NOTIFIER_CLASS}
+ property
+
+ @see JobConf#setJobEndNotificationCustomNotifierClass(java.lang.String)
+ @see org.apache.hadoop.mapreduce.MRJobConfig#MR_JOB_END_NOTIFICATION_CUSTOM_NOTIFIER_CLASS]]>
+      </doc>
+    </method>
+    <method name="setJobEndNotificationCustomNotifierClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="customNotifierClassName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets the class to be invoked in order to send a notification after the job
+ has completed (success/failure).
+
+ A notification url still has to be set which will be passed to
+ {@link org.apache.hadoop.mapreduce.CustomJobEndNotifier#notifyOnce(
+ java.net.URL, org.apache.hadoop.conf.Configuration)}
+ along with the Job's conf.
+
+ If this is set instead of using a simple HttpURLConnection
+ we'll create a new instance of this class
+ which should be an implementation of
+ {@link org.apache.hadoop.mapreduce.CustomJobEndNotifier},
+ and we'll invoke that.
+
+ @param customNotifierClassName the fully-qualified name of the class
+     which implements
+     {@link org.apache.hadoop.mapreduce.CustomJobEndNotifier}
+
+ @see JobConf#setJobEndNotificationURI(java.lang.String)
+ @see
+ org.apache.hadoop.mapreduce.MRJobConfig#MR_JOB_END_NOTIFICATION_CUSTOM_NOTIFIER_CLASS]]>
+      </doc>
+    </method>
+    <method name="getJobLocalDir" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get job-specific shared directory for use as scratch space
+ 
+ <p>
+ When a job starts, a shared directory is created at location
+ <code>
+ ${mapreduce.cluster.local.dir}/taskTracker/$user/jobcache/$jobid/work/ </code>.
+ This directory is exposed to the users through 
+ <code>mapreduce.job.local.dir </code>.
+ So, the tasks can use this space 
+ as scratch space and share files among them. </p>
+ This value is available as System property also.
+ 
+ @return The localized job specific shared directory]]>
+      </doc>
+    </method>
+    <method name="getMemoryForMapTask" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get memory required to run a map task of the job, in MB.
+ 
+ If a value is specified in the configuration, it is returned.
+ Else, it returns {@link JobContext#DEFAULT_MAP_MEMORY_MB}.
+ <p>
+ For backward compatibility, if the job configuration sets the
+ key {@link #MAPRED_TASK_MAXVMEM_PROPERTY} to a value different
+ from {@link #DISABLED_MEMORY_LIMIT}, that value will be used
+ after converting it from bytes to MB.
+ @return memory required to run a map task of the job, in MB,]]>
+      </doc>
+    </method>
+    <method name="setMemoryForMapTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="mem" type="long"/>
+    </method>
+    <method name="getMemoryForReduceTask" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get memory required to run a reduce task of the job, in MB.
+ 
+ If a value is specified in the configuration, it is returned.
+ Else, it returns {@link JobContext#DEFAULT_REDUCE_MEMORY_MB}.
+ <p>
+ For backward compatibility, if the job configuration sets the
+ key {@link #MAPRED_TASK_MAXVMEM_PROPERTY} to a value different
+ from {@link #DISABLED_MEMORY_LIMIT}, that value will be used
+ after converting it from bytes to MB.
+ @return memory required to run a reduce task of the job, in MB.]]>
+      </doc>
+    </method>
+    <method name="setMemoryForReduceTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="mem" type="long"/>
+    </method>
+    <method name="getQueueName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the name of the queue to which this job is submitted.
+ Defaults to 'default'.
+ 
+ @return name of the queue]]>
+      </doc>
+    </method>
+    <method name="setQueueName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the name of the queue to which this job should be submitted.
+ 
+ @param queueName Name of the queue]]>
+      </doc>
+    </method>
+    <method name="normalizeMemoryConfigValue" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="long"/>
+      <doc>
+      <![CDATA[Normalize the negative values in configuration
+ 
+ @param val
+ @return normalized value]]>
+      </doc>
+    </method>
+    <method name="findContainingJar" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="my_class" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Find a jar that contains a class of the same name, if any.
+ It will return a jar file, even if that is not the first thing
+ on the class path that has a class with the same name.
+ 
+ @param my_class the class to find.
+ @return a jar file that contains the class, or null.]]>
+      </doc>
+    </method>
+    <method name="getMaxVirtualMemoryForTask" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #getMemoryForMapTask()} and
+             {@link #getMemoryForReduceTask()}">
+      <doc>
+      <![CDATA[Get the memory required to run a task of this job, in bytes. See
+ {@link #MAPRED_TASK_MAXVMEM_PROPERTY}
+ <p>
+ This method is deprecated. Now, different memory limits can be
+ set for map and reduce tasks of a job, in MB. 
+ <p>
+ For backward compatibility, if the job configuration sets the
+ key {@link #MAPRED_TASK_MAXVMEM_PROPERTY}, that value is returned. 
+ Otherwise, this method will return the larger of the values returned by 
+ {@link #getMemoryForMapTask()} and {@link #getMemoryForReduceTask()}
+ after converting them into bytes.
+
+ @return Memory required to run a task of this job, in bytes.
+ @see #setMaxVirtualMemoryForTask(long)
+ @deprecated Use {@link #getMemoryForMapTask()} and
+             {@link #getMemoryForReduceTask()}]]>
+      </doc>
+    </method>
+    <method name="setMaxVirtualMemoryForTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #setMemoryForMapTask(long mem)}  and
+  Use {@link #setMemoryForReduceTask(long mem)}">
+      <param name="vmem" type="long"/>
+      <doc>
+      <![CDATA[Set the maximum amount of memory any task of this job can use. See
+ {@link #MAPRED_TASK_MAXVMEM_PROPERTY}
+ <p>
+ mapred.task.maxvmem is split into
+ mapreduce.map.memory.mb
+ and mapreduce.map.memory.mb,mapred
+ each of the new key are set
+ as mapred.task.maxvmem / 1024
+ as new values are in MB
+
+ @param vmem Maximum amount of virtual memory in bytes any task of this job
+             can use.
+ @see #getMaxVirtualMemoryForTask()
+ @deprecated
+  Use {@link #setMemoryForMapTask(long mem)}  and
+  Use {@link #setMemoryForReduceTask(long mem)}]]>
+      </doc>
+    </method>
+    <method name="getMaxPhysicalMemoryForTask" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="this variable is deprecated and nolonger in use.">
+      <doc>
+      <![CDATA[@deprecated this variable is deprecated and nolonger in use.]]>
+      </doc>
+    </method>
+    <method name="setMaxPhysicalMemoryForTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="mem" type="long"/>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <field name="MAPRED_TASK_MAXVMEM_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Use {@link #MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY} and
+ {@link #MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY}">
+      <doc>
+      <![CDATA[@deprecated Use {@link #MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY} and
+ {@link #MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY}]]>
+      </doc>
+    </field>
+    <field name="UPPER_LIMIT_ON_TASK_VMEM_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="deprecated, no comment">
+      <doc>
+      <![CDATA[@deprecated]]>
+      </doc>
+    </field>
+    <field name="MAPRED_TASK_DEFAULT_MAXVMEM_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="deprecated, no comment">
+      <doc>
+      <![CDATA[@deprecated]]>
+      </doc>
+    </field>
+    <field name="MAPRED_TASK_MAXPMEM_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="deprecated, no comment">
+      <doc>
+      <![CDATA[@deprecated]]>
+      </doc>
+    </field>
+    <field name="DISABLED_MEMORY_LIMIT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[A value which if set for memory related configuration options,
+ indicates that the options are turned off.
+ Deprecated because it makes no sense in the context of MR2.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_LOCAL_DIR_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Property name for the configuration property mapreduce.cluster.local.dir]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_QUEUE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Name of the queue to which jobs will be submitted, if no queue
+ name is mentioned.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_JOB_MAP_MEMORY_MB_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, while M/R 2.x applications
+ should use {@link #MAPREDUCE_JOB_MAP_MEMORY_MB_PROPERTY}]]>
+      </doc>
+    </field>
+    <field name="MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, while M/R 2.x applications
+ should use {@link #MAPREDUCE_JOB_REDUCE_MEMORY_MB_PROPERTY}]]>
+      </doc>
+    </field>
+    <field name="UNPACK_JAR_PATTERN_DEFAULT" type="java.util.regex.Pattern"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Pattern for the default unpacking behavior for job jars]]>
+      </doc>
+    </field>
+    <field name="MAPRED_TASK_JAVA_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Use {@link #MAPRED_MAP_TASK_JAVA_OPTS} or 
+                 {@link #MAPRED_REDUCE_TASK_JAVA_OPTS}">
+      <doc>
+      <![CDATA[Configuration key to set the java command line options for the child
+ map and reduce tasks.
+ 
+ Java opts for the task tracker child processes.
+ The following symbol, if present, will be interpolated: @taskid@. 
+ It is replaced by current TaskID. Any other occurrences of '@' will go 
+ unchanged.
+ For example, to enable verbose gc logging to a file named for the taskid in
+ /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
+          -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc
+ 
+ The configuration variable {@link #MAPRED_TASK_ENV} can be used to pass 
+ other environment variables to the child processes.
+ 
+ @deprecated Use {@link #MAPRED_MAP_TASK_JAVA_OPTS} or 
+                 {@link #MAPRED_REDUCE_TASK_JAVA_OPTS}]]>
+      </doc>
+    </field>
+    <field name="MAPRED_MAP_TASK_JAVA_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set the java command line options for the map tasks.
+ 
+ Java opts for the task tracker child map processes.
+ The following symbol, if present, will be interpolated: @taskid@. 
+ It is replaced by current TaskID. Any other occurrences of '@' will go 
+ unchanged.
+ For example, to enable verbose gc logging to a file named for the taskid in
+ /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
+          -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc
+ 
+ The configuration variable {@link #MAPRED_MAP_TASK_ENV} can be used to pass 
+ other environment variables to the map processes.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_REDUCE_TASK_JAVA_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set the java command line options for the reduce tasks.
+ 
+ Java opts for the task tracker child reduce processes.
+ The following symbol, if present, will be interpolated: @taskid@. 
+ It is replaced by current TaskID. Any other occurrences of '@' will go 
+ unchanged.
+ For example, to enable verbose gc logging to a file named for the taskid in
+ /tmp and to set the heap maximum to be a gigabyte, pass a 'value' of:
+          -Xmx1024m -verbose:gc -Xloggc:/tmp/@taskid@.gc
+ 
+ The configuration variable {@link #MAPRED_REDUCE_TASK_ENV} can be used to 
+ pass process environment variables to the reduce processes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_MAPRED_TASK_JAVA_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAPRED_TASK_ULIMIT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Configuration key to set the maximum virtual memory available to the child
+ map and reduce tasks (in kilo-bytes). This has been deprecated and will no
+ longer have any effect.">
+      <doc>
+      <![CDATA[@deprecated
+ Configuration key to set the maximum virtual memory available to the child
+ map and reduce tasks (in kilo-bytes). This has been deprecated and will no
+ longer have any effect.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_MAP_TASK_ULIMIT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Configuration key to set the maximum virtual memory available to the
+ map tasks (in kilo-bytes). This has been deprecated and will no
+ longer have any effect.">
+      <doc>
+      <![CDATA[@deprecated
+ Configuration key to set the maximum virtual memory available to the
+ map tasks (in kilo-bytes). This has been deprecated and will no
+ longer have any effect.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_REDUCE_TASK_ULIMIT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Configuration key to set the maximum virtual memory available to the
+ reduce tasks (in kilo-bytes). This has been deprecated and will no
+ longer have any effect.">
+      <doc>
+      <![CDATA[@deprecated
+ Configuration key to set the maximum virtual memory available to the
+ reduce tasks (in kilo-bytes). This has been deprecated and will no
+ longer have any effect.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_TASK_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Use {@link #MAPRED_MAP_TASK_ENV} or 
+                 {@link #MAPRED_REDUCE_TASK_ENV}">
+      <doc>
+      <![CDATA[Configuration key to set the environment of the child map/reduce tasks.
+ 
+ The format of the value is <code>k1=v1,k2=v2</code>. Further it can 
+ reference existing environment variables via <code>$key</code> on
+ Linux or <code>%key%</code> on Windows.
+ 
+ Example:
+ <ul>
+   <li> A=foo - This will set the env variable A to foo. </li>
+ </ul>
+ 
+ @deprecated Use {@link #MAPRED_MAP_TASK_ENV} or 
+                 {@link #MAPRED_REDUCE_TASK_ENV}]]>
+      </doc>
+    </field>
+    <field name="MAPRED_MAP_TASK_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set the environment of the child map tasks.
+ 
+ The format of the value is <code>k1=v1,k2=v2</code>. Further it can
+ reference existing environment variables via <code>$key</code> on
+ Linux or <code>%key%</code> on Windows.
+ 
+ Example:
+ <ul>
+   <li> A=foo - This will set the env variable A to foo. </li>
+ </ul>
+
+ You can also add environment variables individually by appending
+ <code>.VARNAME</code> to this configuration key, where VARNAME is
+ the name of the environment variable.
+
+ Example:
+ <ul>
+   <li>mapreduce.map.env.VARNAME=value</li>
+ </ul>]]>
+      </doc>
+    </field>
+    <field name="MAPRED_REDUCE_TASK_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set the environment of the child reduce tasks.
+ 
+ The format of the value is <code>k1=v1,k2=v2</code>. Further it can 
+ reference existing environment variables via <code>$key</code> on
+ Linux or <code>%key%</code> on Windows.
+ 
+ Example:
+ <ul>
+   <li> A=foo - This will set the env variable A to foo. </li>
+ </ul>
+
+ You can also add environment variables individually by appending
+ <code>.VARNAME</code> to this configuration key, where VARNAME is
+ the name of the environment variable.
+
+ Example:
+ <ul>
+   <li>mapreduce.reduce.env.VARNAME=value</li>
+ </ul>]]>
+      </doc>
+    </field>
+    <field name="MAPRED_MAP_TASK_LOG_LEVEL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set the logging level for the map task.
+
+ The allowed logging levels are:
+ OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE and ALL.]]>
+      </doc>
+    </field>
+    <field name="MAPRED_REDUCE_TASK_LOG_LEVEL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set the logging level for the reduce task.
+
+ The allowed logging levels are:
+ OFF, FATAL, ERROR, WARN, INFO, DEBUG, TRACE and ALL.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_LOG_LEVEL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default logging level for map/reduce tasks.]]>
+      </doc>
+    </field>
+    <field name="WORKFLOW_ID" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#WORKFLOW_ID} instead]]>
+      </doc>
+    </field>
+    <field name="WORKFLOW_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#WORKFLOW_NAME} instead]]>
+      </doc>
+    </field>
+    <field name="WORKFLOW_NODE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#WORKFLOW_NODE_NAME} instead]]>
+      </doc>
+    </field>
+    <field name="WORKFLOW_ADJACENCY_PREFIX_STRING" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#WORKFLOW_ADJACENCY_PREFIX_STRING} instead]]>
+      </doc>
+    </field>
+    <field name="WORKFLOW_ADJACENCY_PREFIX_PATTERN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#WORKFLOW_ADJACENCY_PREFIX_PATTERN} instead]]>
+      </doc>
+    </field>
+    <field name="WORKFLOW_TAGS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ use {@link MRJobConfig#WORKFLOW_TAGS} instead]]>
+      </doc>
+    </field>
+    <field name="MAPREDUCE_RECOVER_JOB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ not use it]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_MAPREDUCE_RECOVER_JOB" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The variable is kept for M/R 1.x applications, M/R 2.x applications should
+ not use it]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A map/reduce job configuration.
+ 
+ <p><code>JobConf</code> is the primary interface for a user to describe a 
+ map-reduce job to the Hadoop framework for execution. The framework tries to
+ faithfully execute the job as-is described by <code>JobConf</code>, however:
+ <ol>
+   <li>
+   Some configuration parameters might have been marked as 
+   <a href="{@docRoot}/org/apache/hadoop/conf/Configuration.html#FinalParams">
+   final</a> by administrators and hence cannot be altered.
+   </li>
+   <li>
+   While some job parameters are straight-forward to set 
+   (e.g. {@link #setNumReduceTasks(int)}), some parameters interact subtly
+   with the rest of the framework and/or job-configuration and is relatively
+   more complex for the user to control finely
+   (e.g. {@link #setNumMapTasks(int)}).
+   </li>
+ </ol>
+ 
+ <p><code>JobConf</code> typically specifies the {@link Mapper}, combiner 
+ (if any), {@link Partitioner}, {@link Reducer}, {@link InputFormat} and 
+ {@link OutputFormat} implementations to be used etc.
+
+ <p>Optionally <code>JobConf</code> is used to specify other advanced facets 
+ of the job such as <code>Comparator</code>s to be used, files to be put in  
+ the {@link DistributedCache}, whether or not intermediate and/or job outputs 
+ are to be compressed (and how), debugability via user-provided scripts 
+ ( {@link #setMapDebugScript(String)}/{@link #setReduceDebugScript(String)}),
+ for doing post-processing on task logs, task's stdout, stderr, syslog. 
+ and etc.</p>
+ 
+ <p>Here is an example on how to configure a job via <code>JobConf</code>:</p>
+ <p><blockquote><pre>
+     // Create a new JobConf
+     JobConf job = new JobConf(new Configuration(), MyJob.class);
+     
+     // Specify various job-specific parameters     
+     job.setJobName("myjob");
+     
+     FileInputFormat.setInputPaths(job, new Path("in"));
+     FileOutputFormat.setOutputPath(job, new Path("out"));
+     
+     job.setMapperClass(MyJob.MyMapper.class);
+     job.setCombinerClass(MyJob.MyReducer.class);
+     job.setReducerClass(MyJob.MyReducer.class);
+     
+     job.setInputFormat(SequenceFileInputFormat.class);
+     job.setOutputFormat(SequenceFileOutputFormat.class);
+ </pre></blockquote>
+ 
+ @see JobClient
+ @see ClusterStatus
+ @see Tool
+ @see DistributedCache]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.JobConf -->
+  <!-- start interface org.apache.hadoop.mapred.JobConfigurable -->
+  <interface name="JobConfigurable"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="configure"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Initializes a new instance from a {@link JobConf}.
+
+ @param job the configuration]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[That what may be configured.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.JobConfigurable -->
+  <!-- start interface org.apache.hadoop.mapred.JobContext -->
+  <interface name="JobContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.JobContext"/>
+    <method name="getJobConf" return="org.apache.hadoop.mapred.JobConf"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the job Configuration
+ 
+ @return JobConf]]>
+      </doc>
+    </method>
+    <method name="getProgressible" return="org.apache.hadoop.util.Progressable"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the progress mechanism for reporting progress.
+ 
+ @return progress mechanism]]>
+      </doc>
+    </method>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.JobContext -->
+  <!-- start class org.apache.hadoop.mapred.JobID -->
+  <class name="JobID" extends="org.apache.hadoop.mapreduce.JobID"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="JobID" type="java.lang.String, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a JobID object 
+ @param jtIdentifier jobTracker identifier
+ @param id job number]]>
+      </doc>
+    </constructor>
+    <constructor name="JobID"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="downgrade" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="old" type="org.apache.hadoop.mapreduce.JobID"/>
+      <doc>
+      <![CDATA[Downgrade a new JobID to an old one
+ @param old a new or old JobID
+ @return either old or a new JobID build to match old]]>
+      </doc>
+    </method>
+    <method name="read" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="forName" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="str" type="java.lang.String"/>
+      <exception name="IllegalArgumentException" type="java.lang.IllegalArgumentException"/>
+      <doc>
+      <![CDATA[Construct a JobId object from given string 
+ @return constructed JobId object or null if the given String is null
+ @throws IllegalArgumentException if the given string is malformed]]>
+      </doc>
+    </method>
+    <method name="getJobIDsPattern" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jtIdentifier" type="java.lang.String"/>
+      <param name="jobId" type="java.lang.Integer"/>
+      <doc>
+      <![CDATA[Returns a regex pattern which matches task IDs. Arguments can 
+ be given null, in which case that part of the regex will be generic.  
+ For example to obtain a regex matching <i>any job</i> 
+ run on the jobtracker started at <i>200707121733</i>, we would use :
+ <pre> 
+ JobID.getTaskIDsPattern("200707121733", null);
+ </pre>
+ which will return :
+ <pre> "job_200707121733_[0-9]*" </pre> 
+ @param jtIdentifier jobTracker identifier, or null
+ @param jobId job number, or null
+ @return a regex pattern matching JobIDs]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[JobID represents the immutable and unique identifier for 
+ the job. JobID consists of two parts. First part 
+ represents the jobtracker identifier, so that jobID to jobtracker map 
+ is defined. For cluster setup this string is the jobtracker 
+ start time, for local setting, it is "local".
+ Second part of the JobID is the job number. <br> 
+ An example JobID is : 
+ <code>job_200707121733_0003</code> , which represents the third job 
+ running at the jobtracker started at <code>200707121733</code>. 
+ <p>
+ Applications should never construct or parse JobID strings, but rather 
+ use appropriate constructors or {@link #forName(String)} method. 
+ 
+ @see TaskID
+ @see TaskAttemptID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.JobID -->
+  <!-- start class org.apache.hadoop.mapred.JobPriority -->
+  <class name="JobPriority" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapred.JobPriority[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapred.JobPriority"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Used to describe the priority of the running job. 
+ DEFAULT : While submitting a job, if the user is not specifying priority,
+ YARN has the capability to pick the default priority as per its config.
+ Hence MapReduce can indicate such cases with this new enum.
+ UNDEFINED_PRIORITY : YARN supports priority as an integer. Hence other than
+ the five defined enums, YARN can consider other integers also. To generalize
+ such cases, this specific enum is used.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.JobPriority -->
+  <!-- start class org.apache.hadoop.mapred.JobQueueInfo -->
+  <class name="JobQueueInfo" extends="org.apache.hadoop.mapreduce.QueueInfo"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="JobQueueInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor for Job Queue Info.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobQueueInfo" type="java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a new JobQueueInfo object using the queue name and the
+ scheduling information passed.
+ 
+ @param queueName Name of the job queue
+ @param schedulingInfo Scheduling Information associated with the job
+ queue]]>
+      </doc>
+    </constructor>
+    <method name="getQueueState" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Use getState() instead]]>
+      </doc>
+    </method>
+    <method name="getChildren" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Class that contains the information regarding the Job Queues which are 
+ maintained by the Hadoop Map/Reduce framework.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.JobQueueInfo -->
+  <!-- start class org.apache.hadoop.mapred.JobStatus -->
+  <class name="JobStatus" extends="org.apache.hadoop.mapreduce.JobStatus"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="JobStatus"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param runState The current state of the job]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, int, org.apache.hadoop.mapred.JobPriority"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param runState The current state of the job
+ @param jp Priority of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, int, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on cleanup
+ @param runState The current state of the job
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file. 
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, int, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param runState The current state of the job
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file. 
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file. 
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, boolean"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.
+ @param isUber Whether job running in uber mode]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, boolean, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.
+ @param isUber Whether job running in uber mode
+ @param historyFile history file]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param queue job queue name.
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, boolean"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param queue job queue name.
+ @param jobFile job configuration file. 
+ @param trackingUrl link to the web-ui for details of the job.
+ @param isUber Whether job running in uber mode]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, boolean, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param queue job queue name.
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.
+ @param isUber Whether job running in uber mode
+ @param historyFile history file]]>
+      </doc>
+    </constructor>
+    <method name="getJobRunState" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="state" type="int"/>
+      <doc>
+      <![CDATA[Helper method to get human-readable state of the job.
+ @param state job state
+ @return human-readable state of the job]]>
+      </doc>
+    </method>
+    <method name="downgrade" return="org.apache.hadoop.mapred.JobStatus"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="stat" type="org.apache.hadoop.mapreduce.JobStatus"/>
+    </method>
+    <method name="getJobId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use getJobID instead">
+      <doc>
+      <![CDATA[@deprecated use getJobID instead]]>
+      </doc>
+    </method>
+    <method name="getJobID" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return The jobid of the Job]]>
+      </doc>
+    </method>
+    <method name="getJobPriority" return="org.apache.hadoop.mapred.JobPriority"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the priority of the job
+ @return job priority]]>
+      </doc>
+    </method>
+    <method name="setMapProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the map progress of this job
+ @param p The value of map progress to set to]]>
+      </doc>
+    </method>
+    <method name="setCleanupProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the cleanup progress of this job
+ @param p The value of cleanup progress to set to]]>
+      </doc>
+    </method>
+    <method name="setSetupProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the setup progress of this job
+ @param p The value of setup progress to set to]]>
+      </doc>
+    </method>
+    <method name="setReduceProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the reduce progress of this Job
+ @param p The value of reduce progress to set to]]>
+      </doc>
+    </method>
+    <method name="setFinishTime"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="finishTime" type="long"/>
+      <doc>
+      <![CDATA[Set the finish time of the job
+ @param finishTime The finishTime of the job]]>
+      </doc>
+    </method>
+    <method name="setHistoryFile"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="historyFile" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the job history file url for a completed job]]>
+      </doc>
+    </method>
+    <method name="setTrackingUrl"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the link to the web-ui for details of the job.]]>
+      </doc>
+    </method>
+    <method name="setRetired"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set the job retire flag to true.]]>
+      </doc>
+    </method>
+    <method name="getRunState" return="int"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return running state of the job]]>
+      </doc>
+    </method>
+    <method name="setStartTime"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="startTime" type="long"/>
+      <doc>
+      <![CDATA[Set the start time of the job
+ @param startTime The startTime of the job]]>
+      </doc>
+    </method>
+    <method name="setUsername"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="userName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[@param userName The username of the job]]>
+      </doc>
+    </method>
+    <method name="setJobACLs"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="acls" type="java.util.Map"/>
+    </method>
+    <method name="setFailureInfo"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="failureInfo" type="java.lang.String"/>
+    </method>
+    <method name="setJobPriority"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jp" type="org.apache.hadoop.mapred.JobPriority"/>
+      <doc>
+      <![CDATA[Set the priority of the job, defaulting to NORMAL.
+ @param jp new job priority]]>
+      </doc>
+    </method>
+    <method name="mapProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in maps]]>
+      </doc>
+    </method>
+    <method name="cleanupProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in cleanup]]>
+      </doc>
+    </method>
+    <method name="setupProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in setup]]>
+      </doc>
+    </method>
+    <method name="reduceProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in reduce]]>
+      </doc>
+    </method>
+    <field name="RUNNING" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SUCCEEDED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FAILED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PREP" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="KILLED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Describes the current status of a job.  This is
+ not intended to be a comprehensive piece of data.
+ For that, look at JobProfile.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.JobStatus -->
+  <!-- start class org.apache.hadoop.mapred.KeyValueLineRecordReader -->
+  <class name="KeyValueLineRecordReader" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.RecordReader"/>
+    <constructor name="KeyValueLineRecordReader" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.mapred.FileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="getKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createKey" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createValue" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="findSeparator" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="utf" type="byte[]"/>
+      <param name="start" type="int"/>
+      <param name="length" type="int"/>
+      <param name="sep" type="byte"/>
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Read key/value pair in a line.]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class treats a line in the input as a key/value pair separated by a 
+ separator character. The separator can be specified in config file 
+ under the attribute name mapreduce.input.keyvaluelinerecordreader.key.value.separator. The default
+ separator is the tab character ('\t').]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.KeyValueLineRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.KeyValueTextInputFormat -->
+  <class name="KeyValueTextInputFormat" extends="org.apache.hadoop.mapred.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="KeyValueTextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link InputFormat} for plain text files. Files are broken into lines.
+ Either linefeed or carriage-return are used to signal end of line. Each line
+ is divided into key and value parts by a separator byte. If no such a byte
+ exists, the key will be the entire line and value will be empty.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.KeyValueTextInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.MapFileOutputFormat -->
+  <class name="MapFileOutputFormat" extends="org.apache.hadoop.mapred.FileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MapFileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getReaders" return="org.apache.hadoop.io.MapFile.Reader[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="dir" type="org.apache.hadoop.fs.Path"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Open the output generated by this format.]]>
+      </doc>
+    </method>
+    <method name="getEntry" return="org.apache.hadoop.io.Writable"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="readers" type="org.apache.hadoop.io.MapFile.Reader[]"/>
+      <param name="partitioner" type="org.apache.hadoop.mapred.Partitioner"/>
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get an entry from output generated by this class.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[An {@link OutputFormat} that writes {@link MapFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.MapFileOutputFormat -->
+  <!-- start interface org.apache.hadoop.mapred.Mapper -->
+  <interface name="Mapper"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <implements name="org.apache.hadoop.io.Closeable"/>
+    <method name="map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K1"/>
+      <param name="value" type="V1"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Maps a single input key/value pair into an intermediate key/value pair.
+ 
+ <p>Output pairs need not be of the same types as input pairs.  A given 
+ input pair may map to zero or many output pairs.  Output pairs are 
+ collected with calls to 
+ {@link OutputCollector#collect(Object,Object)}.</p>
+
+ <p>Applications can use the {@link Reporter} provided to report progress 
+ or just indicate that they are alive. In scenarios where the application 
+ takes significant amount of time to process individual key/value
+ pairs, this is crucial since the framework might assume that the task has 
+ timed-out and kill that task. The other way of avoiding this is to set 
+ <a href="{@docRoot}/../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml#mapreduce.task.timeout">
+ mapreduce.task.timeout</a> to a high-enough value (or even zero for no 
+ time-outs).</p>
+ 
+ @param key the input key.
+ @param value the input value.
+ @param output collects mapped keys and values.
+ @param reporter facility to report progress.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Maps input key/value pairs to a set of intermediate key/value pairs.  
+ 
+ <p>Maps are the individual tasks which transform input records into a 
+ intermediate records. The transformed intermediate records need not be of 
+ the same type as the input records. A given input pair may map to zero or 
+ many output pairs.</p> 
+ 
+ <p>The Hadoop Map-Reduce framework spawns one map task for each 
+ {@link InputSplit} generated by the {@link InputFormat} for the job.
+ <code>Mapper</code> implementations can access the {@link JobConf} for the 
+ job via the {@link JobConfigurable#configure(JobConf)} and initialize
+ themselves. Similarly they can use the {@link Closeable#close()} method for
+ de-initialization.</p>
+ 
+ <p>The framework then calls 
+ {@link #map(Object, Object, OutputCollector, Reporter)} 
+ for each key/value pair in the <code>InputSplit</code> for that task.</p>
+ 
+ <p>All intermediate values associated with a given output key are 
+ subsequently grouped by the framework, and passed to a {@link Reducer} to  
+ determine the final output. Users can control the grouping by specifying
+ a <code>Comparator</code> via 
+ {@link JobConf#setOutputKeyComparatorClass(Class)}.</p>
+
+ <p>The grouped <code>Mapper</code> outputs are partitioned per 
+ <code>Reducer</code>. Users can control which keys (and hence records) go to 
+ which <code>Reducer</code> by implementing a custom {@link Partitioner}.
+ 
+ <p>Users can optionally specify a <code>combiner</code>, via 
+ {@link JobConf#setCombinerClass(Class)}, to perform local aggregation of the 
+ intermediate outputs, which helps to cut down the amount of data transferred 
+ from the <code>Mapper</code> to the <code>Reducer</code>.
+ 
+ <p>The intermediate, grouped outputs are always stored in 
+ {@link SequenceFile}s. Applications can specify if and how the intermediate
+ outputs are to be compressed and which {@link CompressionCodec}s are to be
+ used via the <code>JobConf</code>.</p>
+  
+ <p>If the job has 
+ <a href="{@docRoot}/org/apache/hadoop/mapred/JobConf.html#ReducerNone">zero
+ reduces</a> then the output of the <code>Mapper</code> is directly written
+ to the {@link FileSystem} without grouping by keys.</p>
+ 
+ <p>Example:</p>
+ <p><blockquote><pre>
+     public class MyMapper&lt;K extends WritableComparable, V extends Writable&gt; 
+     extends MapReduceBase implements Mapper&lt;K, V, K, V&gt; {
+     
+       static enum MyCounters { NUM_RECORDS }
+       
+       private String mapTaskId;
+       private String inputFile;
+       private int noRecords = 0;
+       
+       public void configure(JobConf job) {
+         mapTaskId = job.get(JobContext.TASK_ATTEMPT_ID);
+         inputFile = job.get(JobContext.MAP_INPUT_FILE);
+       }
+       
+       public void map(K key, V val,
+                       OutputCollector&lt;K, V&gt; output, Reporter reporter)
+       throws IOException {
+         // Process the &lt;key, value&gt; pair (assume this takes a while)
+         // ...
+         // ...
+         
+         // Let the framework know that we are alive, and kicking!
+         // reporter.progress();
+         
+         // Process some more
+         // ...
+         // ...
+         
+         // Increment the no. of &lt;key, value&gt; pairs processed
+         ++noRecords;
+
+         // Increment counters
+         reporter.incrCounter(NUM_RECORDS, 1);
+        
+         // Every 100 records update application-level status
+         if ((noRecords%100) == 0) {
+           reporter.setStatus(mapTaskId + " processed " + noRecords + 
+                              " from input-file: " + inputFile); 
+         }
+         
+         // Output the result
+         output.collect(key, val);
+       }
+     }
+ </pre></blockquote>
+
+ <p>Applications may write a custom {@link MapRunnable} to exert greater
+ control on map processing e.g. multi-threaded <code>Mapper</code>s etc.</p>
+ 
+ @see JobConf
+ @see InputFormat
+ @see Partitioner  
+ @see Reducer
+ @see MapReduceBase
+ @see MapRunnable
+ @see SequenceFile]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.Mapper -->
+  <!-- start class org.apache.hadoop.mapred.MapReduceBase -->
+  <class name="MapReduceBase" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Closeable"/>
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="MapReduceBase"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Default implementation that does nothing.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Default implementation that does nothing.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Base class for {@link Mapper} and {@link Reducer} implementations.
+ 
+ <p>Provides default no-op implementations for a few methods, most non-trivial
+ applications need to override some of them.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.MapReduceBase -->
+  <!-- start interface org.apache.hadoop.mapred.MapRunnable -->
+  <interface name="MapRunnable"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <method name="run"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="input" type="org.apache.hadoop.mapred.RecordReader"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Start mapping input <tt>&lt;key, value&gt;</tt> pairs.
+  
+ <p>Mapping of input records to output records is complete when this method 
+ returns.</p>
+ 
+ @param input the {@link RecordReader} to read the input records.
+ @param output the {@link OutputCollector} to collect the outputrecords.
+ @param reporter {@link Reporter} to report progress, status-updates etc.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Expert: Generic interface for {@link Mapper}s.
+ 
+ <p>Custom implementations of <code>MapRunnable</code> can exert greater 
+ control on map processing e.g. multi-threaded, asynchronous mappers etc.</p>
+ 
+ @see Mapper]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.MapRunnable -->
+  <!-- start class org.apache.hadoop.mapred.MapRunner -->
+  <class name="MapRunner" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.MapRunnable"/>
+    <constructor name="MapRunner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="input" type="org.apache.hadoop.mapred.RecordReader"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getMapper" return="org.apache.hadoop.mapred.Mapper"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Default {@link MapRunnable} implementation.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.MapRunner -->
+  <!-- start class org.apache.hadoop.mapred.MultiFileInputFormat -->
+  <class name="MultiFileInputFormat" extends="org.apache.hadoop.mapred.FileInputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultiFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="numSplits" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An abstract {@link InputFormat} that returns {@link MultiFileSplit}'s
+ in {@link #getSplits(JobConf, int)} method. Splits are constructed from 
+ the files under the input paths. Each split returned contains <i>nearly</i>
+ equal content length. <br>  
+ Subclasses implement {@link #getRecordReader(InputSplit, JobConf, Reporter)}
+ to construct <code>RecordReader</code>'s for <code>MultiFileSplit</code>'s.
+ @see MultiFileSplit]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.MultiFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.MultiFileSplit -->
+  <class name="MultiFileSplit" extends="org.apache.hadoop.mapred.lib.CombineFileSplit"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultiFileSplit" type="org.apache.hadoop.mapred.JobConf, org.apache.hadoop.fs.Path[], long[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[A sub-collection of input files. Unlike {@link FileSplit}, MultiFileSplit 
+ class does not represent a split of a file, but a split of input files 
+ into smaller sets. The atomic unit of split is a file. <br> 
+ MultiFileSplit can be used to implement {@link RecordReader}'s, with 
+ reading one record per file.
+ @see FileSplit
+ @see MultiFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.MultiFileSplit -->
+  <!-- start interface org.apache.hadoop.mapred.OutputCollector -->
+  <interface name="OutputCollector"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="collect"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Adds a key/value pair to the output.
+
+ @param key the key to collect.
+ @param value to value to collect.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Collects the <code>&lt;key, value&gt;</code> pairs output by {@link Mapper}s
+ and {@link Reducer}s.
+  
+ <p><code>OutputCollector</code> is the generalization of the facility 
+ provided by the Map-Reduce framework to collect data output by either the 
+ <code>Mapper</code> or the <code>Reducer</code> i.e. intermediate outputs 
+ or the output of the job.</p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.OutputCollector -->
+  <!-- start class org.apache.hadoop.mapred.OutputCommitter -->
+  <class name="OutputCommitter" extends="org.apache.hadoop.mapreduce.OutputCommitter"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="OutputCommitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setupJob"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For the framework to setup the job output during initialization.  This is
+ called from the application master process for the entire job. This will be
+ called multiple times, once per job attempt.
+ 
+ @param jobContext Context of the job whose output is being written.
+ @throws IOException if temporary output could not be created]]>
+      </doc>
+    </method>
+    <method name="cleanupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #commitJob(JobContext)} or 
+                 {@link #abortJob(JobContext, int)} instead.">
+      <param name="jobContext" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For cleaning up the job's output after job completion.  This is called
+ from the application master process for the entire job. This may be called
+ multiple times.
+ 
+ @param jobContext Context of the job whose output is being written.
+ @throws IOException
+ @deprecated Use {@link #commitJob(JobContext)} or 
+                 {@link #abortJob(JobContext, int)} instead.]]>
+      </doc>
+    </method>
+    <method name="commitJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For committing job's output after successful job completion. Note that this
+ is invoked for jobs with final runstate as SUCCESSFUL.  This is called
+ from the application master process for the entire job. This is guaranteed
+ to only be called once.  If it throws an exception the entire job will
+ fail.
+ 
+ @param jobContext Context of the job whose output is being written.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="abortJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapred.JobContext"/>
+      <param name="status" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For aborting an unsuccessful job's output. Note that this is invoked for 
+ jobs with final runstate as {@link JobStatus#FAILED} or 
+ {@link JobStatus#KILLED}. This is called from the application
+ master process for the entire job. This may be called multiple times.
+ 
+ @param jobContext Context of the job whose output is being written.
+ @param status final runstate of the job
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setupTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Sets up output for the task. This is called from each individual task's
+ process that will output to HDFS, and it is called just for that task. This
+ may be called multiple times for the same task, but for different task
+ attempts.
+ 
+ @param taskContext Context of the task whose output is being written.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="needsTaskCommit" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check whether task needs a commit.  This is called from each individual
+ task's process that will output to HDFS, and it is called just for that
+ task.
+ 
+ @param taskContext
+ @return true/false
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="commitTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[To promote the task's temporary output to final output location.
+ If {@link #needsTaskCommit(TaskAttemptContext)} returns true and this
+ task is the task that the AM determines finished first, this method
+ is called to commit an individual task's output.  This is to mark
+ that tasks output as complete, as {@link #commitJob(JobContext)} will 
+ also be called later on if the entire job finished successfully. This
+ is called from a task's process. This may be called multiple times for the
+ same task, but different task attempts.  It should be very rare for this to
+ be called multiple times and requires odd networking failures to make this
+ happen. In the future the Hadoop framework may eliminate this race.
+ 
+ @param taskContext Context of the task whose output is being written.
+ @throws IOException if commit is not]]>
+      </doc>
+    </method>
+    <method name="abortTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Discard the task output. This is called from a task's process to clean 
+ up a single task's output that can not yet been committed. This may be
+ called multiple times for the same task, but for different task attempts.
+ 
+ @param taskContext
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #isRecoverySupported(JobContext)} instead.">
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this is
+ a bridge between the two.
+ 
+ @deprecated Use {@link #isRecoverySupported(JobContext)} instead.]]>
+      </doc>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Is task output recovery supported for restarting jobs?
+ 
+ If task output recovery is supported, job restart can be done more
+ efficiently.
+
+ @param jobContext
+          Context of the job whose output is being written.
+ @return <code>true</code> if task output recovery is supported,
+         <code>false</code> otherwise
+ @throws IOException
+ @see #recoverTask(TaskAttemptContext)]]>
+      </doc>
+    </method>
+    <method name="isCommitJobRepeatable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapred.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns true if an in-progress job commit can be retried. If the MR AM is
+ re-run then it will check this value to determine if it can retry an
+ in-progress commit that was started by a previous version.
+ Note that in rare scenarios, the previous AM version might still be running
+ at that time, due to system anomalies. Hence if this method returns true
+ then the retry commit operation should be able to run concurrently with
+ the previous operation.
+
+ If repeatable job commit is supported, job restart can tolerate previous
+ AM failures during job commit.
+
+ By default, it is not supported. Extended classes (like:
+ FileOutputCommitter) should explicitly override it if provide support.
+
+ @param jobContext
+          Context of the job whose output is being written.
+ @return <code>true</code> repeatable job commit is supported,
+         <code>false</code> otherwise
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isCommitJobRepeatable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="recoverTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapred.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Recover the task output. 
+ 
+ The retry-count for the job will be passed via the 
+ {@link MRConstants#APPLICATION_ATTEMPT_ID} key in  
+ {@link TaskAttemptContext#getConfiguration()} for the 
+ <code>OutputCommitter</code>. This is called from the application master
+ process, but it is called individually for each task.
+ 
+ If an exception is thrown the task will be attempted again. 
+ 
+ @param taskContext Context of the task whose output is being recovered
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="cleanupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="Use {@link #commitJob(org.apache.hadoop.mapreduce.JobContext)}
+             or {@link #abortJob(org.apache.hadoop.mapreduce.JobContext, org.apache.hadoop.mapreduce.JobStatus.State)}
+             instead.">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.
+ @deprecated Use {@link #commitJob(org.apache.hadoop.mapreduce.JobContext)}
+             or {@link #abortJob(org.apache.hadoop.mapreduce.JobContext, org.apache.hadoop.mapreduce.JobStatus.State)}
+             instead.]]>
+      </doc>
+    </method>
+    <method name="commitJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="abortJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="runState" type="org.apache.hadoop.mapreduce.JobStatus.State"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="setupTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="needsTaskCommit" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="commitTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="abortTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="recoverTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this
+ is a bridge between the two.]]>
+      </doc>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="true" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This method implements the new interface by calling the old method. Note
+ that the input types are different between the new and old apis and this is
+ a bridge between the two.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>OutputCommitter</code> describes the commit of task output for a 
+ Map-Reduce job.
+
+ <p>The Map-Reduce framework relies on the <code>OutputCommitter</code> of 
+ the job to:<p>
+ <ol>
+   <li>
+   Setup the job during initialization. For example, create the temporary 
+   output directory for the job during the initialization of the job.
+   </li>
+   <li>
+   Cleanup the job after the job completion. For example, remove the
+   temporary output directory after the job completion. 
+   </li>
+   <li>
+   Setup the task temporary output.
+   </li> 
+   <li>
+   Check whether a task needs a commit. This is to avoid the commit
+   procedure if a task does not need commit.
+   </li>
+   <li>
+   Commit of the task output.
+   </li>  
+   <li>
+   Discard the task commit.
+   </li>
+ </ol>
+ The methods in this class can be called from several different processes and
+ from several different contexts.  It is important to know which process and
+ which context each is called from.  Each method should be marked accordingly
+ in its documentation.  It is also important to note that not all methods are
+ guaranteed to be called once and only once.  If a method is not guaranteed to
+ have this property the output committer needs to handle this appropriately. 
+ Also note it will only be in rare situations where they may be called 
+ multiple times for the same task.
+ 
+ @see FileOutputCommitter 
+ @see JobContext
+ @see TaskAttemptContext]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.OutputCommitter -->
+  <!-- start interface org.apache.hadoop.mapred.OutputFormat -->
+  <interface name="OutputFormat"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the {@link RecordWriter} for the given job.
+
+ @param ignored
+ @param job configuration for the job whose output is being written.
+ @param name the unique name for this part of the output.
+ @param progress mechanism for reporting progress while writing to file.
+ @return a {@link RecordWriter} to write the output for the job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check for validity of the output-specification for the job.
+  
+ <p>This is to validate the output specification for the job when it is
+ a job is submitted.  Typically checks that it does not already exist,
+ throwing an exception when it already exists, so that output is not
+ overwritten.</p>
+
+ @param ignored
+ @param job job configuration.
+ @throws IOException when output should not be attempted]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>OutputFormat</code> describes the output-specification for a 
+ Map-Reduce job.
+
+ <p>The Map-Reduce framework relies on the <code>OutputFormat</code> of the
+ job to:<p>
+ <ol>
+   <li>
+   Validate the output-specification of the job. For e.g. check that the 
+   output directory doesn't already exist. 
+   <li>
+   Provide the {@link RecordWriter} implementation to be used to write out
+   the output files of the job. Output files are stored in a 
+   {@link FileSystem}.
+   </li>
+ </ol>
+ 
+ @see RecordWriter
+ @see JobConf]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.OutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.OutputLogFilter -->
+  <class name="OutputLogFilter" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.fs.PathFilter"/>
+    <constructor name="OutputLogFilter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="accept" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <doc>
+    <![CDATA[This class filters log files from directory given
+ It doesnt accept paths having _logs.
+ This can be used to list paths of output directory as follows:
+   Path[] fileList = FileUtil.stat2Paths(fs.listStatus(outDir,
+                                   new OutputLogFilter()));]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.OutputLogFilter -->
+  <!-- start interface org.apache.hadoop.mapred.Partitioner -->
+  <interface name="Partitioner"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <method name="getPartition" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K2"/>
+      <param name="value" type="V2"/>
+      <param name="numPartitions" type="int"/>
+      <doc>
+      <![CDATA[Get the paritition number for a given key (hence record) given the total 
+ number of partitions i.e. number of reduce-tasks for the job.
+   
+ <p>Typically a hash function on a all or a subset of the key.</p>
+
+ @param key the key to be paritioned.
+ @param value the entry value.
+ @param numPartitions the total number of partitions.
+ @return the partition number for the <code>key</code>.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Partitions the key space.
+ 
+ <p><code>Partitioner</code> controls the partitioning of the keys of the 
+ intermediate map-outputs. The key (or a subset of the key) is used to derive
+ the partition, typically by a hash function. The total number of partitions
+ is the same as the number of reduce tasks for the job. Hence this controls
+ which of the <code>m</code> reduce tasks the intermediate key (and hence the 
+ record) is sent for reduction.</p>
+
+ <p>Note: A <code>Partitioner</code> is created only when there are multiple
+ reducers.</p>
+ 
+ @see Reducer]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.Partitioner -->
+  <!-- start interface org.apache.hadoop.mapred.RecordReader -->
+  <interface name="RecordReader"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.io.Closeable"/>
+    <method name="next" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Reads the next key/value pair from the input for processing.
+
+ @param key the key to read data into
+ @param value the value to read data into
+ @return true iff a key/value was read, false if at EOF]]>
+      </doc>
+    </method>
+    <method name="createKey" return="K"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an object of the appropriate type to be used as a key.
+ 
+ @return a new key object.]]>
+      </doc>
+    </method>
+    <method name="createValue" return="V"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an object of the appropriate type to be used as a value.
+ 
+ @return a new value object.]]>
+      </doc>
+    </method>
+    <method name="getPos" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns the current position in the input.
+ 
+ @return the current position in the input.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close this {@link InputSplit} to future operations.
+ 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[How much of the input has the {@link RecordReader} consumed i.e.
+ has been processed by?
+ 
+ @return progress from <code>0.0</code> to <code>1.0</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>RecordReader</code> reads &lt;key, value&gt; pairs from an 
+ {@link InputSplit}.
+   
+ <p><code>RecordReader</code>, typically, converts the byte-oriented view of 
+ the input, provided by the <code>InputSplit</code>, and presents a 
+ record-oriented view for the {@link Mapper} and {@link Reducer} tasks for
+ processing. It thus assumes the responsibility of processing record 
+ boundaries and presenting the tasks with keys and values.</p>
+ 
+ @see InputSplit
+ @see InputFormat]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.RecordReader -->
+  <!-- start interface org.apache.hadoop.mapred.RecordWriter -->
+  <interface name="RecordWriter"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="write"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Writes a key/value pair.
+
+ @param key the key to write.
+ @param value the value to write.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close this <code>RecordWriter</code> to future operations.
+ 
+ @param reporter facility to report progress.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>RecordWriter</code> writes the output &lt;key, value&gt; pairs 
+ to an output file.
+ 
+ <p><code>RecordWriter</code> implementations write the job outputs to the
+ {@link FileSystem}.
+ 
+ @see OutputFormat]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.RecordWriter -->
+  <!-- start interface org.apache.hadoop.mapred.Reducer -->
+  <interface name="Reducer"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <implements name="org.apache.hadoop.io.Closeable"/>
+    <method name="reduce"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K2"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<i>Reduces</i> values for a given key.  
+ 
+ <p>The framework calls this method for each 
+ <code>&lt;key, (list of values)&gt;</code> pair in the grouped inputs.
+ Output values must be of the same type as input values.  Input keys must 
+ not be altered. The framework will <b>reuse</b> the key and value objects
+ that are passed into the reduce, therefore the application should clone
+ the objects they want to keep a copy of. In many cases, all values are 
+ combined into zero or one value.
+ </p>
+   
+ <p>Output pairs are collected with calls to  
+ {@link OutputCollector#collect(Object,Object)}.</p>
+
+ <p>Applications can use the {@link Reporter} provided to report progress 
+ or just indicate that they are alive. In scenarios where the application 
+ takes a significant amount of time to process individual key/value 
+ pairs, this is crucial since the framework might assume that the task has 
+ timed-out and kill that task. The other way of avoiding this is to set 
+ <a href="{@docRoot}/../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml#mapreduce.task.timeout">
+ mapreduce.task.timeout</a> to a high-enough value (or even zero for no 
+ time-outs).</p>
+ 
+ @param key the key.
+ @param values the list of values to reduce.
+ @param output to collect keys and combined values.
+ @param reporter facility to report progress.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Reduces a set of intermediate values which share a key to a smaller set of
+ values.  
+ 
+ <p>The number of <code>Reducer</code>s for the job is set by the user via 
+ {@link JobConf#setNumReduceTasks(int)}. <code>Reducer</code> implementations 
+ can access the {@link JobConf} for the job via the 
+ {@link JobConfigurable#configure(JobConf)} method and initialize themselves. 
+ Similarly they can use the {@link Closeable#close()} method for
+ de-initialization.</p>
+
+ <p><code>Reducer</code> has 3 primary phases:</p>
+ <ol>
+   <li>
+   
+   <b id="Shuffle">Shuffle</b>
+   
+   <p><code>Reducer</code> is input the grouped output of a {@link Mapper}.
+   In the phase the framework, for each <code>Reducer</code>, fetches the 
+   relevant partition of the output of all the <code>Mapper</code>s, via HTTP. 
+   </p>
+   </li>
+   
+   <li>
+   <b id="Sort">Sort</b>
+   
+   <p>The framework groups <code>Reducer</code> inputs by <code>key</code>s 
+   (since different <code>Mapper</code>s may have output the same key) in this
+   stage.</p>
+   
+   <p>The shuffle and sort phases occur simultaneously i.e. while outputs are
+   being fetched they are merged.</p>
+      
+   <b id="SecondarySort">SecondarySort</b>
+   
+   <p>If equivalence rules for keys while grouping the intermediates are 
+   different from those for grouping keys before reduction, then one may 
+   specify a <code>Comparator</code> via 
+   {@link JobConf#setOutputValueGroupingComparator(Class)}.Since 
+   {@link JobConf#setOutputKeyComparatorClass(Class)} can be used to 
+   control how intermediate keys are grouped, these can be used in conjunction 
+   to simulate <i>secondary sort on values</i>.</p>
+   
+   
+   For example, say that you want to find duplicate web pages and tag them 
+   all with the url of the "best" known example. You would set up the job 
+   like:
+   <ul>
+     <li>Map Input Key: url</li>
+     <li>Map Input Value: document</li>
+     <li>Map Output Key: document checksum, url pagerank</li>
+     <li>Map Output Value: url</li>
+     <li>Partitioner: by checksum</li>
+     <li>OutputKeyComparator: by checksum and then decreasing pagerank</li>
+     <li>OutputValueGroupingComparator: by checksum</li>
+   </ul>
+   </li>
+   
+   <li>   
+   <b id="Reduce">Reduce</b>
+   
+   <p>In this phase the 
+   {@link #reduce(Object, Iterator, OutputCollector, Reporter)}
+   method is called for each <code>&lt;key, (list of values)&gt;</code> pair in
+   the grouped inputs.</p>
+   <p>The output of the reduce task is typically written to the 
+   {@link FileSystem} via 
+   {@link OutputCollector#collect(Object, Object)}.</p>
+   </li>
+ </ol>
+ 
+ <p>The output of the <code>Reducer</code> is <b>not re-sorted</b>.</p>
+ 
+ <p>Example:</p>
+ <p><blockquote><pre>
+     public class MyReducer&lt;K extends WritableComparable, V extends Writable&gt; 
+     extends MapReduceBase implements Reducer&lt;K, V, K, V&gt; {
+     
+       static enum MyCounters { NUM_RECORDS }
+        
+       private String reduceTaskId;
+       private int noKeys = 0;
+       
+       public void configure(JobConf job) {
+         reduceTaskId = job.get(JobContext.TASK_ATTEMPT_ID);
+       }
+       
+       public void reduce(K key, Iterator&lt;V&gt; values,
+                          OutputCollector&lt;K, V&gt; output, 
+                          Reporter reporter)
+       throws IOException {
+       
+         // Process
+         int noValues = 0;
+         while (values.hasNext()) {
+           V value = values.next();
+           
+           // Increment the no. of values for this key
+           ++noValues;
+           
+           // Process the &lt;key, value&gt; pair (assume this takes a while)
+           // ...
+           // ...
+           
+           // Let the framework know that we are alive, and kicking!
+           if ((noValues%10) == 0) {
+             reporter.progress();
+           }
+         
+           // Process some more
+           // ...
+           // ...
+           
+           // Output the &lt;key, value&gt; 
+           output.collect(key, value);
+         }
+         
+         // Increment the no. of &lt;key, list of values&gt; pairs processed
+         ++noKeys;
+         
+         // Increment counters
+         reporter.incrCounter(NUM_RECORDS, 1);
+         
+         // Every 100 keys update application-level status
+         if ((noKeys%100) == 0) {
+           reporter.setStatus(reduceTaskId + " processed " + noKeys);
+         }
+       }
+     }
+ </pre></blockquote>
+ 
+ @see Mapper
+ @see Partitioner
+ @see Reporter
+ @see MapReduceBase]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.Reducer -->
+  <!-- start interface org.apache.hadoop.mapred.Reporter -->
+  <interface name="Reporter"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.util.Progressable"/>
+    <method name="setStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="status" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the status description for the task.
+ 
+ @param status brief description of the current status.]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.Enum"/>
+      <doc>
+      <![CDATA[Get the {@link Counter} of the given group with the given name.
+ 
+ @param name counter name
+ @return the <code>Counter</code> of the given group/name.]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="org.apache.hadoop.mapred.Counters.Counter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="group" type="java.lang.String"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get the {@link Counter} of the given group with the given name.
+ 
+ @param group counter group
+ @param name counter name
+ @return the <code>Counter</code> of the given group/name.]]>
+      </doc>
+    </method>
+    <method name="incrCounter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Enum"/>
+      <param name="amount" type="long"/>
+      <doc>
+      <![CDATA[Increments the counter identified by the key, which can be of
+ any {@link Enum} type, by the specified amount.
+ 
+ @param key key to identify the counter to be incremented. The key can be
+            be any <code>Enum</code>. 
+ @param amount A non-negative amount by which the counter is to 
+               be incremented.]]>
+      </doc>
+    </method>
+    <method name="incrCounter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="group" type="java.lang.String"/>
+      <param name="counter" type="java.lang.String"/>
+      <param name="amount" type="long"/>
+      <doc>
+      <![CDATA[Increments the counter identified by the group and counter name
+ by the specified amount.
+ 
+ @param group name to identify the group of the counter to be incremented.
+ @param counter name to identify the counter within the group.
+ @param amount A non-negative amount by which the counter is to 
+               be incremented.]]>
+      </doc>
+    </method>
+    <method name="getInputSplit" return="org.apache.hadoop.mapred.InputSplit"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="UnsupportedOperationException" type="java.lang.UnsupportedOperationException"/>
+      <doc>
+      <![CDATA[Get the {@link InputSplit} object for a map.
+ 
+ @return the <code>InputSplit</code> that the map is reading from.
+ @throws UnsupportedOperationException if called outside a mapper]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the progress of the task. Progress is represented as a number between
+ 0 and 1 (inclusive).]]>
+      </doc>
+    </method>
+    <field name="NULL" type="org.apache.hadoop.mapred.Reporter"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[A constant of Reporter type that does nothing.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A facility for Map-Reduce applications to report progress and update 
+ counters, status information etc.
+ 
+ <p>{@link Mapper} and {@link Reducer} can use the <code>Reporter</code>
+ provided to report progress or just indicate that they are alive. In 
+ scenarios where the application takes significant amount of time to
+ process individual key/value pairs, this is crucial since the framework 
+ might assume that the task has timed-out and kill that task.
+
+ <p>Applications can also update {@link Counters} via the provided 
+ <code>Reporter</code> .</p>
+ 
+ @see Progressable
+ @see Counters]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.Reporter -->
+  <!-- start interface org.apache.hadoop.mapred.RunningJob -->
+  <interface name="RunningJob"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getConfiguration" return="org.apache.hadoop.conf.Configuration"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the underlying job configuration
+
+ @return the configuration of the job.]]>
+      </doc>
+    </method>
+    <method name="getID" return="org.apache.hadoop.mapred.JobID"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the job identifier.
+ 
+ @return the job identifier.]]>
+      </doc>
+    </method>
+    <method name="getJobID" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="This method is deprecated and will be removed. Applications should 
+ rather use {@link #getID()}.">
+      <doc>
+      <![CDATA[@deprecated This method is deprecated and will be removed. Applications should 
+ rather use {@link #getID()}.]]>
+      </doc>
+    </method>
+    <method name="getJobName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the name of the job.
+ 
+ @return the name of the job.]]>
+      </doc>
+    </method>
+    <method name="getJobFile" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the path of the submitted job configuration.
+ 
+ @return the path of the submitted job configuration.]]>
+      </doc>
+    </method>
+    <method name="getTrackingURL" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the URL where some job progress information will be displayed.
+ 
+ @return the URL where some job progress information will be displayed.]]>
+      </doc>
+    </method>
+    <method name="mapProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's map-tasks, as a float between 0.0 
+ and 1.0.  When all map tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's map-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="reduceProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's reduce-tasks, as a float between 0.0 
+ and 1.0.  When all reduce tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's reduce-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="cleanupProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's cleanup-tasks, as a float between 0.0 
+ and 1.0.  When all cleanup tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's cleanup-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setupProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's setup-tasks, as a float between 0.0 
+ and 1.0.  When all setup tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's setup-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isComplete" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check if the job is finished or not. 
+ This is a non-blocking call.
+ 
+ @return <code>true</code> if the job is complete, else <code>false</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isSuccessful" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check if the job completed successfully. 
+ 
+ @return <code>true</code> if the job succeeded, else <code>false</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="waitForCompletion"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Blocks until the job is complete.
+ 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getJobState" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns the current state of the Job.
+ {@link JobStatus}
+ 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getJobStatus" return="org.apache.hadoop.mapred.JobStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns a snapshot of the current status, {@link JobStatus}, of the Job.
+ Need to call again for latest information.
+ 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="killJob"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Kill the running job. Blocks until all job tasks have been killed as well.
+ If the job is no longer running, it simply returns.
+ 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setJobPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Set the priority of a running job.
+ @param priority the new priority for the job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getTaskCompletionEvents" return="org.apache.hadoop.mapred.TaskCompletionEvent[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startFrom" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get events indicating completion (success/failure) of component tasks.
+  
+ @param startFrom index to start fetching events from
+ @return an array of {@link TaskCompletionEvent}s
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="killTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskId" type="org.apache.hadoop.mapred.TaskAttemptID"/>
+      <param name="shouldFail" type="boolean"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Kill indicated task attempt.
+ 
+ @param taskId the id of the task to be terminated.
+ @param shouldFail if true the task is failed and added to failed tasks 
+                   list, otherwise it is just killed, w/o affecting 
+                   job failure status.  
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="killTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Applications should rather use {@link #killTask(TaskAttemptID, boolean)}">
+      <param name="taskId" type="java.lang.String"/>
+      <param name="shouldFail" type="boolean"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Applications should rather use {@link #killTask(TaskAttemptID, boolean)}]]>
+      </doc>
+    </method>
+    <method name="getCounters" return="org.apache.hadoop.mapred.Counters"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the counters for this job.
+ 
+ @return the counters for this job or null if the job has been retired.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getTaskDiagnostics" return="java.lang.String[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskid" type="org.apache.hadoop.mapred.TaskAttemptID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the diagnostic messages for a given task attempt.
+ @param taskid
+ @return the list of diagnostic messages for the task
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getHistoryUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the url where history file is archived. Returns empty string if 
+ history file is not available yet. 
+ 
+ @return the url where history file is archived
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isRetired" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check whether the job has been removed from JobTracker memory and retired.
+ On retire, the job history file is copied to a location known by 
+ {@link #getHistoryUrl()}
+ @return <code>true</code> if the job retired, else <code>false</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getFailureInfo" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get failure info for the job.
+ @return the failure info for the job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>RunningJob</code> is the user-interface to query for details on a 
+ running Map-Reduce job.
+ 
+ <p>Clients can get hold of <code>RunningJob</code> via the {@link JobClient}
+ and then query the running-job for details such as name, configuration, 
+ progress etc.</p> 
+ 
+ @see JobClient]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.RunningJob -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat -->
+  <class name="SequenceFileAsBinaryInputFormat" extends="org.apache.hadoop.mapred.SequenceFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsBinaryInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[InputFormat reading keys, values from SequenceFiles in binary (raw)
+ format.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileAsBinaryInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat -->
+  <class name="SequenceFileAsBinaryOutputFormat" extends="org.apache.hadoop.mapred.SequenceFileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsBinaryOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setSequenceFileOutputKeyClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the key class for the {@link SequenceFile}
+ <p>This allows the user to specify the key class to be different 
+ from the actual class ({@link BytesWritable}) used for writing </p>
+ 
+ @param conf the {@link JobConf} to modify
+ @param theClass the SequenceFile output key class.]]>
+      </doc>
+    </method>
+    <method name="setSequenceFileOutputValueClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the value class for the {@link SequenceFile}
+ <p>This allows the user to specify the value class to be different 
+ from the actual class ({@link BytesWritable}) used for writing </p>
+ 
+ @param conf the {@link JobConf} to modify
+ @param theClass the SequenceFile output key class.]]>
+      </doc>
+    </method>
+    <method name="getSequenceFileOutputKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the key class for the {@link SequenceFile}
+ 
+ @return the key class of the {@link SequenceFile}]]>
+      </doc>
+    </method>
+    <method name="getSequenceFileOutputValueClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the value class for the {@link SequenceFile}
+ 
+ @return the value class of the {@link SequenceFile}]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link OutputFormat} that writes keys, values to 
+ {@link SequenceFile}s in binary(raw) format]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileAsBinaryOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileAsTextInputFormat -->
+  <class name="SequenceFileAsTextInputFormat" extends="org.apache.hadoop.mapred.SequenceFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsTextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class is similar to SequenceFileInputFormat, 
+ except it generates SequenceFileAsTextRecordReader 
+ which converts the input keys and values to their 
+ String forms by calling toString() method.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileAsTextInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileAsTextRecordReader -->
+  <class name="SequenceFileAsTextRecordReader" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.RecordReader"/>
+    <constructor name="SequenceFileAsTextRecordReader" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.mapred.FileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="createKey" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createValue" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Read key/value pair in a line.]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class converts the input keys and values to their String forms by calling toString()
+ method. This class to SequenceFileAsTextInputFormat class is as LineRecordReader
+ class to TextInputFormat class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileAsTextRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileInputFilter -->
+  <class name="SequenceFileInputFilter" extends="org.apache.hadoop.mapred.SequenceFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileInputFilter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a record reader for the given split
+ @param split file split
+ @param job job configuration
+ @param reporter reporter who sends report to task tracker
+ @return RecordReader]]>
+      </doc>
+    </method>
+    <method name="setFilterClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="filterClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[set the filter class
+ 
+ @param conf application configuration
+ @param filterClass filter class]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A class that allows a map/red job to work on a sample of sequence files.
+ The sample is decided by the filter class set by the job.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileInputFilter -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileInputFormat -->
+  <class name="SequenceFileInputFormat" extends="org.apache.hadoop.mapred.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="listStatus" return="org.apache.hadoop.fs.FileStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link InputFormat} for {@link SequenceFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileOutputFormat -->
+  <class name="SequenceFileOutputFormat" extends="org.apache.hadoop.mapred.FileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getReaders" return="org.apache.hadoop.io.SequenceFile.Reader[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="dir" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Open the output generated by this format.]]>
+      </doc>
+    </method>
+    <method name="getOutputCompressionType" return="org.apache.hadoop.io.SequenceFile.CompressionType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the {@link CompressionType} for the output {@link SequenceFile}.
+ @param conf the {@link JobConf}
+ @return the {@link CompressionType} for the output {@link SequenceFile}, 
+         defaulting to {@link CompressionType#RECORD}]]>
+      </doc>
+    </method>
+    <method name="setOutputCompressionType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="style" type="org.apache.hadoop.io.SequenceFile.CompressionType"/>
+      <doc>
+      <![CDATA[Set the {@link CompressionType} for the output {@link SequenceFile}.
+ @param conf the {@link JobConf} to modify
+ @param style the {@link CompressionType} for the output
+              {@link SequenceFile}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[An {@link OutputFormat} that writes {@link SequenceFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.SequenceFileRecordReader -->
+  <class name="SequenceFileRecordReader" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.RecordReader"/>
+    <constructor name="SequenceFileRecordReader" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.mapred.FileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="getKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The class of key that must be passed to {@link
+ #next(Object, Object)}..]]>
+      </doc>
+    </method>
+    <method name="getValueClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The class of value that must be passed to {@link
+ #next(Object, Object)}..]]>
+      </doc>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getCurrentValue"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return the progress within the input split
+ @return 0.0 to 1.0 of the input byte range]]>
+      </doc>
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="seek"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="pos" type="long"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="conf" type="org.apache.hadoop.conf.Configuration"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An {@link RecordReader} for {@link SequenceFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SequenceFileRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.SkipBadRecords -->
+  <class name="SkipBadRecords" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SkipBadRecords"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAttemptsToStartSkipping" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the number of Task attempts AFTER which skip mode 
+ will be kicked off. When skip mode is kicked off, the 
+ tasks reports the range of records which it will process 
+ next to the TaskTracker. So that on failures, TT knows which 
+ ones are possibly the bad records. On further executions, 
+ those are skipped.
+ Default value is 2.
+ 
+ @param conf the configuration
+ @return attemptsToStartSkipping no of task attempts]]>
+      </doc>
+    </method>
+    <method name="setAttemptsToStartSkipping"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="attemptsToStartSkipping" type="int"/>
+      <doc>
+      <![CDATA[Set the number of Task attempts AFTER which skip mode 
+ will be kicked off. When skip mode is kicked off, the 
+ tasks reports the range of records which it will process 
+ next to the TaskTracker. So that on failures, TT knows which 
+ ones are possibly the bad records. On further executions, 
+ those are skipped.
+ Default value is 2.
+ 
+ @param conf the configuration
+ @param attemptsToStartSkipping no of task attempts]]>
+      </doc>
+    </method>
+    <method name="getAutoIncrMapperProcCount" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the flag which if set to true, 
+ {@link SkipBadRecords#COUNTER_MAP_PROCESSED_RECORDS} is incremented 
+ by MapRunner after invoking the map function. This value must be set to 
+ false for applications which process the records asynchronously 
+ or buffer the input records. For example streaming. 
+ In such cases applications should increment this counter on their own.
+ Default value is true.
+ 
+ @param conf the configuration
+ @return <code>true</code> if auto increment 
+                       {@link SkipBadRecords#COUNTER_MAP_PROCESSED_RECORDS}.
+         <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="setAutoIncrMapperProcCount"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="autoIncr" type="boolean"/>
+      <doc>
+      <![CDATA[Set the flag which if set to true, 
+ {@link SkipBadRecords#COUNTER_MAP_PROCESSED_RECORDS} is incremented 
+ by MapRunner after invoking the map function. This value must be set to 
+ false for applications which process the records asynchronously 
+ or buffer the input records. For example streaming. 
+ In such cases applications should increment this counter on their own.
+ Default value is true.
+ 
+ @param conf the configuration
+ @param autoIncr whether to auto increment 
+        {@link SkipBadRecords#COUNTER_MAP_PROCESSED_RECORDS}.]]>
+      </doc>
+    </method>
+    <method name="getAutoIncrReducerProcCount" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the flag which if set to true, 
+ {@link SkipBadRecords#COUNTER_REDUCE_PROCESSED_GROUPS} is incremented 
+ by framework after invoking the reduce function. This value must be set to 
+ false for applications which process the records asynchronously 
+ or buffer the input records. For example streaming. 
+ In such cases applications should increment this counter on their own.
+ Default value is true.
+ 
+ @param conf the configuration
+ @return <code>true</code> if auto increment 
+                    {@link SkipBadRecords#COUNTER_REDUCE_PROCESSED_GROUPS}.
+         <code>false</code> otherwise.]]>
+      </doc>
+    </method>
+    <method name="setAutoIncrReducerProcCount"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="autoIncr" type="boolean"/>
+      <doc>
+      <![CDATA[Set the flag which if set to true, 
+ {@link SkipBadRecords#COUNTER_REDUCE_PROCESSED_GROUPS} is incremented 
+ by framework after invoking the reduce function. This value must be set to 
+ false for applications which process the records asynchronously 
+ or buffer the input records. For example streaming. 
+ In such cases applications should increment this counter on their own.
+ Default value is true.
+ 
+ @param conf the configuration
+ @param autoIncr whether to auto increment 
+        {@link SkipBadRecords#COUNTER_REDUCE_PROCESSED_GROUPS}.]]>
+      </doc>
+    </method>
+    <method name="getSkipOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the directory to which skipped records are written. By default it is 
+ the sub directory of the output _logs directory.
+ User can stop writing skipped records by setting the value null.
+ 
+ @param conf the configuration.
+ @return path skip output directory. Null is returned if this is not set 
+ and output directory is also not set.]]>
+      </doc>
+    </method>
+    <method name="setSkipOutputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the directory to which skipped records are written. By default it is 
+ the sub directory of the output _logs directory.
+ User can stop writing skipped records by setting the value null.
+ 
+ @param conf the configuration.
+ @param path skip output directory path]]>
+      </doc>
+    </method>
+    <method name="getMapperMaxSkipRecords" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the number of acceptable skip records surrounding the bad record PER 
+ bad record in mapper. The number includes the bad record as well.
+ To turn the feature of detection/skipping of bad records off, set the 
+ value to 0.
+ The framework tries to narrow down the skipped range by retrying  
+ until this threshold is met OR all attempts get exhausted for this task. 
+ Set the value to Long.MAX_VALUE to indicate that framework need not try to 
+ narrow down. Whatever records(depends on application) get skipped are 
+ acceptable.
+ Default value is 0.
+ 
+ @param conf the configuration
+ @return maxSkipRecs acceptable skip records.]]>
+      </doc>
+    </method>
+    <method name="setMapperMaxSkipRecords"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="maxSkipRecs" type="long"/>
+      <doc>
+      <![CDATA[Set the number of acceptable skip records surrounding the bad record PER 
+ bad record in mapper. The number includes the bad record as well.
+ To turn the feature of detection/skipping of bad records off, set the 
+ value to 0.
+ The framework tries to narrow down the skipped range by retrying  
+ until this threshold is met OR all attempts get exhausted for this task. 
+ Set the value to Long.MAX_VALUE to indicate that framework need not try to 
+ narrow down. Whatever records(depends on application) get skipped are 
+ acceptable.
+ Default value is 0.
+ 
+ @param conf the configuration
+ @param maxSkipRecs acceptable skip records.]]>
+      </doc>
+    </method>
+    <method name="getReducerMaxSkipGroups" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the number of acceptable skip groups surrounding the bad group PER 
+ bad group in reducer. The number includes the bad group as well.
+ To turn the feature of detection/skipping of bad groups off, set the 
+ value to 0.
+ The framework tries to narrow down the skipped range by retrying  
+ until this threshold is met OR all attempts get exhausted for this task. 
+ Set the value to Long.MAX_VALUE to indicate that framework need not try to 
+ narrow down. Whatever groups(depends on application) get skipped are 
+ acceptable.
+ Default value is 0.
+ 
+ @param conf the configuration
+ @return maxSkipGrps acceptable skip groups.]]>
+      </doc>
+    </method>
+    <method name="setReducerMaxSkipGroups"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="maxSkipGrps" type="long"/>
+      <doc>
+      <![CDATA[Set the number of acceptable skip groups surrounding the bad group PER 
+ bad group in reducer. The number includes the bad group as well.
+ To turn the feature of detection/skipping of bad groups off, set the 
+ value to 0.
+ The framework tries to narrow down the skipped range by retrying  
+ until this threshold is met OR all attempts get exhausted for this task. 
+ Set the value to Long.MAX_VALUE to indicate that framework need not try to 
+ narrow down. Whatever groups(depends on application) get skipped are 
+ acceptable.
+ Default value is 0.
+ 
+ @param conf the configuration
+ @param maxSkipGrps acceptable skip groups.]]>
+      </doc>
+    </method>
+    <field name="COUNTER_GROUP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Special counters which are written by the application and are 
+ used by the framework for detecting bad records. For detecting bad records 
+ these counters must be incremented by the application.]]>
+      </doc>
+    </field>
+    <field name="COUNTER_MAP_PROCESSED_RECORDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of processed map records.
+ @see SkipBadRecords#getAutoIncrMapperProcCount(Configuration)]]>
+      </doc>
+    </field>
+    <field name="COUNTER_REDUCE_PROCESSED_GROUPS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of processed reduce groups.
+ @see SkipBadRecords#getAutoIncrReducerProcCount(Configuration)]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[Utility class for skip bad records functionality. It contains various 
+ settings related to skipping of bad records.
+ 
+ <p>Hadoop provides an optional mode of execution in which the bad records
+ are detected and skipped in further attempts.
+ 
+ <p>This feature can be used when map/reduce tasks crashes deterministically on 
+ certain input. This happens due to bugs in the map/reduce function. The usual
+ course would be to fix these bugs. But sometimes this is not possible; 
+ perhaps the bug is in third party libraries for which the source code is 
+ not available. Due to this, the task never reaches to completion even with 
+ multiple attempts and complete data for that task is lost.</p>
+  
+ <p>With this feature, only a small portion of data is lost surrounding 
+ the bad record, which may be acceptable for some user applications.
+ see {@link SkipBadRecords#setMapperMaxSkipRecords(Configuration, long)}</p>
+ 
+ <p>The skipping mode gets kicked off after certain no of failures 
+ see {@link SkipBadRecords#setAttemptsToStartSkipping(Configuration, int)}</p>
+  
+ <p>In the skipping mode, the map/reduce task maintains the record range which 
+ is getting processed at all times. Before giving the input to the
+ map/reduce function, it sends this record range to the Task tracker.
+ If task crashes, the Task tracker knows which one was the last reported
+ range. On further attempts that range get skipped.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SkipBadRecords -->
+  <!-- start class org.apache.hadoop.mapred.SplitLocationInfo -->
+  <class name="SplitLocationInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SplitLocationInfo" type="java.lang.String, boolean"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="isOnDisk" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isInMemory" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getLocation" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.SplitLocationInfo -->
+  <!-- start interface org.apache.hadoop.mapred.TaskAttemptContext -->
+  <interface name="TaskAttemptContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+    <method name="getTaskAttemptID" return="org.apache.hadoop.mapred.TaskAttemptID"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProgressible" return="org.apache.hadoop.util.Progressable"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getJobConf" return="org.apache.hadoop.mapred.JobConf"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.TaskAttemptContext -->
+  <!-- start class org.apache.hadoop.mapred.TaskAttemptID -->
+  <class name="TaskAttemptID" extends="org.apache.hadoop.mapreduce.TaskAttemptID"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TaskAttemptID" type="org.apache.hadoop.mapred.TaskID, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskAttemptID object from given {@link TaskID}.  
+ @param taskId TaskID that this task belongs to  
+ @param id the task attempt number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskAttemptID" type="java.lang.String, int, boolean, int, int"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #TaskAttemptID(String, int, TaskType, int, int)}.">
+      <doc>
+      <![CDATA[Constructs a TaskId object from given parts.
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number 
+ @param isMap whether the tip is a map 
+ @param taskId taskId number
+ @param id the task attempt number
+ @deprecated Use {@link #TaskAttemptID(String, int, TaskType, int, int)}.]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskAttemptID" type="java.lang.String, int, org.apache.hadoop.mapreduce.TaskType, int, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskId object from given parts.
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number 
+ @param type the TaskType 
+ @param taskId taskId number
+ @param id the task attempt number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskAttemptID"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="downgrade" return="org.apache.hadoop.mapred.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="old" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <doc>
+      <![CDATA[Downgrade a new TaskAttemptID to an old one
+ @param old the new id
+ @return either old or a new TaskAttemptID constructed to match old]]>
+      </doc>
+    </method>
+    <method name="getTaskID" return="org.apache.hadoop.mapred.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getJobID" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="read" return="org.apache.hadoop.mapred.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="forName" return="org.apache.hadoop.mapred.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="str" type="java.lang.String"/>
+      <exception name="IllegalArgumentException" type="java.lang.IllegalArgumentException"/>
+      <doc>
+      <![CDATA[Construct a TaskAttemptID object from given string 
+ @return constructed TaskAttemptID object or null if the given String is null
+ @throws IllegalArgumentException if the given string is malformed]]>
+      </doc>
+    </method>
+    <method name="getTaskAttemptIDsPattern" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jtIdentifier" type="java.lang.String"/>
+      <param name="jobId" type="java.lang.Integer"/>
+      <param name="isMap" type="java.lang.Boolean"/>
+      <param name="taskId" type="java.lang.Integer"/>
+      <param name="attemptId" type="java.lang.Integer"/>
+      <doc>
+      <![CDATA[Returns a regex pattern which matches task attempt IDs. Arguments can 
+ be given null, in which case that part of the regex will be generic.  
+ For example to obtain a regex matching <i>all task attempt IDs</i> 
+ of <i>any jobtracker</i>, in <i>any job</i>, of the <i>first 
+ map task</i>, we would use :
+ <pre> 
+ TaskAttemptID.getTaskAttemptIDsPattern(null, null, true, 1, null);
+ </pre>
+ which will return :
+ <pre> "attempt_[^_]*_[0-9]*_m_000001_[0-9]*" </pre> 
+ @param jtIdentifier jobTracker identifier, or null
+ @param jobId job number, or null
+ @param isMap whether the tip is a map, or null 
+ @param taskId taskId number, or null
+ @param attemptId the task attempt number, or null
+ @return a regex pattern matching TaskAttemptIDs]]>
+      </doc>
+    </method>
+    <method name="getTaskAttemptIDsPattern" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jtIdentifier" type="java.lang.String"/>
+      <param name="jobId" type="java.lang.Integer"/>
+      <param name="type" type="org.apache.hadoop.mapreduce.TaskType"/>
+      <param name="taskId" type="java.lang.Integer"/>
+      <param name="attemptId" type="java.lang.Integer"/>
+      <doc>
+      <![CDATA[Returns a regex pattern which matches task attempt IDs. Arguments can 
+ be given null, in which case that part of the regex will be generic.  
+ For example to obtain a regex matching <i>all task attempt IDs</i> 
+ of <i>any jobtracker</i>, in <i>any job</i>, of the <i>first 
+ map task</i>, we would use :
+ <pre> 
+ TaskAttemptID.getTaskAttemptIDsPattern(null, null, TaskType.MAP, 1, null);
+ </pre>
+ which will return :
+ <pre> "attempt_[^_]*_[0-9]*_m_000001_[0-9]*" </pre> 
+ @param jtIdentifier jobTracker identifier, or null
+ @param jobId job number, or null
+ @param type the {@link TaskType} 
+ @param taskId taskId number, or null
+ @param attemptId the task attempt number, or null
+ @return a regex pattern matching TaskAttemptIDs]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[TaskAttemptID represents the immutable and unique identifier for 
+ a task attempt. Each task attempt is one particular instance of a Map or
+ Reduce Task identified by its TaskID. 
+ 
+ TaskAttemptID consists of 2 parts. First part is the 
+ {@link TaskID}, that this TaskAttemptID belongs to.
+ Second part is the task attempt number. <br> 
+ An example TaskAttemptID is : 
+ <code>attempt_200707121733_0003_m_000005_0</code> , which represents the
+ zeroth task attempt for the fifth map task in the third job 
+ running at the jobtracker started at <code>200707121733</code>.
+ <p>
+ Applications should never construct or parse TaskAttemptID strings
+ , but rather use appropriate constructors or {@link #forName(String)} 
+ method. 
+ 
+ @see JobID
+ @see TaskID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TaskAttemptID -->
+  <!-- start class org.apache.hadoop.mapred.TaskCompletionEvent -->
+  <class name="TaskCompletionEvent" extends="org.apache.hadoop.mapreduce.TaskCompletionEvent"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TaskCompletionEvent"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor for Writable.]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskCompletionEvent" type="int, org.apache.hadoop.mapred.TaskAttemptID, int, boolean, org.apache.hadoop.mapred.TaskCompletionEvent.Status, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructor. eventId should be created externally and incremented
+ per event for each job. 
+ @param eventId event id, event id should be unique and assigned in
+  incrementally, starting from 0. 
+ @param taskId task id
+ @param status task's status 
+ @param taskTrackerHttp task tracker's host:port for http.]]>
+      </doc>
+    </constructor>
+    <method name="getTaskId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use {@link #getTaskAttemptId()} instead.">
+      <doc>
+      <![CDATA[Returns task id. 
+ @return task id
+ @deprecated use {@link #getTaskAttemptId()} instead.]]>
+      </doc>
+    </method>
+    <method name="getTaskAttemptId" return="org.apache.hadoop.mapred.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns task id. 
+ @return task id]]>
+      </doc>
+    </method>
+    <method name="getTaskStatus" return="org.apache.hadoop.mapred.TaskCompletionEvent.Status"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns {@link Status}
+ @return task completion status]]>
+      </doc>
+    </method>
+    <method name="setTaskId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use {@link #setTaskAttemptId(TaskAttemptID)} instead.">
+      <param name="taskId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets task id. 
+ @param taskId
+ @deprecated use {@link #setTaskAttemptId(TaskAttemptID)} instead.]]>
+      </doc>
+    </method>
+    <method name="setTaskID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use {@link #setTaskAttemptId(TaskAttemptID)} instead.">
+      <param name="taskId" type="org.apache.hadoop.mapred.TaskAttemptID"/>
+      <doc>
+      <![CDATA[Sets task id.
+ @param taskId
+ @deprecated use {@link #setTaskAttemptId(TaskAttemptID)} instead.]]>
+      </doc>
+    </method>
+    <method name="setTaskAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="taskId" type="org.apache.hadoop.mapred.TaskAttemptID"/>
+      <doc>
+      <![CDATA[Sets task id. 
+ @param taskId]]>
+      </doc>
+    </method>
+    <field name="EMPTY_ARRAY" type="org.apache.hadoop.mapred.TaskCompletionEvent[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This is used to track task completion events on 
+ job tracker.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TaskCompletionEvent -->
+  <!-- start class org.apache.hadoop.mapred.TaskCompletionEvent.Status -->
+  <class name="TaskCompletionEvent.Status" extends="java.lang.Enum"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapred.TaskCompletionEvent.Status[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapred.TaskCompletionEvent.Status"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TaskCompletionEvent.Status -->
+  <!-- start class org.apache.hadoop.mapred.TaskID -->
+  <class name="TaskID" extends="org.apache.hadoop.mapreduce.TaskID"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TaskID" type="org.apache.hadoop.mapreduce.JobID, boolean, int"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #TaskID(String, int, TaskType, int)}">
+      <doc>
+      <![CDATA[Constructs a TaskID object from given {@link JobID}.  
+ @param jobId JobID that this tip belongs to 
+ @param isMap whether the tip is a map 
+ @param id the tip number
+ @deprecated Use {@link #TaskID(String, int, TaskType, int)}]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID" type="java.lang.String, int, boolean, int"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #TaskID(org.apache.hadoop.mapreduce.JobID, TaskType,
+ int)}">
+      <doc>
+      <![CDATA[Constructs a TaskInProgressId object from given parts.
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number 
+ @param isMap whether the tip is a map 
+ @param id the tip number
+ @deprecated Use {@link #TaskID(org.apache.hadoop.mapreduce.JobID, TaskType,
+ int)}]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID" type="org.apache.hadoop.mapreduce.JobID, org.apache.hadoop.mapreduce.TaskType, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskID object from given {@link JobID}.  
+ @param jobId JobID that this tip belongs to 
+ @param type the {@link TaskType} 
+ @param id the tip number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID" type="java.lang.String, int, org.apache.hadoop.mapreduce.TaskType, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskInProgressId object from given parts.
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number 
+ @param type the {@link TaskType} 
+ @param id the tip number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="downgrade" return="org.apache.hadoop.mapred.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="old" type="org.apache.hadoop.mapreduce.TaskID"/>
+      <doc>
+      <![CDATA[Downgrade a new TaskID to an old one
+ @param old a new or old TaskID
+ @return either old or a new TaskID build to match old]]>
+      </doc>
+    </method>
+    <method name="read" return="org.apache.hadoop.mapred.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getJobID" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getTaskIDsPattern" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link TaskID#getTaskIDsPattern(String, Integer, TaskType,
+ Integer)}">
+      <param name="jtIdentifier" type="java.lang.String"/>
+      <param name="jobId" type="java.lang.Integer"/>
+      <param name="isMap" type="java.lang.Boolean"/>
+      <param name="taskId" type="java.lang.Integer"/>
+      <doc>
+      <![CDATA[Returns a regex pattern which matches task IDs. Arguments can 
+ be given null, in which case that part of the regex will be generic.  
+ For example to obtain a regex matching <i>the first map task</i> 
+ of <i>any jobtracker</i>, of <i>any job</i>, we would use :
+ <pre> 
+ TaskID.getTaskIDsPattern(null, null, true, 1);
+ </pre>
+ which will return :
+ <pre> "task_[^_]*_[0-9]*_m_000001*" </pre> 
+ @param jtIdentifier jobTracker identifier, or null
+ @param jobId job number, or null
+ @param isMap whether the tip is a map, or null 
+ @param taskId taskId number, or null
+ @return a regex pattern matching TaskIDs
+ @deprecated Use {@link TaskID#getTaskIDsPattern(String, Integer, TaskType,
+ Integer)}]]>
+      </doc>
+    </method>
+    <method name="getTaskIDsPattern" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jtIdentifier" type="java.lang.String"/>
+      <param name="jobId" type="java.lang.Integer"/>
+      <param name="type" type="org.apache.hadoop.mapreduce.TaskType"/>
+      <param name="taskId" type="java.lang.Integer"/>
+      <doc>
+      <![CDATA[Returns a regex pattern which matches task IDs. Arguments can 
+ be given null, in which case that part of the regex will be generic.  
+ For example to obtain a regex matching <i>the first map task</i> 
+ of <i>any jobtracker</i>, of <i>any job</i>, we would use :
+ <pre> 
+ TaskID.getTaskIDsPattern(null, null, true, 1);
+ </pre>
+ which will return :
+ <pre> "task_[^_]*_[0-9]*_m_000001*" </pre> 
+ @param jtIdentifier jobTracker identifier, or null
+ @param jobId job number, or null
+ @param type the {@link TaskType}, or null 
+ @param taskId taskId number, or null
+ @return a regex pattern matching TaskIDs]]>
+      </doc>
+    </method>
+    <method name="forName" return="org.apache.hadoop.mapred.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="str" type="java.lang.String"/>
+      <exception name="IllegalArgumentException" type="java.lang.IllegalArgumentException"/>
+    </method>
+    <doc>
+    <![CDATA[TaskID represents the immutable and unique identifier for 
+ a Map or Reduce Task. Each TaskID encompasses multiple attempts made to
+ execute the Map or Reduce Task, each of which are uniquely indentified by
+ their TaskAttemptID.
+ 
+ TaskID consists of 3 parts. First part is the {@link JobID}, that this 
+ TaskInProgress belongs to. Second part of the TaskID is either 'm' or 'r' 
+ representing whether the task is a map task or a reduce task. 
+ And the third part is the task number. <br> 
+ An example TaskID is : 
+ <code>task_200707121733_0003_m_000005</code> , which represents the
+ fifth map task in the third job running at the jobtracker 
+ started at <code>200707121733</code>. 
+ <p>
+ Applications should never construct or parse TaskID strings
+ , but rather use appropriate constructors or {@link #forName(String)} 
+ method. 
+ 
+ @see JobID
+ @see TaskAttemptID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TaskID -->
+  <!-- start class org.apache.hadoop.mapred.TaskReport -->
+  <class name="TaskReport" extends="org.apache.hadoop.mapreduce.TaskReport"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TaskReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getTaskId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The string of the task id.]]>
+      </doc>
+    </method>
+    <method name="getTaskID" return="org.apache.hadoop.mapred.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The id of the task.]]>
+      </doc>
+    </method>
+    <method name="getCounters" return="org.apache.hadoop.mapred.Counters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setSuccessfulAttempt"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="t" type="org.apache.hadoop.mapred.TaskAttemptID"/>
+      <doc>
+      <![CDATA[set successful attempt ID of the task.]]>
+      </doc>
+    </method>
+    <method name="getSuccessfulTaskAttempt" return="org.apache.hadoop.mapred.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the attempt ID that took this task to completion]]>
+      </doc>
+    </method>
+    <method name="setRunningTaskAttempts"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="runningAttempts" type="java.util.Collection"/>
+      <doc>
+      <![CDATA[set running attempt(s) of the task.]]>
+      </doc>
+    </method>
+    <method name="getRunningTaskAttempts" return="java.util.Collection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the running task attempt IDs for this task]]>
+      </doc>
+    </method>
+    <method name="setFinishTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="finishTime" type="long"/>
+      <doc>
+      <![CDATA[set finish time of task. 
+ @param finishTime finish time of task.]]>
+      </doc>
+    </method>
+    <method name="setStartTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="startTime" type="long"/>
+      <doc>
+      <![CDATA[set start time of the task.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A report on the state of a task.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TaskReport -->
+  <!-- start class org.apache.hadoop.mapred.TextInputFormat -->
+  <class name="TextInputFormat" extends="org.apache.hadoop.mapred.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="TextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link InputFormat} for plain text files.  Files are broken into lines.
+ Either linefeed or carriage-return are used to signal end of line.  Keys are
+ the position in the file, and values are the line of text..]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TextInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.TextOutputFormat -->
+  <class name="TextOutputFormat" extends="org.apache.hadoop.mapred.FileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TextOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link OutputFormat} that writes plain text files.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.TextOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.Utils -->
+  <class name="Utils" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Utils"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[A utility class. It provides
+   A path filter utility to filter out output/part files in the output dir]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.Utils -->
+</package>
+<package name="org.apache.hadoop.mapred.jobcontrol">
+  <!-- start class org.apache.hadoop.mapred.jobcontrol.Job -->
+  <class name="Job" extends="org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Job" type="org.apache.hadoop.mapred.JobConf, java.util.ArrayList"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Construct a job.
+ @param jobConf a mapred job configuration representing a job to be executed.
+ @param dependingJobs an array of jobs the current job depends on]]>
+      </doc>
+    </constructor>
+    <constructor name="Job" type="org.apache.hadoop.mapred.JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="getAssignedJobID" return="org.apache.hadoop.mapred.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the mapred ID of this job as assigned by the mapred framework.]]>
+      </doc>
+    </method>
+    <method name="setAssignedJobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="setAssignedJobID should not be called.
+ JOBID is set by the framework.">
+      <param name="mapredJobID" type="org.apache.hadoop.mapred.JobID"/>
+      <doc>
+      <![CDATA[@deprecated setAssignedJobID should not be called.
+ JOBID is set by the framework.]]>
+      </doc>
+    </method>
+    <method name="getJobConf" return="org.apache.hadoop.mapred.JobConf"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the mapred job conf of this job]]>
+      </doc>
+    </method>
+    <method name="setJobConf"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobConf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Set the mapred job conf for this job.
+ @param jobConf the mapred job conf for this job.]]>
+      </doc>
+    </method>
+    <method name="getState" return="int"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the state of this job]]>
+      </doc>
+    </method>
+    <method name="setState"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="state" type="int"/>
+      <doc>
+      <![CDATA[This is a no-op function, Its a behavior change from 1.x We no more can
+ change the state from job
+ 
+ @param state
+          the new state for this job.]]>
+      </doc>
+    </method>
+    <method name="addDependingJob" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dependingJob" type="org.apache.hadoop.mapred.jobcontrol.Job"/>
+      <doc>
+      <![CDATA[Add a job to this jobs' dependency list. 
+ Dependent jobs can only be added while a Job 
+ is waiting to run, not during or afterwards.
+ 
+ @param dependingJob Job that this Job depends on.
+ @return <tt>true</tt> if the Job was added.]]>
+      </doc>
+    </method>
+    <method name="getJobClient" return="org.apache.hadoop.mapred.JobClient"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the job client of this job]]>
+      </doc>
+    </method>
+    <method name="getDependingJobs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the depending jobs of this job]]>
+      </doc>
+    </method>
+    <method name="getMapredJobID" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the mapred ID of this job as assigned by the mapred framework.]]>
+      </doc>
+    </method>
+    <method name="setMapredJobID"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="mapredJobID" type="java.lang.String"/>
+      <doc>
+      <![CDATA[This is no-op method for backward compatibility. It's a behavior change
+ from 1.x, we can not change job ids from job.
+ 
+ @param mapredJobID
+          the mapred job ID for this job.]]>
+      </doc>
+    </method>
+    <field name="SUCCESS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="WAITING" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RUNNING" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="READY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FAILED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEPENDENT_FAILED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.jobcontrol.Job -->
+  <!-- start class org.apache.hadoop.mapred.jobcontrol.JobControl -->
+  <class name="JobControl" extends="org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="JobControl" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a job control for a group of jobs.
+ @param groupName a name identifying this group]]>
+      </doc>
+    </constructor>
+    <method name="getWaitingJobs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the waiting state]]>
+      </doc>
+    </method>
+    <method name="getRunningJobs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the running state]]>
+      </doc>
+    </method>
+    <method name="getReadyJobs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the ready state]]>
+      </doc>
+    </method>
+    <method name="getSuccessfulJobs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the success state]]>
+      </doc>
+    </method>
+    <method name="getFailedJobs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="addJobs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobs" type="java.util.Collection"/>
+      <doc>
+      <![CDATA[Add a collection of jobs
+ 
+ @param jobs]]>
+      </doc>
+    </method>
+    <method name="getState" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the thread state]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.jobcontrol.JobControl -->
+</package>
+<package name="org.apache.hadoop.mapred.join">
+  <!-- start class org.apache.hadoop.mapred.join.ArrayListBackedIterator -->
+  <class name="ArrayListBackedIterator" extends="org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ResetableIterator"/>
+    <constructor name="ArrayListBackedIterator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ArrayListBackedIterator" type="java.util.ArrayList"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class provides an implementation of ResetableIterator. The
+ implementation uses an {@link java.util.ArrayList} to store elements
+ added to it, replaying them as requested.
+ Prefer {@link StreamBackedIterator}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.ArrayListBackedIterator -->
+  <!-- start interface org.apache.hadoop.mapred.join.ComposableInputFormat -->
+  <interface name="ComposableInputFormat"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputFormat"/>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.join.ComposableRecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Refinement of InputFormat requiring implementors to provide
+ ComposableRecordReader instead of RecordReader.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.join.ComposableInputFormat -->
+  <!-- start interface org.apache.hadoop.mapred.join.ComposableRecordReader -->
+  <interface name="ComposableRecordReader"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.RecordReader"/>
+    <implements name="java.lang.Comparable"/>
+    <method name="id" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the position in the collector this class occupies.]]>
+      </doc>
+    </method>
+    <method name="key" return="K"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the key this RecordReader would supply on a call to next(K,V)]]>
+      </doc>
+    </method>
+    <method name="key"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Clone the key at the head of this RecordReader into the object provided.]]>
+      </doc>
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns true if the stream is not empty, but provides no guarantee that
+ a call to next(K,V) will succeed.]]>
+      </doc>
+    </method>
+    <method name="skip"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Skip key-value pairs with keys less than or equal to the key provided.]]>
+      </doc>
+    </method>
+    <method name="accept"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jc" type="org.apache.hadoop.mapred.join.CompositeRecordReader.JoinCollector"/>
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[While key-value pairs from this RecordReader match the given key, register
+ them with the JoinCollector provided.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Additional operations required of a RecordReader to participate in a join.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.join.ComposableRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.CompositeInputFormat -->
+  <class name="CompositeInputFormat" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ComposableInputFormat"/>
+    <constructor name="CompositeInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setFormat"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Interpret a given string as a composite expression.
+ {@code
+   func  ::= <ident>([<func>,]*<func>)
+   func  ::= tbl(<class>,"<path>")
+   class ::= @see java.lang.Class#forName(java.lang.String)
+   path  ::= @see org.apache.hadoop.fs.Path#Path(java.lang.String)
+ }
+ Reads expression from the <tt>mapred.join.expr</tt> property and
+ user-supplied join types from <tt>mapred.join.define.&lt;ident&gt;</tt>
+  types. Paths supplied to <tt>tbl</tt> are given as input paths to the
+ InputFormat class listed.
+ @see #compose(java.lang.String, java.lang.Class, java.lang.String...)]]>
+      </doc>
+    </method>
+    <method name="addDefaults"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Adds the default set of identifiers to the parser.]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="numSplits" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Build a CompositeInputSplit from the child InputFormats by assigning the
+ ith split from each child to the ith composite split.]]>
+      </doc>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.join.ComposableRecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Construct a CompositeRecordReader for the children of this InputFormat
+ as defined in the init expression.
+ The outermost join need only be composable, not necessarily a composite.
+ Mandating TupleWritable isn't strictly correct.]]>
+      </doc>
+    </method>
+    <method name="compose" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="inf" type="java.lang.Class"/>
+      <param name="path" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Convenience method for constructing composite formats.
+ Given InputFormat class (inf), path (p) return:
+ {@code tbl(<inf>, <p>) }]]>
+      </doc>
+    </method>
+    <method name="compose" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="java.lang.String"/>
+      <param name="inf" type="java.lang.Class"/>
+      <param name="path" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Convenience method for constructing composite formats.
+ Given operation (op), Object class (inf), set of paths (p) return:
+ {@code <op>(tbl(<inf>,<p1>),tbl(<inf>,<p2>),...,tbl(<inf>,<pn>)) }]]>
+      </doc>
+    </method>
+    <method name="compose" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="java.lang.String"/>
+      <param name="inf" type="java.lang.Class"/>
+      <param name="path" type="org.apache.hadoop.fs.Path[]"/>
+      <doc>
+      <![CDATA[Convenience method for constructing composite formats.
+ Given operation (op), Object class (inf), set of paths (p) return:
+ {@code <op>(tbl(<inf>,<p1>),tbl(<inf>,<p2>),...,tbl(<inf>,<pn>)) }]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[An InputFormat capable of performing joins over a set of data sources sorted
+ and partitioned the same way.
+
+ A user may define new join types by setting the property
+ <tt>mapred.join.define.&lt;ident&gt;</tt> to a classname. In the expression
+ <tt>mapred.join.expr</tt>, the identifier will be assumed to be a
+ ComposableRecordReader.
+ <tt>mapred.join.keycomparator</tt> can be a classname used to compare keys
+ in the join.
+ @see #setFormat
+ @see JoinRecordReader
+ @see MultiFilterRecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.CompositeInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.join.CompositeInputSplit -->
+  <class name="CompositeInputSplit" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputSplit"/>
+    <constructor name="CompositeInputSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CompositeInputSplit" type="int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="s" type="org.apache.hadoop.mapred.InputSplit"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add an InputSplit to this collection.
+ @throws IOException If capacity was not specified during construction
+                     or if capacity has been reached.]]>
+      </doc>
+    </method>
+    <method name="get" return="org.apache.hadoop.mapred.InputSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Get ith child InputSplit.]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return the aggregate length of all child InputSplits currently added.]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the length of ith child InputSplit.]]>
+      </doc>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Collect a set of hosts from all child InputSplits.]]>
+      </doc>
+    </method>
+    <method name="getLocation" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[getLocations from ith InputSplit.]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Write splits in the following format.
+ {@code
+ <count><class1><class2>...<classn><split1><split2>...<splitn>
+ }]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}
+ @throws IOException If the child InputSplit cannot be read, typically
+                     for faliing access checks.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This InputSplit contains a set of child InputSplits. Any InputSplit inserted
+ into this collection must have a public default constructor.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.CompositeInputSplit -->
+  <!-- start class org.apache.hadoop.mapred.join.CompositeRecordReader -->
+  <class name="CompositeRecordReader" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="CompositeRecordReader" type="int, int, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a RecordReader with <tt>capacity</tt> children to position
+ <tt>id</tt> in the parent reader.
+ The id of a root CompositeRecordReader is -1 by convention, but relying
+ on this is not recommended.]]>
+      </doc>
+    </constructor>
+    <method name="combine" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="value" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+    </method>
+    <method name="id" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the position in the collector this class occupies.]]>
+      </doc>
+    </method>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getRecordReaderQueue" return="java.util.PriorityQueue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return sorted list of RecordReaders for this composite.]]>
+      </doc>
+    </method>
+    <method name="getComparator" return="org.apache.hadoop.io.WritableComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return comparator defining the ordering for RecordReaders in this
+ composite.]]>
+      </doc>
+    </method>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rr" type="org.apache.hadoop.mapred.join.ComposableRecordReader"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add a RecordReader to this collection.
+ The id() of a RecordReader determines where in the Tuple its
+ entry will appear. Adding RecordReaders with the same id has
+ undefined behavior.]]>
+      </doc>
+    </method>
+    <method name="key" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the key for the current join or the value at the top of the
+ RecordReader heap.]]>
+      </doc>
+    </method>
+    <method name="key"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Clone the key at the top of this RR into the given object.]]>
+      </doc>
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return true if it is possible that this could emit more values.]]>
+      </doc>
+    </method>
+    <method name="skip"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Pass skip key to child RRs.]]>
+      </doc>
+    </method>
+    <method name="getDelegate" return="org.apache.hadoop.mapred.join.ResetableIterator"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Obtain an iterator over the child RRs apropos of the value type
+ ultimately emitted from this join.]]>
+      </doc>
+    </method>
+    <method name="accept"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jc" type="org.apache.hadoop.mapred.join.CompositeRecordReader.JoinCollector"/>
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[If key provided matches that of this Composite, give JoinCollector
+ iterator over values it may emit.]]>
+      </doc>
+    </method>
+    <method name="fillJoinCollector"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="iterkey" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For all child RRs offering the key provided, obtain an iterator
+ at that position in the JoinCollector.]]>
+      </doc>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.mapred.join.ComposableRecordReader"/>
+      <doc>
+      <![CDATA[Implement Comparable contract (compare key of join or head of heap
+ with that of another).]]>
+      </doc>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new key value common to all child RRs.
+ @throws ClassCastException if key classes differ.]]>
+      </doc>
+    </method>
+    <method name="createInternalValue" return="org.apache.hadoop.mapred.join.TupleWritable"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a value to be used internally for joins.]]>
+      </doc>
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Unsupported (returns zero in all cases).]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close all child RRs.]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Report progress as the minimum of all child RR progress.]]>
+      </doc>
+    </method>
+    <field name="jc" type="org.apache.hadoop.mapred.join.CompositeRecordReader.JoinCollector"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="kids" type="org.apache.hadoop.mapred.join.ComposableRecordReader[]"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A RecordReader that can effect joins of RecordReaders sharing a common key
+ type and partitioning.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.CompositeRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.InnerJoinRecordReader -->
+  <class name="InnerJoinRecordReader" extends="org.apache.hadoop.mapred.join.JoinRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="combine" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="dst" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Return true iff the tuple is full (all data sources contain this key).]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Full inner join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.InnerJoinRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.JoinRecordReader -->
+  <class name="JoinRecordReader" extends="org.apache.hadoop.mapred.join.CompositeRecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ComposableRecordReader"/>
+    <constructor name="JoinRecordReader" type="int, org.apache.hadoop.mapred.JobConf, int, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Emit the next set of key, value pairs as defined by the child
+ RecordReaders and operation associated with this composite RR.]]>
+      </doc>
+    </method>
+    <method name="createValue" return="org.apache.hadoop.mapred.join.TupleWritable"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getDelegate" return="org.apache.hadoop.mapred.join.ResetableIterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return an iterator wrapping the JoinCollector.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Base class for Composite joins returning Tuples of arbitrary Writables.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.JoinRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.MultiFilterRecordReader -->
+  <class name="MultiFilterRecordReader" extends="org.apache.hadoop.mapred.join.CompositeRecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ComposableRecordReader"/>
+    <constructor name="MultiFilterRecordReader" type="int, org.apache.hadoop.mapred.JobConf, int, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="emit" return="V"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="dst" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For each tuple emitted, return a value (typically one of the values
+ in the tuple).
+ Modifying the Writables in the tuple is permitted and unlikely to affect
+ join behavior in most cases, but it is not recommended. It's safer to
+ clone first.]]>
+      </doc>
+    </method>
+    <method name="combine" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="dst" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Default implementation offers {@link #emit} every Tuple from the
+ collector (the outer join of child RRs).]]>
+      </doc>
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="createValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getDelegate" return="org.apache.hadoop.mapred.join.ResetableIterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return an iterator returning a single value from the tuple.
+ @see MultiFilterDelegationIterator]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Base class for Composite join returning values derived from multiple
+ sources, but generally not tuples.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.MultiFilterRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.OuterJoinRecordReader -->
+  <class name="OuterJoinRecordReader" extends="org.apache.hadoop.mapred.join.JoinRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="combine" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="dst" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Emit everything from the collector.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Full outer join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.OuterJoinRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.OverrideRecordReader -->
+  <class name="OverrideRecordReader" extends="org.apache.hadoop.mapred.join.MultiFilterRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="emit" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="dst" type="org.apache.hadoop.mapred.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Emit the value with the highest position in the tuple.]]>
+      </doc>
+    </method>
+    <method name="fillJoinCollector"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="iterkey" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Instead of filling the JoinCollector with iterators from all
+ data sources, fill only the rightmost for this key.
+ This not only saves space by discarding the other sources, but
+ it also emits the number of key-value pairs in the preferred
+ RecordReader instead of repeating that stream n times, where
+ n is the cardinality of the cross product of the discarded
+ streams for the given key.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Prefer the &quot;rightmost&quot; data source for this key.
+ For example, <tt>override(S1,S2,S3)</tt> will prefer values
+ from S3 over S2, and values from S2 over S1 for all keys
+ emitted from all sources.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.OverrideRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser -->
+  <class name="Parser" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Parser"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Very simple shift-reduce parser for join expressions.
+
+ This should be sufficient for the user extension permitted now, but ought to
+ be replaced with a parser generator if more complex grammars are supported.
+ In particular, this &quot;shift-reduce&quot; parser has no states. Each set
+ of formals requires a different internal node type, which is responsible for
+ interpreting the list of tokens it receives. This is sufficient for the
+ current grammar, but it has several annoying properties that might inhibit
+ extension. In particular, parenthesis are always function calls; an
+ algebraic or filter grammar would not only require a node type, but must
+ also work around the internals of this parser.
+
+ For most other cases, adding classes to the hierarchy- particularly by
+ extending JoinRecordReader and MultiFilterRecordReader- is fairly
+ straightforward. One need only override the relevant method(s) (usually only
+ {@link CompositeRecordReader#combine}) and include a property to map its
+ value to an identifier in the parser.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser.Node -->
+  <class name="Parser.Node" extends="java.lang.Object"
+    abstract="true"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ComposableInputFormat"/>
+    <constructor name="Node" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addIdentifier"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="ident" type="java.lang.String"/>
+      <param name="mcstrSig" type="java.lang.Class[]"/>
+      <param name="nodetype" type="java.lang.Class"/>
+      <param name="cl" type="java.lang.Class"/>
+      <exception name="NoSuchMethodException" type="java.lang.NoSuchMethodException"/>
+      <doc>
+      <![CDATA[For a given identifier, add a mapping to the nodetype for the parse
+ tree and to the ComposableRecordReader to be created, including the
+ formals required to invoke the constructor.
+ The nodetype and constructor signature should be filled in from the
+ child node.]]>
+      </doc>
+    </method>
+    <method name="setID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="id" type="int"/>
+    </method>
+    <method name="setKeyComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="cmpcl" type="java.lang.Class"/>
+    </method>
+    <field name="rrCstrMap" type="java.util.Map"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="id" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="ident" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="cmpcl" type="java.lang.Class"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser.Node -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser.NodeToken -->
+  <class name="Parser.NodeToken" extends="org.apache.hadoop.mapred.join.Parser.Token"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getNode" return="org.apache.hadoop.mapred.join.Parser.Node"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser.NodeToken -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser.NumToken -->
+  <class name="Parser.NumToken" extends="org.apache.hadoop.mapred.join.Parser.Token"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NumToken" type="double"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNum" return="double"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser.NumToken -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser.StrToken -->
+  <class name="Parser.StrToken" extends="org.apache.hadoop.mapred.join.Parser.Token"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StrToken" type="org.apache.hadoop.mapred.join.Parser.TType, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getStr" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser.StrToken -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser.Token -->
+  <class name="Parser.Token" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getType" return="org.apache.hadoop.mapred.join.Parser.TType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNode" return="org.apache.hadoop.mapred.join.Parser.Node"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getNum" return="double"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getStr" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Tagged-union type for tokens from the join expression.
+ @see Parser.TType]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser.Token -->
+  <!-- start class org.apache.hadoop.mapred.join.Parser.TType -->
+  <class name="Parser.TType" extends="java.lang.Enum"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapred.join.Parser.TType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapred.join.Parser.TType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.Parser.TType -->
+  <!-- start interface org.apache.hadoop.mapred.join.ResetableIterator -->
+  <interface name="ResetableIterator"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.join.ResetableIterator"/>
+    <doc>
+    <![CDATA[This defines an interface to a stateful Iterator that can replay elements
+ added to it directly.
+ Note that this does not extend {@link java.util.Iterator}.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.join.ResetableIterator -->
+  <!-- start class org.apache.hadoop.mapred.join.StreamBackedIterator -->
+  <class name="StreamBackedIterator" extends="org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ResetableIterator"/>
+    <constructor name="StreamBackedIterator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class provides an implementation of ResetableIterator. This
+ implementation uses a byte array to store elements added to it.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.StreamBackedIterator -->
+  <!-- start class org.apache.hadoop.mapred.join.TupleWritable -->
+  <class name="TupleWritable" extends="org.apache.hadoop.mapreduce.lib.join.TupleWritable"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TupleWritable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an empty tuple with no allocated storage for writables.]]>
+      </doc>
+    </constructor>
+    <constructor name="TupleWritable" type="org.apache.hadoop.io.Writable[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Initialize tuple with storage; unknown whether any of them contain
+ &quot;written&quot; values.]]>
+      </doc>
+    </constructor>
+    <doc>
+    <![CDATA[Writable type storing multiple {@link org.apache.hadoop.io.Writable}s.
+
+ This is *not* a general-purpose tuple type. In almost all cases, users are
+ encouraged to implement their own serializable types, which can perform
+ better validation and provide more efficient encodings than this class is
+ capable. TupleWritable relies on the join framework for type safety and
+ assumes its instances will rarely be persisted, assumptions not only
+ incompatible with, but contrary to the general case.
+
+ @see org.apache.hadoop.io.Writable]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.TupleWritable -->
+  <!-- start class org.apache.hadoop.mapred.join.WrappedRecordReader -->
+  <class name="WrappedRecordReader" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.join.ComposableRecordReader"/>
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <method name="id" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="key" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the key at the head of this RR.]]>
+      </doc>
+    </method>
+    <method name="key"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="qkey" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Clone the key at the head of this RR into the object supplied.]]>
+      </doc>
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return true if the RR- including the k,v pair stored in this object-
+ is exhausted.]]>
+      </doc>
+    </method>
+    <method name="skip"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Skip key-value pairs with keys less than or equal to the key provided.]]>
+      </doc>
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Read the next k,v pair into the head of this object; return true iff
+ the RR and this are exhausted.]]>
+      </doc>
+    </method>
+    <method name="accept"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="org.apache.hadoop.mapred.join.CompositeRecordReader.JoinCollector"/>
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add an iterator to the collector at the position occupied by this
+ RecordReader over the values in this stream paired with the key
+ provided (ie register a stream of values from this source matching K
+ with a collector).]]>
+      </doc>
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="U"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Write key-value pair at the head of this stream to the objects provided;
+ get next key-value pair from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Request new key from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="createValue" return="U"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Request new value from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Request progress from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Request position from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Forward close request to proxied RR.]]>
+      </doc>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.mapred.join.ComposableRecordReader"/>
+      <doc>
+      <![CDATA[Implement Comparable contract (compare key at head of proxied RR
+ with that of another).]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Return true iff compareTo(other) retn true.]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Proxy class for a RecordReader participating in the join framework.
+ This class keeps track of the &quot;head&quot; key-value pair for the
+ provided RecordReader and keeps a store of values matching a key when
+ this source is participating in a join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.join.WrappedRecordReader -->
+</package>
+<package name="org.apache.hadoop.mapred.lib">
+  <!-- start class org.apache.hadoop.mapred.lib.BinaryPartitioner -->
+  <class name="BinaryPartitioner" extends="org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Partitioner"/>
+    <constructor name="BinaryPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <doc>
+    <![CDATA[Partition {@link BinaryComparable} keys using a configurable part of 
+ the bytes array returned by {@link BinaryComparable#getBytes()}. 
+ 
+ @see org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.BinaryPartitioner -->
+  <!-- start class org.apache.hadoop.mapred.lib.ChainMapper -->
+  <class name="ChainMapper" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <constructor name="ChainMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructor.]]>
+      </doc>
+    </constructor>
+    <method name="addMapper"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="klass" type="java.lang.Class"/>
+      <param name="inputKeyClass" type="java.lang.Class"/>
+      <param name="inputValueClass" type="java.lang.Class"/>
+      <param name="outputKeyClass" type="java.lang.Class"/>
+      <param name="outputValueClass" type="java.lang.Class"/>
+      <param name="byValue" type="boolean"/>
+      <param name="mapperConf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Adds a Mapper class to the chain job's JobConf.
+ <p>
+ It has to be specified how key and values are passed from one element of
+ the chain to the next, by value or by reference. If a Mapper leverages the
+ assumed semantics that the key and values are not modified by the collector
+ 'by value' must be used. If the Mapper does not expect this semantics, as
+ an optimization to avoid serialization and deserialization 'by reference'
+ can be used.
+ <p>
+ For the added Mapper the configuration given for it,
+ <code>mapperConf</code>, have precedence over the job's JobConf. This
+ precedence is in effect when the task is running.
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainMapper, this is done by the addMapper for the last mapper in the chain
+ <p>
+
+ @param job              job's JobConf to add the Mapper class.
+ @param klass            the Mapper class to add.
+ @param inputKeyClass    mapper input key class.
+ @param inputValueClass  mapper input value class.
+ @param outputKeyClass   mapper output key class.
+ @param outputValueClass mapper output value class.
+ @param byValue          indicates if key/values should be passed by value
+ to the next Mapper in the chain, if any.
+ @param mapperConf       a JobConf with the configuration for the Mapper
+ class. It is recommended to use a JobConf without default values using the
+ <code>JobConf(boolean loadDefaults)</code> constructor with FALSE.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Configures the ChainMapper and all the Mappers in the chain.
+ <p>
+ If this method is overriden <code>super.configure(...)</code> should be
+ invoked at the beginning of the overwriter method.]]>
+      </doc>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Object"/>
+      <param name="value" type="java.lang.Object"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Chains the <code>map(...)</code> methods of the Mappers in the chain.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Closes  the ChainMapper and all the Mappers in the chain.
+ <p>
+ If this method is overriden <code>super.close()</code> should be
+ invoked at the end of the overwriter method.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The ChainMapper class allows to use multiple Mapper classes within a single
+ Map task.
+ <p>
+ The Mapper classes are invoked in a chained (or piped) fashion, the output of
+ the first becomes the input of the second, and so on until the last Mapper,
+ the output of the last Mapper will be written to the task's output.
+ <p>
+ The key functionality of this feature is that the Mappers in the chain do not
+ need to be aware that they are executed in a chain. This enables having
+ reusable specialized Mappers that can be combined to perform composite
+ operations within a single task.
+ <p>
+ Special care has to be taken when creating chains that the key/values output
+ by a Mapper are valid for the following Mapper in the chain. It is assumed
+ all Mappers and the Reduce in the chain use maching output and input key and
+ value classes as no conversion is done by the chaining code.
+ <p>
+ Using the ChainMapper and the ChainReducer classes is possible to compose
+ Map/Reduce jobs that look like <code>[MAP+ / REDUCE MAP*]</code>. And
+ immediate benefit of this pattern is a dramatic reduction in disk IO.
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainMapper, this is done by the addMapper for the last mapper in the chain.
+ <p>
+ ChainMapper usage pattern:
+ <p>
+ <pre>
+ ...
+ conf.setJobName("chain");
+ conf.setInputFormat(TextInputFormat.class);
+ conf.setOutputFormat(TextOutputFormat.class);
+
+ JobConf mapAConf = new JobConf(false);
+ ...
+ ChainMapper.addMapper(conf, AMap.class, LongWritable.class, Text.class,
+   Text.class, Text.class, true, mapAConf);
+
+ JobConf mapBConf = new JobConf(false);
+ ...
+ ChainMapper.addMapper(conf, BMap.class, Text.class, Text.class,
+   LongWritable.class, Text.class, false, mapBConf);
+
+ JobConf reduceConf = new JobConf(false);
+ ...
+ ChainReducer.setReducer(conf, XReduce.class, LongWritable.class, Text.class,
+   Text.class, Text.class, true, reduceConf);
+
+ ChainReducer.addMapper(conf, CMap.class, Text.class, Text.class,
+   LongWritable.class, Text.class, false, null);
+
+ ChainReducer.addMapper(conf, DMap.class, LongWritable.class, Text.class,
+   LongWritable.class, LongWritable.class, true, null);
+
+ FileInputFormat.setInputPaths(conf, inDir);
+ FileOutputFormat.setOutputPath(conf, outDir);
+ ...
+
+ JobClient jc = new JobClient(conf);
+ RunningJob job = jc.submitJob(conf);
+ ...
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.ChainMapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.ChainReducer -->
+  <class name="ChainReducer" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Reducer"/>
+    <constructor name="ChainReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructor.]]>
+      </doc>
+    </constructor>
+    <method name="setReducer"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="klass" type="java.lang.Class"/>
+      <param name="inputKeyClass" type="java.lang.Class"/>
+      <param name="inputValueClass" type="java.lang.Class"/>
+      <param name="outputKeyClass" type="java.lang.Class"/>
+      <param name="outputValueClass" type="java.lang.Class"/>
+      <param name="byValue" type="boolean"/>
+      <param name="reducerConf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Sets the Reducer class to the chain job's JobConf.
+ <p>
+ It has to be specified how key and values are passed from one element of
+ the chain to the next, by value or by reference. If a Reducer leverages the
+ assumed semantics that the key and values are not modified by the collector
+ 'by value' must be used. If the Reducer does not expect this semantics, as
+ an optimization to avoid serialization and deserialization 'by reference'
+ can be used.
+ <p>
+ For the added Reducer the configuration given for it,
+ <code>reducerConf</code>, have precedence over the job's JobConf. This
+ precedence is in effect when the task is running.
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainReducer, this is done by the setReducer or the addMapper for the last
+ element in the chain.
+
+ @param job              job's JobConf to add the Reducer class.
+ @param klass            the Reducer class to add.
+ @param inputKeyClass    reducer input key class.
+ @param inputValueClass  reducer input value class.
+ @param outputKeyClass   reducer output key class.
+ @param outputValueClass reducer output value class.
+ @param byValue          indicates if key/values should be passed by value
+ to the next Mapper in the chain, if any.
+ @param reducerConf      a JobConf with the configuration for the Reducer
+ class. It is recommended to use a JobConf without default values using the
+ <code>JobConf(boolean loadDefaults)</code> constructor with FALSE.]]>
+      </doc>
+    </method>
+    <method name="addMapper"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="klass" type="java.lang.Class"/>
+      <param name="inputKeyClass" type="java.lang.Class"/>
+      <param name="inputValueClass" type="java.lang.Class"/>
+      <param name="outputKeyClass" type="java.lang.Class"/>
+      <param name="outputValueClass" type="java.lang.Class"/>
+      <param name="byValue" type="boolean"/>
+      <param name="mapperConf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Adds a Mapper class to the chain job's JobConf.
+ <p>
+ It has to be specified how key and values are passed from one element of
+ the chain to the next, by value or by reference. If a Mapper leverages the
+ assumed semantics that the key and values are not modified by the collector
+ 'by value' must be used. If the Mapper does not expect this semantics, as
+ an optimization to avoid serialization and deserialization 'by reference'
+ can be used.
+ <p>
+ For the added Mapper the configuration given for it,
+ <code>mapperConf</code>, have precedence over the job's JobConf. This
+ precedence is in effect when the task is running.
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainMapper, this is done by the addMapper for the last mapper in the chain
+ .
+
+ @param job              chain job's JobConf to add the Mapper class.
+ @param klass            the Mapper class to add.
+ @param inputKeyClass    mapper input key class.
+ @param inputValueClass  mapper input value class.
+ @param outputKeyClass   mapper output key class.
+ @param outputValueClass mapper output value class.
+ @param byValue          indicates if key/values should be passed by value
+ to the next Mapper in the chain, if any.
+ @param mapperConf       a JobConf with the configuration for the Mapper
+ class. It is recommended to use a JobConf without default values using the
+ <code>JobConf(boolean loadDefaults)</code> constructor with FALSE.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Configures the ChainReducer, the Reducer and all the Mappers in the chain.
+ <p>
+ If this method is overriden <code>super.configure(...)</code> should be
+ invoked at the beginning of the overwriter method.]]>
+      </doc>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Object"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Chains the <code>reduce(...)</code> method of the Reducer with the
+ <code>map(...) </code> methods of the Mappers in the chain.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Closes  the ChainReducer, the Reducer and all the Mappers in the chain.
+ <p>
+ If this method is overriden <code>super.close()</code> should be
+ invoked at the end of the overwriter method.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The ChainReducer class allows to chain multiple Mapper classes after a
+ Reducer within the Reducer task.
+ <p>
+ For each record output by the Reducer, the Mapper classes are invoked in a
+ chained (or piped) fashion, the output of the first becomes the input of the
+ second, and so on until the last Mapper, the output of the last Mapper will
+ be written to the task's output.
+ <p>
+ The key functionality of this feature is that the Mappers in the chain do not
+ need to be aware that they are executed after the Reducer or in a chain.
+ This enables having reusable specialized Mappers that can be combined to
+ perform composite operations within a single task.
+ <p>
+ Special care has to be taken when creating chains that the key/values output
+ by a Mapper are valid for the following Mapper in the chain. It is assumed
+ all Mappers and the Reduce in the chain use maching output and input key and
+ value classes as no conversion is done by the chaining code.
+ <p>
+ Using the ChainMapper and the ChainReducer classes is possible to compose
+ Map/Reduce jobs that look like <code>[MAP+ / REDUCE MAP*]</code>. And
+ immediate benefit of this pattern is a dramatic reduction in disk IO.
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainReducer, this is done by the setReducer or the addMapper for the last
+ element in the chain.
+ <p>
+ ChainReducer usage pattern:
+ <p>
+ <pre>
+ ...
+ conf.setJobName("chain");
+ conf.setInputFormat(TextInputFormat.class);
+ conf.setOutputFormat(TextOutputFormat.class);
+
+ JobConf mapAConf = new JobConf(false);
+ ...
+ ChainMapper.addMapper(conf, AMap.class, LongWritable.class, Text.class,
+   Text.class, Text.class, true, mapAConf);
+
+ JobConf mapBConf = new JobConf(false);
+ ...
+ ChainMapper.addMapper(conf, BMap.class, Text.class, Text.class,
+   LongWritable.class, Text.class, false, mapBConf);
+
+ JobConf reduceConf = new JobConf(false);
+ ...
+ ChainReducer.setReducer(conf, XReduce.class, LongWritable.class, Text.class,
+   Text.class, Text.class, true, reduceConf);
+
+ ChainReducer.addMapper(conf, CMap.class, Text.class, Text.class,
+   LongWritable.class, Text.class, false, null);
+
+ ChainReducer.addMapper(conf, DMap.class, LongWritable.class, Text.class,
+   LongWritable.class, LongWritable.class, true, null);
+
+ FileInputFormat.setInputPaths(conf, inDir);
+ FileOutputFormat.setOutputPath(conf, outDir);
+ ...
+
+ JobClient jc = new JobClient(conf);
+ RunningJob job = jc.submitJob(conf);
+ ...
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.ChainReducer -->
+  <!-- start class org.apache.hadoop.mapred.lib.CombineFileInputFormat -->
+  <class name="CombineFileInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputFormat"/>
+    <constructor name="CombineFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[default constructor]]>
+      </doc>
+    </constructor>
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="numSplits" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createPool"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="Use {@link #createPool(List)}.">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="filters" type="java.util.List"/>
+      <doc>
+      <![CDATA[Create a new pool and add the filters to it.
+ A split cannot have files from different pools.
+ @deprecated Use {@link #createPool(List)}.]]>
+      </doc>
+    </method>
+    <method name="createPool"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="Use {@link #createPool(PathFilter...)}.">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="filters" type="org.apache.hadoop.fs.PathFilter[]"/>
+      <doc>
+      <![CDATA[Create a new pool and add the filters to it. 
+ A pathname can satisfy any one of the specified filters.
+ A split cannot have files from different pools.
+ @deprecated Use {@link #createPool(PathFilter...)}.]]>
+      </doc>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This is not implemented yet.]]>
+      </doc>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="listStatus" return="org.apache.hadoop.fs.FileStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[List input directories.
+ Subclasses may override to, e.g., select only files matching a regular
+ expression. 
+ 
+ @param job the job to list input paths for
+ @return array of FileStatus objects
+ @throws IOException if zero items.]]>
+      </doc>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <doc>
+    <![CDATA[An abstract {@link org.apache.hadoop.mapred.InputFormat} that returns {@link CombineFileSplit}'s
+ in {@link org.apache.hadoop.mapred.InputFormat#getSplits(JobConf, int)} method. 
+ Splits are constructed from the files under the input paths. 
+ A split cannot have files from different pools.
+ Each split returned may contain blocks from different files.
+ If a maxSplitSize is specified, then blocks on the same node are
+ combined to form a single split. Blocks that are left over are
+ then combined with other blocks in the same rack. 
+ If maxSplitSize is not specified, then blocks from the same rack
+ are combined in a single split; no attempt is made to create
+ node-local splits.
+ If the maxSplitSize is equal to the block size, then this class
+ is similar to the default spliting behaviour in Hadoop: each
+ block is a locally processed split.
+ Subclasses implement {@link org.apache.hadoop.mapred.InputFormat#getRecordReader(InputSplit, JobConf, Reporter)}
+ to construct <code>RecordReader</code>'s for <code>CombineFileSplit</code>'s.
+ @see CombineFileSplit]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.CombineFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.CombineFileRecordReader -->
+  <class name="CombineFileRecordReader" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.RecordReader"/>
+    <constructor name="CombineFileRecordReader" type="org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.lib.CombineFileSplit, org.apache.hadoop.mapred.Reporter, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[A generic RecordReader that can hand out different recordReaders
+ for each chunk in the CombineFileSplit.]]>
+      </doc>
+    </constructor>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[return the amount of data processed]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[return progress based on the amount of data processed so far.]]>
+      </doc>
+    </method>
+    <method name="initNextRecordReader" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the record reader for the next chunk in this CombineFileSplit.]]>
+      </doc>
+    </method>
+    <field name="split" type="org.apache.hadoop.mapred.lib.CombineFileSplit"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="jc" type="org.apache.hadoop.mapred.JobConf"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="reporter" type="org.apache.hadoop.mapred.Reporter"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="rrConstructor" type="java.lang.reflect.Constructor"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="idx" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="progress" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="curReader" type="org.apache.hadoop.mapred.RecordReader"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A generic RecordReader that can hand out different recordReaders
+ for each chunk in a {@link CombineFileSplit}.
+ A CombineFileSplit can combine data chunks from multiple files. 
+ This class allows using different RecordReaders for processing
+ these data chunks from different files.
+ @see CombineFileSplit]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.CombineFileRecordReader -->
+  <!-- start class org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper -->
+  <class name="CombineFileRecordReaderWrapper" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.RecordReader"/>
+    <constructor name="CombineFileRecordReaderWrapper" type="org.apache.hadoop.mapred.FileInputFormat, org.apache.hadoop.mapred.lib.CombineFileSplit, org.apache.hadoop.conf.Configuration, org.apache.hadoop.mapred.Reporter, java.lang.Integer"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A wrapper class for a record reader that handles a single file split. It
+ delegates most of the methods to the wrapped instance. A concrete subclass
+ needs to provide a constructor that calls this parent constructor with the
+ appropriate input format. The subclass constructor must satisfy the specific
+ constructor signature that is required by
+ <code>CombineFileRecordReader</code>.
+
+ Subclassing is needed to get a concrete record reader wrapper because of the
+ constructor requirement.
+
+ @see CombineFileRecordReader
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.CombineFileSplit -->
+  <class name="CombineFileSplit" extends="org.apache.hadoop.mapreduce.lib.input.CombineFileSplit"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputSplit"/>
+    <constructor name="CombineFileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CombineFileSplit" type="org.apache.hadoop.mapred.JobConf, org.apache.hadoop.fs.Path[], long[], long[], java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CombineFileSplit" type="org.apache.hadoop.mapred.JobConf, org.apache.hadoop.fs.Path[], long[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CombineFileSplit" type="org.apache.hadoop.mapred.lib.CombineFileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Copy constructor]]>
+      </doc>
+    </constructor>
+    <method name="getJob" return="org.apache.hadoop.mapred.JobConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.CombineFileSplit -->
+  <!-- start class org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat -->
+  <class name="CombineSequenceFileInputFormat" extends="org.apache.hadoop.mapred.lib.CombineFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineSequenceFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Input format that is a <code>CombineFileInputFormat</code>-equivalent for
+ <code>SequenceFileInputFormat</code>.
+
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.CombineSequenceFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.CombineTextInputFormat -->
+  <class name="CombineTextInputFormat" extends="org.apache.hadoop.mapred.lib.CombineFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineTextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Input format that is a <code>CombineFileInputFormat</code>-equivalent for
+ <code>TextInputFormat</code>.
+
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.CombineTextInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.FieldSelectionMapReduce -->
+  <class name="FieldSelectionMapReduce" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <implements name="org.apache.hadoop.mapred.Reducer"/>
+    <constructor name="FieldSelectionMapReduce"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="val" type="V"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[The identify function. Input key/value pair is written directly to output.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements a mapper/reducer class that can be used to perform
+ field selections in a manner similar to unix cut. The input data is treated
+ as fields separated by a user specified separator (the default value is
+ "\t"). The user can specify a list of fields that form the map output keys,
+ and a list of fields that form the map output values. If the inputformat is
+ TextInputFormat, the mapper will ignore the key to the map function. and the
+ fields are from the value only. Otherwise, the fields are the union of those
+ from the key and those from the value.
+ 
+ The field separator is under attribute "mapreduce.fieldsel.data.field.separator"
+ 
+ The map output field list spec is under attribute 
+ "mapreduce.fieldsel.map.output.key.value.fields.spec".
+ The value is expected to be like "keyFieldsSpec:valueFieldsSpec"
+ key/valueFieldsSpec are comma (,) separated field spec: fieldSpec,fieldSpec,fieldSpec ...
+ Each field spec can be a simple number (e.g. 5) specifying a specific field, or a range
+ (like 2-5) to specify a range of fields, or an open range (like 3-) specifying all 
+ the fields starting from field 3. The open range field spec applies value fields only.
+ They have no effect on the key fields.
+ 
+ Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields 4,3,0 and 1 for keys,
+ and use fields 6,5,1,2,3,7 and above for values.
+ 
+ The reduce output field list spec is under attribute 
+ "mapreduce.fieldsel.reduce.output.key.value.fields.spec".
+ 
+ The reducer extracts output key/value pairs in a similar manner, except that
+ the key is never ignored.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.FieldSelectionMapReduce -->
+  <!-- start class org.apache.hadoop.mapred.lib.FilterOutputFormat -->
+  <class name="FilterOutputFormat" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.OutputFormat"/>
+    <constructor name="FilterOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FilterOutputFormat" type="org.apache.hadoop.mapred.OutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a FilterOutputFormat based on the supplied output format.
+ @param out the underlying OutputFormat]]>
+      </doc>
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="baseOut" type="org.apache.hadoop.mapred.OutputFormat"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[FilterOutputFormat is a convenience class that wraps OutputFormat.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.FilterOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.HashPartitioner -->
+  <class name="HashPartitioner" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Partitioner"/>
+    <constructor name="HashPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K2"/>
+      <param name="value" type="V2"/>
+      <param name="numReduceTasks" type="int"/>
+      <doc>
+      <![CDATA[Use {@link Object#hashCode()} to partition.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Partition keys by their {@link Object#hashCode()}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.HashPartitioner -->
+  <!-- start class org.apache.hadoop.mapred.lib.IdentityMapper -->
+  <class name="IdentityMapper" extends="org.apache.hadoop.mapred.MapReduceBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <constructor name="IdentityMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="val" type="V"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[The identity function.  Input key/value pair is written directly to
+ output.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Implements the identity function, mapping inputs directly to outputs.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.IdentityMapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.IdentityReducer -->
+  <class name="IdentityReducer" extends="org.apache.hadoop.mapred.MapReduceBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Reducer"/>
+    <constructor name="IdentityReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Writes all keys and values directly to output.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Performs no reduction, writing all input values directly to the output.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.IdentityReducer -->
+  <!-- start class org.apache.hadoop.mapred.lib.InputSampler -->
+  <class name="InputSampler" extends="org.apache.hadoop.mapreduce.lib.partition.InputSampler"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InputSampler" type="org.apache.hadoop.mapred.JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="writePartitionFile"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="sampler" type="org.apache.hadoop.mapred.lib.InputSampler.Sampler"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.InputSampler -->
+  <!-- start class org.apache.hadoop.mapred.lib.InverseMapper -->
+  <class name="InverseMapper" extends="org.apache.hadoop.mapred.MapReduceBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <constructor name="InverseMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[The inverse function.  Input keys and values are swapped.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A {@link Mapper} that swaps keys and values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.InverseMapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.KeyFieldBasedComparator -->
+  <class name="KeyFieldBasedComparator" extends="org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="KeyFieldBasedComparator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <doc>
+    <![CDATA[This comparator implementation provides a subset of the features provided
+ by the Unix/GNU Sort. In particular, the supported features are:
+ -n, (Sort numerically)
+ -r, (Reverse the result of comparison)
+ -k pos1[,pos2], where pos is of the form f[.c][opts], where f is the number
+  of the field to use, and c is the number of the first character from the
+  beginning of the field. Fields and character posns are numbered starting
+  with 1; a character position of zero in pos2 indicates the field's last
+  character. If '.c' is omitted from pos1, it defaults to 1 (the beginning
+  of the field); if omitted from pos2, it defaults to 0 (the end of the
+  field). opts are ordering options (any of 'nr' as described above). 
+ We assume that the fields in the key are separated by
+ {@link JobContext#MAP_OUTPUT_KEY_FIELD_SEPARATOR}]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.KeyFieldBasedComparator -->
+  <!-- start class org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner -->
+  <class name="KeyFieldBasedPartitioner" extends="org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Partitioner"/>
+    <constructor name="KeyFieldBasedPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <doc>
+    <![CDATA[Defines a way to partition keys based on certain key fields (also see
+  {@link KeyFieldBasedComparator}.
+  The key specification supported is of the form -k pos1[,pos2], where,
+  pos is of the form f[.c][opts], where f is the number
+  of the key field to use, and c is the number of the first character from
+  the beginning of the field. Fields and character posns are numbered 
+  starting with 1; a character position of zero in pos2 indicates the
+  field's last character. If '.c' is omitted from pos1, it defaults to 1
+  (the beginning of the field); if omitted from pos2, it defaults to 0 
+  (the end of the field).]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner -->
+  <!-- start class org.apache.hadoop.mapred.lib.LazyOutputFormat -->
+  <class name="LazyOutputFormat" extends="org.apache.hadoop.mapred.lib.FilterOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LazyOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setOutputFormatClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the underlying output format for LazyOutputFormat.
+ @param job the {@link JobConf} to modify
+ @param theClass the underlying class]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A Convenience class that creates output lazily.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.LazyOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.LongSumReducer -->
+  <class name="LongSumReducer" extends="org.apache.hadoop.mapred.MapReduceBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Reducer"/>
+    <constructor name="LongSumReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A {@link Reducer} that sums long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.LongSumReducer -->
+  <!-- start class org.apache.hadoop.mapred.lib.MultipleInputs -->
+  <class name="MultipleInputs" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleInputs"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addInputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="inputFormatClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Add a {@link Path} with a custom {@link InputFormat} to the list of
+ inputs for the map-reduce job.
+ 
+ @param conf The configuration of the job
+ @param path {@link Path} to be added to the list of inputs for the job
+ @param inputFormatClass {@link InputFormat} class to use for this path]]>
+      </doc>
+    </method>
+    <method name="addInputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="inputFormatClass" type="java.lang.Class"/>
+      <param name="mapperClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Add a {@link Path} with a custom {@link InputFormat} and
+ {@link Mapper} to the list of inputs for the map-reduce job.
+ 
+ @param conf The configuration of the job
+ @param path {@link Path} to be added to the list of inputs for the job
+ @param inputFormatClass {@link InputFormat} class to use for this path
+ @param mapperClass {@link Mapper} class to use for this path]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class supports MapReduce jobs that have multiple input paths with
+ a different {@link InputFormat} and {@link Mapper} for each path]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.MultipleInputs -->
+  <!-- start class org.apache.hadoop.mapred.lib.MultipleOutputFormat -->
+  <class name="MultipleOutputFormat" extends="org.apache.hadoop.mapred.FileOutputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="arg3" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a composite record writer that can write key/value data to different
+ output files
+ 
+ @param fs
+          the file system to use
+ @param job
+          the job conf for the job
+ @param name
+          the leaf file name for the output file (such as part-00000")
+ @param arg3
+          a progressable for reporting progress.
+ @return a composite record writer
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="generateLeafFileName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate the leaf name for the output file name. The default behavior does
+ not change the leaf file name (such as part-00000)
+ 
+ @param name
+          the leaf file name for the output file
+ @return the given leaf file name]]>
+      </doc>
+    </method>
+    <method name="generateFileNameForKeyValue" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate the file output file name based on the given key and the leaf file
+ name. The default behavior is that the file name does not depend on the
+ key.
+ 
+ @param key
+          the key of the output data
+ @param name
+          the leaf file name
+ @return generated file name]]>
+      </doc>
+    </method>
+    <method name="generateActualKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <doc>
+      <![CDATA[Generate the actual key from the given key/value. The default behavior is that
+ the actual key is equal to the given key
+ 
+ @param key
+          the key of the output data
+ @param value
+          the value of the output data
+ @return the actual key derived from the given key/value]]>
+      </doc>
+    </method>
+    <method name="generateActualValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <doc>
+      <![CDATA[Generate the actual value from the given key and value. The default behavior is that
+ the actual value is equal to the given value
+ 
+ @param key
+          the key of the output data
+ @param value
+          the value of the output data
+ @return the actual value derived from the given key/value]]>
+      </doc>
+    </method>
+    <method name="getInputFileBasedOutputFileName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate the outfile name based on a given name and the input file name. If
+ the {@link JobContext#MAP_INPUT_FILE} does not exists (i.e. this is not for a map only job),
+ the given name is returned unchanged. If the config value for
+ "num.of.trailing.legs.to.use" is not set, or set 0 or negative, the given
+ name is returned unchanged. Otherwise, return a file name consisting of the
+ N trailing legs of the input file name where N is the config value for
+ "num.of.trailing.legs.to.use".
+ 
+ @param job
+          the job config
+ @param name
+          the output file name
+ @return the outfile name based on a given name and the input file name.]]>
+      </doc>
+    </method>
+    <method name="getBaseRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="arg3" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@param fs
+          the file system to use
+ @param job
+          a job conf object
+ @param name
+          the name of the file over which a record writer object will be
+          constructed
+ @param arg3
+          a progressable object
+ @return A RecordWriter object over the given file
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This abstract class extends the FileOutputFormat, allowing to write the
+ output data to different output files. There are three basic use cases for
+ this class.
+ 
+ Case one: This class is used for a map reduce job with at least one reducer.
+ The reducer wants to write data to different files depending on the actual
+ keys. It is assumed that a key (or value) encodes the actual key (value)
+ and the desired location for the actual key (value).
+ 
+ Case two: This class is used for a map only job. The job wants to use an
+ output file name that is either a part of the input file name of the input
+ data, or some derivation of it.
+ 
+ Case three: This class is used for a map only job. The job wants to use an
+ output file name that depends on both the keys and the input file name,]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.MultipleOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.MultipleOutputs -->
+  <class name="MultipleOutputs" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleOutputs" type="org.apache.hadoop.mapred.JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Creates and initializes multiple named outputs support, it should be
+ instantiated in the Mapper/Reducer configure method.
+
+ @param job the job configuration object]]>
+      </doc>
+    </constructor>
+    <method name="getNamedOutputsList" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Returns list of channel names.
+
+ @param conf job conf
+ @return List of channel Names]]>
+      </doc>
+    </method>
+    <method name="isMultiNamedOutput" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns if a named output is multiple.
+
+ @param conf        job conf
+ @param namedOutput named output
+ @return <code>true</code> if the name output is multi, <code>false</code>
+         if it is single. If the name output is not defined it returns
+         <code>false</code>]]>
+      </doc>
+    </method>
+    <method name="getNamedOutputFormatClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns the named output OutputFormat.
+
+ @param conf        job conf
+ @param namedOutput named output
+ @return namedOutput OutputFormat]]>
+      </doc>
+    </method>
+    <method name="getNamedOutputKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns the key class for a named output.
+
+ @param conf        job conf
+ @param namedOutput named output
+ @return class for the named output key]]>
+      </doc>
+    </method>
+    <method name="getNamedOutputValueClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns the value class for a named output.
+
+ @param conf        job conf
+ @param namedOutput named output
+ @return class of named output value]]>
+      </doc>
+    </method>
+    <method name="addNamedOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="outputFormatClass" type="java.lang.Class"/>
+      <param name="keyClass" type="java.lang.Class"/>
+      <param name="valueClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Adds a named output for the job.
+
+ @param conf              job conf to add the named output
+ @param namedOutput       named output name, it has to be a word, letters
+                          and numbers only, cannot be the word 'part' as
+                          that is reserved for the
+                          default output.
+ @param outputFormatClass OutputFormat class.
+ @param keyClass          key class
+ @param valueClass        value class]]>
+      </doc>
+    </method>
+    <method name="addMultiNamedOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="outputFormatClass" type="java.lang.Class"/>
+      <param name="keyClass" type="java.lang.Class"/>
+      <param name="valueClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Adds a multi named output for the job.
+
+ @param conf              job conf to add the named output
+ @param namedOutput       named output name, it has to be a word, letters
+                          and numbers only, cannot be the word 'part' as
+                          that is reserved for the
+                          default output.
+ @param outputFormatClass OutputFormat class.
+ @param keyClass          key class
+ @param valueClass        value class]]>
+      </doc>
+    </method>
+    <method name="setCountersEnabled"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="enabled" type="boolean"/>
+      <doc>
+      <![CDATA[Enables or disables counters for the named outputs.
+ <p>
+ By default these counters are disabled.
+ <p>
+ MultipleOutputs supports counters, by default the are disabled.
+ The counters group is the {@link MultipleOutputs} class name.
+ </p>
+ The names of the counters are the same as the named outputs. For multi
+ named outputs the name of the counter is the concatenation of the named
+ output, and underscore '_' and the multiname.
+
+ @param conf    job conf to enableadd the named output.
+ @param enabled indicates if the counters will be enabled or not.]]>
+      </doc>
+    </method>
+    <method name="getCountersEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Returns if the counters for the named outputs are enabled or not.
+ <p>
+ By default these counters are disabled.
+ <p>
+ MultipleOutputs supports counters, by default the are disabled.
+ The counters group is the {@link MultipleOutputs} class name.
+ </p>
+ The names of the counters are the same as the named outputs. For multi
+ named outputs the name of the counter is the concatenation of the named
+ output, and underscore '_' and the multiname.
+
+
+ @param conf    job conf to enableadd the named output.
+ @return TRUE if the counters are enabled, FALSE if they are disabled.]]>
+      </doc>
+    </method>
+    <method name="getNamedOutputs" return="java.util.Iterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns iterator with the defined name outputs.
+
+ @return iterator with the defined named outputs]]>
+      </doc>
+    </method>
+    <method name="getCollector" return="org.apache.hadoop.mapred.OutputCollector"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the output collector for a named output.
+
+ @param namedOutput the named output name
+ @param reporter    the reporter
+ @return the output collector for the given named output
+ @throws IOException thrown if output collector could not be created]]>
+      </doc>
+    </method>
+    <method name="getCollector" return="org.apache.hadoop.mapred.OutputCollector"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="multiName" type="java.lang.String"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the output collector for a multi named output.
+
+ @param namedOutput the named output name
+ @param multiName   the multi name part
+ @param reporter    the reporter
+ @return the output collector for the given named output
+ @throws IOException thrown if output collector could not be created]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Closes all the opened named outputs.
+ <p>
+ If overriden subclasses must invoke <code>super.close()</code> at the
+ end of their <code>close()</code>
+
+ @throws java.io.IOException thrown if any of the MultipleOutput files
+                             could not be closed properly.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The MultipleOutputs class simplifies writing to additional outputs other
+ than the job default output via the <code>OutputCollector</code> passed to
+ the <code>map()</code> and <code>reduce()</code> methods of the
+ <code>Mapper</code> and <code>Reducer</code> implementations.
+ <p>
+ Each additional output, or named output, may be configured with its own
+ <code>OutputFormat</code>, with its own key class and with its own value
+ class.
+ <p>
+ A named output can be a single file or a multi file. The later is referred as
+ a multi named output.
+ <p>
+ A multi named output is an unbound set of files all sharing the same
+ <code>OutputFormat</code>, key class and value class configuration.
+ <p>
+ When named outputs are used within a <code>Mapper</code> implementation,
+ key/values written to a name output are not part of the reduce phase, only
+ key/values written to the job <code>OutputCollector</code> are part of the
+ reduce phase.
+ <p>
+ MultipleOutputs supports counters, by default the are disabled. The counters
+ group is the {@link MultipleOutputs} class name.
+ </p>
+ The names of the counters are the same as the named outputs. For multi
+ named outputs the name of the counter is the concatenation of the named
+ output, and underscore '_' and the multiname.
+ <p>
+ Job configuration usage pattern is:
+ <pre>
+
+ JobConf conf = new JobConf();
+
+ conf.setInputPath(inDir);
+ FileOutputFormat.setOutputPath(conf, outDir);
+
+ conf.setMapperClass(MOMap.class);
+ conf.setReducerClass(MOReduce.class);
+ ...
+
+ // Defines additional single text based output 'text' for the job
+ MultipleOutputs.addNamedOutput(conf, "text", TextOutputFormat.class,
+ LongWritable.class, Text.class);
+
+ // Defines additional multi sequencefile based output 'sequence' for the
+ // job
+ MultipleOutputs.addMultiNamedOutput(conf, "seq",
+   SequenceFileOutputFormat.class,
+   LongWritable.class, Text.class);
+ ...
+
+ JobClient jc = new JobClient();
+ RunningJob job = jc.submitJob(conf);
+
+ ...
+ </pre>
+ <p>
+ Job configuration usage pattern is:
+ <pre>
+
+ public class MOReduce implements
+   Reducer&lt;WritableComparable, Writable&gt; {
+ private MultipleOutputs mos;
+
+ public void configure(JobConf conf) {
+ ...
+ mos = new MultipleOutputs(conf);
+ }
+
+ public void reduce(WritableComparable key, Iterator&lt;Writable&gt; values,
+ OutputCollector output, Reporter reporter)
+ throws IOException {
+ ...
+ mos.getCollector("text", reporter).collect(key, new Text("Hello"));
+ mos.getCollector("seq", "A", reporter).collect(key, new Text("Bye"));
+ mos.getCollector("seq", "B", reporter).collect(key, new Text("Chau"));
+ ...
+ }
+
+ public void close() throws IOException {
+ mos.close();
+ ...
+ }
+
+ }
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.MultipleOutputs -->
+  <!-- start class org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat -->
+  <class name="MultipleSequenceFileOutputFormat" extends="org.apache.hadoop.mapred.lib.MultipleOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleSequenceFileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getBaseRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="arg3" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class extends the MultipleOutputFormat, allowing to write the output data 
+ to different output files in sequence file output format.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.MultipleTextOutputFormat -->
+  <class name="MultipleTextOutputFormat" extends="org.apache.hadoop.mapred.lib.MultipleOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleTextOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getBaseRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="arg3" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class extends the MultipleOutputFormat, allowing to write the output
+ data to different output files in Text output format.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.MultipleTextOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.MultithreadedMapRunner -->
+  <class name="MultithreadedMapRunner" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.MapRunnable"/>
+    <constructor name="MultithreadedMapRunner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobConf" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="input" type="org.apache.hadoop.mapred.RecordReader"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Multithreaded implementation for {@link MapRunnable}.
+ <p>
+ It can be used instead of the default implementation,
+ of {@link org.apache.hadoop.mapred.MapRunner}, when the Map
+ operation is not CPU bound in order to improve throughput.
+ <p>
+ Map implementations using this MapRunnable must be thread-safe.
+ <p>
+ The Map-Reduce job has to be configured to use this MapRunnable class (using
+ the JobConf.setMapRunnerClass method) and
+ the number of threads the thread-pool can use with the
+ <code>mapred.map.multithreadedrunner.threads</code> property, its default
+ value is 10 threads.
+ <p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.MultithreadedMapRunner -->
+  <!-- start class org.apache.hadoop.mapred.lib.NLineInputFormat -->
+  <class name="NLineInputFormat" extends="org.apache.hadoop.mapred.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="NLineInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="numSplits" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Logically splits the set of input files for the job, splits N lines
+ of the input as one split.
+ 
+ @see org.apache.hadoop.mapred.FileInputFormat#getSplits(JobConf, int)]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="createFileSplit" return="org.apache.hadoop.mapred.FileSplit"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fileName" type="org.apache.hadoop.fs.Path"/>
+      <param name="begin" type="long"/>
+      <param name="length" type="long"/>
+      <doc>
+      <![CDATA[NLineInputFormat uses LineRecordReader, which always reads
+ (and consumes) at least one character out of its upper split
+ boundary. So to make sure that each mapper gets N lines, we
+ move back the upper split limits of each split 
+ by one character here.
+ @param fileName  Path of file
+ @param begin  the position of the first byte in the file to process
+ @param length  number of bytes in InputSplit
+ @return  FileSplit]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[NLineInputFormat which splits N lines of input as one split.
+
+ In many "pleasantly" parallel applications, each process/mapper 
+ processes the same input file (s), but with computations are 
+ controlled by different parameters.(Referred to as "parameter sweeps").
+ One way to achieve this, is to specify a set of parameters 
+ (one set per line) as input in a control file 
+ (which is the input path to the map-reduce application,
+ where as the input dataset is specified 
+ via a config variable in JobConf.).
+ 
+ The NLineInputFormat can be used in such applications, that splits 
+ the input file such that by default, one line is fed as
+ a value to one map task, and key is the offset.
+ i.e. (k,v) is (LongWritable, Text).
+ The location hints will span the whole mapred cluster.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.NLineInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.NullOutputFormat -->
+  <class name="NullOutputFormat" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.OutputFormat"/>
+    <constructor name="NullOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ignored" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <doc>
+    <![CDATA[Consume all outputs and put them in /dev/null.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.NullOutputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.RegexMapper -->
+  <class name="RegexMapper" extends="org.apache.hadoop.mapred.MapReduceBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <constructor name="RegexMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A {@link Mapper} that extracts text matching a regular expression.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.RegexMapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.TokenCountMapper -->
+  <class name="TokenCountMapper" extends="org.apache.hadoop.mapred.MapReduceBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <constructor name="TokenCountMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A {@link Mapper} that maps text values into &lt;token,freq&gt; pairs.  Uses
+ {@link StringTokenizer} to break text into tokens.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.TokenCountMapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.TotalOrderPartitioner -->
+  <class name="TotalOrderPartitioner" extends="org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Partitioner"/>
+    <constructor name="TotalOrderPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="setPartitionFile"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use 
+ {@link #setPartitionFile(Configuration, Path)}
+ instead">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="p" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the path to the SequenceFile storing the sorted partition keyset.
+ It must be the case that for <tt>R</tt> reduces, there are <tt>R-1</tt>
+ keys in the SequenceFile.
+ @deprecated Use 
+ {@link #setPartitionFile(Configuration, Path)}
+ instead]]>
+      </doc>
+    </method>
+    <method name="getPartitionFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use 
+ {@link #getPartitionFile(Configuration)}
+ instead">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the path to the SequenceFile storing the sorted partition keyset.
+ @see #setPartitionFile(JobConf,Path)
+ @deprecated Use 
+ {@link #getPartitionFile(Configuration)}
+ instead]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Partitioner effecting a total order by reading split points from
+ an externally generated source.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.TotalOrderPartitioner -->
+</package>
+<package name="org.apache.hadoop.mapred.lib.aggregate">
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum -->
+  <class name="DoubleValueSum" extends="org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="DoubleValueSum"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that sums up a sequence of double
+ values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.DoubleValueSum -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.LongValueMax -->
+  <class name="LongValueMax" extends="org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="LongValueMax"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the maximum of 
+ a sequence of long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.LongValueMax -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.LongValueMin -->
+  <class name="LongValueMin" extends="org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="LongValueMin"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the minimum of 
+ a sequence of long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.LongValueMin -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.LongValueSum -->
+  <class name="LongValueSum" extends="org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="LongValueSum"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that sums up 
+ a sequence of long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.LongValueSum -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.StringValueMax -->
+  <class name="StringValueMax" extends="org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="StringValueMax"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the biggest of 
+ a sequence of strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.StringValueMax -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.StringValueMin -->
+  <class name="StringValueMin" extends="org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="StringValueMin"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the smallest of 
+ a sequence of strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.StringValueMin -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.UniqValueCount -->
+  <class name="UniqValueCount" extends="org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="UniqValueCount"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <constructor name="UniqValueCount" type="long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[constructor
+ @param maxNum the limit in the number of unique values to keep.]]>
+      </doc>
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that dedupes a sequence of objects.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.UniqValueCount -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor -->
+  <class name="UserDefinedValueAggregatorDescriptor" extends="org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor"/>
+    <constructor name="UserDefinedValueAggregatorDescriptor" type="java.lang.String, org.apache.hadoop.mapred.JobConf"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@param className the class name of the user defined descriptor class
+ @param job a configure object used for decriptor configuration]]>
+      </doc>
+    </constructor>
+    <method name="createInstance" return="java.lang.Object"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="className" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Create an instance of the given class
+ @param className the name of the class
+ @return a dynamically created instance of the given class]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Do nothing.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a wrapper for a user defined value aggregator 
+ descriptor.
+ It serves two functions: One is to create an object of 
+ ValueAggregatorDescriptor from the name of a user defined class that may be 
+ dynamically loaded. The other is to delegate invocations of 
+ generateKeyValPairs function to the created object.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor -->
+  <!-- start interface org.apache.hadoop.mapred.lib.aggregate.ValueAggregator -->
+  <interface name="ValueAggregator"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <doc>
+    <![CDATA[This interface defines the minimal protocol for value aggregators.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.lib.aggregate.ValueAggregator -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor -->
+  <class name="ValueAggregatorBaseDescriptor" extends="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor"/>
+    <constructor name="ValueAggregatorBaseDescriptor"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="generateEntry" return="java.util.Map.Entry"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="id" type="java.lang.String"/>
+      <param name="val" type="org.apache.hadoop.io.Text"/>
+      <doc>
+      <![CDATA[@param type the aggregation type
+ @param id the aggregation id
+ @param val the val associated with the id to be aggregated
+ @return an Entry whose key is the aggregation id prefixed with 
+ the aggregation type.]]>
+      </doc>
+    </method>
+    <method name="generateValueAggregator" return="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <doc>
+      <![CDATA[@param type the aggregation type
+ @return a value aggregator of the given type.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[get the input file name.
+ 
+ @param job a job configuration object]]>
+      </doc>
+    </method>
+    <field name="UNIQ_VALUE_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LONG_VALUE_SUM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DOUBLE_VALUE_SUM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="VALUE_HISTOGRAM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LONG_VALUE_MAX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LONG_VALUE_MIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="STRING_VALUE_MAX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="STRING_VALUE_MIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements the common functionalities of 
+ the subclasses of ValueAggregatorDescriptor class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorCombiner -->
+  <class name="ValueAggregatorCombiner" extends="org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorCombiner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Combiner does not need to configure.]]>
+      </doc>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Combines values for a given key.  
+ @param key the key is expected to be a Text object, whose prefix indicates
+ the type of aggregation to aggregate the values. 
+ @param values the values to combine
+ @param output to collect combined values]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Do nothing.]]>
+      </doc>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="arg0" type="K1"/>
+      <param name="arg1" type="V1"/>
+      <param name="arg2" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="arg3" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Do nothing. Should not be called.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements the generic combiner of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorCombiner -->
+  <!-- start interface org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor -->
+  <interface name="ValueAggregatorDescriptor"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor"/>
+    <method name="configure"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Configure the object
+ 
+ @param job
+          a JobConf object that may contain the information that can be used
+          to configure the object.]]>
+      </doc>
+    </method>
+    <field name="TYPE_SEPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ONE" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This interface defines the contract a value aggregator descriptor must
+ support. Such a descriptor can be configured with a JobConf object. Its main
+ function is to generate a list of aggregation-id/value pairs. An aggregation
+ id encodes an aggregation type which is used to guide the way to aggregate
+ the value in the reduce/combiner phrase of an Aggregate based job.The mapper in
+ an Aggregate based map/reduce job may create one or more of
+ ValueAggregatorDescriptor objects at configuration time. For each input
+ key/value pair, the mapper will use those objects to create aggregation
+ id/value pairs.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorDescriptor -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob -->
+  <class name="ValueAggregatorJob" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorJob"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createValueAggregatorJobs" return="org.apache.hadoop.mapred.jobcontrol.JobControl"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <param name="descriptors" type="java.lang.Class[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createValueAggregatorJobs" return="org.apache.hadoop.mapred.jobcontrol.JobControl"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createValueAggregatorJob" return="org.apache.hadoop.mapred.JobConf"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <param name="caller" type="java.lang.Class"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create an Aggregate based map/reduce job.
+
+ @param args the arguments used for job creation. Generic hadoop
+ arguments are accepted.
+ @param caller the the caller class.
+ @return a JobConf object ready for submission.
+
+ @throws IOException
+ @see GenericOptionsParser]]>
+      </doc>
+    </method>
+    <method name="createValueAggregatorJob" return="org.apache.hadoop.mapred.JobConf"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create an Aggregate based map/reduce job.
+ 
+ @param args the arguments used for job creation. Generic hadoop
+ arguments are accepted.
+ @return a JobConf object ready for submission.
+ 
+ @throws IOException
+ @see GenericOptionsParser]]>
+      </doc>
+    </method>
+    <method name="createValueAggregatorJob" return="org.apache.hadoop.mapred.JobConf"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <param name="descriptors" type="java.lang.Class[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setAggregatorDescriptors"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="descriptors" type="java.lang.Class[]"/>
+    </method>
+    <method name="createValueAggregatorJob" return="org.apache.hadoop.mapred.JobConf"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <param name="descriptors" type="java.lang.Class[]"/>
+      <param name="caller" type="java.lang.Class"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[create and run an Aggregate based map/reduce job.
+ 
+ @param args the arguments used for job creation
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This is the main class for creating a map/reduce job using Aggregate
+ framework. The Aggregate is a specialization of map/reduce framework,
+ specilizing for performing various simple aggregations.
+ 
+ Generally speaking, in order to implement an application using Map/Reduce
+ model, the developer is to implement Map and Reduce functions (and possibly
+ combine function). However, a lot of applications related to counting and
+ statistics computing have very similar characteristics. Aggregate abstracts
+ out the general patterns of these functions and implementing those patterns.
+ In particular, the package provides generic mapper/redducer/combiner classes,
+ and a set of built-in value aggregators, and a generic utility class that
+ helps user create map/reduce jobs using the generic class. The built-in
+ aggregators include:
+ 
+ sum over numeric values count the number of distinct values compute the
+ histogram of values compute the minimum, maximum, media,average, standard
+ deviation of numeric values
+ 
+ The developer using Aggregate will need only to provide a plugin class
+ conforming to the following interface:
+ 
+ public interface ValueAggregatorDescriptor { public ArrayList&lt;Entry&gt;
+ generateKeyValPairs(Object key, Object value); public void
+ configure(JobConfjob); }
+ 
+ The package also provides a base class, ValueAggregatorBaseDescriptor,
+ implementing the above interface. The user can extend the base class and
+ implement generateKeyValPairs accordingly.
+ 
+ The primary work of generateKeyValPairs is to emit one or more key/value
+ pairs based on the input key/value pair. The key in an output key/value pair
+ encode two pieces of information: aggregation type and aggregation id. The
+ value will be aggregated onto the aggregation id according the aggregation
+ type.
+ 
+ This class offers a function to generate a map/reduce job using Aggregate
+ framework. The function takes the following parameters: input directory spec
+ input format (text or sequence file) output directory a file specifying the
+ user plugin class]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase -->
+  <class name="ValueAggregatorJobBase" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.Mapper"/>
+    <implements name="org.apache.hadoop.mapred.Reducer"/>
+    <constructor name="ValueAggregatorJobBase"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+    </method>
+    <method name="logSpec"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="aggregatorDescriptorList" type="java.util.ArrayList"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This abstract class implements some common functionalities of the
+ the generic mapper, reducer and combiner classes of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorMapper -->
+  <class name="ValueAggregatorMapper" extends="org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K1"/>
+      <param name="value" type="V1"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[the map function. It iterates through the value aggregator descriptor 
+  list to generate aggregation id/value pairs and emit them.]]>
+      </doc>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="arg0" type="org.apache.hadoop.io.Text"/>
+      <param name="arg1" type="java.util.Iterator"/>
+      <param name="arg2" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="arg3" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Do nothing. Should not be called.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements the generic mapper of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorMapper -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorReducer -->
+  <class name="ValueAggregatorReducer" extends="org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="values" type="java.util.Iterator"/>
+      <param name="output" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@param key
+          the key is expected to be a Text object, whose prefix indicates
+          the type of aggregation to aggregate the values. In effect, data
+          driven computing is achieved. It is assumed that each aggregator's
+          getReport method emits appropriate output for the aggregator. This
+          may be further customiized.
+ @param values
+          the values to be aggregated]]>
+      </doc>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="arg0" type="K1"/>
+      <param name="arg1" type="V1"/>
+      <param name="arg2" type="org.apache.hadoop.mapred.OutputCollector"/>
+      <param name="arg3" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Do nothing. Should not be called]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements the generic reducer of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorReducer -->
+  <!-- start class org.apache.hadoop.mapred.lib.aggregate.ValueHistogram -->
+  <class name="ValueHistogram" extends="org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.lib.aggregate.ValueAggregator"/>
+    <constructor name="ValueHistogram"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This class implements a value aggregator that computes the 
+ histogram of a sequence of strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.aggregate.ValueHistogram -->
+</package>
+<package name="org.apache.hadoop.mapred.lib.db">
+  <!-- start class org.apache.hadoop.mapred.lib.db.DBConfiguration -->
+  <class name="DBConfiguration" extends="org.apache.hadoop.mapreduce.lib.db.DBConfiguration"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="configureDB"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="driverClass" type="java.lang.String"/>
+      <param name="dbUrl" type="java.lang.String"/>
+      <param name="userName" type="java.lang.String"/>
+      <param name="passwd" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets the DB access related fields in the JobConf.  
+ @param job the job
+ @param driverClass JDBC Driver class name
+ @param dbUrl JDBC DB access URL. 
+ @param userName DB access username 
+ @param passwd DB access passwd]]>
+      </doc>
+    </method>
+    <method name="configureDB"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="driverClass" type="java.lang.String"/>
+      <param name="dbUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets the DB access related fields in the JobConf.  
+ @param job the job
+ @param driverClass JDBC Driver class name
+ @param dbUrl JDBC DB access URL.]]>
+      </doc>
+    </method>
+    <field name="DRIVER_CLASS_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The JDBC Driver class name]]>
+      </doc>
+    </field>
+    <field name="URL_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[JDBC Database access URL]]>
+      </doc>
+    </field>
+    <field name="USERNAME_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[User name to access the database]]>
+      </doc>
+    </field>
+    <field name="PASSWORD_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Password to access the database]]>
+      </doc>
+    </field>
+    <field name="INPUT_TABLE_NAME_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Input table name]]>
+      </doc>
+    </field>
+    <field name="INPUT_FIELD_NAMES_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Field names in the Input table]]>
+      </doc>
+    </field>
+    <field name="INPUT_CONDITIONS_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[WHERE clause in the input SELECT statement]]>
+      </doc>
+    </field>
+    <field name="INPUT_ORDER_BY_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[ORDER BY clause in the input SELECT statement]]>
+      </doc>
+    </field>
+    <field name="INPUT_QUERY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whole input query, exluding LIMIT...OFFSET]]>
+      </doc>
+    </field>
+    <field name="INPUT_COUNT_QUERY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Input query to get the count of records]]>
+      </doc>
+    </field>
+    <field name="INPUT_CLASS_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Class name implementing DBWritable which will hold input tuples]]>
+      </doc>
+    </field>
+    <field name="OUTPUT_TABLE_NAME_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Output table name]]>
+      </doc>
+    </field>
+    <field name="OUTPUT_FIELD_NAMES_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Field names in the Output table]]>
+      </doc>
+    </field>
+    <field name="OUTPUT_FIELD_COUNT_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of fields in the Output table]]>
+      </doc>
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.db.DBConfiguration -->
+  <!-- start class org.apache.hadoop.mapred.lib.db.DBInputFormat -->
+  <class name="DBInputFormat" extends="org.apache.hadoop.mapreduce.lib.db.DBInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.InputFormat"/>
+    <implements name="org.apache.hadoop.mapred.JobConfigurable"/>
+    <constructor name="DBInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getRecordReader" return="org.apache.hadoop.mapred.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapred.InputSplit"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="reporter" type="org.apache.hadoop.mapred.Reporter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="org.apache.hadoop.mapred.InputSplit[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="chunks" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="setInput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="inputClass" type="java.lang.Class"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="conditions" type="java.lang.String"/>
+      <param name="orderBy" type="java.lang.String"/>
+      <param name="fieldNames" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Initializes the map-part of the job with the appropriate input settings.
+ 
+ @param job The job
+ @param inputClass the class object implementing DBWritable, which is the 
+ Java object holding tuple fields.
+ @param tableName The table to read data from
+ @param conditions The condition which to select data with, eg. '(updated &gt;
+ 20070101 AND length &gt; 0)'
+ @param orderBy the fieldNames in the orderBy clause.
+ @param fieldNames The field names in the table
+ @see #setInput(JobConf, Class, String, String)]]>
+      </doc>
+    </method>
+    <method name="setInput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="inputClass" type="java.lang.Class"/>
+      <param name="inputQuery" type="java.lang.String"/>
+      <param name="inputCountQuery" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Initializes the map-part of the job with the appropriate input settings.
+ 
+ @param job The job
+ @param inputClass the class object implementing DBWritable, which is the 
+ Java object holding tuple fields.
+ @param inputQuery the input query to select fields. Example : 
+ "SELECT f1, f2, f3 FROM Mytable ORDER BY f1"
+ @param inputCountQuery the input query that returns the number of records in
+ the table. 
+ Example : "SELECT COUNT(f1) FROM Mytable"
+ @see #setInput(JobConf, Class, String, String, String, String...)]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.db.DBInputFormat -->
+  <!-- start class org.apache.hadoop.mapred.lib.db.DBOutputFormat -->
+  <class name="DBOutputFormat" extends="org.apache.hadoop.mapreduce.lib.db.DBOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapred.OutputFormat"/>
+    <constructor name="DBOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="filesystem" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapred.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="filesystem" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="progress" type="org.apache.hadoop.util.Progressable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="setOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="fieldNames" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Initializes the reduce-part of the job with the appropriate output settings
+ 
+ @param job The job
+ @param tableName The table to insert data into
+ @param fieldNames The field names in the table.]]>
+      </doc>
+    </method>
+    <method name="setOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="fieldCount" type="int"/>
+      <doc>
+      <![CDATA[Initializes the reduce-part of the job with the appropriate output settings
+ 
+ @param job The job
+ @param tableName The table to insert data into
+ @param fieldCount the number of fields in the table.]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.lib.db.DBOutputFormat -->
+  <!-- start interface org.apache.hadoop.mapred.lib.db.DBWritable -->
+  <interface name="DBWritable"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.db.DBWritable"/>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapred.lib.db.DBWritable -->
+</package>
+<package name="org.apache.hadoop.mapred.pipes">
+  <!-- start class org.apache.hadoop.mapred.pipes.Submitter -->
+  <class name="Submitter" extends="org.apache.hadoop.conf.Configured"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.util.Tool"/>
+    <constructor name="Submitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="Submitter" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getExecutable" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Get the URI of the application's executable.
+ @param conf
+ @return the URI where the application's executable is located]]>
+      </doc>
+    </method>
+    <method name="setExecutable"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="executable" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the URI for the application's executable. Normally this is a hdfs: 
+ location.
+ @param conf
+ @param executable The URI of the application's executable.]]>
+      </doc>
+    </method>
+    <method name="setIsJavaRecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="value" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the job is using a Java RecordReader.
+ @param conf the configuration to modify
+ @param value the new value]]>
+      </doc>
+    </method>
+    <method name="getIsJavaRecordReader" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Check whether the job is using a Java RecordReader
+ @param conf the configuration to check
+ @return is it a Java RecordReader?]]>
+      </doc>
+    </method>
+    <method name="setIsJavaMapper"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="value" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the Mapper is written in Java.
+ @param conf the configuration to modify
+ @param value the new value]]>
+      </doc>
+    </method>
+    <method name="getIsJavaMapper" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Check whether the job is using a Java Mapper.
+ @param conf the configuration to check
+ @return is it a Java Mapper?]]>
+      </doc>
+    </method>
+    <method name="setIsJavaReducer"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="value" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the Reducer is written in Java.
+ @param conf the configuration to modify
+ @param value the new value]]>
+      </doc>
+    </method>
+    <method name="getIsJavaReducer" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Check whether the job is using a Java Reducer.
+ @param conf the configuration to check
+ @return is it a Java Reducer?]]>
+      </doc>
+    </method>
+    <method name="setIsJavaRecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="value" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the job will use a Java RecordWriter.
+ @param conf the configuration to modify
+ @param value the new value to set]]>
+      </doc>
+    </method>
+    <method name="getIsJavaRecordWriter" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Will the reduce use a Java RecordWriter?
+ @param conf the configuration to check
+ @return true, if the output of the job will be written by Java]]>
+      </doc>
+    </method>
+    <method name="getKeepCommandFile" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <doc>
+      <![CDATA[Does the user want to keep the command file for debugging? If this is
+ true, pipes will write a copy of the command data to a file in the
+ task directory named "downlink.data", which may be used to run the C++
+ program under the debugger. You probably also want to set 
+ JobConf.setKeepFailedTaskFiles(true) to keep the entire directory from
+ being deleted.
+ To run using the data file, set the environment variable 
+ "mapreduce.pipes.commandfile" to point to the file.
+ @param conf the configuration to check
+ @return will the framework save the command file?]]>
+      </doc>
+    </method>
+    <method name="setKeepCommandFile"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <param name="keep" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether to keep the command file for debugging
+ @param conf the configuration to modify
+ @param keep the new value]]>
+      </doc>
+    </method>
+    <method name="submitJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link Submitter#runJob(JobConf)}">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Submit a job to the map/reduce cluster. All of the necessary modifications
+ to the job to run under pipes are made to the configuration.
+ @param conf the job to submit to the cluster (MODIFIED)
+ @throws IOException
+ @deprecated Use {@link Submitter#runJob(JobConf)}]]>
+      </doc>
+    </method>
+    <method name="runJob" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Submit a job to the map/reduce cluster. All of the necessary modifications
+ to the job to run under pipes are made to the configuration.
+ @param conf the job to submit to the cluster (MODIFIED)
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="jobSubmit" return="org.apache.hadoop.mapred.RunningJob"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.mapred.JobConf"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Submit a job to the Map-Reduce framework.
+ This returns a handle to the {@link RunningJob} which can be used to track
+ the running-job.
+ 
+ @param conf the job configuration.
+ @return a handle to the {@link RunningJob} which can be used to track the
+         running-job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="run" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+      <doc>
+      <![CDATA[Submit a pipes job based on the command line arguments.
+ @param args]]>
+      </doc>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="PRESERVE_COMMANDFILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="EXECUTABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INTERPRETOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IS_JAVA_MAP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IS_JAVA_RR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IS_JAVA_RW" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IS_JAVA_REDUCE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PARTITIONER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INPUT_FORMAT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PORT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[The main entry point and job submitter. It may either be used as a command
+ line-based or API-based method to launch Pipes jobs.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapred.pipes.Submitter -->
+</package>
+<package name="org.apache.hadoop.mapreduce">
+  <!-- start class org.apache.hadoop.mapreduce.Cluster -->
+  <class name="Cluster" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Cluster" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <constructor name="Cluster" type="java.net.InetSocketAddress, org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close the <code>Cluster</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getFileSystem" return="org.apache.hadoop.fs.FileSystem"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the file system where job-specific files are stored
+ 
+ @return object of FileSystem
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getJob" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapreduce.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get job corresponding to jobid.
+ 
+ @param jobId
+ @return object of {@link Job}
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getQueues" return="org.apache.hadoop.mapreduce.QueueInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get all the queues in cluster.
+ 
+ @return array of {@link QueueInfo}
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="org.apache.hadoop.mapreduce.QueueInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get queue information for the specified name.
+ 
+ @param name queuename
+ @return object of {@link QueueInfo}
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getLogParams" return="org.apache.hadoop.mapreduce.v2.LogParams"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobID" type="org.apache.hadoop.mapreduce.JobID"/>
+      <param name="taskAttemptID" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get log parameters for the specified jobID or taskAttemptID
+ @param jobID the job id.
+ @param taskAttemptID the task attempt id. Optional.
+ @return the LogParams
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getClusterStatus" return="org.apache.hadoop.mapreduce.ClusterMetrics"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get current cluster status.
+ 
+ @return object of {@link ClusterMetrics}
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getActiveTaskTrackers" return="org.apache.hadoop.mapreduce.TaskTrackerInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get all active trackers in the cluster.
+ 
+ @return array of {@link TaskTrackerInfo}
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getBlackListedTaskTrackers" return="org.apache.hadoop.mapreduce.TaskTrackerInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get blacklisted trackers.
+ 
+ @return array of {@link TaskTrackerInfo}
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getAllJobs" return="org.apache.hadoop.mapreduce.Job[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #getAllJobStatuses()} instead.">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get all the jobs in cluster.
+ 
+ @return array of {@link Job}
+ @throws IOException
+ @throws InterruptedException
+ @deprecated Use {@link #getAllJobStatuses()} instead.]]>
+      </doc>
+    </method>
+    <method name="getAllJobStatuses" return="org.apache.hadoop.mapreduce.JobStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get job status for all jobs in the cluster.
+ @return job status for all jobs in cluster
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getSystemDir" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Grab the jobtracker system directory path where 
+ job-specific files will  be placed.
+ 
+ @return the system directory where job-specific files are to be placed.]]>
+      </doc>
+    </method>
+    <method name="getStagingAreaDir" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Grab the jobtracker's view of the staging directory path where 
+ job-specific files will  be placed.
+ 
+ @return the staging directory where job-specific files are to be placed.]]>
+      </doc>
+    </method>
+    <method name="getJobHistoryUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobId" type="org.apache.hadoop.mapreduce.JobID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the job history file path for a given job id. The job history file at 
+ this path may or may not be existing depending on the job completion state.
+ The file is present only for the completed jobs.
+ @param jobId the JobID of the job submitted by the current user.
+ @return the file path of the job history file
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getQueueAclsForCurrentUser" return="org.apache.hadoop.mapreduce.QueueAclsInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Gets the Queue ACLs for current user
+ @return array of QueueAclsInfo object for current user.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getRootQueues" return="org.apache.hadoop.mapreduce.QueueInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Gets the root level queues.
+ @return array of JobQueueInfo object.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getChildQueues" return="org.apache.hadoop.mapreduce.QueueInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Returns immediate children of queueName.
+ @param queueName
+ @return array of JobQueueInfo which are children of queueName
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getJobTrackerStatus" return="org.apache.hadoop.mapreduce.Cluster.JobTrackerStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the JobTracker's status.
+ 
+ @return {@link JobTrackerStatus} of the JobTracker
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getTaskTrackerExpiryInterval" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the tasktracker expiry interval for the cluster
+ @return the expiry interval in msec]]>
+      </doc>
+    </method>
+    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="org.apache.hadoop.io.Text"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get a delegation token for the user from the JobTracker.
+ @param renewer the user who can renew the token
+ @return the new token
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="renewDelegationToken" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link Token#renew} instead">
+      <param name="token" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Renew a delegation token
+ @param token the token to renew
+ @return the new expiration time
+ @throws InvalidToken
+ @throws IOException
+ @deprecated Use {@link Token#renew} instead]]>
+      </doc>
+    </method>
+    <method name="cancelDelegationToken"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link Token#cancel} instead">
+      <param name="token" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Cancel a delegation token from the JobTracker
+ @param token the token to cancel
+ @throws IOException
+ @deprecated Use {@link Token#cancel} instead]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Provides a way to access information about the map/reduce cluster.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.Cluster -->
+  <!-- start class org.apache.hadoop.mapreduce.ClusterMetrics -->
+  <class name="ClusterMetrics" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="ClusterMetrics"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ClusterMetrics" type="int, int, int, int, int, int, int, int, int, int, int, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ClusterMetrics" type="int, int, int, int, int, int, int, int, int, int, int, int, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRunningMaps" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of running map tasks in the cluster.
+ 
+ @return running maps]]>
+      </doc>
+    </method>
+    <method name="getRunningReduces" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of running reduce tasks in the cluster.
+ 
+ @return running reduces]]>
+      </doc>
+    </method>
+    <method name="getOccupiedMapSlots" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get number of occupied map slots in the cluster.
+ 
+ @return occupied map slot count]]>
+      </doc>
+    </method>
+    <method name="getOccupiedReduceSlots" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of occupied reduce slots in the cluster.
+ 
+ @return occupied reduce slot count]]>
+      </doc>
+    </method>
+    <method name="getReservedMapSlots" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get number of reserved map slots in the cluster.
+ 
+ @return reserved map slot count]]>
+      </doc>
+    </method>
+    <method name="getReservedReduceSlots" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of reserved reduce slots in the cluster.
+ 
+ @return reserved reduce slot count]]>
+      </doc>
+    </method>
+    <method name="getMapSlotCapacity" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the total number of map slots in the cluster.
+ 
+ @return map slot capacity]]>
+      </doc>
+    </method>
+    <method name="getReduceSlotCapacity" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the total number of reduce slots in the cluster.
+ 
+ @return reduce slot capacity]]>
+      </doc>
+    </method>
+    <method name="getTotalJobSubmissions" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the total number of job submissions in the cluster.
+ 
+ @return total number of job submissions]]>
+      </doc>
+    </method>
+    <method name="getTaskTrackerCount" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of active trackers in the cluster.
+ 
+ @return active tracker count.]]>
+      </doc>
+    </method>
+    <method name="getBlackListedTaskTrackerCount" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of blacklisted trackers in the cluster.
+ 
+ @return blacklisted tracker count]]>
+      </doc>
+    </method>
+    <method name="getGrayListedTaskTrackerCount" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of graylisted trackers in the cluster.
+ 
+ @return graylisted tracker count]]>
+      </doc>
+    </method>
+    <method name="getDecommissionedTaskTrackerCount" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of decommissioned trackers in the cluster.
+ 
+ @return decommissioned tracker count]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Status information on the current state of the Map-Reduce cluster.
+ 
+ <p><code>ClusterMetrics</code> provides clients with information such as:
+ <ol>
+   <li>
+   Size of the cluster.  
+   </li>
+   <li>
+   Number of blacklisted and decommissioned trackers.  
+   </li>
+   <li>
+   Slot capacity of the cluster. 
+   </li>
+   <li>
+   The number of currently occupied/reserved map and reduce slots.
+   </li>
+   <li>
+   The number of currently running map and reduce tasks.
+   </li>
+   <li>
+   The number of job submissions.
+   </li>
+ </ol>
+ 
+ <p>Clients can query for the latest <code>ClusterMetrics</code>, via 
+ {@link Cluster#getClusterStatus()}.</p>
+ 
+ @see Cluster]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.ClusterMetrics -->
+  <!-- start interface org.apache.hadoop.mapreduce.Counter -->
+  <interface name="Counter"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <method name="setDisplayName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="(and no-op by default)">
+      <param name="displayName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the display name of the counter
+ @param displayName of the counter
+ @deprecated (and no-op by default)]]>
+      </doc>
+    </method>
+    <method name="getName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the name of the counter]]>
+      </doc>
+    </method>
+    <method name="getDisplayName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the display name of the counter.
+ @return the user facing name of the counter]]>
+      </doc>
+    </method>
+    <method name="getValue" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[What is the current value of this counter?
+ @return the current value]]>
+      </doc>
+    </method>
+    <method name="setValue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="value" type="long"/>
+      <doc>
+      <![CDATA[Set this counter by the given value
+ @param value the value to set]]>
+      </doc>
+    </method>
+    <method name="increment"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="incr" type="long"/>
+      <doc>
+      <![CDATA[Increment this counter by the given value
+ @param incr the value to increase this counter by]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A named counter that tracks the progress of a map/reduce job.
+
+ <p><code>Counters</code> represent global counters, defined either by the
+ Map-Reduce framework or applications. Each <code>Counter</code> is named by
+ an {@link Enum} and has a long for the value.</p>
+
+ <p><code>Counters</code> are bunched into Groups, each comprising of
+ counters from a particular <code>Enum</code> class.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.Counter -->
+  <!-- start interface org.apache.hadoop.mapreduce.CounterGroup -->
+  <interface name="CounterGroup"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.counters.CounterGroupBase"/>
+    <doc>
+    <![CDATA[A group of {@link Counter}s that logically belong together. Typically,
+ it is an {@link Enum} subclass and the counters are the values.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.CounterGroup -->
+  <!-- start class org.apache.hadoop.mapreduce.Counters -->
+  <class name="Counters" extends="org.apache.hadoop.mapreduce.counters.AbstractCounters"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Counters"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor]]>
+      </doc>
+    </constructor>
+    <constructor name="Counters" type="org.apache.hadoop.mapreduce.counters.AbstractCounters"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct the Counters object from the another counters object
+ @param <C> the type of counter
+ @param <G> the type of counter group
+ @param counters the old counters object]]>
+      </doc>
+    </constructor>
+    <doc>
+    <![CDATA[<p><code>Counters</code> holds per job/task counters, defined either by the
+ Map-Reduce framework or applications. Each <code>Counter</code> can be of
+ any {@link Enum} type.</p>
+
+ <p><code>Counters</code> are bunched into {@link CounterGroup}s, each
+ comprising of counters from a particular <code>Enum</code> class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.Counters -->
+  <!-- start class org.apache.hadoop.mapreduce.ID -->
+  <class name="ID" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.WritableComparable"/>
+    <constructor name="ID" type="int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[constructs an ID object from the given int]]>
+      </doc>
+    </constructor>
+    <constructor name="ID"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[returns the int which represents the identifier]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="that" type="org.apache.hadoop.mapreduce.ID"/>
+      <doc>
+      <![CDATA[Compare IDs by associated numbers]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="SEPARATOR" type="char"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="id" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A general identifier, which internally stores the id
+ as an integer. This is the super class of {@link JobID}, 
+ {@link TaskID} and {@link TaskAttemptID}.
+ 
+ @see JobID
+ @see TaskID
+ @see TaskAttemptID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.ID -->
+  <!-- start class org.apache.hadoop.mapreduce.InputFormat -->
+  <class name="InputFormat" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSplits" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Logically split the set of input files for the job.  
+ 
+ <p>Each {@link InputSplit} is then assigned to an individual {@link Mapper}
+ for processing.</p>
+
+ <p><i>Note</i>: The split is a <i>logical</i> split of the inputs and the
+ input files are not physically split into chunks. For e.g. a split could
+ be <i>&lt;input-file-path, start, offset&gt;</i> tuple. The InputFormat
+ also creates the {@link RecordReader} to read the {@link InputSplit}.
+ 
+ @param context job configuration.
+ @return an array of {@link InputSplit}s for the job.]]>
+      </doc>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Create a record reader for a given split. The framework will call
+ {@link RecordReader#initialize(InputSplit, TaskAttemptContext)} before
+ the split is used.
+ @param split the split to be read
+ @param context the information about the task
+ @return a new record reader
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>InputFormat</code> describes the input-specification for a 
+ Map-Reduce job. 
+ 
+ <p>The Map-Reduce framework relies on the <code>InputFormat</code> of the
+ job to:<p>
+ <ol>
+   <li>
+   Validate the input-specification of the job. 
+   <li>
+   Split-up the input file(s) into logical {@link InputSplit}s, each of 
+   which is then assigned to an individual {@link Mapper}.
+   </li>
+   <li>
+   Provide the {@link RecordReader} implementation to be used to glean
+   input records from the logical <code>InputSplit</code> for processing by 
+   the {@link Mapper}.
+   </li>
+ </ol>
+ 
+ <p>The default behavior of file-based {@link InputFormat}s, typically 
+ sub-classes of {@link FileInputFormat}, is to split the 
+ input into <i>logical</i> {@link InputSplit}s based on the total size, in 
+ bytes, of the input files. However, the {@link FileSystem} blocksize of  
+ the input files is treated as an upper bound for input splits. A lower bound 
+ on the split size can be set via 
+ <a href="{@docRoot}/../hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml#mapreduce.input.fileinputformat.split.minsize">
+ mapreduce.input.fileinputformat.split.minsize</a>.</p>
+ 
+ <p>Clearly, logical splits based on input-size is insufficient for many 
+ applications since record boundaries are to respected. In such cases, the
+ application has to also implement a {@link RecordReader} on whom lies the
+ responsibility to respect record-boundaries and present a record-oriented
+ view of the logical <code>InputSplit</code> to the individual task.
+
+ @see InputSplit
+ @see RecordReader
+ @see FileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.InputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.InputSplit -->
+  <class name="InputSplit" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InputSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getLength" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the size of the split, so that the input splits can be sorted by size.
+ @return the number of bytes in the split
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the list of nodes by name where the data for the split would be local.
+ The locations do not need to be serialized.
+ 
+ @return a new array of the node nodes.
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getLocationInfo" return="org.apache.hadoop.mapred.SplitLocationInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets info about which nodes the input split is stored on and how it is
+ stored at each location.
+ 
+ @return list of <code>SplitLocationInfo</code>s describing how the split
+    data is stored at each location. A null value indicates that all the
+    locations have the data stored on disk.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>InputSplit</code> represents the data to be processed by an 
+ individual {@link Mapper}. 
+
+ <p>Typically, it presents a byte-oriented view on the input and is the 
+ responsibility of {@link RecordReader} of the job to process this and present
+ a record-oriented view.
+ 
+ @see InputFormat
+ @see RecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.InputSplit -->
+  <!-- start class org.apache.hadoop.mapreduce.Job -->
+  <class name="Job" extends="org.apache.hadoop.mapreduce.task.JobContextImpl"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.JobContext"/>
+    <implements name="java.lang.AutoCloseable"/>
+    <constructor name="Job"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #getInstance()}">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #getInstance()}]]>
+      </doc>
+    </constructor>
+    <constructor name="Job" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #getInstance(Configuration)}">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #getInstance(Configuration)}]]>
+      </doc>
+    </constructor>
+    <constructor name="Job" type="org.apache.hadoop.conf.Configuration, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #getInstance(Configuration, String)}">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #getInstance(Configuration, String)}]]>
+      </doc>
+    </constructor>
+    <method name="getInstance" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Creates a new {@link Job} with no particular {@link Cluster} .
+ A Cluster will be created with a generic {@link Configuration}.
+ 
+ @return the {@link Job} , with no connection to a cluster yet.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getInstance" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Creates a new {@link Job} with no particular {@link Cluster} and a 
+ given {@link Configuration}.
+ 
+ The <code>Job</code> makes a copy of the <code>Configuration</code> so 
+ that any necessary internal modifications do not reflect on the incoming 
+ parameter.
+ 
+ A Cluster will be created from the conf parameter only when it's needed.
+ 
+ @param conf the configuration
+ @return the {@link Job} , with no connection to a cluster yet.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getInstance" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="jobName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Creates a new {@link Job} with no particular {@link Cluster} and a given jobName.
+ A Cluster will be created from the conf parameter only when it's needed.
+
+ The <code>Job</code> makes a copy of the <code>Configuration</code> so 
+ that any necessary internal modifications do not reflect on the incoming 
+ parameter.
+ 
+ @param conf the configuration
+ @return the {@link Job} , with no connection to a cluster yet.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getInstance" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="status" type="org.apache.hadoop.mapreduce.JobStatus"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Creates a new {@link Job} with no particular {@link Cluster} and given
+ {@link Configuration} and {@link JobStatus}.
+ A Cluster will be created from the conf parameter only when it's needed.
+ 
+ The <code>Job</code> makes a copy of the <code>Configuration</code> so 
+ that any necessary internal modifications do not reflect on the incoming 
+ parameter.
+ 
+ @param status job status
+ @param conf job configuration
+ @return the {@link Job} , with no connection to a cluster yet.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getInstance" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #getInstance()}">
+      <param name="ignored" type="org.apache.hadoop.mapreduce.Cluster"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Creates a new {@link Job} with no particular {@link Cluster}.
+ A Cluster will be created from the conf parameter only when it's needed.
+
+ The <code>Job</code> makes a copy of the <code>Configuration</code> so 
+ that any necessary internal modifications do not reflect on the incoming 
+ parameter.
+ 
+ @param ignored
+ @return the {@link Job} , with no connection to a cluster yet.
+ @throws IOException
+ @deprecated Use {@link #getInstance()}]]>
+      </doc>
+    </method>
+    <method name="getInstance" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #getInstance(Configuration)}">
+      <param name="ignored" type="org.apache.hadoop.mapreduce.Cluster"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Creates a new {@link Job} with no particular {@link Cluster} and given
+ {@link Configuration}.
+ A Cluster will be created from the conf parameter only when it's needed.
+ 
+ The <code>Job</code> makes a copy of the <code>Configuration</code> so 
+ that any necessary internal modifications do not reflect on the incoming 
+ parameter.
+ 
+ @param ignored
+ @param conf job configuration
+ @return the {@link Job} , with no connection to a cluster yet.
+ @throws IOException
+ @deprecated Use {@link #getInstance(Configuration)}]]>
+      </doc>
+    </method>
+    <method name="getStatus" return="org.apache.hadoop.mapreduce.JobStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getJobState" return="org.apache.hadoop.mapreduce.JobStatus.State"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Returns the current state of the Job.
+ 
+ @return JobStatus#State
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getTrackingURL" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the URL where some job progress information will be displayed.
+ 
+ @return the URL where some job progress information will be displayed.]]>
+      </doc>
+    </method>
+    <method name="getJobFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the path of the submitted job configuration.
+ 
+ @return the path of the submitted job configuration.]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get start time of the job.
+ 
+ @return the start time of the job]]>
+      </doc>
+    </method>
+    <method name="getFinishTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get finish time of the job.
+ 
+ @return the finish time of the job]]>
+      </doc>
+    </method>
+    <method name="getSchedulingInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get scheduling info of the job.
+ 
+ @return the scheduling info of the job]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.mapreduce.JobPriority"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get scheduling info of the job.
+ 
+ @return the priority info of the job]]>
+      </doc>
+    </method>
+    <method name="getJobName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The user-specified job name.]]>
+      </doc>
+    </method>
+    <method name="getHistoryUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="isRetired" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Dump stats to screen.]]>
+      </doc>
+    </method>
+    <method name="getTaskReports" return="org.apache.hadoop.mapreduce.TaskReport[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="org.apache.hadoop.mapreduce.TaskType"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the information of the current state of the tasks of a job.
+ 
+ @param type Type of the task
+ @return the list of all of the map tips.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="mapProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's map-tasks, as a float between 0.0 
+ and 1.0.  When all map tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's map-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="reduceProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's reduce-tasks, as a float between 0.0 
+ and 1.0.  When all reduce tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's reduce-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="cleanupProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's cleanup-tasks, as a float between 0.0 
+ and 1.0.  When all cleanup tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's cleanup-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setupProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the <i>progress</i> of the job's setup-tasks, as a float between 0.0 
+ and 1.0.  When all setup tasks have completed, the function returns 1.0.
+ 
+ @return the progress of the job's setup-tasks.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isComplete" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check if the job is finished or not. 
+ This is a non-blocking call.
+ 
+ @return <code>true</code> if the job is complete, else <code>false</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isSuccessful" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check if the job completed successfully. 
+ 
+ @return <code>true</code> if the job succeeded, else <code>false</code>.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="killJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Kill the running job.  Blocks until all job tasks have been
+ killed as well.  If the job is no longer running, it simply returns.
+ 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setPriority"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobPriority" type="org.apache.hadoop.mapreduce.JobPriority"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Set the priority of a running job.
+ @param jobPriority the new priority for the job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setPriorityAsInteger"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobPriority" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Set the priority of a running job.
+
+ @param jobPriority
+          the new priority for the job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getTaskCompletionEvents" return="org.apache.hadoop.mapreduce.TaskCompletionEvent[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startFrom" type="int"/>
+      <param name="numEvents" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get events indicating completion (success/failure) of component tasks.
+  
+ @param startFrom index to start fetching events from
+ @param numEvents number of events to fetch
+ @return an array of {@link TaskCompletionEvent}s
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getTaskCompletionEvents" return="org.apache.hadoop.mapred.TaskCompletionEvent[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startFrom" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get events indicating completion (success/failure) of component tasks.
+  
+ @param startFrom index to start fetching events from
+ @return an array of {@link org.apache.hadoop.mapred.TaskCompletionEvent}s
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="killTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskId" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Kill indicated task attempt.
+ 
+ @param taskId the id of the task to be terminated.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="failTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskId" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Fail indicated task attempt.
+ 
+ @param taskId the id of the task to be terminated.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getCounters" return="org.apache.hadoop.mapreduce.Counters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets the counters for this job. May return null if the job has been
+ retired and the job is no longer in the completed job store.
+ 
+ @return the counters for this job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getTaskDiagnostics" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskid" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Gets the diagnostic messages for a given task attempt.
+ @param taskid
+ @return the list of diagnostic messages for the task
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setNumReduceTasks"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="tasks" type="int"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the number of reduce tasks for the job.
+ @param tasks the number of reduce tasks
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setWorkingDirectory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dir" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Set the current working directory for the default file system.
+ 
+ @param dir the new current working directory.
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setInputFormatClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the {@link InputFormat} for the job.
+ @param cls the <code>InputFormat</code> to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setOutputFormatClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the {@link OutputFormat} for the job.
+ @param cls the <code>OutputFormat</code> to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setMapperClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the {@link Mapper} for the job.
+ @param cls the <code>Mapper</code> to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setJarByClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the Jar by finding where a given class came from.
+ @param cls the example class]]>
+      </doc>
+    </method>
+    <method name="setJar"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jar" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the job jar]]>
+      </doc>
+    </method>
+    <method name="setUser"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="user" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the reported username for this job.
+ 
+ @param user the username for this job.]]>
+      </doc>
+    </method>
+    <method name="setCombinerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the combiner class for the job.
+ @param cls the combiner to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setReducerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the {@link Reducer} for the job.
+ @param cls the <code>Reducer</code> to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setPartitionerClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the {@link Partitioner} for the job.
+ @param cls the <code>Partitioner</code> to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setMapOutputKeyClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the key class for the map output data. This allows the user to
+ specify the map output key class to be different than the final output
+ value class.
+ 
+ @param theClass the map output key class.
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setMapOutputValueClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the value class for the map output data. This allows the user to
+ specify the map output value class to be different than the final output
+ value class.
+ 
+ @param theClass the map output value class.
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setOutputKeyClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the key class for the job output data.
+ 
+ @param theClass the key class for the job output data.
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setOutputValueClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="theClass" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the value class for job outputs.
+ 
+ @param theClass the value class for job outputs.
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setCombinerKeyGroupingComparatorClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Define the comparator that controls which keys are grouped together
+ for a single call to combiner,
+ {@link Reducer#reduce(Object, Iterable,
+ org.apache.hadoop.mapreduce.Reducer.Context)}
+
+ @param cls the raw comparator to use
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setSortComparatorClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Define the comparator that controls how the keys are sorted before they
+ are passed to the {@link Reducer}.
+ @param cls the raw comparator
+ @throws IllegalStateException if the job is submitted
+ @see #setCombinerKeyGroupingComparatorClass(Class)]]>
+      </doc>
+    </method>
+    <method name="setGroupingComparatorClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cls" type="java.lang.Class"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Define the comparator that controls which keys are grouped together
+ for a single call to 
+ {@link Reducer#reduce(Object, Iterable, 
+                       org.apache.hadoop.mapreduce.Reducer.Context)}
+ @param cls the raw comparator to use
+ @throws IllegalStateException if the job is submitted
+ @see #setCombinerKeyGroupingComparatorClass(Class)]]>
+      </doc>
+    </method>
+    <method name="setJobName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <exception name="IllegalStateException" type="java.lang.IllegalStateException"/>
+      <doc>
+      <![CDATA[Set the user-specified job name.
+ 
+ @param name the job's new name.
+ @throws IllegalStateException if the job is submitted]]>
+      </doc>
+    </method>
+    <method name="setSpeculativeExecution"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="speculativeExecution" type="boolean"/>
+      <doc>
+      <![CDATA[Turn speculative execution on or off for this job. 
+ 
+ @param speculativeExecution <code>true</code> if speculative execution 
+                             should be turned on, else <code>false</code>.]]>
+      </doc>
+    </method>
+    <method name="setMapSpeculativeExecution"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="speculativeExecution" type="boolean"/>
+      <doc>
+      <![CDATA[Turn speculative execution on or off for this job for map tasks. 
+ 
+ @param speculativeExecution <code>true</code> if speculative execution 
+                             should be turned on for map tasks,
+                             else <code>false</code>.]]>
+      </doc>
+    </method>
+    <method name="setReduceSpeculativeExecution"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="speculativeExecution" type="boolean"/>
+      <doc>
+      <![CDATA[Turn speculative execution on or off for this job for reduce tasks. 
+ 
+ @param speculativeExecution <code>true</code> if speculative execution 
+                             should be turned on for reduce tasks,
+                             else <code>false</code>.]]>
+      </doc>
+    </method>
+    <method name="setJobSetupCleanupNeeded"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="needed" type="boolean"/>
+      <doc>
+      <![CDATA[Specify whether job-setup and job-cleanup is needed for the job 
+ 
+ @param needed If <code>true</code>, job-setup and job-cleanup will be
+               considered from {@link OutputCommitter} 
+               else ignored.]]>
+      </doc>
+    </method>
+    <method name="setCacheArchives"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="archives" type="java.net.URI[]"/>
+      <doc>
+      <![CDATA[Set the given set of archives
+ @param archives The list of archives that need to be localized]]>
+      </doc>
+    </method>
+    <method name="setCacheFiles"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="files" type="java.net.URI[]"/>
+      <doc>
+      <![CDATA[Set the given set of files
+ @param files The list of files that need to be localized]]>
+      </doc>
+    </method>
+    <method name="addCacheArchive"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uri" type="java.net.URI"/>
+      <doc>
+      <![CDATA[Add a archives to be localized
+ @param uri The uri of the cache to be localized]]>
+      </doc>
+    </method>
+    <method name="addCacheFile"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uri" type="java.net.URI"/>
+      <doc>
+      <![CDATA[Add a file to be localized
+ @param uri The uri of the cache to be localized]]>
+      </doc>
+    </method>
+    <method name="addFileToClassPath"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add an file path to the current set of classpath entries It adds the file
+ to cache as well.
+ 
+ Files added with this method will not be unpacked while being added to the
+ classpath.
+ To add archives to classpath, use the {@link #addArchiveToClassPath(Path)}
+ method instead.
+
+ @param file Path of the file to be added]]>
+      </doc>
+    </method>
+    <method name="addArchiveToClassPath"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="archive" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add an archive path to the current set of classpath entries. It adds the
+ archive to cache as well.
+ 
+ Archive files will be unpacked and added to the classpath
+ when being distributed.
+
+ @param archive Path of the archive to be added]]>
+      </doc>
+    </method>
+    <method name="createSymlink"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Originally intended to enable symlinks, but currently symlinks cannot be
+ disabled.]]>
+      </doc>
+    </method>
+    <method name="setMaxMapAttempts"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[Expert: Set the number of maximum attempts that will be made to run a
+ map task.
+ 
+ @param n the number of attempts per map task.]]>
+      </doc>
+    </method>
+    <method name="setMaxReduceAttempts"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[Expert: Set the number of maximum attempts that will be made to run a
+ reduce task.
+ 
+ @param n the number of attempts per reduce task.]]>
+      </doc>
+    </method>
+    <method name="setProfileEnabled"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="newValue" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the system should collect profiler information for some of 
+ the tasks in this job? The information is stored in the user log 
+ directory.
+ @param newValue true means it should be gathered]]>
+      </doc>
+    </method>
+    <method name="setProfileParams"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="value" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the profiler configuration arguments. If the string contains a '%s' it
+ will be replaced with the name of the profiling output file when the task
+ runs.
+
+ This value is passed to the task child JVM on the command line.
+
+ @param value the configuration string]]>
+      </doc>
+    </method>
+    <method name="setProfileTaskRange"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isMap" type="boolean"/>
+      <param name="newValue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the ranges of maps or reduces to profile. setProfileEnabled(true) 
+ must also be called.
+ @param newValue a set of integer ranges of the map ids]]>
+      </doc>
+    </method>
+    <method name="setCancelDelegationTokenUponJobCompletion"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="value" type="boolean"/>
+      <doc>
+      <![CDATA[Sets the flag that will allow the JobTracker to cancel the HDFS delegation
+ tokens upon job completion. Defaults to true.]]>
+      </doc>
+    </method>
+    <method name="addFileToSharedCache" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.net.URI"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Add a file to job config for shared cache processing. If shared cache is
+ enabled, it will return true, otherwise, return false. We don't check with
+ SCM here given application might not be able to provide the job id;
+ ClientSCMProtocol.use requires the application id. Job Submitter will read
+ the files from job config and take care of things.
+
+ @param resource The resource that Job Submitter will process later using
+          shared cache.
+ @param conf Configuration to add the resource to
+ @return whether the resource has been added to the configuration]]>
+      </doc>
+    </method>
+    <method name="addFileToSharedCacheAndClasspath" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.net.URI"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Add a file to job config for shared cache processing. If shared cache is
+ enabled, it will return true, otherwise, return false. We don't check with
+ SCM here given application might not be able to provide the job id;
+ ClientSCMProtocol.use requires the application id. Job Submitter will read
+ the files from job config and take care of things. Job Submitter will also
+ add the file to classpath. Intended to be used by user code.
+
+ @param resource The resource that Job Submitter will process later using
+          shared cache.
+ @param conf Configuration to add the resource to
+ @return whether the resource has been added to the configuration]]>
+      </doc>
+    </method>
+    <method name="addArchiveToSharedCache" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.net.URI"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Add an archive to job config for shared cache processing. If shared cache
+ is enabled, it will return true, otherwise, return false. We don't check
+ with SCM here given application might not be able to provide the job id;
+ ClientSCMProtocol.use requires the application id. Job Submitter will read
+ the files from job config and take care of things. Intended to be used by
+ user code.
+
+ @param resource The resource that Job Submitter will process later using
+          shared cache.
+ @param conf Configuration to add the resource to
+ @return whether the resource has been added to the configuration]]>
+      </doc>
+    </method>
+    <method name="setFileSharedCacheUploadPolicies"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="policies" type="java.util.Map"/>
+      <doc>
+      <![CDATA[This is to set the shared cache upload policies for files. If the parameter
+ was previously set, this method will replace the old value with the new
+ provided map.
+
+ @param conf Configuration which stores the shared cache upload policies
+ @param policies A map containing the shared cache upload policies for a set
+          of resources. The key is the url of the resource and the value is
+          the upload policy. True if it should be uploaded, false otherwise.]]>
+      </doc>
+    </method>
+    <method name="setArchiveSharedCacheUploadPolicies"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="policies" type="java.util.Map"/>
+      <doc>
+      <![CDATA[This is to set the shared cache upload policies for archives. If the
+ parameter was previously set, this method will replace the old value with
+ the new provided map.
+
+ @param conf Configuration which stores the shared cache upload policies
+ @param policies A map containing the shared cache upload policies for a set
+          of resources. The key is the url of the resource and the value is
+          the upload policy. True if it should be uploaded, false otherwise.]]>
+      </doc>
+    </method>
+    <method name="getFileSharedCacheUploadPolicies" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[This is to get the shared cache upload policies for files.
+
+ @param conf Configuration which stores the shared cache upload policies
+ @return A map containing the shared cache upload policies for a set of
+         resources. The key is the url of the resource and the value is the
+         upload policy. True if it should be uploaded, false otherwise.]]>
+      </doc>
+    </method>
+    <method name="getArchiveSharedCacheUploadPolicies" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[This is to get the shared cache upload policies for archives.
+
+ @param conf Configuration which stores the shared cache upload policies
+ @return A map containing the shared cache upload policies for a set of
+         resources. The key is the url of the resource and the value is the
+         upload policy. True if it should be uploaded, false otherwise.]]>
+      </doc>
+    </method>
+    <method name="submit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Submit the job to the cluster and return immediately.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="waitForCompletion" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="verbose" type="boolean"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Submit the job to the cluster and wait for it to finish.
+ @param verbose print the progress to the user
+ @return true if the job succeeded
+ @throws IOException thrown if the communication with the 
+         <code>JobTracker</code> is lost]]>
+      </doc>
+    </method>
+    <method name="monitorAndPrintJob" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Monitor a job and print status in real-time as progress is made and tasks 
+ fail.
+ @return true if the job succeeded
+ @throws IOException if communication to the JobTracker fails]]>
+      </doc>
+    </method>
+    <method name="getProgressPollInterval" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[The interval at which monitorAndPrintJob() prints status]]>
+      </doc>
+    </method>
+    <method name="getCompletionPollInterval" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[The interval at which waitForCompletion() should check.]]>
+      </doc>
+    </method>
+    <method name="getTaskOutputFilter" return="org.apache.hadoop.mapreduce.Job.TaskStatusFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the task output filter.
+ 
+ @param conf the configuration.
+ @return the filter level.]]>
+      </doc>
+    </method>
+    <method name="setTaskOutputFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="newValue" type="org.apache.hadoop.mapreduce.Job.TaskStatusFilter"/>
+      <doc>
+      <![CDATA[Modify the Configuration to set the task output filter.
+ 
+ @param conf the Configuration to modify.
+ @param newValue the value to set.]]>
+      </doc>
+    </method>
+    <method name="isUber" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reservation to which the job is submitted to, if any
+
+ @return the reservationId the identifier of the job's reservation, null if
+         the job does not have any reservation associated with it]]>
+      </doc>
+    </method>
+    <method name="setReservationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+      <doc>
+      <![CDATA[Set the reservation to which the job is submitted to
+
+ @param reservationId the reservationId to set]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close the <code>Job</code>.
+ @throws IOException if fail to close.]]>
+      </doc>
+    </method>
+    <field name="OUTPUT_FILTER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="COMPLETION_POLL_INTERVAL_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Key in mapred-*.xml that sets completionPollInvervalMillis]]>
+      </doc>
+    </field>
+    <field name="PROGRESS_MONITOR_POLL_INTERVAL_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Key in mapred-*.xml that sets progMonitorPollIntervalMillis]]>
+      </doc>
+    </field>
+    <field name="USED_GENERIC_PARSER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SUBMIT_REPLICATION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SUBMIT_REPLICATION" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="USE_WILDCARD_FOR_LIBJARS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_USE_WILDCARD_FOR_LIBJARS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[The job submitter's view of the Job.
+ 
+ <p>It allows the user to configure the
+ job, submit it, control its execution, and query the state. The set methods
+ only work until the job is submitted, afterwards they will throw an 
+ IllegalStateException. </p>
+ 
+ <p>
+ Normally the user creates the application, describes various facets of the
+ job via {@link Job} and then submits the job and monitor its progress.</p>
+ 
+ <p>Here is an example on how to submit a job:</p>
+ <p><blockquote><pre>
+     // Create a new Job
+     Job job = Job.getInstance();
+     job.setJarByClass(MyJob.class);
+     
+     // Specify various job-specific parameters     
+     job.setJobName("myjob");
+     
+     job.setInputPath(new Path("in"));
+     job.setOutputPath(new Path("out"));
+     
+     job.setMapperClass(MyJob.MyMapper.class);
+     job.setReducerClass(MyJob.MyReducer.class);
+
+     // Submit the job, then poll for progress until the job is complete
+     job.waitForCompletion(true);
+ </pre></blockquote>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.Job -->
+  <!-- start interface org.apache.hadoop.mapreduce.JobContext -->
+  <interface name="JobContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.MRJobConfig"/>
+    <method name="getConfiguration" return="org.apache.hadoop.conf.Configuration"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the configuration for the job.
+ @return the shared configuration object]]>
+      </doc>
+    </method>
+    <method name="getCredentials" return="org.apache.hadoop.security.Credentials"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get credentials for the job.
+ @return credentials for the job]]>
+      </doc>
+    </method>
+    <method name="getJobID" return="org.apache.hadoop.mapreduce.JobID"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the unique ID for the job.
+ @return the object with the job id]]>
+      </doc>
+    </method>
+    <method name="getNumReduceTasks" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get configured the number of reduce tasks for this job. Defaults to 
+ <code>1</code>.
+ @return the number of reduce tasks for this job.]]>
+      </doc>
+    </method>
+    <method name="getWorkingDirectory" return="org.apache.hadoop.fs.Path"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the current working directory for the default file system.
+ 
+ @return the directory name.]]>
+      </doc>
+    </method>
+    <method name="getOutputKeyClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the key class for the job output data.
+ @return the key class for the job output data.]]>
+      </doc>
+    </method>
+    <method name="getOutputValueClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the value class for job outputs.
+ @return the value class for job outputs.]]>
+      </doc>
+    </method>
+    <method name="getMapOutputKeyClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the key class for the map output data. If it is not set, use the
+ (final) output key class. This allows the map output key class to be
+ different than the final output key class.
+ @return the map output key class.]]>
+      </doc>
+    </method>
+    <method name="getMapOutputValueClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the value class for the map output data. If it is not set, use the
+ (final) output value class This allows the map output value class to be
+ different than the final output value class.
+  
+ @return the map output value class.]]>
+      </doc>
+    </method>
+    <method name="getJobName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-specified job name. This is only used to identify the 
+ job to the user.
+ 
+ @return the job's name, defaulting to "".]]>
+      </doc>
+    </method>
+    <method name="getInputFormatClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Get the {@link InputFormat} class for the job.
+ 
+ @return the {@link InputFormat} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getMapperClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Get the {@link Mapper} class for the job.
+ 
+ @return the {@link Mapper} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getCombinerClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Get the combiner class for the job.
+ 
+ @return the combiner class for the job.]]>
+      </doc>
+    </method>
+    <method name="getReducerClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Get the {@link Reducer} class for the job.
+ 
+ @return the {@link Reducer} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getOutputFormatClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Get the {@link OutputFormat} class for the job.
+ 
+ @return the {@link OutputFormat} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getPartitionerClass" return="java.lang.Class"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[Get the {@link Partitioner} class for the job.
+ 
+ @return the {@link Partitioner} class for the job.]]>
+      </doc>
+    </method>
+    <method name="getSortComparator" return="org.apache.hadoop.io.RawComparator"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link RawComparator} comparator used to compare keys.
+ 
+ @return the {@link RawComparator} comparator used to compare keys.]]>
+      </doc>
+    </method>
+    <method name="getJar" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the pathname of the job's jar.
+ @return the pathname]]>
+      </doc>
+    </method>
+    <method name="getCombinerKeyGroupingComparator" return="org.apache.hadoop.io.RawComparator"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user defined {@link RawComparator} comparator for
+ grouping keys of inputs to the combiner.
+
+ @return comparator set by the user for grouping values.
+ @see Job#setCombinerKeyGroupingComparatorClass(Class)]]>
+      </doc>
+    </method>
+    <method name="getGroupingComparator" return="org.apache.hadoop.io.RawComparator"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user defined {@link RawComparator} comparator for
+ grouping keys of inputs to the reduce.
+
+ @return comparator set by the user for grouping values.
+ @see Job#setGroupingComparatorClass(Class)
+ @see #getCombinerKeyGroupingComparator()]]>
+      </doc>
+    </method>
+    <method name="getJobSetupCleanupNeeded" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether job-setup and job-cleanup is needed for the job 
+ 
+ @return boolean]]>
+      </doc>
+    </method>
+    <method name="getTaskCleanupNeeded" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether task-cleanup is needed for the job 
+ 
+ @return boolean]]>
+      </doc>
+    </method>
+    <method name="getProfileEnabled" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether the task profiling is enabled.
+ @return true if some tasks will be profiled]]>
+      </doc>
+    </method>
+    <method name="getProfileParams" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the profiler configuration arguments.
+
+ The default value for this property is
+ "-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s"
+ 
+ @return the parameters to pass to the task child to configure profiling]]>
+      </doc>
+    </method>
+    <method name="getProfileTaskRange" return="org.apache.hadoop.conf.Configuration.IntegerRanges"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isMap" type="boolean"/>
+      <doc>
+      <![CDATA[Get the range of maps or reduces to profile.
+ @param isMap is the task a map?
+ @return the task ranges]]>
+      </doc>
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reported username for this job.
+ 
+ @return the username]]>
+      </doc>
+    </method>
+    <method name="getSymlink" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Originally intended to check if symlinks should be used, but currently
+ symlinks cannot be disabled.
+ @return true]]>
+      </doc>
+    </method>
+    <method name="getArchiveClassPaths" return="org.apache.hadoop.fs.Path[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the archive entries in classpath as an array of Path]]>
+      </doc>
+    </method>
+    <method name="getCacheArchives" return="java.net.URI[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get cache archives set in the Configuration
+ @return A URI array of the caches set in the Configuration
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getCacheFiles" return="java.net.URI[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get cache files set in the Configuration
+ @return A URI array of the files set in the Configuration
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getLocalCacheArchives" return="org.apache.hadoop.fs.Path[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="the array returned only includes the items the were 
+ downloaded. There is no way to map this to what is returned by
+ {@link #getCacheArchives()}.">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return the path array of the localized caches
+ @return A path array of localized caches
+ @throws IOException
+ @deprecated the array returned only includes the items the were 
+ downloaded. There is no way to map this to what is returned by
+ {@link #getCacheArchives()}.]]>
+      </doc>
+    </method>
+    <method name="getLocalCacheFiles" return="org.apache.hadoop.fs.Path[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="the array returned only includes the items the were 
+ downloaded. There is no way to map this to what is returned by
+ {@link #getCacheFiles()}.">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return the path array of the localized files
+ @return A path array of localized files
+ @throws IOException
+ @deprecated the array returned only includes the items the were 
+ downloaded. There is no way to map this to what is returned by
+ {@link #getCacheFiles()}.]]>
+      </doc>
+    </method>
+    <method name="getFileClassPaths" return="org.apache.hadoop.fs.Path[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the file entries in classpath as an array of Path]]>
+      </doc>
+    </method>
+    <method name="getArchiveTimestamps" return="java.lang.String[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the timestamps of the archives.  Used by internal
+ DistributedCache and MapReduce code.
+ @return a string array of timestamps]]>
+      </doc>
+    </method>
+    <method name="getFileTimestamps" return="java.lang.String[]"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the timestamps of the files.  Used by internal
+ DistributedCache and MapReduce code.
+ @return a string array of timestamps]]>
+      </doc>
+    </method>
+    <method name="getMaxMapAttempts" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configured number of maximum attempts that will be made to run a
+ map task, as specified by the <code>mapred.map.max.attempts</code>
+ property. If this property is not already set, the default is 4 attempts.
+  
+ @return the max number of attempts per map task.]]>
+      </doc>
+    </method>
+    <method name="getMaxReduceAttempts" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configured number of maximum attempts  that will be made to run a
+ reduce task, as specified by the <code>mapred.reduce.max.attempts</code>
+ property. If this property is not already set, the default is 4 attempts.
+ 
+ @return the max number of attempts per reduce task.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A read-only view of the job that is provided to the tasks while they
+ are running.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.JobContext -->
+  <!-- start class org.apache.hadoop.mapreduce.JobCounter -->
+  <class name="JobCounter" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.JobCounter[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.JobCounter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.JobCounter -->
+  <!-- start class org.apache.hadoop.mapreduce.JobID -->
+  <class name="JobID" extends="org.apache.hadoop.mapred.ID"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="JobID" type="java.lang.String, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a JobID object 
+ @param jtIdentifier jobTracker identifier
+ @param id job number]]>
+      </doc>
+    </constructor>
+    <constructor name="JobID"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getJtIdentifier" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="org.apache.hadoop.mapreduce.ID"/>
+      <doc>
+      <![CDATA[Compare JobIds by first jtIdentifiers, then by job numbers]]>
+      </doc>
+    </method>
+    <method name="appendTo" return="java.lang.StringBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="builder" type="java.lang.StringBuilder"/>
+      <doc>
+      <![CDATA[Add the stuff after the "job" prefix to the given builder. This is useful,
+ because the sub-ids use this substring at the start of their string.
+ @param builder the builder to append to
+ @return the builder that was passed in]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="forName" return="org.apache.hadoop.mapreduce.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="str" type="java.lang.String"/>
+      <exception name="IllegalArgumentException" type="java.lang.IllegalArgumentException"/>
+      <doc>
+      <![CDATA[Construct a JobId object from given string 
+ @return constructed JobId object or null if the given String is null
+ @throws IllegalArgumentException if the given string is malformed]]>
+      </doc>
+    </method>
+    <field name="JOB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="JOBID_REGEX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="idFormat" type="java.text.NumberFormat"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[JobID represents the immutable and unique identifier for 
+ the job. JobID consists of two parts. First part 
+ represents the jobtracker identifier, so that jobID to jobtracker map 
+ is defined. For cluster setup this string is the jobtracker 
+ start time, for local setting, it is "local" and a random number.
+ Second part of the JobID is the job number. <br> 
+ An example JobID is : 
+ <code>job_200707121733_0003</code> , which represents the third job 
+ running at the jobtracker started at <code>200707121733</code>. 
+ <p>
+ Applications should never construct or parse JobID strings, but rather 
+ use appropriate constructors or {@link #forName(String)} method. 
+ 
+ @see TaskID
+ @see TaskAttemptID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.JobID -->
+  <!-- start class org.apache.hadoop.mapreduce.JobPriority -->
+  <class name="JobPriority" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.JobPriority[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.JobPriority"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Used to describe the priority of the running job. 
+ DEFAULT : While submitting a job, if the user is not specifying priority,
+ YARN has the capability to pick the default priority as per its config.
+ Hence MapReduce can indicate such cases with this new enum.
+ UNDEFINED_PRIORITY : YARN supports priority as an integer. Hence other than
+ the five defined enums, YARN can consider other integers also. To generalize
+ such cases, this specific enum is used.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.JobPriority -->
+  <!-- start class org.apache.hadoop.mapreduce.JobStatus -->
+  <class name="JobStatus" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <implements name="java.lang.Cloneable"/>
+    <constructor name="JobStatus"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapreduce.JobID, float, float, float, float, org.apache.hadoop.mapreduce.JobStatus.State, org.apache.hadoop.mapreduce.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapreduce.JobID, float, float, float, float, org.apache.hadoop.mapreduce.JobStatus.State, org.apache.hadoop.mapreduce.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param queue queue name
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapreduce.JobID, float, float, float, float, org.apache.hadoop.mapreduce.JobStatus.State, org.apache.hadoop.mapreduce.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, boolean"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param queue queue name
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.
+ @param isUber Whether job running in uber mode]]>
+      </doc>
+    </constructor>
+    <constructor name="JobStatus" type="org.apache.hadoop.mapreduce.JobID, float, float, float, float, org.apache.hadoop.mapreduce.JobStatus.State, org.apache.hadoop.mapreduce.JobPriority, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, boolean, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a job status object for a given jobid.
+ @param jobid The jobid of the job
+ @param setupProgress The progress made on the setup
+ @param mapProgress The progress made on the maps
+ @param reduceProgress The progress made on the reduces
+ @param cleanupProgress The progress made on the cleanup
+ @param runState The current state of the job
+ @param jp Priority of the job.
+ @param user userid of the person who submitted the job.
+ @param jobName user-specified job name.
+ @param queue queue name
+ @param jobFile job configuration file.
+ @param trackingUrl link to the web-ui for details of the job.
+ @param isUber Whether job running in uber mode
+ @param historyFile history file]]>
+      </doc>
+    </constructor>
+    <method name="setMapProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the map progress of this job
+ @param p The value of map progress to set to]]>
+      </doc>
+    </method>
+    <method name="setCleanupProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the cleanup progress of this job
+ @param p The value of cleanup progress to set to]]>
+      </doc>
+    </method>
+    <method name="setSetupProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the setup progress of this job
+ @param p The value of setup progress to set to]]>
+      </doc>
+    </method>
+    <method name="setReduceProgress"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="p" type="float"/>
+      <doc>
+      <![CDATA[Sets the reduce progress of this Job
+ @param p The value of reduce progress to set to]]>
+      </doc>
+    </method>
+    <method name="setPriority"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="jp" type="org.apache.hadoop.mapreduce.JobPriority"/>
+      <doc>
+      <![CDATA[Set the priority of the job, defaulting to NORMAL.
+ @param jp new job priority]]>
+      </doc>
+    </method>
+    <method name="setFinishTime"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="finishTime" type="long"/>
+      <doc>
+      <![CDATA[Set the finish time of the job
+ @param finishTime The finishTime of the job]]>
+      </doc>
+    </method>
+    <method name="setHistoryFile"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="historyFile" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the job history file url for a completed job]]>
+      </doc>
+    </method>
+    <method name="setTrackingUrl"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the link to the web-ui for details of the job.]]>
+      </doc>
+    </method>
+    <method name="setRetired"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set the job retire flag to true.]]>
+      </doc>
+    </method>
+    <method name="setState"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="state" type="org.apache.hadoop.mapreduce.JobStatus.State"/>
+      <doc>
+      <![CDATA[Change the current run state of the job.]]>
+      </doc>
+    </method>
+    <method name="setStartTime"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="startTime" type="long"/>
+      <doc>
+      <![CDATA[Set the start time of the job
+ @param startTime The startTime of the job]]>
+      </doc>
+    </method>
+    <method name="setUsername"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="userName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[@param userName The username of the job]]>
+      </doc>
+    </method>
+    <method name="setSchedulingInfo"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="schedulingInfo" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Used to set the scheduling information associated to a particular Job.
+ 
+ @param schedulingInfo Scheduling information of the job]]>
+      </doc>
+    </method>
+    <method name="setJobACLs"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="acls" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the job acls.
+ 
+ @param acls {@link Map} from {@link JobACL} to {@link AccessControlList}]]>
+      </doc>
+    </method>
+    <method name="setQueue"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set queue name
+ @param queue queue name]]>
+      </doc>
+    </method>
+    <method name="setFailureInfo"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="failureInfo" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set diagnostic information.
+ @param failureInfo diagnostic information]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get queue name
+ @return queue name]]>
+      </doc>
+    </method>
+    <method name="getMapProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in maps]]>
+      </doc>
+    </method>
+    <method name="getCleanupProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in cleanup]]>
+      </doc>
+    </method>
+    <method name="getSetupProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in setup]]>
+      </doc>
+    </method>
+    <method name="getReduceProgress" return="float"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Percentage of progress in reduce]]>
+      </doc>
+    </method>
+    <method name="getState" return="org.apache.hadoop.mapreduce.JobStatus.State"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return running state of the job]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return start time of the job]]>
+      </doc>
+    </method>
+    <method name="clone" return="java.lang.Object"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getJobID" return="org.apache.hadoop.mapreduce.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return The jobid of the Job]]>
+      </doc>
+    </method>
+    <method name="getUsername" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the username of the job]]>
+      </doc>
+    </method>
+    <method name="getSchedulingInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets the Scheduling information associated to a particular Job.
+ @return the scheduling information of the job]]>
+      </doc>
+    </method>
+    <method name="getJobACLs" return="java.util.Map"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the job acls.
+ 
+ @return a {@link Map} from {@link JobACL} to {@link AccessControlList}]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.mapreduce.JobPriority"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the priority of the job
+ @return job priority]]>
+      </doc>
+    </method>
+    <method name="getFailureInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets any available info on the reason of failure of the job.
+ @return diagnostic information on why a job might have failed.]]>
+      </doc>
+    </method>
+    <method name="isJobComplete" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns true if the status is for a completed job.]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getJobName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-specified job name.]]>
+      </doc>
+    </method>
+    <method name="getJobFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configuration file for the job.]]>
+      </doc>
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the link to the web-ui for details of the job.]]>
+      </doc>
+    </method>
+    <method name="getFinishTime" return="long"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the finish time of the job.]]>
+      </doc>
+    </method>
+    <method name="isRetired" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Check whether the job has retired.]]>
+      </doc>
+    </method>
+    <method name="getHistoryFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the job history file name for a completed job. If job is not 
+ completed or history file not available then return null.]]>
+      </doc>
+    </method>
+    <method name="getNumUsedSlots" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return number of used mapred slots]]>
+      </doc>
+    </method>
+    <method name="setNumUsedSlots"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[@param n number of used mapred slots]]>
+      </doc>
+    </method>
+    <method name="getNumReservedSlots" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the number of reserved slots]]>
+      </doc>
+    </method>
+    <method name="setNumReservedSlots"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[@param n the number of reserved slots]]>
+      </doc>
+    </method>
+    <method name="getUsedMem" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the used memory]]>
+      </doc>
+    </method>
+    <method name="setUsedMem"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="m" type="int"/>
+      <doc>
+      <![CDATA[@param m the used memory]]>
+      </doc>
+    </method>
+    <method name="getReservedMem" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the reserved memory]]>
+      </doc>
+    </method>
+    <method name="setReservedMem"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="r" type="int"/>
+      <doc>
+      <![CDATA[@param r the reserved memory]]>
+      </doc>
+    </method>
+    <method name="getNeededMem" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the needed memory]]>
+      </doc>
+    </method>
+    <method name="setNeededMem"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="int"/>
+      <doc>
+      <![CDATA[@param n the needed memory]]>
+      </doc>
+    </method>
+    <method name="isUber" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether job running in uber mode
+ @return job in uber-mode]]>
+      </doc>
+    </method>
+    <method name="setUber"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isUber" type="boolean"/>
+      <doc>
+      <![CDATA[Set uber-mode flag 
+ @param isUber Whether job running in uber-mode]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Describes the current status of a job.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.JobStatus -->
+  <!-- start interface org.apache.hadoop.mapreduce.MapContext -->
+  <interface name="MapContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.TaskInputOutputContext"/>
+    <method name="getInputSplit" return="org.apache.hadoop.mapreduce.InputSplit"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the input split for this map.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The context that is given to the {@link Mapper}.
+ @param <KEYIN> the key input type to the Mapper
+ @param <VALUEIN> the value input type to the Mapper
+ @param <KEYOUT> the key output type from the Mapper
+ @param <VALUEOUT> the value output type from the Mapper]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.MapContext -->
+  <!-- start class org.apache.hadoop.mapreduce.Mapper -->
+  <class name="Mapper" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Mapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Called once at the beginning of the task.]]>
+      </doc>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="key" type="KEYIN"/>
+      <param name="value" type="VALUEIN"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Called once for each key/value pair in the input split. Most applications
+ should override this, but the default is the identity function.]]>
+      </doc>
+    </method>
+    <method name="cleanup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Called once at the end of the task.]]>
+      </doc>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Expert users can override this method for more complete control over the
+ execution of the Mapper.
+ @param context
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Maps input key/value pairs to a set of intermediate key/value pairs.  
+ 
+ <p>Maps are the individual tasks which transform input records into a 
+ intermediate records. The transformed intermediate records need not be of 
+ the same type as the input records. A given input pair may map to zero or 
+ many output pairs.</p> 
+ 
+ <p>The Hadoop Map-Reduce framework spawns one map task for each 
+ {@link InputSplit} generated by the {@link InputFormat} for the job.
+ <code>Mapper</code> implementations can access the {@link Configuration} for 
+ the job via the {@link JobContext#getConfiguration()}.
+ 
+ <p>The framework first calls 
+ {@link #setup(org.apache.hadoop.mapreduce.Mapper.Context)}, followed by
+ {@link #map(Object, Object, org.apache.hadoop.mapreduce.Mapper.Context)}
+ for each key/value pair in the <code>InputSplit</code>. Finally 
+ {@link #cleanup(org.apache.hadoop.mapreduce.Mapper.Context)} is called.</p>
+ 
+ <p>All intermediate values associated with a given output key are 
+ subsequently grouped by the framework, and passed to a {@link Reducer} to  
+ determine the final output. Users can control the sorting and grouping by 
+ specifying two key {@link RawComparator} classes.</p>
+
+ <p>The <code>Mapper</code> outputs are partitioned per 
+ <code>Reducer</code>. Users can control which keys (and hence records) go to 
+ which <code>Reducer</code> by implementing a custom {@link Partitioner}.
+ 
+ <p>Users can optionally specify a <code>combiner</code>, via 
+ {@link Job#setCombinerClass(Class)}, to perform local aggregation of the 
+ intermediate outputs, which helps to cut down the amount of data transferred 
+ from the <code>Mapper</code> to the <code>Reducer</code>.
+ 
+ <p>Applications can specify if and how the intermediate
+ outputs are to be compressed and which {@link CompressionCodec}s are to be
+ used via the <code>Configuration</code>.</p>
+  
+ <p>If the job has zero
+ reduces then the output of the <code>Mapper</code> is directly written
+ to the {@link OutputFormat} without sorting by keys.</p>
+ 
+ <p>Example:</p>
+ <p><blockquote><pre>
+ public class TokenCounterMapper 
+     extends Mapper&lt;Object, Text, Text, IntWritable&gt;{
+    
+   private final static IntWritable one = new IntWritable(1);
+   private Text word = new Text();
+   
+   public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
+     StringTokenizer itr = new StringTokenizer(value.toString());
+     while (itr.hasMoreTokens()) {
+       word.set(itr.nextToken());
+       context.write(word, one);
+     }
+   }
+ }
+ </pre></blockquote>
+
+ <p>Applications may override the
+ {@link #run(org.apache.hadoop.mapreduce.Mapper.Context)} method to exert
+ greater control on map processing e.g. multi-threaded <code>Mapper</code>s 
+ etc.</p>
+ 
+ @see InputFormat
+ @see JobContext
+ @see Partitioner  
+ @see Reducer]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.Mapper -->
+  <!-- start class org.apache.hadoop.mapreduce.MarkableIterator -->
+  <class name="MarkableIterator" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.MarkableIteratorInterface"/>
+    <constructor name="MarkableIterator" type="java.util.Iterator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new iterator layered on the input iterator
+ @param itr underlying iterator that implements MarkableIteratorInterface]]>
+      </doc>
+    </constructor>
+    <method name="mark"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="clearMark"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="next" return="VALUE"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="remove"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<code>MarkableIterator</code> is a wrapper iterator class that 
+ implements the {@link MarkableIteratorInterface}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.MarkableIterator -->
+  <!-- start class org.apache.hadoop.mapreduce.OutputCommitter -->
+  <class name="OutputCommitter" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="OutputCommitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setupJob"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For the framework to setup the job output during initialization.  This is
+ called from the application master process for the entire job. This will be
+ called multiple times, once per job attempt.
+ 
+ @param jobContext Context of the job whose output is being written.
+ @throws IOException if temporary output could not be created]]>
+      </doc>
+    </method>
+    <method name="cleanupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #commitJob(JobContext)} and
+                 {@link #abortJob(JobContext, JobStatus.State)} instead.">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For cleaning up the job's output after job completion.  This is called
+ from the application master process for the entire job. This may be called
+ multiple times.
+ 
+ @param jobContext Context of the job whose output is being written.
+ @throws IOException
+ @deprecated Use {@link #commitJob(JobContext)} and
+                 {@link #abortJob(JobContext, JobStatus.State)} instead.]]>
+      </doc>
+    </method>
+    <method name="commitJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For committing job's output after successful job completion. Note that this
+ is invoked for jobs with final runstate as SUCCESSFUL.  This is called
+ from the application master process for the entire job. This is guaranteed
+ to only be called once.  If it throws an exception the entire job will
+ fail.	
+ 
+ @param jobContext Context of the job whose output is being written.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="abortJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="state" type="org.apache.hadoop.mapreduce.JobStatus.State"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For aborting an unsuccessful job's output. Note that this is invoked for 
+ jobs with final runstate as {@link JobStatus.State#FAILED} or 
+ {@link JobStatus.State#KILLED}.  This is called from the application
+ master process for the entire job. This may be called multiple times.
+
+ @param jobContext Context of the job whose output is being written.
+ @param state final runstate of the job
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setupTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Sets up output for the task.  This is called from each individual task's
+ process that will output to HDFS, and it is called just for that task. This
+ may be called multiple times for the same task, but for different task
+ attempts.
+ 
+ @param taskContext Context of the task whose output is being written.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="needsTaskCommit" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Check whether task needs a commit.  This is called from each individual
+ task's process that will output to HDFS, and it is called just for that
+ task.
+ 
+ @param taskContext
+ @return true/false
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="commitTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[To promote the task's temporary output to final output location.
+ If {@link #needsTaskCommit(TaskAttemptContext)} returns true and this
+ task is the task that the AM determines finished first, this method
+ is called to commit an individual task's output.  This is to mark
+ that tasks output as complete, as {@link #commitJob(JobContext)} will 
+ also be called later on if the entire job finished successfully. This
+ is called from a task's process. This may be called multiple times for the
+ same task, but different task attempts.  It should be very rare for this to
+ be called multiple times and requires odd networking failures to make this
+ happen. In the future the Hadoop framework may eliminate this race.
+ 
+ @param taskContext Context of the task whose output is being written.
+ @throws IOException if commit is not successful.]]>
+      </doc>
+    </method>
+    <method name="abortTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Discard the task output. This is called from a task's process to clean 
+ up a single task's output that can not yet been committed. This may be
+ called multiple times for the same task, but for different task attempts.
+ 
+ @param taskContext
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #isRecoverySupported(JobContext)} instead.">
+      <doc>
+      <![CDATA[Is task output recovery supported for restarting jobs?
+ 
+ If task output recovery is supported, job restart can be done more
+ efficiently.
+ 
+ @return <code>true</code> if task output recovery is supported,
+         <code>false</code> otherwise
+ @see #recoverTask(TaskAttemptContext)
+ @deprecated Use {@link #isRecoverySupported(JobContext)} instead.]]>
+      </doc>
+    </method>
+    <method name="isCommitJobRepeatable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns true if an in-progress job commit can be retried. If the MR AM is
+ re-run then it will check this value to determine if it can retry an
+ in-progress commit that was started by a previous version.
+ Note that in rare scenarios, the previous AM version might still be running
+ at that time, due to system anomalies. Hence if this method returns true
+ then the retry commit operation should be able to run concurrently with
+ the previous operation.
+
+ If repeatable job commit is supported, job restart can tolerate previous
+ AM failures during job commit.
+
+ By default, it is not supported. Extended classes (like:
+ FileOutputCommitter) should explicitly override it if provide support.
+
+ @param jobContext
+          Context of the job whose output is being written.
+ @return <code>true</code> repeatable job commit is supported,
+         <code>false</code> otherwise
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Is task output recovery supported for restarting jobs?
+ 
+ If task output recovery is supported, job restart can be done more
+ efficiently.
+ 
+ @param jobContext
+          Context of the job whose output is being written.
+ @return <code>true</code> if task output recovery is supported,
+         <code>false</code> otherwise
+ @throws IOException
+ @see #recoverTask(TaskAttemptContext)]]>
+      </doc>
+    </method>
+    <method name="recoverTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Recover the task output. 
+ 
+ The retry-count for the job will be passed via the 
+ {@link MRJobConfig#APPLICATION_ATTEMPT_ID} key in  
+ {@link TaskAttemptContext#getConfiguration()} for the 
+ <code>OutputCommitter</code>.  This is called from the application master
+ process, but it is called individually for each task.
+ 
+ If an exception is thrown the task will be attempted again. 
+ 
+ This may be called multiple times for the same task.  But from different
+ application attempts.
+ 
+ @param taskContext Context of the task whose output is being recovered
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>OutputCommitter</code> describes the commit of task output for a 
+ Map-Reduce job.
+
+ <p>The Map-Reduce framework relies on the <code>OutputCommitter</code> of 
+ the job to:<p>
+ <ol>
+   <li>
+   Setup the job during initialization. For example, create the temporary 
+   output directory for the job during the initialization of the job.
+   </li>
+   <li>
+   Cleanup the job after the job completion. For example, remove the
+   temporary output directory after the job completion. 
+   </li>
+   <li>
+   Setup the task temporary output.
+   </li> 
+   <li>
+   Check whether a task needs a commit. This is to avoid the commit
+   procedure if a task does not need commit.
+   </li>
+   <li>
+   Commit of the task output.
+   </li>  
+   <li>
+   Discard the task commit.
+   </li>
+ </ol>
+ The methods in this class can be called from several different processes and
+ from several different contexts.  It is important to know which process and
+ which context each is called from.  Each method should be marked accordingly
+ in its documentation.  It is also important to note that not all methods are
+ guaranteed to be called once and only once.  If a method is not guaranteed to
+ have this property the output committer needs to handle this appropriately. 
+ Also note it will only be in rare situations where they may be called 
+ multiple times for the same task.
+ 
+ @see org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter 
+ @see JobContext
+ @see TaskAttemptContext]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.OutputCommitter -->
+  <!-- start class org.apache.hadoop.mapreduce.OutputFormat -->
+  <class name="OutputFormat" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="OutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the {@link RecordWriter} for the given task.
+
+ @param context the information about the current task.
+ @return a {@link RecordWriter} to write the output for the job.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Check for validity of the output-specification for the job.
+  
+ <p>This is to validate the output specification for the job when it is
+ a job is submitted.  Typically checks that it does not already exist,
+ throwing an exception when it already exists, so that output is not
+ overwritten.</p>
+
+ @param context information about the job
+ @throws IOException when output should not be attempted]]>
+      </doc>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the output committer for this output format. This is responsible
+ for ensuring the output is committed correctly.
+ @param context the task context
+ @return an output committer
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>OutputFormat</code> describes the output-specification for a 
+ Map-Reduce job.
+
+ <p>The Map-Reduce framework relies on the <code>OutputFormat</code> of the
+ job to:<p>
+ <ol>
+   <li>
+   Validate the output-specification of the job. For e.g. check that the 
+   output directory doesn't already exist. 
+   <li>
+   Provide the {@link RecordWriter} implementation to be used to write out
+   the output files of the job. Output files are stored in a 
+   {@link FileSystem}.
+   </li>
+ </ol>
+ 
+ @see RecordWriter]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.OutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.Partitioner -->
+  <class name="Partitioner" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Partitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getPartition" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="KEY"/>
+      <param name="value" type="VALUE"/>
+      <param name="numPartitions" type="int"/>
+      <doc>
+      <![CDATA[Get the partition number for a given key (hence record) given the total 
+ number of partitions i.e. number of reduce-tasks for the job.
+   
+ <p>Typically a hash function on a all or a subset of the key.</p>
+
+ @param key the key to be partioned.
+ @param value the entry value.
+ @param numPartitions the total number of partitions.
+ @return the partition number for the <code>key</code>.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Partitions the key space.
+ 
+ <p><code>Partitioner</code> controls the partitioning of the keys of the 
+ intermediate map-outputs. The key (or a subset of the key) is used to derive
+ the partition, typically by a hash function. The total number of partitions
+ is the same as the number of reduce tasks for the job. Hence this controls
+ which of the <code>m</code> reduce tasks the intermediate key (and hence the 
+ record) is sent for reduction.</p>
+
+ <p>Note: A <code>Partitioner</code> is created only when there are multiple
+ reducers.</p>
+
+ <p>Note: If you require your Partitioner class to obtain the Job's
+ configuration object, implement the {@link Configurable} interface.</p>
+ 
+ @see Reducer]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.Partitioner -->
+  <!-- start class org.apache.hadoop.mapreduce.QueueAclsInfo -->
+  <class name="QueueAclsInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="QueueAclsInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor for QueueAclsInfo.]]>
+      </doc>
+    </constructor>
+    <constructor name="QueueAclsInfo" type="java.lang.String, java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a new QueueAclsInfo object using the queue name and the
+ queue operations array
+ 
+ @param queueName Name of the job queue
+ @param operations]]>
+      </doc>
+    </constructor>
+    <method name="getQueueName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get queue name.
+ 
+ @return name]]>
+      </doc>
+    </method>
+    <method name="setQueueName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+    </method>
+    <method name="getOperations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get opearations allowed on queue.
+ 
+ @return array of String]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Class to encapsulate Queue ACLs for a particular
+  user.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.QueueAclsInfo -->
+  <!-- start class org.apache.hadoop.mapreduce.QueueInfo -->
+  <class name="QueueInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="QueueInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor for QueueInfo.]]>
+      </doc>
+    </constructor>
+    <constructor name="QueueInfo" type="java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a new QueueInfo object using the queue name and the
+ scheduling information passed.
+ 
+ @param queueName Name of the job queue
+ @param schedulingInfo Scheduling Information associated with the job
+ queue]]>
+      </doc>
+    </constructor>
+    <constructor name="QueueInfo" type="java.lang.String, java.lang.String, org.apache.hadoop.mapreduce.QueueState, org.apache.hadoop.mapreduce.JobStatus[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@param queueName
+ @param schedulingInfo
+ @param state
+ @param stats]]>
+      </doc>
+    </constructor>
+    <method name="setQueueName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the queue name of the JobQueueInfo
+ 
+ @param queueName Name of the job queue.]]>
+      </doc>
+    </method>
+    <method name="getQueueName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the queue name from JobQueueInfo
+ 
+ @return queue name]]>
+      </doc>
+    </method>
+    <method name="setSchedulingInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="schedulingInfo" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the scheduling information associated to particular job queue
+ 
+ @param schedulingInfo]]>
+      </doc>
+    </method>
+    <method name="getSchedulingInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets the scheduling information associated to particular job queue.
+ If nothing is set would return <b>"N/A"</b>
+ 
+ @return Scheduling information associated to particular Job Queue]]>
+      </doc>
+    </method>
+    <method name="setState"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="state" type="org.apache.hadoop.mapreduce.QueueState"/>
+      <doc>
+      <![CDATA[Set the state of the queue
+ @param state state of the queue.]]>
+      </doc>
+    </method>
+    <method name="getState" return="org.apache.hadoop.mapreduce.QueueState"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the queue state
+ @return the queue state.]]>
+      </doc>
+    </method>
+    <method name="setJobStatuses"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="stats" type="org.apache.hadoop.mapreduce.JobStatus[]"/>
+    </method>
+    <method name="getQueueChildren" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get immediate children.
+ 
+ @return list of QueueInfo]]>
+      </doc>
+    </method>
+    <method name="setQueueChildren"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="children" type="java.util.List"/>
+    </method>
+    <method name="getProperties" return="java.util.Properties"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get properties.
+ 
+ @return Properties]]>
+      </doc>
+    </method>
+    <method name="setProperties"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="props" type="java.util.Properties"/>
+    </method>
+    <method name="getJobStatuses" return="org.apache.hadoop.mapreduce.JobStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the jobs submitted to queue
+ @return list of JobStatus for the submitted jobs]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Class that contains the information regarding the Job Queues which are 
+ maintained by the Hadoop Map/Reduce framework.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.QueueInfo -->
+  <!-- start class org.apache.hadoop.mapreduce.QueueState -->
+  <class name="QueueState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.QueueState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.QueueState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <method name="getStateName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the stateName]]>
+      </doc>
+    </method>
+    <method name="getState" return="org.apache.hadoop.mapreduce.QueueState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="state" type="java.lang.String"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Enum representing queue state]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.QueueState -->
+  <!-- start class org.apache.hadoop.mapreduce.RecordReader -->
+  <class name="RecordReader" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.io.Closeable"/>
+    <constructor name="RecordReader"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="initialize"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Called once at initialization.
+ @param split the split that defines the range of records to read
+ @param context the information about the task
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Read the next key, value pair.
+ @return true if a key/value pair was read
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getCurrentKey" return="KEYIN"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the current key
+ @return the current key or null if there is no current key
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getCurrentValue" return="VALUEIN"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the current value.
+ @return the object that was read
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[The current progress of the record reader through its data.
+ @return a number between 0.0 and 1.0 that is the fraction of the data read
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close the record reader.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The record reader breaks the data into key/value pairs for input to the
+ {@link Mapper}.
+ @param <KEYIN>
+ @param <VALUEIN>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.RecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.RecordWriter -->
+  <class name="RecordWriter" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RecordWriter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="write"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Writes a key/value pair.
+
+ @param key the key to write.
+ @param value the value to write.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Close this <code>RecordWriter</code> to future operations.
+ 
+ @param context the context of the task
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<code>RecordWriter</code> writes the output &lt;key, value&gt; pairs 
+ to an output file.
+ 
+ <p><code>RecordWriter</code> implementations write the job outputs to the
+ {@link FileSystem}.
+ 
+ @see OutputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.RecordWriter -->
+  <!-- start interface org.apache.hadoop.mapreduce.ReduceContext -->
+  <interface name="ReduceContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.TaskInputOutputContext"/>
+    <method name="nextKey" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Start processing next unique key.]]>
+      </doc>
+    </method>
+    <method name="getValues" return="java.lang.Iterable"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Iterate through the values for the current key, reusing the same value 
+ object, which is stored in the context.
+ @return the series of values associated with the current key. All of the 
+ objects returned directly and indirectly from this method are reused.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The context passed to the {@link Reducer}.
+ @param <KEYIN> the class of the input keys
+ @param <VALUEIN> the class of the input values
+ @param <KEYOUT> the class of the output keys
+ @param <VALUEOUT> the class of the output values]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.ReduceContext -->
+  <!-- start class org.apache.hadoop.mapreduce.Reducer -->
+  <class name="Reducer" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Reducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Called once at the start of the task.]]>
+      </doc>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="key" type="KEYIN"/>
+      <param name="values" type="java.lang.Iterable"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[This method is called once for each key. Most applications will define
+ their reduce class by overriding this method. The default implementation
+ is an identity function.]]>
+      </doc>
+    </method>
+    <method name="cleanup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Called once at the end of the task.]]>
+      </doc>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Advanced application writers can use the 
+ {@link #run(org.apache.hadoop.mapreduce.Reducer.Context)} method to
+ control how the reduce task works.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Reduces a set of intermediate values which share a key to a smaller set of
+ values.  
+ 
+ <p><code>Reducer</code> implementations 
+ can access the {@link Configuration} for the job via the 
+ {@link JobContext#getConfiguration()} method.</p>
+
+ <p><code>Reducer</code> has 3 primary phases:</p>
+ <ol>
+   <li>
+   
+   <b id="Shuffle">Shuffle</b>
+   
+   <p>The <code>Reducer</code> copies the sorted output from each 
+   {@link Mapper} using HTTP across the network.</p>
+   </li>
+   
+   <li>
+   <b id="Sort">Sort</b>
+   
+   <p>The framework merge sorts <code>Reducer</code> inputs by 
+   <code>key</code>s 
+   (since different <code>Mapper</code>s may have output the same key).</p>
+   
+   <p>The shuffle and sort phases occur simultaneously i.e. while outputs are
+   being fetched they are merged.</p>
+      
+   <b id="SecondarySort">SecondarySort</b>
+   
+   <p>To achieve a secondary sort on the values returned by the value 
+   iterator, the application should extend the key with the secondary
+   key and define a grouping comparator. The keys will be sorted using the
+   entire key, but will be grouped using the grouping comparator to decide
+   which keys and values are sent in the same call to reduce.The grouping 
+   comparator is specified via 
+   {@link Job#setGroupingComparatorClass(Class)}. The sort order is
+   controlled by 
+   {@link Job#setSortComparatorClass(Class)}.</p>
+   
+   
+   For example, say that you want to find duplicate web pages and tag them 
+   all with the url of the "best" known example. You would set up the job 
+   like:
+   <ul>
+     <li>Map Input Key: url</li>
+     <li>Map Input Value: document</li>
+     <li>Map Output Key: document checksum, url pagerank</li>
+     <li>Map Output Value: url</li>
+     <li>Partitioner: by checksum</li>
+     <li>OutputKeyComparator: by checksum and then decreasing pagerank</li>
+     <li>OutputValueGroupingComparator: by checksum</li>
+   </ul>
+   </li>
+   
+   <li>   
+   <b id="Reduce">Reduce</b>
+   
+   <p>In this phase the 
+   {@link #reduce(Object, Iterable, org.apache.hadoop.mapreduce.Reducer.Context)}
+   method is called for each <code>&lt;key, (collection of values)&gt;</code> in
+   the sorted inputs.</p>
+   <p>The output of the reduce task is typically written to a 
+   {@link RecordWriter} via 
+   {@link Context#write(Object, Object)}.</p>
+   </li>
+ </ol>
+ 
+ <p>The output of the <code>Reducer</code> is <b>not re-sorted</b>.</p>
+ 
+ <p>Example:</p>
+ <p><blockquote><pre>
+ public class IntSumReducer&lt;Key&gt; extends Reducer&lt;Key,IntWritable,
+                                                 Key,IntWritable&gt; {
+   private IntWritable result = new IntWritable();
+ 
+   public void reduce(Key key, Iterable&lt;IntWritable&gt; values,
+                      Context context) throws IOException, InterruptedException {
+     int sum = 0;
+     for (IntWritable val : values) {
+       sum += val.get();
+     }
+     result.set(sum);
+     context.write(key, result);
+   }
+ }
+ </pre></blockquote>
+ 
+ @see Mapper
+ @see Partitioner]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.Reducer -->
+  <!-- start interface org.apache.hadoop.mapreduce.TaskAttemptContext -->
+  <interface name="TaskAttemptContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.JobContext"/>
+    <implements name="org.apache.hadoop.util.Progressable"/>
+    <method name="getTaskAttemptID" return="org.apache.hadoop.mapreduce.TaskAttemptID"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the unique name for this task attempt.]]>
+      </doc>
+    </method>
+    <method name="setStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="msg" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the current status of the task to the given string.]]>
+      </doc>
+    </method>
+    <method name="getStatus" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the last set status message.
+ @return the current status message]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The current progress of the task attempt.
+ @return a number between 0.0 and 1.0 (inclusive) indicating the attempt's
+ progress.]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="org.apache.hadoop.mapreduce.Counter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.Enum"/>
+      <doc>
+      <![CDATA[Get the {@link Counter} for the given <code>counterName</code>.
+ @param counterName counter name
+ @return the <code>Counter</code> for the given <code>counterName</code>]]>
+      </doc>
+    </method>
+    <method name="getCounter" return="org.apache.hadoop.mapreduce.Counter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="groupName" type="java.lang.String"/>
+      <param name="counterName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get the {@link Counter} for the given <code>groupName</code> and 
+ <code>counterName</code>.
+ @param counterName counter name
+ @return the <code>Counter</code> for the given <code>groupName</code> and 
+         <code>counterName</code>]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The context for task attempts.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.TaskAttemptContext -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskAttemptID -->
+  <class name="TaskAttemptID" extends="org.apache.hadoop.mapred.ID"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TaskAttemptID" type="org.apache.hadoop.mapreduce.TaskID, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskAttemptID object from given {@link TaskID}.  
+ @param taskId TaskID that this task belongs to  
+ @param id the task attempt number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskAttemptID" type="java.lang.String, int, org.apache.hadoop.mapreduce.TaskType, int, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskId object from given parts.
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number 
+ @param type the TaskType 
+ @param taskId taskId number
+ @param id the task attempt number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskAttemptID" type="java.lang.String, int, boolean, int, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskId object from given parts.
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number
+ @param isMap whether the tip is a map
+ @param taskId taskId number
+ @param id the task attempt number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskAttemptID"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getJobID" return="org.apache.hadoop.mapreduce.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the {@link JobID} object that this task attempt belongs to]]>
+      </doc>
+    </method>
+    <method name="getTaskID" return="org.apache.hadoop.mapreduce.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the {@link TaskID} object that this task attempt belongs to]]>
+      </doc>
+    </method>
+    <method name="isMap" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns whether this TaskID is a map ID]]>
+      </doc>
+    </method>
+    <method name="getTaskType" return="org.apache.hadoop.mapreduce.TaskType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the TaskType of the TaskAttemptID]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="appendTo" return="java.lang.StringBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="builder" type="java.lang.StringBuilder"/>
+      <doc>
+      <![CDATA[Add the unique string to the StringBuilder
+ @param builder the builder to append ot
+ @return the builder that was passed in.]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="org.apache.hadoop.mapreduce.ID"/>
+      <doc>
+      <![CDATA[Compare TaskIds by first tipIds, then by task numbers.]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="forName" return="org.apache.hadoop.mapreduce.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="str" type="java.lang.String"/>
+      <exception name="IllegalArgumentException" type="java.lang.IllegalArgumentException"/>
+      <doc>
+      <![CDATA[Construct a TaskAttemptID object from given string 
+ @return constructed TaskAttemptID object or null if the given String is null
+ @throws IllegalArgumentException if the given string is malformed]]>
+      </doc>
+    </method>
+    <field name="ATTEMPT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[TaskAttemptID represents the immutable and unique identifier for 
+ a task attempt. Each task attempt is one particular instance of a Map or
+ Reduce Task identified by its TaskID. 
+ 
+ TaskAttemptID consists of 2 parts. First part is the 
+ {@link TaskID}, that this TaskAttemptID belongs to.
+ Second part is the task attempt number. <br> 
+ An example TaskAttemptID is : 
+ <code>attempt_200707121733_0003_m_000005_0</code> , which represents the
+ zeroth task attempt for the fifth map task in the third job 
+ running at the jobtracker started at <code>200707121733</code>.
+ <p>
+ Applications should never construct or parse TaskAttemptID strings
+ , but rather use appropriate constructors or {@link #forName(String)} 
+ method. 
+ 
+ @see JobID
+ @see TaskID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskAttemptID -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskCompletionEvent -->
+  <class name="TaskCompletionEvent" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="TaskCompletionEvent"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor for Writable.]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskCompletionEvent" type="int, org.apache.hadoop.mapreduce.TaskAttemptID, int, boolean, org.apache.hadoop.mapreduce.TaskCompletionEvent.Status, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructor. eventId should be created externally and incremented
+ per event for each job. 
+ @param eventId event id, event id should be unique and assigned in
+  incrementally, starting from 0. 
+ @param taskId task id
+ @param status task's status 
+ @param taskTrackerHttp task tracker's host:port for http.]]>
+      </doc>
+    </constructor>
+    <method name="getEventId" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns event Id. 
+ @return event id]]>
+      </doc>
+    </method>
+    <method name="getTaskAttemptId" return="org.apache.hadoop.mapreduce.TaskAttemptID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns task id. 
+ @return task id]]>
+      </doc>
+    </method>
+    <method name="getStatus" return="org.apache.hadoop.mapreduce.TaskCompletionEvent.Status"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns {@link Status}
+ @return task completion status]]>
+      </doc>
+    </method>
+    <method name="getTaskTrackerHttp" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[http location of the tasktracker where this task ran. 
+ @return http location of tasktracker user logs]]>
+      </doc>
+    </method>
+    <method name="getTaskRunTime" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns time (in millisec) the task took to complete.]]>
+      </doc>
+    </method>
+    <method name="setTaskRunTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="taskCompletionTime" type="int"/>
+      <doc>
+      <![CDATA[Set the task completion time
+ @param taskCompletionTime time (in millisec) the task took to complete]]>
+      </doc>
+    </method>
+    <method name="setEventId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="eventId" type="int"/>
+      <doc>
+      <![CDATA[set event Id. should be assigned incrementally starting from 0. 
+ @param eventId]]>
+      </doc>
+    </method>
+    <method name="setTaskAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="taskId" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <doc>
+      <![CDATA[Sets task id. 
+ @param taskId]]>
+      </doc>
+    </method>
+    <method name="setTaskStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="status" type="org.apache.hadoop.mapreduce.TaskCompletionEvent.Status"/>
+      <doc>
+      <![CDATA[Set task status. 
+ @param status]]>
+      </doc>
+    </method>
+    <method name="setTaskTrackerHttp"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="taskTrackerHttp" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set task tracker http location. 
+ @param taskTrackerHttp]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isMapTask" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="idWithinJob" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="EMPTY_ARRAY" type="org.apache.hadoop.mapreduce.TaskCompletionEvent[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This is used to track task completion events on 
+ job tracker.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskCompletionEvent -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskCompletionEvent.Status -->
+  <class name="TaskCompletionEvent.Status" extends="java.lang.Enum"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.TaskCompletionEvent.Status[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.TaskCompletionEvent.Status"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskCompletionEvent.Status -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskCounter -->
+  <class name="TaskCounter" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.TaskCounter[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.TaskCounter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskCounter -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskID -->
+  <class name="TaskID" extends="org.apache.hadoop.mapred.ID"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TaskID" type="org.apache.hadoop.mapreduce.JobID, org.apache.hadoop.mapreduce.TaskType, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskID object from given {@link JobID}.
+
+ @param jobId JobID that this tip belongs to 
+ @param type the {@link TaskType} of the task 
+ @param id the tip number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID" type="java.lang.String, int, org.apache.hadoop.mapreduce.TaskType, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskInProgressId object from given parts.
+
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number 
+ @param type the TaskType 
+ @param id the tip number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID" type="org.apache.hadoop.mapreduce.JobID, boolean, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskID object from given {@link JobID}.
+
+ @param jobId JobID that this tip belongs to
+ @param isMap whether the tip is a map
+ @param id the tip number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID" type="java.lang.String, int, boolean, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a TaskInProgressId object from given parts.
+
+ @param jtIdentifier jobTracker identifier
+ @param jobId job number
+ @param isMap whether the tip is a map
+ @param id the tip number]]>
+      </doc>
+    </constructor>
+    <constructor name="TaskID"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor for Writable. Sets the task type to
+ {@link TaskType#REDUCE}, the ID to 0, and the job ID to an empty job ID.]]>
+      </doc>
+    </constructor>
+    <method name="getJobID" return="org.apache.hadoop.mapreduce.JobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the {@link JobID} object that this tip belongs to.
+
+ @return the JobID object]]>
+      </doc>
+    </method>
+    <method name="isMap" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns whether this TaskID is a map ID.
+
+ @return whether this TaskID is a map ID]]>
+      </doc>
+    </method>
+    <method name="getTaskType" return="org.apache.hadoop.mapreduce.TaskType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the type of the task.
+
+ @return the type of the task]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="org.apache.hadoop.mapreduce.ID"/>
+      <doc>
+      <![CDATA[Compare TaskInProgressIds by first jobIds, then by tip numbers.
+ Reducers are defined as greater than mappers.
+
+ @param o the TaskID against which to compare
+ @return 0 if equal, positive if this TaskID is greater, and negative if
+ this TaskID is less]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="appendTo" return="java.lang.StringBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="builder" type="java.lang.StringBuilder"/>
+      <doc>
+      <![CDATA[Add the unique string to the given builder.
+
+ @param builder the builder to append to
+ @return the builder that was passed in]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="forName" return="org.apache.hadoop.mapreduce.TaskID"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="str" type="java.lang.String"/>
+      <exception name="IllegalArgumentException" type="java.lang.IllegalArgumentException"/>
+      <doc>
+      <![CDATA[Construct a TaskID object from given string.
+
+ @param str the target string
+ @return constructed TaskID object or null if the given String is null
+ @throws IllegalArgumentException if the given string is malformed]]>
+      </doc>
+    </method>
+    <method name="getRepresentingCharacter" return="char"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="org.apache.hadoop.mapreduce.TaskType"/>
+      <doc>
+      <![CDATA[Gets the character representing the {@link TaskType}.
+
+ @param type the TaskType
+ @return the character]]>
+      </doc>
+    </method>
+    <method name="getTaskType" return="org.apache.hadoop.mapreduce.TaskType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="c" type="char"/>
+      <doc>
+      <![CDATA[Gets the {@link TaskType} corresponding to the character.
+
+ @param c the character
+ @return the TaskType]]>
+      </doc>
+    </method>
+    <method name="getAllTaskTypes" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns a string of characters describing all possible {@link TaskType}
+ values
+
+ @return a string of all task type characters]]>
+      </doc>
+    </method>
+    <field name="TASK" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="idFormat" type="java.text.NumberFormat"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="TASK_ID_REGEX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="taskIdPattern" type="java.util.regex.Pattern"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[TaskID represents the immutable and unique identifier for 
+ a Map or Reduce Task. Each TaskID encompasses multiple attempts made to
+ execute the Map or Reduce Task, each of which are uniquely indentified by
+ their TaskAttemptID.
+ 
+ TaskID consists of 3 parts. First part is the {@link JobID}, that this 
+ TaskInProgress belongs to. Second part of the TaskID is either 'm' or 'r' 
+ representing whether the task is a map task or a reduce task. 
+ And the third part is the task number. <br> 
+ An example TaskID is : 
+ <code>task_200707121733_0003_m_000005</code> , which represents the
+ fifth map task in the third job running at the jobtracker 
+ started at <code>200707121733</code>. 
+ <p>
+ Applications should never construct or parse TaskID strings
+ , but rather use appropriate constructors or {@link #forName(String)} 
+ method. 
+ 
+ @see JobID
+ @see TaskAttemptID]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskID -->
+  <!-- start interface org.apache.hadoop.mapreduce.TaskInputOutputContext -->
+  <interface name="TaskInputOutputContext"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+    <method name="nextKeyValue" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Advance to the next key, value pair, returning null if at end.
+ @return the key object that was read into, or null if no more]]>
+      </doc>
+    </method>
+    <method name="getCurrentKey" return="KEYIN"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the current key.
+ @return the current key object or null if there isn't one
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="getCurrentValue" return="VALUEIN"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the current value.
+ @return the value object that was read into
+ @throws IOException
+ @throws InterruptedException]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="KEYOUT"/>
+      <param name="value" type="VALUEOUT"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Generate an output key/value pair.]]>
+      </doc>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link OutputCommitter} for the task-attempt.
+ @return the <code>OutputCommitter</code> for the task-attempt]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A context object that allows input and output from the task. It is only
+ supplied to the {@link Mapper} or {@link Reducer}.
+ @param <KEYIN> the input key type for the task
+ @param <VALUEIN> the input value type for the task
+ @param <KEYOUT> the output key type for the task
+ @param <VALUEOUT> the output value type for the task]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.TaskInputOutputContext -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskTrackerInfo -->
+  <class name="TaskTrackerInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="TaskTrackerInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TaskTrackerInfo" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TaskTrackerInfo" type="java.lang.String, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getTaskTrackerName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets the tasktracker's name.
+ 
+ @return tracker's name.]]>
+      </doc>
+    </method>
+    <method name="isBlacklisted" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether tracker is blacklisted
+ @return true if tracker is blacklisted
+         false otherwise]]>
+      </doc>
+    </method>
+    <method name="getReasonForBlacklist" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets the reason for which the tasktracker was blacklisted.
+ 
+ @return reason which tracker was blacklisted]]>
+      </doc>
+    </method>
+    <method name="getBlacklistReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Gets a descriptive report about why the tasktracker was blacklisted.
+ 
+ @return report describing why the tasktracker was blacklisted.]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Information about TaskTracker.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskTrackerInfo -->
+  <!-- start class org.apache.hadoop.mapreduce.TaskType -->
+  <class name="TaskType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.TaskType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.TaskType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enum for map, reduce, job-setup, job-cleanup, task-cleanup task types.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.TaskType -->
+</package>
+<package name="org.apache.hadoop.mapreduce.checkpoint">
+</package>
+<package name="org.apache.hadoop.mapreduce.counters">
+  <!-- start class org.apache.hadoop.mapreduce.counters.AbstractCounters -->
+  <class name="AbstractCounters" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <implements name="java.lang.Iterable"/>
+    <constructor name="AbstractCounters" type="org.apache.hadoop.mapreduce.counters.CounterGroupFactory"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AbstractCounters" type="org.apache.hadoop.mapreduce.counters.AbstractCounters, org.apache.hadoop.mapreduce.counters.CounterGroupFactory"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct from another counters object.
+ @param <C1> type of the other counter
+ @param <G1> type of the other counter group
+ @param counters the counters object to copy
+ @param groupFactory the factory for new groups]]>
+      </doc>
+    </constructor>
+    <method name="findCounter" return="C"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="groupName" type="java.lang.String"/>
+      <param name="counterName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Find a counter, create one if necessary
+ @param groupName of the counter
+ @param counterName name of the counter
+ @return the matching counter]]>
+      </doc>
+    </method>
+    <method name="findCounter" return="C"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Enum"/>
+      <doc>
+      <![CDATA[Find the counter for the given enum. The same enum will always return the
+ same counter.
+ @param key the counter key
+ @return the matching counter object]]>
+      </doc>
+    </method>
+    <method name="getGroupNames" return="java.lang.Iterable"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the names of all counter classes.
+ @return Set of counter names.]]>
+      </doc>
+    </method>
+    <method name="iterator" return="java.util.Iterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getGroup" return="G"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="groupName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns the named counter group, or an empty group if there is none
+ with the specified name.
+ @param groupName name of the group
+ @return the group]]>
+      </doc>
+    </method>
+    <method name="countCounters" return="int"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the total number of counters, by summing the number of counters
+ in each group.
+ @return the total number of counters]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Write the set of groups.
+ Counters ::= version #fgroups (groupId, group)* #groups (group)*]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return textual representation of the counter values.
+ @return the string]]>
+      </doc>
+    </method>
+    <method name="incrAllCounters"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.mapreduce.counters.AbstractCounters"/>
+      <doc>
+      <![CDATA[Increments multiple counters by their amounts in another Counters
+ instance.
+ @param other the other Counters instance]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericRight" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An abstract class to provide common implementation for the Counters
+ container in both mapred and mapreduce packages.
+
+ @param <C> type of counter inside the counters
+ @param <G> type of group inside the counters]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.counters.AbstractCounters -->
+  <!-- start interface org.apache.hadoop.mapreduce.counters.CounterGroupBase -->
+  <interface name="CounterGroupBase"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <implements name="java.lang.Iterable"/>
+    <method name="getName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the internal name of the group
+ @return the internal name]]>
+      </doc>
+    </method>
+    <method name="getDisplayName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the display name of the group.
+ @return the human readable name]]>
+      </doc>
+    </method>
+    <method name="setDisplayName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="displayName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the display name of the group
+ @param displayName of the group]]>
+      </doc>
+    </method>
+    <method name="addCounter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counter" type="T"/>
+      <doc>
+      <![CDATA[Add a counter to this group.
+ @param counter to add]]>
+      </doc>
+    </method>
+    <method name="addCounter" return="T"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <param name="displayName" type="java.lang.String"/>
+      <param name="value" type="long"/>
+      <doc>
+      <![CDATA[Add a counter to this group
+ @param name  of the counter
+ @param displayName of the counter
+ @param value of the counter
+ @return the counter]]>
+      </doc>
+    </method>
+    <method name="findCounter" return="T"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+      <param name="displayName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Find a counter in the group.
+ @param counterName the name of the counter
+ @param displayName the display name of the counter
+ @return the counter that was found or added]]>
+      </doc>
+    </method>
+    <method name="findCounter" return="T"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+      <param name="create" type="boolean"/>
+      <doc>
+      <![CDATA[Find a counter in the group
+ @param counterName the name of the counter
+ @param create create the counter if not found if true
+ @return the counter that was found or added or null if create is false]]>
+      </doc>
+    </method>
+    <method name="findCounter" return="T"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="counterName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Find a counter in the group.
+ @param counterName the name of the counter
+ @return the counter that was found or added]]>
+      </doc>
+    </method>
+    <method name="size" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the number of counters in this group.]]>
+      </doc>
+    </method>
+    <method name="incrAllCounters"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rightGroup" type="org.apache.hadoop.mapreduce.counters.CounterGroupBase"/>
+      <doc>
+      <![CDATA[Increment all counters by a group of counters
+ @param rightGroup  the group to be added to this group]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The common counter group interface.
+
+ @param <T> type of the counter for the group]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.counters.CounterGroupBase -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.aggregate">
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum -->
+  <class name="DoubleValueSum" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="DoubleValueSum"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default constructor]]>
+      </doc>
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          an object whose string representation represents a double value.]]>
+      </doc>
+    </method>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="double"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          a double value.]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the aggregated value]]>
+      </doc>
+    </method>
+    <method name="getSum" return="double"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the aggregated value]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of one element. The element is a string
+         representation of the aggregated value. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that sums up a sequence of double
+ values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.DoubleValueSum -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax -->
+  <class name="LongValueMax" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="LongValueMax"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          an object whose string representation represents a long value.]]>
+      </doc>
+    </method>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="newVal" type="long"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param newVal
+          a long value.]]>
+      </doc>
+    </method>
+    <method name="getVal" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the aggregated value]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the aggregated value]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of one element. The element is a string
+         representation of the aggregated value. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the maximum of 
+ a sequence of long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.LongValueMax -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin -->
+  <class name="LongValueMin" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="LongValueMin"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          an object whose string representation represents a long value.]]>
+      </doc>
+    </method>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="newVal" type="long"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param newVal
+          a long value.]]>
+      </doc>
+    </method>
+    <method name="getVal" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the aggregated value]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the aggregated value]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of one element. The element is a string
+         representation of the aggregated value. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the minimum of 
+ a sequence of long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.LongValueMin -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum -->
+  <class name="LongValueSum" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="LongValueSum"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          an object whose string representation represents a long value.]]>
+      </doc>
+    </method>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="long"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          a long value.]]>
+      </doc>
+    </method>
+    <method name="getSum" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the aggregated value]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the aggregated value]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of one element. The element is a string
+         representation of the aggregated value. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that sums up 
+ a sequence of long values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.LongValueSum -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax -->
+  <class name="StringValueMax" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="StringValueMax"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          a string.]]>
+      </doc>
+    </method>
+    <method name="getVal" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the aggregated value]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the aggregated value]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of one element. The element is a string
+         representation of the aggregated value. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the biggest of 
+ a sequence of strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.StringValueMax -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin -->
+  <class name="StringValueMin" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="StringValueMin"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          a string.]]>
+      </doc>
+    </method>
+    <method name="getVal" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the aggregated value]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the aggregated value]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of one element. The element is a string
+         representation of the aggregated value. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that maintain the smallest of 
+ a sequence of strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.StringValueMin -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount -->
+  <class name="UniqValueCount" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="UniqValueCount"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the default constructor]]>
+      </doc>
+    </constructor>
+    <constructor name="UniqValueCount" type="long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[constructor
+ @param maxNum the limit in the number of unique values to keep.]]>
+      </doc>
+    </constructor>
+    <method name="setMaxItems" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="n" type="long"/>
+      <doc>
+      <![CDATA[Set the limit on the number of unique values
+ @param n the desired limit on the number of unique values
+ @return the new limit on the number of unique values]]>
+      </doc>
+    </method>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val
+          an object.]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return the number of unique objects aggregated]]>
+      </doc>
+    </method>
+    <method name="getUniqueItems" return="java.util.Set"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the set of the unique objects]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return return an array of the unique objects. The return value is
+         expected to be used by the a combiner.]]>
+      </doc>
+    </method>
+    <field name="MAX_NUM_UNIQUE_VALUES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements a value aggregator that dedupes a sequence of objects.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.UniqValueCount -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor -->
+  <class name="UserDefinedValueAggregatorDescriptor" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor"/>
+    <constructor name="UserDefinedValueAggregatorDescriptor" type="java.lang.String, org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@param className the class name of the user defined descriptor class
+ @param conf a configure object used for decriptor configuration]]>
+      </doc>
+    </constructor>
+    <method name="createInstance" return="java.lang.Object"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="className" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Create an instance of the given class
+ @param className the name of the class
+ @return a dynamically created instance of the given class]]>
+      </doc>
+    </method>
+    <method name="generateKeyValPairs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Object"/>
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Generate a list of aggregation-id/value pairs for the given 
+   key/value pairs by delegating the invocation to the real object.
+   
+ @param key
+          input key
+ @param val
+          input value
+ @return a list of aggregation id/value pairs. An aggregation id encodes an
+         aggregation type which is used to guide the way to aggregate the
+         value in the reduce/combiner phrase of an Aggregate based job.]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of this object.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Do nothing.]]>
+      </doc>
+    </method>
+    <field name="theAggregatorDescriptor" type="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements a wrapper for a user defined value 
+ aggregator descriptor.
+ It serves two functions: One is to create an object of 
+ ValueAggregatorDescriptor from the name of a user defined class
+ that may be dynamically loaded. The other is to
+ delegate invocations of generateKeyValPairs function to the created object.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.UserDefinedValueAggregatorDescriptor -->
+  <!-- start interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator -->
+  <interface name="ValueAggregator"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="addNextValue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add a value to the aggregator
+ 
+ @param val the value to be added]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of the agregator]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return an array of values as the outputs of the combiner.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This interface defines the minimal protocol for value aggregators.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor -->
+  <class name="ValueAggregatorBaseDescriptor" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor"/>
+    <constructor name="ValueAggregatorBaseDescriptor"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="generateEntry" return="java.util.Map.Entry"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="id" type="java.lang.String"/>
+      <param name="val" type="org.apache.hadoop.io.Text"/>
+      <doc>
+      <![CDATA[@param type the aggregation type
+ @param id the aggregation id
+ @param val the val associated with the id to be aggregated
+ @return an Entry whose key is the aggregation id prefixed with 
+ the aggregation type.]]>
+      </doc>
+    </method>
+    <method name="generateValueAggregator" return="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="uniqCount" type="long"/>
+      <doc>
+      <![CDATA[@param type the aggregation type
+ @param uniqCount the limit in the number of unique values to keep, 
+                  if type is UNIQ_VALUE_COUNT 
+ @return a value aggregator of the given type.]]>
+      </doc>
+    </method>
+    <method name="generateKeyValPairs" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Object"/>
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Generate 1 or 2 aggregation-id/value pairs for the given key/value pair.
+ The first id will be of type LONG_VALUE_SUM, with "record_count" as
+ its aggregation id. If the input is a file split,
+ the second id of the same type will be generated too, with the file name 
+ as its aggregation id. This achieves the behavior of counting the total 
+ number of records in the input data, and the number of records 
+ in each input file.
+ 
+ @param key
+          input key
+ @param val
+          input value
+ @return a list of aggregation id/value pairs. An aggregation id encodes an
+         aggregation type which is used to guide the way to aggregate the
+         value in the reduce/combiner phrase of an Aggregate based job.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[get the input file name.
+ 
+ @param conf a configuration object]]>
+      </doc>
+    </method>
+    <field name="UNIQ_VALUE_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LONG_VALUE_SUM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DOUBLE_VALUE_SUM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="VALUE_HISTOGRAM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LONG_VALUE_MAX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LONG_VALUE_MIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="STRING_VALUE_MAX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="STRING_VALUE_MIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="inputFile" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements the common functionalities of 
+ the subclasses of ValueAggregatorDescriptor class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorBaseDescriptor -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner -->
+  <class name="ValueAggregatorCombiner" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorCombiner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="values" type="java.lang.Iterable"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Combines values for a given key.  
+ @param key the key is expected to be a Text object, whose prefix indicates
+ the type of aggregation to aggregate the values. 
+ @param values the values to combine
+ @param context to collect combined values]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements the generic combiner of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorCombiner -->
+  <!-- start interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor -->
+  <interface name="ValueAggregatorDescriptor"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="generateKeyValPairs" return="java.util.ArrayList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Object"/>
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Generate a list of aggregation-id/value pairs for 
+ the given key/value pair.
+ This function is usually called by the mapper of an Aggregate based job.
+ 
+ @param key
+          input key
+ @param val
+          input value
+ @return a list of aggregation id/value pairs. An aggregation id encodes an
+         aggregation type which is used to guide the way to aggregate the
+         value in the reduce/combiner phrase of an Aggregate based job.]]>
+      </doc>
+    </method>
+    <method name="configure"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Configure the object
+ 
+ @param conf
+          a Configuration object that may contain the information 
+          that can be used to configure the object.]]>
+      </doc>
+    </method>
+    <field name="TYPE_SEPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ONE" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This interface defines the contract a value aggregator descriptor must
+ support. Such a descriptor can be configured with a {@link Configuration}
+ object. Its main function is to generate a list of aggregation-id/value 
+ pairs. An aggregation id encodes an aggregation type which is used to 
+ guide the way to aggregate the value in the reduce/combiner phrase of an
+ Aggregate based job. 
+ The mapper in an Aggregate based map/reduce job may create one or more of
+ ValueAggregatorDescriptor objects at configuration time. For each input
+ key/value pair, the mapper will use those objects to create aggregation
+ id/value pairs.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob -->
+  <class name="ValueAggregatorJob" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorJob"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createValueAggregatorJobs" return="org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <param name="descriptors" type="java.lang.Class[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createValueAggregatorJobs" return="org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createValueAggregatorJob" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create an Aggregate based map/reduce job.
+ 
+ @param conf The configuration for job
+ @param args the arguments used for job creation. Generic hadoop
+ arguments are accepted.
+ @return a Job object ready for submission.
+ 
+ @throws IOException
+ @see GenericOptionsParser]]>
+      </doc>
+    </method>
+    <method name="createValueAggregatorJob" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <param name="descriptors" type="java.lang.Class[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setAggregatorDescriptors" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="descriptors" type="java.lang.Class[]"/>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <doc>
+      <![CDATA[create and run an Aggregate based map/reduce job.
+ 
+ @param args the arguments used for job creation
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This is the main class for creating a map/reduce job using Aggregate
+ framework. The Aggregate is a specialization of map/reduce framework,
+ specializing for performing various simple aggregations.
+ 
+ Generally speaking, in order to implement an application using Map/Reduce
+ model, the developer is to implement Map and Reduce functions (and possibly
+ combine function). However, a lot of applications related to counting and
+ statistics computing have very similar characteristics. Aggregate abstracts
+ out the general patterns of these functions and implementing those patterns.
+ In particular, the package provides generic mapper/redducer/combiner 
+ classes, and a set of built-in value aggregators, and a generic utility 
+ class that helps user create map/reduce jobs using the generic class. 
+ The built-in aggregators include:
+ 
+ sum over numeric values count the number of distinct values compute the
+ histogram of values compute the minimum, maximum, media,average, standard
+ deviation of numeric values
+ 
+ The developer using Aggregate will need only to provide a plugin class
+ conforming to the following interface:
+ 
+ public interface ValueAggregatorDescriptor { public ArrayList&lt;Entry&gt;
+ generateKeyValPairs(Object key, Object value); public void
+ configure(Configuration conf); }
+ 
+ The package also provides a base class, ValueAggregatorBaseDescriptor,
+ implementing the above interface. The user can extend the base class and
+ implement generateKeyValPairs accordingly.
+ 
+ The primary work of generateKeyValPairs is to emit one or more key/value
+ pairs based on the input key/value pair. The key in an output key/value pair
+ encode two pieces of information: aggregation type and aggregation id. The
+ value will be aggregated onto the aggregation id according the aggregation
+ type.
+ 
+ This class offers a function to generate a map/reduce job using Aggregate
+ framework. The function takes the following parameters: input directory spec
+ input format (text or sequence file) output directory a file specifying the
+ user plugin class]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJob -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase -->
+  <class name="ValueAggregatorJobBase" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorJobBase"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getValueAggregatorDescriptor" return="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorDescriptor"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="spec" type="java.lang.String"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getAggregatorDescriptors" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="logSpec"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <field name="DESCRIPTOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DESCRIPTOR_NUM" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="USER_JAR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="aggregatorDescriptorList" type="java.util.ArrayList"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This abstract class implements some common functionalities of the
+ the generic mapper, reducer and combiner classes of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper -->
+  <class name="ValueAggregatorMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K1"/>
+      <param name="value" type="V1"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[the map function. It iterates through the value aggregator descriptor 
+  list to generate aggregation id/value pairs and emit them.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements the generic mapper of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer -->
+  <class name="ValueAggregatorReducer" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ValueAggregatorReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="values" type="java.lang.Iterable"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[@param key
+        the key is expected to be a Text object, whose prefix indicates
+        the type of aggregation to aggregate the values. In effect, data
+        driven computing is achieved. It is assumed that each aggregator's
+        getReport method emits appropriate output for the aggregator. This
+        may be further customized.
+ @param values the values to be aggregated
+ @param context]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements the generic reducer of Aggregate.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorReducer -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram -->
+  <class name="ValueHistogram" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregator"/>
+    <constructor name="ValueHistogram"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addNextValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[add the given val to the aggregator.
+ 
+ @param val the value to be added. It is expected to be a string
+ in the form of xxxx\tnum, meaning xxxx has num occurrences.]]>
+      </doc>
+    </method>
+    <method name="getReport" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the string representation of this aggregator.
+ It includes the following basic statistics of the histogram:
+    the number of unique values
+    the minimum value
+    the media value
+    the maximum value
+    the average value
+    the standard deviation]]>
+      </doc>
+    </method>
+    <method name="getReportDetails" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return a string representation of the list of value/frequence pairs of 
+ the histogram]]>
+      </doc>
+    </method>
+    <method name="getCombinerOutput" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return a list value/frequence pairs.
+  The return value is expected to be used by the reducer.]]>
+      </doc>
+    </method>
+    <method name="getReportItems" return="java.util.TreeMap"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return a TreeMap representation of the histogram]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[reset the aggregator]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class implements a value aggregator that computes the 
+ histogram of a sequence of strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.aggregate.ValueHistogram -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.chain">
+  <!-- start class org.apache.hadoop.mapreduce.lib.chain.ChainMapper -->
+  <class name="ChainMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ChainMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addMapper"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="klass" type="java.lang.Class"/>
+      <param name="inputKeyClass" type="java.lang.Class"/>
+      <param name="inputValueClass" type="java.lang.Class"/>
+      <param name="outputKeyClass" type="java.lang.Class"/>
+      <param name="outputValueClass" type="java.lang.Class"/>
+      <param name="mapperConf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Adds a {@link Mapper} class to the chain mapper.
+ 
+ <p>
+ The key and values are passed from one element of the chain to the next, by
+ value. For the added Mapper the configuration given for it,
+ <code>mapperConf</code>, have precedence over the job's Configuration. This
+ precedence is in effect when the task is running.
+ </p>
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainMapper, this is done by the addMapper for the last mapper in the chain
+ </p>
+ 
+ @param job
+          The job.
+ @param klass
+          the Mapper class to add.
+ @param inputKeyClass
+          mapper input key class.
+ @param inputValueClass
+          mapper input value class.
+ @param outputKeyClass
+          mapper output key class.
+ @param outputValueClass
+          mapper output value class.
+ @param mapperConf
+          a configuration for the Mapper class. It is recommended to use a
+          Configuration without default values using the
+          <code>Configuration(boolean loadDefaults)</code> constructor with
+          FALSE.]]>
+      </doc>
+    </method>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <doc>
+    <![CDATA[The ChainMapper class allows to use multiple Mapper classes within a single
+ Map task.
+ 
+ <p>
+ The Mapper classes are invoked in a chained (or piped) fashion, the output of
+ the first becomes the input of the second, and so on until the last Mapper,
+ the output of the last Mapper will be written to the task's output.
+ </p>
+ <p>
+ The key functionality of this feature is that the Mappers in the chain do not
+ need to be aware that they are executed in a chain. This enables having
+ reusable specialized Mappers that can be combined to perform composite
+ operations within a single task.
+ </p>
+ <p>
+ Special care has to be taken when creating chains that the key/values output
+ by a Mapper are valid for the following Mapper in the chain. It is assumed
+ all Mappers and the Reduce in the chain use matching output and input key and
+ value classes as no conversion is done by the chaining code.
+ </p>
+ <p>
+ Using the ChainMapper and the ChainReducer classes is possible to compose
+ Map/Reduce jobs that look like <code>[MAP+ / REDUCE MAP*]</code>. And
+ immediate benefit of this pattern is a dramatic reduction in disk IO.
+ </p>
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainMapper, this is done by the addMapper for the last mapper in the chain.
+ </p>
+ ChainMapper usage pattern:
+ <p>
+ 
+ <pre>
+ ...
+ Job = new Job(conf);
+
+ Configuration mapAConf = new Configuration(false);
+ ...
+ ChainMapper.addMapper(job, AMap.class, LongWritable.class, Text.class,
+   Text.class, Text.class, true, mapAConf);
+
+ Configuration mapBConf = new Configuration(false);
+ ...
+ ChainMapper.addMapper(job, BMap.class, Text.class, Text.class,
+   LongWritable.class, Text.class, false, mapBConf);
+
+ ...
+
+ job.waitForComplettion(true);
+ ...
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.chain.ChainMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.chain.ChainReducer -->
+  <class name="ChainReducer" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ChainReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setReducer"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="klass" type="java.lang.Class"/>
+      <param name="inputKeyClass" type="java.lang.Class"/>
+      <param name="inputValueClass" type="java.lang.Class"/>
+      <param name="outputKeyClass" type="java.lang.Class"/>
+      <param name="outputValueClass" type="java.lang.Class"/>
+      <param name="reducerConf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Sets the {@link Reducer} class to the chain job.
+ 
+ <p>
+ The key and values are passed from one element of the chain to the next, by
+ value. For the added Reducer the configuration given for it,
+ <code>reducerConf</code>, have precedence over the job's Configuration.
+ This precedence is in effect when the task is running.
+ </p>
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainReducer, this is done by the setReducer or the addMapper for the last
+ element in the chain.
+ </p>
+ 
+ @param job
+          the job
+ @param klass
+          the Reducer class to add.
+ @param inputKeyClass
+          reducer input key class.
+ @param inputValueClass
+          reducer input value class.
+ @param outputKeyClass
+          reducer output key class.
+ @param outputValueClass
+          reducer output value class.
+ @param reducerConf
+          a configuration for the Reducer class. It is recommended to use a
+          Configuration without default values using the
+          <code>Configuration(boolean loadDefaults)</code> constructor with
+          FALSE.]]>
+      </doc>
+    </method>
+    <method name="addMapper"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="klass" type="java.lang.Class"/>
+      <param name="inputKeyClass" type="java.lang.Class"/>
+      <param name="inputValueClass" type="java.lang.Class"/>
+      <param name="outputKeyClass" type="java.lang.Class"/>
+      <param name="outputValueClass" type="java.lang.Class"/>
+      <param name="mapperConf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Adds a {@link Mapper} class to the chain reducer.
+ 
+ <p>
+ The key and values are passed from one element of the chain to the next, by
+ value For the added Mapper the configuration given for it,
+ <code>mapperConf</code>, have precedence over the job's Configuration. This
+ precedence is in effect when the task is running.
+ </p>
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainMapper, this is done by the addMapper for the last mapper in the
+ chain.
+ </p>
+ 
+ @param job
+          The job.
+ @param klass
+          the Mapper class to add.
+ @param inputKeyClass
+          mapper input key class.
+ @param inputValueClass
+          mapper input value class.
+ @param outputKeyClass
+          mapper output key class.
+ @param outputValueClass
+          mapper output value class.
+ @param mapperConf
+          a configuration for the Mapper class. It is recommended to use a
+          Configuration without default values using the
+          <code>Configuration(boolean loadDefaults)</code> constructor with
+          FALSE.]]>
+      </doc>
+    </method>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <doc>
+    <![CDATA[The ChainReducer class allows to chain multiple Mapper classes after a
+ Reducer within the Reducer task.
+ 
+ <p>
+ For each record output by the Reducer, the Mapper classes are invoked in a
+ chained (or piped) fashion. The output of the reducer becomes the input of
+ the first mapper and output of first becomes the input of the second, and so
+ on until the last Mapper, the output of the last Mapper will be written to
+ the task's output.
+ </p>
+ <p>
+ The key functionality of this feature is that the Mappers in the chain do not
+ need to be aware that they are executed after the Reducer or in a chain. This
+ enables having reusable specialized Mappers that can be combined to perform
+ composite operations within a single task.
+ </p>
+ <p>
+ Special care has to be taken when creating chains that the key/values output
+ by a Mapper are valid for the following Mapper in the chain. It is assumed
+ all Mappers and the Reduce in the chain use matching output and input key and
+ value classes as no conversion is done by the chaining code.
+ </p>
+ <p> Using the ChainMapper and the ChainReducer classes is possible to
+ compose Map/Reduce jobs that look like <code>[MAP+ / REDUCE MAP*]</code>. And
+ immediate benefit of this pattern is a dramatic reduction in disk IO. </p>
+ <p>
+ IMPORTANT: There is no need to specify the output key/value classes for the
+ ChainReducer, this is done by the setReducer or the addMapper for the last
+ element in the chain.
+ </p>
+ ChainReducer usage pattern:
+ <p>
+ 
+ <pre>
+ ...
+ Job = new Job(conf);
+ ....
+
+ Configuration reduceConf = new Configuration(false);
+ ...
+ ChainReducer.setReducer(job, XReduce.class, LongWritable.class, Text.class,
+   Text.class, Text.class, true, reduceConf);
+
+ ChainReducer.addMapper(job, CMap.class, Text.class, Text.class,
+   LongWritable.class, Text.class, false, null);
+
+ ChainReducer.addMapper(job, DMap.class, LongWritable.class, Text.class,
+   LongWritable.class, LongWritable.class, true, null);
+
+ ...
+
+ job.waitForCompletion(true);
+ ...
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.chain.ChainReducer -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.db">
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter -->
+  <class name="BigDecimalSplitter" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.db.DBSplitter"/>
+    <constructor name="BigDecimalSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="split" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <method name="tryDivide" return="java.math.BigDecimal"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="numerator" type="java.math.BigDecimal"/>
+      <param name="denominator" type="java.math.BigDecimal"/>
+      <doc>
+      <![CDATA[Divide numerator by denominator. If impossible in exact mode, use rounding.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over BigDecimal values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.BooleanSplitter -->
+  <class name="BooleanSplitter" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.db.DBSplitter"/>
+    <constructor name="BooleanSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="split" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over boolean values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.BooleanSplitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat -->
+  <class name="DataDrivenDBInputFormat" extends="org.apache.hadoop.mapreduce.lib.db.DBInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="DataDrivenDBInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSplitter" return="org.apache.hadoop.mapreduce.lib.db.DBSplitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="sqlDataType" type="int"/>
+      <doc>
+      <![CDATA[@return the DBSplitter implementation to use to divide the table/query into InputSplits.]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getBoundingValsQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return a query which returns the minimum and maximum values for
+ the order-by column.
+
+ The min value should be in the first column, and the
+ max value should be in the second column of the results.]]>
+      </doc>
+    </method>
+    <method name="setBoundingQuery"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="query" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the user-defined bounding query to use with a user-defined query.
+      This *must* include the substring "$CONDITIONS"
+      (DataDrivenDBInputFormat.SUBSTITUTE_TOKEN) inside the WHERE clause,
+      so that DataDrivenDBInputFormat knows where to insert split clauses.
+      e.g., "SELECT foo FROM mytable WHERE $CONDITIONS"
+      This will be expanded to something like:
+        SELECT foo FROM mytable WHERE (id &gt; 100) AND (id &lt; 250)
+      inside each split.]]>
+      </doc>
+    </method>
+    <method name="createDBRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setInput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="inputClass" type="java.lang.Class"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="conditions" type="java.lang.String"/>
+      <param name="splitBy" type="java.lang.String"/>
+      <param name="fieldNames" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Note that the "orderBy" column is called the "splitBy" in this version.
+ We reuse the same field, but it's not strictly ordering it -- just partitioning
+ the results.]]>
+      </doc>
+    </method>
+    <method name="setInput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="inputClass" type="java.lang.Class"/>
+      <param name="inputQuery" type="java.lang.String"/>
+      <param name="inputBoundingQuery" type="java.lang.String"/>
+      <doc>
+      <![CDATA[setInput() takes a custom query and a separate "bounding query" to use
+      instead of the custom "count query" used by DBInputFormat.]]>
+      </doc>
+    </method>
+    <field name="SUBSTITUTE_TOKEN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[If users are providing their own query, the following string is expected to
+      appear in the WHERE clause, which will be substituted with a pair of conditions
+      on the input to allow input splits to parallelise the import.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A InputFormat that reads input data from an SQL table.
+ Operates like DBInputFormat, but instead of using LIMIT and OFFSET to demarcate
+ splits, it tries to generate WHERE clauses which separate the data into roughly
+ equivalent shards.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader -->
+  <class name="DataDrivenDBRecordReader" extends="org.apache.hadoop.mapreduce.lib.db.DBRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="DataDrivenDBRecordReader" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit, java.lang.Class, org.apache.hadoop.conf.Configuration, java.sql.Connection, org.apache.hadoop.mapreduce.lib.db.DBConfiguration, java.lang.String, java.lang.String[], java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[@param split The InputSplit to read data for
+ @throws SQLException]]>
+      </doc>
+    </constructor>
+    <method name="getSelectQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the query for selecting the records,
+ subclasses can override this for custom behaviour.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A RecordReader that reads records from a SQL table,
+ using data-driven WHERE clause splits.
+ Emits LongWritables containing the record number as
+ key and DBWritables as value.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DateSplitter -->
+  <class name="DateSplitter" extends="org.apache.hadoop.mapreduce.lib.db.IntegerSplitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="DateSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="split" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <method name="dateToString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="d" type="java.util.Date"/>
+      <doc>
+      <![CDATA[Given a Date 'd', format it as a string for use in a SQL date
+ comparison operation.
+ @param d the date to format.
+ @return the string representing this date in SQL with any appropriate
+ quotation characters, etc.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over date/time values.
+ Make use of logic from IntegerSplitter, since date/time are just longs
+ in Java.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DateSplitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DBConfiguration -->
+  <class name="DBConfiguration" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="DBConfiguration" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="configureDB"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="driverClass" type="java.lang.String"/>
+      <param name="dbUrl" type="java.lang.String"/>
+      <param name="userName" type="java.lang.String"/>
+      <param name="passwd" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets the DB access related fields in the {@link Configuration}.  
+ @param conf the configuration
+ @param driverClass JDBC Driver class name
+ @param dbUrl JDBC DB access URL. 
+ @param userName DB access username 
+ @param passwd DB access passwd]]>
+      </doc>
+    </method>
+    <method name="configureDB"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="driverClass" type="java.lang.String"/>
+      <param name="dbUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Sets the DB access related fields in the JobConf.  
+ @param job the job
+ @param driverClass JDBC Driver class name
+ @param dbUrl JDBC DB access URL.]]>
+      </doc>
+    </method>
+    <method name="getConnection" return="java.sql.Connection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[Returns a connection object o the DB 
+ @throws ClassNotFoundException 
+ @throws SQLException]]>
+      </doc>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getInputTableName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputTableName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="tableName" type="java.lang.String"/>
+    </method>
+    <method name="getInputFieldNames" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputFieldNames"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fieldNames" type="java.lang.String[]"/>
+    </method>
+    <method name="getInputConditions" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputConditions"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conditions" type="java.lang.String"/>
+    </method>
+    <method name="getInputOrderBy" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputOrderBy"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="orderby" type="java.lang.String"/>
+    </method>
+    <method name="getInputQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputQuery"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="query" type="java.lang.String"/>
+    </method>
+    <method name="getInputCountQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputCountQuery"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="query" type="java.lang.String"/>
+    </method>
+    <method name="setInputBoundingQuery"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="query" type="java.lang.String"/>
+    </method>
+    <method name="getInputBoundingQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getInputClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInputClass"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="inputClass" type="java.lang.Class"/>
+    </method>
+    <method name="getOutputTableName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setOutputTableName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="tableName" type="java.lang.String"/>
+    </method>
+    <method name="getOutputFieldNames" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setOutputFieldNames"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fieldNames" type="java.lang.String[]"/>
+    </method>
+    <method name="setOutputFieldCount"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fieldCount" type="int"/>
+    </method>
+    <method name="getOutputFieldCount" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="DRIVER_CLASS_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The JDBC Driver class name]]>
+      </doc>
+    </field>
+    <field name="URL_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[JDBC Database access URL]]>
+      </doc>
+    </field>
+    <field name="USERNAME_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[User name to access the database]]>
+      </doc>
+    </field>
+    <field name="PASSWORD_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Password to access the database]]>
+      </doc>
+    </field>
+    <field name="INPUT_TABLE_NAME_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Input table name]]>
+      </doc>
+    </field>
+    <field name="INPUT_FIELD_NAMES_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Field names in the Input table]]>
+      </doc>
+    </field>
+    <field name="INPUT_CONDITIONS_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[WHERE clause in the input SELECT statement]]>
+      </doc>
+    </field>
+    <field name="INPUT_ORDER_BY_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[ORDER BY clause in the input SELECT statement]]>
+      </doc>
+    </field>
+    <field name="INPUT_QUERY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whole input query, exluding LIMIT...OFFSET]]>
+      </doc>
+    </field>
+    <field name="INPUT_COUNT_QUERY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Input query to get the count of records]]>
+      </doc>
+    </field>
+    <field name="INPUT_BOUNDING_QUERY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Input query to get the max and min values of the jdbc.input.query]]>
+      </doc>
+    </field>
+    <field name="INPUT_CLASS_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Class name implementing DBWritable which will hold input tuples]]>
+      </doc>
+    </field>
+    <field name="OUTPUT_TABLE_NAME_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Output table name]]>
+      </doc>
+    </field>
+    <field name="OUTPUT_FIELD_NAMES_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Field names in the Output table]]>
+      </doc>
+    </field>
+    <field name="OUTPUT_FIELD_COUNT_PROPERTY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of fields in the Output table]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A container for configuration property names for jobs with DB input/output.
+  
+ The job can be configured using the static methods in this class, 
+ {@link DBInputFormat}, and {@link DBOutputFormat}. 
+ Alternatively, the properties can be set in the configuration with proper
+ values. 
+   
+ @see DBConfiguration#configureDB(Configuration, String, String, String, String)
+ @see DBInputFormat#setInput(Job, Class, String, String)
+ @see DBInputFormat#setInput(Job, Class, String, String, String, String...)
+ @see DBOutputFormat#setOutput(Job, String, String...)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DBConfiguration -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DBInputFormat -->
+  <class name="DBInputFormat" extends="org.apache.hadoop.mapreduce.InputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="DBInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDBConf" return="org.apache.hadoop.mapreduce.lib.db.DBConfiguration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getConnection" return="java.sql.Connection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createConnection" return="java.sql.Connection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDBProductName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="createDBRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getCountQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the query for getting the total number of rows, 
+ subclasses can override this for custom behaviour.]]>
+      </doc>
+    </method>
+    <method name="setInput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="inputClass" type="java.lang.Class"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="conditions" type="java.lang.String"/>
+      <param name="orderBy" type="java.lang.String"/>
+      <param name="fieldNames" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Initializes the map-part of the job with the appropriate input settings.
+ 
+ @param job The map-reduce job
+ @param inputClass the class object implementing DBWritable, which is the 
+ Java object holding tuple fields.
+ @param tableName The table to read data from
+ @param conditions The condition which to select data with, 
+ eg. '(updated &gt; 20070101 AND length &gt; 0)'
+ @param orderBy the fieldNames in the orderBy clause.
+ @param fieldNames The field names in the table
+ @see #setInput(Job, Class, String, String)]]>
+      </doc>
+    </method>
+    <method name="setInput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="inputClass" type="java.lang.Class"/>
+      <param name="inputQuery" type="java.lang.String"/>
+      <param name="inputCountQuery" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Initializes the map-part of the job with the appropriate input settings.
+ 
+ @param job The map-reduce job
+ @param inputClass the class object implementing DBWritable, which is the 
+ Java object holding tuple fields.
+ @param inputQuery the input query to select fields. Example : 
+ "SELECT f1, f2, f3 FROM Mytable ORDER BY f1"
+ @param inputCountQuery the input query that returns 
+ the number of records in the table. 
+ Example : "SELECT COUNT(f1) FROM Mytable"
+ @see #setInput(Job, Class, String, String, String, String...)]]>
+      </doc>
+    </method>
+    <method name="closeConnection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <field name="dbProductName" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="conditions" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="connection" type="java.sql.Connection"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="tableName" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="fieldNames" type="java.lang.String[]"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="dbConf" type="org.apache.hadoop.mapreduce.lib.db.DBConfiguration"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A InputFormat that reads input data from an SQL table.
+ <p>
+ DBInputFormat emits LongWritables containing the record number as 
+ key and DBWritables as value. 
+ 
+ The SQL query, and input class can be using one of the two 
+ setInput methods.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DBInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat -->
+  <class name="DBOutputFormat" extends="org.apache.hadoop.mapreduce.OutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="DBOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="constructQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="table" type="java.lang.String"/>
+      <param name="fieldNames" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Constructs the query used as the prepared statement to insert data.
+ 
+ @param table
+          the table to insert into
+ @param fieldNames
+          the fields to insert into. If field names are unknown, supply an
+          array of nulls.]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="setOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="fieldNames" type="java.lang.String[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Initializes the reduce-part of the job with 
+ the appropriate output settings
+ 
+ @param job The job
+ @param tableName The table to insert data into
+ @param fieldNames The field names in the table.]]>
+      </doc>
+    </method>
+    <method name="setOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="tableName" type="java.lang.String"/>
+      <param name="fieldCount" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Initializes the reduce-part of the job 
+ with the appropriate output settings
+ 
+ @param job The job
+ @param tableName The table to insert data into
+ @param fieldCount the number of fields in the table.]]>
+      </doc>
+    </method>
+    <field name="dbProductName" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A OutputFormat that sends the reduce output to a SQL table.
+ <p> 
+ {@link DBOutputFormat} accepts &lt;key,value&gt; pairs, where 
+ key has a type extending DBWritable. Returned {@link RecordWriter} 
+ writes <b>only the key</b> to the database with a batch SQL query.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DBOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.DBRecordReader -->
+  <class name="DBRecordReader" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="DBRecordReader" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit, java.lang.Class, org.apache.hadoop.conf.Configuration, java.sql.Connection, org.apache.hadoop.mapreduce.lib.db.DBConfiguration, java.lang.String, java.lang.String[], java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[@param split The InputSplit to read data for
+ @throws SQLException]]>
+      </doc>
+    </constructor>
+    <method name="executeQuery" return="java.sql.ResultSet"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="query" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <method name="getSelectQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the query for selecting the records, 
+ subclasses can override this for custom behaviour.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentKey" return="org.apache.hadoop.io.LongWritable"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getCurrentValue" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="createValue" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="deprecated, no comment">
+      <doc>
+      <![CDATA[@deprecated]]>
+      </doc>
+    </method>
+    <method name="getPos" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="deprecated, no comment">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated]]>
+      </doc>
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #nextKeyValue()}">
+      <param name="key" type="org.apache.hadoop.io.LongWritable"/>
+      <param name="value" type="T"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #nextKeyValue()}]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getSplit" return="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFieldNames" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="getTableName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="getConditions" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDBConf" return="org.apache.hadoop.mapreduce.lib.db.DBConfiguration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="getConnection" return="java.sql.Connection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="getStatement" return="java.sql.PreparedStatement"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="setStatement"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="stmt" type="java.sql.PreparedStatement"/>
+    </method>
+    <field name="statement" type="java.sql.PreparedStatement"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A RecordReader that reads records from a SQL table.
+ Emits LongWritables containing the record number as 
+ key and DBWritables as value.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.DBRecordReader -->
+  <!-- start interface org.apache.hadoop.mapreduce.lib.db.DBSplitter -->
+  <interface name="DBSplitter"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="split" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[Given a ResultSet containing one record (and already advanced to that record)
+ with two columns (a low value, and a high value, both of the same type), determine
+ a set of splits that span the given values.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[DBSplitter will generate DBInputSplits to use with DataDrivenDBInputFormat.
+ DataDrivenDBInputFormat needs to interpolate between two values that
+ represent the lowest and highest valued records to import. Depending
+ on the data-type of the column, this requires different behavior.
+ DBSplitter implementations should perform this for a data type or family
+ of data types.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.lib.db.DBSplitter -->
+  <!-- start interface org.apache.hadoop.mapreduce.lib.db.DBWritable -->
+  <interface name="DBWritable"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="write"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="statement" type="java.sql.PreparedStatement"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[Sets the fields of the object in the {@link PreparedStatement}.
+ @param statement the statement that the fields are put into.
+ @throws SQLException]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resultSet" type="java.sql.ResultSet"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[Reads the fields of the object from the {@link ResultSet}. 
+ @param resultSet the {@link ResultSet} to get the fields from.
+ @throws SQLException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Objects that are read from/written to a database should implement
+ <code>DBWritable</code>. DBWritable, is similar to {@link Writable} 
+ except that the {@link #write(PreparedStatement)} method takes a 
+ {@link PreparedStatement}, and {@link #readFields(ResultSet)} 
+ takes a {@link ResultSet}. 
+ <p>
+ Implementations are responsible for writing the fields of the object 
+ to PreparedStatement, and reading the fields of the object from the 
+ ResultSet. 
+ 
+ <p>Example:</p>
+ If we have the following table in the database :
+ <pre>
+ CREATE TABLE MyTable (
+   counter        INTEGER NOT NULL,
+   timestamp      BIGINT  NOT NULL,
+ );
+ </pre>
+ then we can read/write the tuples from/to the table with :
+ <p><pre>
+ public class MyWritable implements Writable, DBWritable {
+   // Some data     
+   private int counter;
+   private long timestamp;
+       
+   //Writable#write() implementation
+   public void write(DataOutput out) throws IOException {
+     out.writeInt(counter);
+     out.writeLong(timestamp);
+   }
+       
+   //Writable#readFields() implementation
+   public void readFields(DataInput in) throws IOException {
+     counter = in.readInt();
+     timestamp = in.readLong();
+   }
+       
+   public void write(PreparedStatement statement) throws SQLException {
+     statement.setInt(1, counter);
+     statement.setLong(2, timestamp);
+   }
+       
+   public void readFields(ResultSet resultSet) throws SQLException {
+     counter = resultSet.getInt(1);
+     timestamp = resultSet.getLong(2);
+   } 
+ }
+ </pre>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.lib.db.DBWritable -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.FloatSplitter -->
+  <class name="FloatSplitter" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.db.DBSplitter"/>
+    <constructor name="FloatSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="split" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over floating-point values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.FloatSplitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.IntegerSplitter -->
+  <class name="IntegerSplitter" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.db.DBSplitter"/>
+    <constructor name="IntegerSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="split" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over integer values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.IntegerSplitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.MySQLDataDrivenDBRecordReader -->
+  <class name="MySQLDataDrivenDBRecordReader" extends="org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MySQLDataDrivenDBRecordReader" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit, java.lang.Class, org.apache.hadoop.conf.Configuration, java.sql.Connection, org.apache.hadoop.mapreduce.lib.db.DBConfiguration, java.lang.String, java.lang.String[], java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </constructor>
+    <method name="executeQuery" return="java.sql.ResultSet"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="query" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <doc>
+    <![CDATA[A RecordReader that reads records from a MySQL table via DataDrivenDBRecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.MySQLDataDrivenDBRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.MySQLDBRecordReader -->
+  <class name="MySQLDBRecordReader" extends="org.apache.hadoop.mapreduce.lib.db.DBRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MySQLDBRecordReader" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit, java.lang.Class, org.apache.hadoop.conf.Configuration, java.sql.Connection, org.apache.hadoop.mapreduce.lib.db.DBConfiguration, java.lang.String, java.lang.String[], java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </constructor>
+    <method name="executeQuery" return="java.sql.ResultSet"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="query" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </method>
+    <doc>
+    <![CDATA[A RecordReader that reads records from a MySQL table.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.MySQLDBRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat -->
+  <class name="OracleDataDrivenDBInputFormat" extends="org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="OracleDataDrivenDBInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSplitter" return="org.apache.hadoop.mapreduce.lib.db.DBSplitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="sqlDataType" type="int"/>
+      <doc>
+      <![CDATA[@return the DBSplitter implementation to use to divide the table/query into InputSplits.]]>
+      </doc>
+    </method>
+    <method name="createDBRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A InputFormat that reads input data from an SQL table in an Oracle db.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBRecordReader -->
+  <class name="OracleDataDrivenDBRecordReader" extends="org.apache.hadoop.mapreduce.lib.db.DataDrivenDBRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="OracleDataDrivenDBRecordReader" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit, java.lang.Class, org.apache.hadoop.conf.Configuration, java.sql.Connection, org.apache.hadoop.mapreduce.lib.db.DBConfiguration, java.lang.String, java.lang.String[], java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </constructor>
+    <doc>
+    <![CDATA[A RecordReader that reads records from a Oracle table via DataDrivenDBRecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.OracleDataDrivenDBRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.OracleDateSplitter -->
+  <class name="OracleDateSplitter" extends="org.apache.hadoop.mapreduce.lib.db.DateSplitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="OracleDateSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="dateToString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="d" type="java.util.Date"/>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over date/time values returned by an Oracle db.
+ Make use of logic from DateSplitter, since this just needs to use
+ some Oracle-specific functions on the formatting end when generating
+ InputSplits.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.OracleDateSplitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader -->
+  <class name="OracleDBRecordReader" extends="org.apache.hadoop.mapreduce.lib.db.DBRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="OracleDBRecordReader" type="org.apache.hadoop.mapreduce.lib.db.DBInputFormat.DBInputSplit, java.lang.Class, org.apache.hadoop.conf.Configuration, java.sql.Connection, org.apache.hadoop.mapreduce.lib.db.DBConfiguration, java.lang.String, java.lang.String[], java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="SQLException" type="java.sql.SQLException"/>
+    </constructor>
+    <method name="getSelectQuery" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the query for selecting the records from an Oracle DB.]]>
+      </doc>
+    </method>
+    <method name="setSessionTimeZone"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="conn" type="java.sql.Connection"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[Set session time zone
+ @param conf The current configuration.
+ We read the 'oracle.sessionTimeZone' property from here.
+ @param conn The connection to alter the timezone properties of.]]>
+      </doc>
+    </method>
+    <field name="SESSION_TIMEZONE_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration key to set to a timezone string.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A RecordReader that reads records from an Oracle SQL table.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.OracleDBRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.db.TextSplitter -->
+  <class name="TextSplitter" extends="org.apache.hadoop.mapreduce.lib.db.BigDecimalSplitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TextSplitter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="split" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="results" type="java.sql.ResultSet"/>
+      <param name="colName" type="java.lang.String"/>
+      <exception name="SQLException" type="java.sql.SQLException"/>
+      <doc>
+      <![CDATA[This method needs to determine the splits between two user-provided strings.
+ In the case where the user's strings are 'A' and 'Z', this is not hard; we 
+ could create two splits from ['A', 'M') and ['M', 'Z'], 26 splits for strings
+ beginning with each letter, etc.
+
+ If a user has provided us with the strings "Ham" and "Haze", however, we need
+ to create splits that differ in the third letter.
+
+ The algorithm used is as follows:
+ Since there are 2**16 unicode characters, we interpret characters as digits in
+ base 65536. Given a string 's' containing characters s_0, s_1 .. s_n, we interpret
+ the string as the number: 0.s_0 s_1 s_2.. s_n in base 65536. Having mapped the
+ low and high strings into floating-point values, we then use the BigDecimalSplitter
+ to establish the even split points, then map the resulting floating point values
+ back into strings.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Implement DBSplitter over text strings.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.db.TextSplitter -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.fieldsel">
+  <!-- start class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper -->
+  <class name="FieldSelectionHelper" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FieldSelectionHelper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FieldSelectionHelper" type="org.apache.hadoop.io.Text, org.apache.hadoop.io.Text"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="parseOutputKeyValueSpec" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="keyValueSpec" type="java.lang.String"/>
+      <param name="keyFieldList" type="java.util.List"/>
+      <param name="valueFieldList" type="java.util.List"/>
+    </method>
+    <method name="specToString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fieldSeparator" type="java.lang.String"/>
+      <param name="keyValueSpec" type="java.lang.String"/>
+      <param name="allValueFieldsFrom" type="int"/>
+      <param name="keyFieldList" type="java.util.List"/>
+      <param name="valueFieldList" type="java.util.List"/>
+    </method>
+    <method name="getKey" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getValue" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="extractOutputKeyValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="val" type="java.lang.String"/>
+      <param name="fieldSep" type="java.lang.String"/>
+      <param name="keyFieldList" type="java.util.List"/>
+      <param name="valFieldList" type="java.util.List"/>
+      <param name="allValueFieldsFrom" type="int"/>
+      <param name="ignoreKey" type="boolean"/>
+      <param name="isMap" type="boolean"/>
+    </method>
+    <field name="emptyText" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DATA_FIELD_SEPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DATA_FIELD_SEPERATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Use {@link #DATA_FIELD_SEPARATOR}">
+      <doc>
+      <![CDATA[@deprecated Use {@link #DATA_FIELD_SEPARATOR}]]>
+      </doc>
+    </field>
+    <field name="MAP_OUTPUT_KEY_VALUE_SPEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="REDUCE_OUTPUT_KEY_VALUE_SPEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements a mapper/reducer class that can be used to perform
+ field selections in a manner similar to unix cut. The input data is treated
+ as fields separated by a user specified separator (the default value is
+ "\t"). The user can specify a list of fields that form the map output keys,
+ and a list of fields that form the map output values. If the inputformat is
+ TextInputFormat, the mapper will ignore the key to the map function. and the
+ fields are from the value only. Otherwise, the fields are the union of those
+ from the key and those from the value.
+ 
+ The field separator is under attribute "mapreduce.fieldsel.data.field.separator"
+ 
+ The map output field list spec is under attribute 
+ "mapreduce.fieldsel.map.output.key.value.fields.spec".
+ The value is expected to be like "keyFieldsSpec:valueFieldsSpec"
+ key/valueFieldsSpec are comma (,) separated field spec: fieldSpec,fieldSpec,fieldSpec ...
+ Each field spec can be a simple number (e.g. 5) specifying a specific field, or a range
+ (like 2-5) to specify a range of fields, or an open range (like 3-) specifying all 
+ the fields starting from field 3. The open range field spec applies value fields only.
+ They have no effect on the key fields.
+ 
+ Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields 4,3,0 and 1 for keys,
+ and use fields 6,5,1,2,3,7 and above for values.
+ 
+ The reduce output field list spec is under attribute 
+ "mapreduce.fieldsel.reduce.output.key.value.fields.spec".
+ 
+ The reducer extracts output key/value pairs in a similar manner, except that
+ the key is never ignored.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper -->
+  <class name="FieldSelectionMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FieldSelectionMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="val" type="V"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[The identify function. Input key/value pair is written directly to output.]]>
+      </doc>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements a mapper class that can be used to perform
+ field selections in a manner similar to unix cut. The input data is treated
+ as fields separated by a user specified separator (the default value is
+ "\t"). The user can specify a list of fields that form the map output keys,
+ and a list of fields that form the map output values. If the inputformat is
+ TextInputFormat, the mapper will ignore the key to the map function. and the
+ fields are from the value only. Otherwise, the fields are the union of those
+ from the key and those from the value.
+ 
+ The field separator is under attribute "mapreduce.fieldsel.data.field.separator"
+ 
+ The map output field list spec is under attribute 
+ "mapreduce.fieldsel.map.output.key.value.fields.spec". 
+ The value is expected to be like
+ "keyFieldsSpec:valueFieldsSpec" key/valueFieldsSpec are comma (,) separated
+ field spec: fieldSpec,fieldSpec,fieldSpec ... Each field spec can be a 
+ simple number (e.g. 5) specifying a specific field, or a range (like 2-5)
+ to specify a range of fields, or an open range (like 3-) specifying all 
+ the fields starting from field 3. The open range field spec applies value
+ fields only. They have no effect on the key fields.
+ 
+ Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields
+ 4,3,0 and 1 for keys, and use fields 6,5,1,2,3,7 and above for values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer -->
+  <class name="FieldSelectionReducer" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FieldSelectionReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="values" type="java.lang.Iterable"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class implements a reducer class that can be used to perform field
+ selections in a manner similar to unix cut. 
+ 
+ The input data is treated as fields separated by a user specified
+ separator (the default value is "\t"). The user can specify a list of
+ fields that form the reduce output keys, and a list of fields that form
+ the reduce output values. The fields are the union of those from the key
+ and those from the value.
+ 
+ The field separator is under attribute "mapreduce.fieldsel.data.field.separator"
+ 
+ The reduce output field list spec is under attribute 
+ "mapreduce.fieldsel.reduce.output.key.value.fields.spec". 
+ The value is expected to be like
+ "keyFieldsSpec:valueFieldsSpec" key/valueFieldsSpec are comma (,) 
+ separated field spec: fieldSpec,fieldSpec,fieldSpec ... Each field spec
+ can be a simple number (e.g. 5) specifying a specific field, or a range
+ (like 2-5) to specify a range of fields, or an open range (like 3-) 
+ specifying all the fields starting from field 3. The open range field
+ spec applies value fields only. They have no effect on the key fields.
+ 
+ Here is an example: "4,3,0,1:6,5,1-3,7-". It specifies to use fields
+ 4,3,0 and 1 for keys, and use fields 6,5,1,2,3,7 and above for values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionReducer -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.input">
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat -->
+  <class name="CombineFileInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.FileInputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[default constructor]]>
+      </doc>
+    </constructor>
+    <method name="setMaxSplitSize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="maxSplitSize" type="long"/>
+      <doc>
+      <![CDATA[Specify the maximum size (in bytes) of each split. Each split is
+ approximately equal to the specified size.]]>
+      </doc>
+    </method>
+    <method name="setMinSplitSizeNode"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="minSplitSizeNode" type="long"/>
+      <doc>
+      <![CDATA[Specify the minimum size (in bytes) of each split per node.
+ This applies to data that is left over after combining data on a single
+ node into splits that are of maximum size specified by maxSplitSize.
+ This leftover data will be combined into its own split if its size
+ exceeds minSplitSizeNode.]]>
+      </doc>
+    </method>
+    <method name="setMinSplitSizeRack"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="minSplitSizeRack" type="long"/>
+      <doc>
+      <![CDATA[Specify the minimum size (in bytes) of each split per rack.
+ This applies to data that is left over after combining data on a single
+ rack into splits that are of maximum size specified by maxSplitSize.
+ This leftover data will be combined into its own split if its size
+ exceeds minSplitSizeRack.]]>
+      </doc>
+    </method>
+    <method name="createPool"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="filters" type="java.util.List"/>
+      <doc>
+      <![CDATA[Create a new pool and add the filters to it.
+ A split cannot have files from different pools.]]>
+      </doc>
+    </method>
+    <method name="createPool"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="filters" type="org.apache.hadoop.fs.PathFilter[]"/>
+      <doc>
+      <![CDATA[Create a new pool and add the filters to it. 
+ A pathname can satisfy any one of the specified filters.
+ A split cannot have files from different pools.]]>
+      </doc>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="getSplits" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[This is not implemented yet.]]>
+      </doc>
+    </method>
+    <method name="getFileBlockLocations" return="org.apache.hadoop.fs.BlockLocation[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="stat" type="org.apache.hadoop.fs.FileStatus"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="SPLIT_MINSIZE_PERNODE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SPLIT_MINSIZE_PERRACK" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An abstract {@link InputFormat} that returns {@link CombineFileSplit}'s in 
+ {@link InputFormat#getSplits(JobContext)} method. 
+ 
+ Splits are constructed from the files under the input paths. 
+ A split cannot have files from different pools.
+ Each split returned may contain blocks from different files.
+ If a maxSplitSize is specified, then blocks on the same node are
+ combined to form a single split. Blocks that are left over are
+ then combined with other blocks in the same rack. 
+ If maxSplitSize is not specified, then blocks from the same rack
+ are combined in a single split; no attempt is made to create
+ node-local splits.
+ If the maxSplitSize is equal to the block size, then this class
+ is similar to the default splitting behavior in Hadoop: each
+ block is a locally processed split.
+ Subclasses implement 
+ {@link InputFormat#createRecordReader(InputSplit, TaskAttemptContext)}
+ to construct <code>RecordReader</code>'s for 
+ <code>CombineFileSplit</code>'s.
+ 
+ @see CombineFileSplit]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader -->
+  <class name="CombineFileRecordReader" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineFileRecordReader" type="org.apache.hadoop.mapreduce.lib.input.CombineFileSplit, org.apache.hadoop.mapreduce.TaskAttemptContext, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[A generic RecordReader that can hand out different recordReaders
+ for each chunk in the CombineFileSplit.]]>
+      </doc>
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[return progress based on the amount of data processed so far.]]>
+      </doc>
+    </method>
+    <method name="initNextRecordReader" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the record reader for the next chunk in this CombineFileSplit.]]>
+      </doc>
+    </method>
+    <field name="split" type="org.apache.hadoop.mapreduce.lib.input.CombineFileSplit"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="rrConstructor" type="java.lang.reflect.Constructor"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="idx" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="progress" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="curReader" type="org.apache.hadoop.mapreduce.RecordReader"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A generic RecordReader that can hand out different recordReaders
+ for each chunk in a {@link CombineFileSplit}.
+ A CombineFileSplit can combine data chunks from multiple files. 
+ This class allows using different RecordReaders for processing
+ these data chunks from different files.
+ @see CombineFileSplit]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper -->
+  <class name="CombineFileRecordReaderWrapper" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineFileRecordReaderWrapper" type="org.apache.hadoop.mapreduce.lib.input.FileInputFormat, org.apache.hadoop.mapreduce.lib.input.CombineFileSplit, org.apache.hadoop.mapreduce.TaskAttemptContext, java.lang.Integer"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A wrapper class for a record reader that handles a single file split. It
+ delegates most of the methods to the wrapped instance. A concrete subclass
+ needs to provide a constructor that calls this parent constructor with the
+ appropriate input format. The subclass constructor must satisfy the specific
+ constructor signature that is required by
+ <code>CombineFileRecordReader</code>.
+
+ Subclassing is needed to get a concrete record reader wrapper because of the
+ constructor requirement.
+
+ @see CombineFileRecordReader
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit -->
+  <class name="CombineFileSplit" extends="org.apache.hadoop.mapreduce.InputSplit"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="CombineFileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[default constructor]]>
+      </doc>
+    </constructor>
+    <constructor name="CombineFileSplit" type="org.apache.hadoop.fs.Path[], long[], long[], java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CombineFileSplit" type="org.apache.hadoop.fs.Path[], long[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CombineFileSplit" type="org.apache.hadoop.mapreduce.lib.input.CombineFileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Copy constructor]]>
+      </doc>
+    </constructor>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getStartOffsets" return="long[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns an array containing the start offsets of the files in the split]]>
+      </doc>
+    </method>
+    <method name="getLengths" return="long[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns an array containing the lengths of the files in the split]]>
+      </doc>
+    </method>
+    <method name="getOffset" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Returns the start offset of the i<sup>th</sup> Path]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Returns the length of the i<sup>th</sup> Path]]>
+      </doc>
+    </method>
+    <method name="getNumPaths" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the number of Paths in the split]]>
+      </doc>
+    </method>
+    <method name="getPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Returns the i<sup>th</sup> Path]]>
+      </doc>
+    </method>
+    <method name="getPaths" return="org.apache.hadoop.fs.Path[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns all the Paths in the split]]>
+      </doc>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns all the Paths where this input-split resides]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[A sub-collection of input files. 
+ 
+ Unlike {@link FileSplit}, CombineFileSplit class does not represent 
+ a split of a file, but a split of input files into smaller sets. 
+ A split may contain blocks from different file but all 
+ the blocks in the same split are probably local to some rack <br> 
+ CombineFileSplit can be used to implement {@link RecordReader}'s, 
+ with reading one record per file.
+ 
+ @see FileSplit
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat -->
+  <class name="CombineSequenceFileInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineSequenceFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Input format that is a <code>CombineFileInputFormat</code>-equivalent for
+ <code>SequenceFileInputFormat</code>.
+
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.CombineSequenceFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat -->
+  <class name="CombineTextInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CombineTextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Input format that is a <code>CombineFileInputFormat</code>-equivalent for
+ <code>TextInputFormat</code>.
+
+ @see CombineFileInputFormat]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.CombineTextInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.FileInputFormat -->
+  <class name="FileInputFormat" extends="org.apache.hadoop.mapreduce.InputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setInputDirRecursive"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="inputDirRecursive" type="boolean"/>
+      <doc>
+      <![CDATA[@param job
+          the job to modify
+ @param inputDirRecursive]]>
+      </doc>
+    </method>
+    <method name="getInputDirRecursive" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[@param job
+          the job to look at.
+ @return should the files to be read recursively?]]>
+      </doc>
+    </method>
+    <method name="getFormatMinSplitSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the lower bound on split size imposed by the format.
+ @return the number of bytes of the minimal split for this format]]>
+      </doc>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="filename" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Is the given filename splittable? Usually, true, but if the file is
+ stream compressed, it will not be.
+
+ The default implementation in <code>FileInputFormat</code> always returns
+ true. Implementations that may deal with non-splittable files <i>must</i>
+ override this method.
+
+ <code>FileInputFormat</code> implementations can override this and return
+ <code>false</code> to ensure that individual input files are never split-up
+ so that {@link Mapper}s process entire files.
+ 
+ @param context the job context
+ @param filename the file name to check
+ @return is this file splitable?]]>
+      </doc>
+    </method>
+    <method name="setInputPathFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="filter" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set a PathFilter to be applied to the input paths for the map-reduce job.
+ @param job the job to modify
+ @param filter the PathFilter class use for filtering the input paths.]]>
+      </doc>
+    </method>
+    <method name="setMinInputSplitSize"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="size" type="long"/>
+      <doc>
+      <![CDATA[Set the minimum input split size
+ @param job the job to modify
+ @param size the minimum size]]>
+      </doc>
+    </method>
+    <method name="getMinSplitSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the minimum split size
+ @param job the job
+ @return the minimum number of bytes that can be in a split]]>
+      </doc>
+    </method>
+    <method name="setMaxInputSplitSize"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="size" type="long"/>
+      <doc>
+      <![CDATA[Set the maximum split size
+ @param job the job to modify
+ @param size the maximum split size]]>
+      </doc>
+    </method>
+    <method name="getMaxSplitSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the maximum split size.
+ @param context the job to look at.
+ @return the maximum number of bytes a split can include]]>
+      </doc>
+    </method>
+    <method name="getInputPathFilter" return="org.apache.hadoop.fs.PathFilter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get a PathFilter instance of the filter set for the input paths.
+
+ @return the PathFilter instance set for the job, NULL if none has been set.]]>
+      </doc>
+    </method>
+    <method name="listStatus" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[List input directories.
+ Subclasses may override to, e.g., select only files matching a regular
+ expression. 
+ 
+ @param job the job to list input paths for
+ @return array of FileStatus objects
+ @throws IOException if zero items.]]>
+      </doc>
+    </method>
+    <method name="addInputPathRecursively"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="result" type="java.util.List"/>
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="inputFilter" type="org.apache.hadoop.fs.PathFilter"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add files in the input path recursively into the results.
+ @param result
+          The List to store all files.
+ @param fs
+          The FileSystem.
+ @param path
+          The input path.
+ @param inputFilter
+          The input filter that can be used to filter files/dirs. 
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="makeSplit" return="org.apache.hadoop.mapreduce.lib.input.FileSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+      <param name="start" type="long"/>
+      <param name="length" type="long"/>
+      <param name="hosts" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[A factory that makes the split for this class. It can be overridden
+ by sub-classes to make sub-types]]>
+      </doc>
+    </method>
+    <method name="makeSplit" return="org.apache.hadoop.mapreduce.lib.input.FileSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+      <param name="start" type="long"/>
+      <param name="length" type="long"/>
+      <param name="hosts" type="java.lang.String[]"/>
+      <param name="inMemoryHosts" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[A factory that makes the split for this class. It can be overridden
+ by sub-classes to make sub-types]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Generate the list of files and make them into FileSplits.
+ @param job the job context
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="computeSplitSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="blockSize" type="long"/>
+      <param name="minSize" type="long"/>
+      <param name="maxSize" type="long"/>
+    </method>
+    <method name="getBlockIndex" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="blkLocations" type="org.apache.hadoop.fs.BlockLocation[]"/>
+      <param name="offset" type="long"/>
+    </method>
+    <method name="setInputPaths"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="commaSeparatedPaths" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Sets the given comma separated paths as the list of inputs 
+ for the map-reduce job.
+ 
+ @param job the job
+ @param commaSeparatedPaths Comma separated paths to be set as 
+        the list of inputs for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="addInputPaths"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="commaSeparatedPaths" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add the given comma separated paths to the list of inputs for
+  the map-reduce job.
+ 
+ @param job The job to modify
+ @param commaSeparatedPaths Comma separated paths to be added to
+        the list of inputs for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="setInputPaths"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="inputPaths" type="org.apache.hadoop.fs.Path[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Set the array of {@link Path}s as the list of inputs
+ for the map-reduce job.
+ 
+ @param job The job to modify 
+ @param inputPaths the {@link Path}s of the input directories/files 
+ for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="addInputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add a {@link Path} to the list of inputs for the map-reduce job.
+ 
+ @param job The {@link Job} to modify
+ @param path {@link Path} to be added to the list of inputs for 
+            the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getInputPaths" return="org.apache.hadoop.fs.Path[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the list of input {@link Path}s for the map-reduce job.
+ 
+ @param context The job
+ @return the list of input {@link Path}s for the map-reduce job.]]>
+      </doc>
+    </method>
+    <field name="INPUT_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SPLIT_MAXSIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SPLIT_MINSIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PATHFILTER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NUM_INPUT_FILES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INPUT_DIR_RECURSIVE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INPUT_DIR_NONRECURSIVE_IGNORE_SUBDIRS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LIST_STATUS_NUM_THREADS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_LIST_STATUS_NUM_THREADS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A base class for file-based {@link InputFormat}s.
+
+ <p><code>FileInputFormat</code> is the base class for all file-based 
+ <code>InputFormat</code>s. This provides a generic implementation of
+ {@link #getSplits(JobContext)}.
+
+ Implementations of <code>FileInputFormat</code> can also override the
+ {@link #isSplitable(JobContext, Path)} method to prevent input files
+ from being split-up in certain situations. Implementations that may
+ deal with non-splittable files <i>must</i> override this method, since
+ the default implementation assumes splitting is always possible.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.FileInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter -->
+  <class name="FileInputFormatCounter" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.FileSplit -->
+  <class name="FileSplit" extends="org.apache.hadoop.mapreduce.InputSplit"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="FileSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FileSplit" type="org.apache.hadoop.fs.Path, long, long, java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a split with host information
+
+ @param file the file name
+ @param start the position of the first byte in the file to process
+ @param length the number of bytes in the file to process
+ @param hosts the list of hosts containing the block, possibly null]]>
+      </doc>
+    </constructor>
+    <constructor name="FileSplit" type="org.apache.hadoop.fs.Path, long, long, java.lang.String[], java.lang.String[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructs a split with host and cached-blocks information
+
+ @param file the file name
+ @param start the position of the first byte in the file to process
+ @param length the number of bytes in the file to process
+ @param hosts the list of hosts containing the block
+ @param inMemoryHosts the list of hosts containing the block in memory]]>
+      </doc>
+    </constructor>
+    <method name="getPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The file containing this split's data.]]>
+      </doc>
+    </method>
+    <method name="getStart" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The position of the first byte in the file to process.]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of bytes in the file to process.]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getLocationInfo" return="org.apache.hadoop.mapred.SplitLocationInfo[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[A section of an input file.  Returned by {@link
+ InputFormat#getSplits(JobContext)} and passed to
+ {@link InputFormat#createRecordReader(InputSplit,TaskAttemptContext)}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.FileSplit -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.FixedLengthInputFormat -->
+  <class name="FixedLengthInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FixedLengthInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setRecordLength"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="recordLength" type="int"/>
+      <doc>
+      <![CDATA[Set the length of each record
+ @param conf configuration
+ @param recordLength the length of a record]]>
+      </doc>
+    </method>
+    <method name="getRecordLength" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get record length value
+ @param conf configuration
+ @return the record length, zero means none was set]]>
+      </doc>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <field name="FIXED_RECORD_LENGTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[FixedLengthInputFormat is an input format used to read input files
+ which contain fixed length records.  The content of a record need not be
+ text.  It can be arbitrary binary data.  Users must configure the record
+ length property by calling:
+ FixedLengthInputFormat.setRecordLength(conf, recordLength);<br><br> or
+ conf.setInt(FixedLengthInputFormat.FIXED_RECORD_LENGTH, recordLength);
+ <br><br>
+ @see FixedLengthRecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.FixedLengthInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.InvalidInputException -->
+  <class name="InvalidInputException" extends="java.io.IOException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InvalidInputException" type="java.util.List"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create the exception with the given list.
+ @param probs the list of problems to report. this list is not copied.]]>
+      </doc>
+    </constructor>
+    <method name="getProblems" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the complete list of the problems reported.
+ @return the list of problems, which must not be modified]]>
+      </doc>
+    </method>
+    <method name="getMessage" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a summary message of the problems found.
+ @return the concatenated messages from all of the problems.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class wraps a list of problems with the input, so that the user
+ can get a list of problems together instead of finding and fixing them one 
+ by one.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.InvalidInputException -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader -->
+  <class name="KeyValueLineRecordReader" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="KeyValueLineRecordReader" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="getKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="findSeparator" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="utf" type="byte[]"/>
+      <param name="start" type="int"/>
+      <param name="length" type="int"/>
+      <param name="sep" type="byte"/>
+    </method>
+    <method name="setKeyValue"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.Text"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <param name="line" type="byte[]"/>
+      <param name="lineLen" type="int"/>
+      <param name="pos" type="int"/>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Read key/value pair in a line.]]>
+      </doc>
+    </method>
+    <method name="getCurrentKey" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getCurrentValue" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="KEY_VALUE_SEPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="KEY_VALUE_SEPERATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Use {@link #KEY_VALUE_SEPARATOR}">
+      <doc>
+      <![CDATA[@deprecated Use {@link #KEY_VALUE_SEPARATOR}]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[This class treats a line in the input as a key/value pair separated by a 
+ separator character. The separator can be specified in config file 
+ under the attribute name mapreduce.input.keyvaluelinerecordreader.key.value.separator. The default
+ separator is the tab character ('\t').]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat -->
+  <class name="KeyValueTextInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="KeyValueTextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link InputFormat} for plain text files. Files are broken into lines.
+ Either line feed or carriage-return are used to signal end of line. 
+ Each line is divided into key and value parts by a separator byte. If no
+ such a byte exists, the key will be the entire line and value will be empty.
+ The separator byte can be specified in config file under the attribute name
+ mapreduce.input.keyvaluelinerecordreader.key.value.separator. The default
+ is the tab character ('\t').]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.MultipleInputs -->
+  <class name="MultipleInputs" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleInputs"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addInputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="inputFormatClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Add a {@link Path} with a custom {@link InputFormat} to the list of
+ inputs for the map-reduce job.
+ 
+ @param job The {@link Job}
+ @param path {@link Path} to be added to the list of inputs for the job
+ @param inputFormatClass {@link InputFormat} class to use for this path]]>
+      </doc>
+    </method>
+    <method name="addInputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="inputFormatClass" type="java.lang.Class"/>
+      <param name="mapperClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Add a {@link Path} with a custom {@link InputFormat} and
+ {@link Mapper} to the list of inputs for the map-reduce job.
+ 
+ @param job The {@link Job}
+ @param path {@link Path} to be added to the list of inputs for the job
+ @param inputFormatClass {@link InputFormat} class to use for this path
+ @param mapperClass {@link Mapper} class to use for this path]]>
+      </doc>
+    </method>
+    <field name="DIR_FORMATS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DIR_MAPPERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class supports MapReduce jobs that have multiple input paths with
+ a different {@link InputFormat} and {@link Mapper} for each path]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.MultipleInputs -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.NLineInputFormat -->
+  <class name="NLineInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NLineInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="genericSplit" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getSplits" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Logically splits the set of input files for the job, splits N lines
+ of the input as one split.
+ 
+ @see FileInputFormat#getSplits(JobContext)]]>
+      </doc>
+    </method>
+    <method name="getSplitsForFile" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="status" type="org.apache.hadoop.fs.FileStatus"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="numLinesPerSplit" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createFileSplit" return="org.apache.hadoop.mapreduce.lib.input.FileSplit"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fileName" type="org.apache.hadoop.fs.Path"/>
+      <param name="begin" type="long"/>
+      <param name="length" type="long"/>
+      <doc>
+      <![CDATA[NLineInputFormat uses LineRecordReader, which always reads
+ (and consumes) at least one character out of its upper split
+ boundary. So to make sure that each mapper gets N lines, we
+ move back the upper split limits of each split 
+ by one character here.
+ @param fileName  Path of file
+ @param begin  the position of the first byte in the file to process
+ @param length  number of bytes in InputSplit
+ @return  FileSplit]]>
+      </doc>
+    </method>
+    <method name="setNumLinesPerSplit"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="numLines" type="int"/>
+      <doc>
+      <![CDATA[Set the number of lines per split
+ @param job the job to modify
+ @param numLines the number of lines per split]]>
+      </doc>
+    </method>
+    <method name="getNumLinesPerSplit" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the number of lines per split
+ @param job the job
+ @return the number of lines per split]]>
+      </doc>
+    </method>
+    <field name="LINES_PER_MAP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[NLineInputFormat which splits N lines of input as one split.
+
+ In many "pleasantly" parallel applications, each process/mapper 
+ processes the same input file (s), but with computations are 
+ controlled by different parameters.(Referred to as "parameter sweeps").
+ One way to achieve this, is to specify a set of parameters 
+ (one set per line) as input in a control file 
+ (which is the input path to the map-reduce application,
+ where as the input dataset is specified 
+ via a config variable in JobConf.).
+ 
+ The NLineInputFormat can be used in such applications, that splits 
+ the input file such that by default, one line is fed as
+ a value to one map task, and key is the offset.
+ i.e. (k,v) is (LongWritable, Text).
+ The location hints will span the whole mapred cluster.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.NLineInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat -->
+  <class name="SequenceFileAsBinaryInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsBinaryInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[InputFormat reading keys, values from SequenceFiles in binary (raw)
+ format.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsBinaryInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextInputFormat -->
+  <class name="SequenceFileAsTextInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsTextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class is similar to SequenceFileInputFormat, except it generates
+ SequenceFileAsTextRecordReader which converts the input keys and values
+ to their String forms by calling toString() method.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader -->
+  <class name="SequenceFileAsTextRecordReader" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsTextRecordReader"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentKey" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentValue" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Read key/value pair in a line.]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[This class converts the input keys and values to their String forms by
+ calling toString() method. This class to SequenceFileAsTextInputFormat
+ class is as LineRecordReader class to TextInputFormat class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.SequenceFileAsTextRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter -->
+  <class name="SequenceFileInputFilter" extends="org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileInputFilter"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a record reader for the given split
+ @param split file split
+ @param context the task-attempt context
+ @return RecordReader]]>
+      </doc>
+    </method>
+    <method name="setFilterClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="filterClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[set the filter class
+ 
+ @param job The job
+ @param filterClass filter class]]>
+      </doc>
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILTER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILTER_FREQUENCY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILTER_REGEX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A class that allows a map/red job to work on a sample of sequence files.
+ The sample is decided by the filter class set by the job.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat -->
+  <class name="SequenceFileInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getFormatMinSplitSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="listStatus" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link InputFormat} for {@link SequenceFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader -->
+  <class name="SequenceFileRecordReader" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileRecordReader"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getCurrentKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getCurrentValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return the progress within the input split
+ @return 0.0 to 1.0 of the input byte range]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="conf" type="org.apache.hadoop.conf.Configuration"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An {@link RecordReader} for {@link SequenceFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.SequenceFileRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.input.TextInputFormat -->
+  <class name="TextInputFormat" extends="org.apache.hadoop.mapreduce.lib.input.FileInputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TextInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+    </method>
+    <method name="isSplitable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="file" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link InputFormat} for plain text files.  Files are broken into lines.
+ Either linefeed or carriage-return are used to signal end of line.  Keys are
+ the position in the file, and values are the line of text..]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.input.TextInputFormat -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.jobcontrol">
+  <!-- start class org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob -->
+  <class name="ControlledJob" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ControlledJob" type="org.apache.hadoop.mapreduce.Job, java.util.List"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Construct a job.
+ @param job a mapreduce job to be executed.
+ @param dependingJobs an array of jobs the current job depends on]]>
+      </doc>
+    </constructor>
+    <constructor name="ControlledJob" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Construct a job.
+ 
+ @param conf mapred job configuration representing a job to be executed.
+ @throws IOException]]>
+      </doc>
+    </constructor>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getJobName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the job name of this job]]>
+      </doc>
+    </method>
+    <method name="setJobName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the job name for  this job.
+ @param jobName the job name]]>
+      </doc>
+    </method>
+    <method name="getJobID" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the job ID of this job assigned by JobControl]]>
+      </doc>
+    </method>
+    <method name="setJobID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the job ID for  this job.
+ @param id the job ID]]>
+      </doc>
+    </method>
+    <method name="getMapredJobId" return="org.apache.hadoop.mapreduce.JobID"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the mapred ID of this job as assigned by the mapred framework.]]>
+      </doc>
+    </method>
+    <method name="getJob" return="org.apache.hadoop.mapreduce.Job"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the mapreduce job]]>
+      </doc>
+    </method>
+    <method name="setJob"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <doc>
+      <![CDATA[Set the mapreduce job
+ @param job the mapreduce job for this job.]]>
+      </doc>
+    </method>
+    <method name="getJobState" return="org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the state of this job]]>
+      </doc>
+    </method>
+    <method name="setJobState"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="state" type="org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.State"/>
+      <doc>
+      <![CDATA[Set the state for this job.
+ @param state the new state for this job.]]>
+      </doc>
+    </method>
+    <method name="getMessage" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the message of this job]]>
+      </doc>
+    </method>
+    <method name="setMessage"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="message" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the message for this job.
+ @param message the message for this job.]]>
+      </doc>
+    </method>
+    <method name="getDependentJobs" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the depending jobs of this job]]>
+      </doc>
+    </method>
+    <method name="addDependingJob" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dependingJob" type="org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob"/>
+      <doc>
+      <![CDATA[Add a job to this jobs' dependency list. 
+ Dependent jobs can only be added while a Job 
+ is waiting to run, not during or afterwards.
+ 
+ @param dependingJob Job that this Job depends on.
+ @return <tt>true</tt> if the Job was added.]]>
+      </doc>
+    </method>
+    <method name="isCompleted" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return true if this job is in a complete state]]>
+      </doc>
+    </method>
+    <method name="isReady" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return true if this job is in READY state]]>
+      </doc>
+    </method>
+    <method name="killJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="failJob"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="message" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="submit"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Submit this job to mapred. The state becomes RUNNING if submission 
+ is successful, FAILED otherwise.]]>
+      </doc>
+    </method>
+    <field name="CREATE_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class encapsulates a MapReduce job and its dependency. It monitors 
+  the states of the depending jobs and updates the state of this job.
+  A job starts in the WAITING state. If it does not have any depending jobs,
+  or all of the depending jobs are in SUCCESS state, then the job state 
+  will become READY. If any depending jobs fail, the job will fail too. 
+  When in READY state, the job can be submitted to Hadoop for execution, with
+  the state changing into RUNNING state. From RUNNING state, the job 
+  can get into SUCCESS or FAILED state, depending 
+  the status of the job execution.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl -->
+  <class name="JobControl" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Runnable"/>
+    <constructor name="JobControl" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Construct a job control for a group of jobs.
+ @param groupName a name identifying this group]]>
+      </doc>
+    </constructor>
+    <method name="getWaitingJobList" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the waiting state]]>
+      </doc>
+    </method>
+    <method name="getRunningJobList" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the running state]]>
+      </doc>
+    </method>
+    <method name="getReadyJobsList" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the ready state]]>
+      </doc>
+    </method>
+    <method name="getSuccessfulJobList" return="java.util.List"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the jobs in the success state]]>
+      </doc>
+    </method>
+    <method name="getFailedJobList" return="java.util.List"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="addJob" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="aJob" type="org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob"/>
+      <doc>
+      <![CDATA[Add a new controlled job.
+ @param aJob the new controlled job]]>
+      </doc>
+    </method>
+    <method name="addJob" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="aJob" type="org.apache.hadoop.mapred.jobcontrol.Job"/>
+      <doc>
+      <![CDATA[Add a new job.
+ @param aJob the new job]]>
+      </doc>
+    </method>
+    <method name="addJobCollection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobs" type="java.util.Collection"/>
+      <doc>
+      <![CDATA[Add a collection of jobs
+ 
+ @param jobs]]>
+      </doc>
+    </method>
+    <method name="getThreadState" return="org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.ThreadState"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the thread state]]>
+      </doc>
+    </method>
+    <method name="stop"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[set the thread state to STOPPING so that the 
+ thread will stop when it wakes up.]]>
+      </doc>
+    </method>
+    <method name="suspend"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[suspend the running thread]]>
+      </doc>
+    </method>
+    <method name="resume"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[resume the suspended thread]]>
+      </doc>
+    </method>
+    <method name="allFinished" return="boolean"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The main loop for the thread.
+  The loop does the following:
+  	Check the states of the running jobs
+  	Update the states of waiting jobs
+  	Submit the jobs in ready state]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class encapsulates a set of MapReduce jobs and its dependency.
+   
+  It tracks the states of the jobs by placing them into different tables
+  according to their states. 
+  
+  This class provides APIs for the client app to add a job to the group 
+  and to get the jobs in the group in different states. When a job is 
+  added, an ID unique to the group is assigned to the job. 
+  
+  This class has a thread that submits jobs when they become ready, 
+  monitors the states of the running jobs, and updates the states of jobs
+  based on the state changes of their depending jobs states. The class 
+  provides APIs for suspending/resuming the thread, and 
+  for stopping the thread.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.join">
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator -->
+  <class name="ArrayListBackedIterator" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.join.ResetableIterator"/>
+    <constructor name="ArrayListBackedIterator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ArrayListBackedIterator" type="java.util.ArrayList"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="X"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="replay" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="X"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="item" type="X"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="clear"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[This class provides an implementation of ResetableIterator. The
+ implementation uses an {@link java.util.ArrayList} to store elements
+ added to it, replaying them as requested.
+ Prefer {@link StreamBackedIterator}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.ArrayListBackedIterator -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat -->
+  <class name="ComposableInputFormat" extends="org.apache.hadoop.mapreduce.InputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ComposableInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <doc>
+    <![CDATA[Refinement of InputFormat requiring implementors to provide
+ ComposableRecordReader instead of RecordReader.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader -->
+  <class name="ComposableRecordReader" extends="org.apache.hadoop.mapreduce.RecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ComposableRecordReader"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Additional operations required of a RecordReader to participate in a join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat -->
+  <class name="CompositeInputFormat" extends="org.apache.hadoop.mapreduce.InputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CompositeInputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setFormat"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Interpret a given string as a composite expression.
+ {@code
+   func  ::= <ident>([<func>,]*<func>)
+   func  ::= tbl(<class>,"<path>")
+   class ::= @see java.lang.Class#forName(java.lang.String)
+   path  ::= @see org.apache.hadoop.fs.Path#Path(java.lang.String)
+ }
+ Reads expression from the <tt>mapreduce.join.expr</tt> property and
+ user-supplied join types from <tt>mapreduce.join.define.&lt;ident&gt;</tt>
+  types. Paths supplied to <tt>tbl</tt> are given as input paths to the
+ InputFormat class listed.
+ @see #compose(java.lang.String, java.lang.Class, java.lang.String...)]]>
+      </doc>
+    </method>
+    <method name="addDefaults"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Adds the default set of identifiers to the parser.]]>
+      </doc>
+    </method>
+    <method name="getSplits" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Build a CompositeInputSplit from the child InputFormats by assigning the
+ ith split from each child to the ith composite split.]]>
+      </doc>
+    </method>
+    <method name="createRecordReader" return="org.apache.hadoop.mapreduce.RecordReader"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Construct a CompositeRecordReader for the children of this InputFormat
+ as defined in the init expression.
+ The outermost join need only be composable, not necessarily a composite.
+ Mandating TupleWritable isn't strictly correct.]]>
+      </doc>
+    </method>
+    <method name="compose" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="inf" type="java.lang.Class"/>
+      <param name="path" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Convenience method for constructing composite formats.
+ Given InputFormat class (inf), path (p) return:
+ {@code tbl(<inf>, <p>) }]]>
+      </doc>
+    </method>
+    <method name="compose" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="java.lang.String"/>
+      <param name="inf" type="java.lang.Class"/>
+      <param name="path" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Convenience method for constructing composite formats.
+ Given operation (op), Object class (inf), set of paths (p) return:
+ {@code <op>(tbl(<inf>,<p1>),tbl(<inf>,<p2>),...,tbl(<inf>,<pn>)) }]]>
+      </doc>
+    </method>
+    <method name="compose" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="java.lang.String"/>
+      <param name="inf" type="java.lang.Class"/>
+      <param name="path" type="org.apache.hadoop.fs.Path[]"/>
+      <doc>
+      <![CDATA[Convenience method for constructing composite formats.
+ Given operation (op), Object class (inf), set of paths (p) return:
+ {@code <op>(tbl(<inf>,<p1>),tbl(<inf>,<p2>),...,tbl(<inf>,<pn>)) }]]>
+      </doc>
+    </method>
+    <field name="JOIN_EXPR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="JOIN_COMPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An InputFormat capable of performing joins over a set of data sources sorted
+ and partitioned the same way.
+
+ A user may define new join types by setting the property
+ <tt>mapreduce.join.define.&lt;ident&gt;</tt> to a classname. 
+ In the expression <tt>mapreduce.join.expr</tt>, the identifier will be
+ assumed to be a ComposableRecordReader.
+ <tt>mapreduce.join.keycomparator</tt> can be a classname used to compare 
+ keys in the join.
+ @see #setFormat
+ @see JoinRecordReader
+ @see MultiFilterRecordReader]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.CompositeInputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit -->
+  <class name="CompositeInputSplit" extends="org.apache.hadoop.mapreduce.InputSplit"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="CompositeInputSplit"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CompositeInputSplit" type="int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="s" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Add an InputSplit to this collection.
+ @throws IOException If capacity was not specified during construction
+                     or if capacity has been reached.]]>
+      </doc>
+    </method>
+    <method name="get" return="org.apache.hadoop.mapreduce.InputSplit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Get ith child InputSplit.]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return the aggregate length of all child InputSplits currently added.]]>
+      </doc>
+    </method>
+    <method name="getLength" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the length of ith child InputSplit.]]>
+      </doc>
+    </method>
+    <method name="getLocations" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Collect a set of hosts from all child InputSplits.]]>
+      </doc>
+    </method>
+    <method name="getLocation" return="java.lang.String[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[getLocations from ith InputSplit.]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Write splits in the following format.
+ {@code
+ <count><class1><class2>...<classn><split1><split2>...<splitn>
+ }]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}
+ @throws IOException If the child InputSplit cannot be read, typically
+                     for failing access checks.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This InputSplit contains a set of child InputSplits. Any InputSplit inserted
+ into this collection must have a public default constructor.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.CompositeInputSplit -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader -->
+  <class name="CompositeRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="CompositeRecordReader" type="int, int, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a RecordReader with <tt>capacity</tt> children to position
+ <tt>id</tt> in the parent reader.
+ The id of a root CompositeRecordReader is -1 by convention, but relying
+ on this is not recommended.]]>
+      </doc>
+    </constructor>
+    <method name="combine" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="value" type="org.apache.hadoop.mapreduce.lib.join.TupleWritable"/>
+    </method>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="id" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the position in the collector this class occupies.]]>
+      </doc>
+    </method>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="getRecordReaderQueue" return="java.util.PriorityQueue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return sorted list of RecordReaders for this composite.]]>
+      </doc>
+    </method>
+    <method name="getComparator" return="org.apache.hadoop.io.WritableComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return comparator defining the ordering for RecordReaders in this
+ composite.]]>
+      </doc>
+    </method>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rr" type="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Add a RecordReader to this collection.
+ The id() of a RecordReader determines where in the Tuple its
+ entry will appear. Adding RecordReaders with the same id has
+ undefined behavior.]]>
+      </doc>
+    </method>
+    <method name="key" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the key for the current join or the value at the top of the
+ RecordReader heap.]]>
+      </doc>
+    </method>
+    <method name="key"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Clone the key at the top of this RR into the given object.]]>
+      </doc>
+    </method>
+    <method name="getCurrentKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return true if it is possible that this could emit more values.]]>
+      </doc>
+    </method>
+    <method name="skip"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Pass skip key to child RRs.]]>
+      </doc>
+    </method>
+    <method name="getDelegate" return="org.apache.hadoop.mapreduce.lib.join.ResetableIterator"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Obtain an iterator over the child RRs apropos of the value type
+ ultimately emitted from this join.]]>
+      </doc>
+    </method>
+    <method name="accept"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jc" type="org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector"/>
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[If key provided matches that of this Composite, give JoinCollector
+ iterator over values it may emit.]]>
+      </doc>
+    </method>
+    <method name="fillJoinCollector"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="iterkey" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[For all child RRs offering the key provided, obtain an iterator
+ at that position in the JoinCollector.]]>
+      </doc>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader"/>
+      <doc>
+      <![CDATA[Implement Comparable contract (compare key of join or head of heap
+ with that of another).]]>
+      </doc>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new key common to all child RRs.
+ @throws ClassCastException if key classes differ.]]>
+      </doc>
+    </method>
+    <method name="createTupleWritable" return="org.apache.hadoop.mapreduce.lib.join.TupleWritable"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a value to be used internally for joins.]]>
+      </doc>
+    </method>
+    <method name="getCurrentValue" return="X"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close all child RRs.]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Report progress as the minimum of all child RR progress.]]>
+      </doc>
+    </method>
+    <field name="conf" type="org.apache.hadoop.conf.Configuration"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="keyclass" type="java.lang.Class"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="jc" type="org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="kids" type="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader[]"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="key" type="K"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="value" type="X"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A RecordReader that can effect joins of RecordReaders sharing a common key
+ type and partitioning.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader -->
+  <class name="InnerJoinRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.JoinRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="combine" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="dst" type="org.apache.hadoop.mapreduce.lib.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Return true iff the tuple is full (all data sources contain this key).]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Full inner join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.InnerJoinRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.JoinRecordReader -->
+  <class name="JoinRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="JoinRecordReader" type="int, org.apache.hadoop.conf.Configuration, int, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Emit the next set of key, value pairs as defined by the child
+ RecordReaders and operation associated with this composite RR.]]>
+      </doc>
+    </method>
+    <method name="createValue" return="org.apache.hadoop.mapreduce.lib.join.TupleWritable"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDelegate" return="org.apache.hadoop.mapreduce.lib.join.ResetableIterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return an iterator wrapping the JoinCollector.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Base class for Composite joins returning Tuples of arbitrary Writables.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.JoinRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader -->
+  <class name="MultiFilterRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultiFilterRecordReader" type="int, org.apache.hadoop.conf.Configuration, int, java.lang.Class"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="emit" return="V"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="dst" type="org.apache.hadoop.mapreduce.lib.join.TupleWritable"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[For each tuple emitted, return a value (typically one of the values
+ in the tuple).
+ Modifying the Writables in the tuple is permitted and unlikely to affect
+ join behavior in most cases, but it is not recommended. It's safer to
+ clone first.]]>
+      </doc>
+    </method>
+    <method name="combine" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="dst" type="org.apache.hadoop.mapreduce.lib.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Default implementation offers {@link #emit} every Tuple from the
+ collector (the outer join of child RRs).]]>
+      </doc>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getDelegate" return="org.apache.hadoop.mapreduce.lib.join.ResetableIterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return an iterator returning a single value from the tuple.
+ @see MultiFilterDelegationIterator]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Base class for Composite join returning values derived from multiple
+ sources, but generally not tuples.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.OuterJoinRecordReader -->
+  <class name="OuterJoinRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.JoinRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="combine" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="srcs" type="java.lang.Object[]"/>
+      <param name="dst" type="org.apache.hadoop.mapreduce.lib.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Emit everything from the collector.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Full outer join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.OuterJoinRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader -->
+  <class name="OverrideRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.MultiFilterRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="emit" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="dst" type="org.apache.hadoop.mapreduce.lib.join.TupleWritable"/>
+      <doc>
+      <![CDATA[Emit the value with the highest position in the tuple.]]>
+      </doc>
+    </method>
+    <method name="createValue" return="V"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="fillJoinCollector"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="iterkey" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Instead of filling the JoinCollector with iterators from all
+ data sources, fill only the rightmost for this key.
+ This not only saves space by discarding the other sources, but
+ it also emits the number of key-value pairs in the preferred
+ RecordReader instead of repeating that stream n times, where
+ n is the cardinality of the cross product of the discarded
+ streams for the given key.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Prefer the &quot;rightmost&quot; data source for this key.
+ For example, <tt>override(S1,S2,S3)</tt> will prefer values
+ from S3 over S2, and values from S2 over S1 for all keys
+ emitted from all sources.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.OverrideRecordReader -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser -->
+  <class name="Parser" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Parser"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Very simple shift-reduce parser for join expressions.
+
+ This should be sufficient for the user extension permitted now, but ought to
+ be replaced with a parser generator if more complex grammars are supported.
+ In particular, this &quot;shift-reduce&quot; parser has no states. Each set
+ of formals requires a different internal node type, which is responsible for
+ interpreting the list of tokens it receives. This is sufficient for the
+ current grammar, but it has several annoying properties that might inhibit
+ extension. In particular, parenthesis are always function calls; an
+ algebraic or filter grammar would not only require a node type, but must
+ also work around the internals of this parser.
+
+ For most other cases, adding classes to the hierarchy- particularly by
+ extending JoinRecordReader and MultiFilterRecordReader- is fairly
+ straightforward. One need only override the relevant method(s) (usually only
+ {@link CompositeRecordReader#combine}) and include a property to map its
+ value to an identifier in the parser.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser.Node -->
+  <class name="Parser.Node" extends="org.apache.hadoop.mapreduce.lib.join.ComposableInputFormat"
+    abstract="true"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Node" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="addIdentifier"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="ident" type="java.lang.String"/>
+      <param name="mcstrSig" type="java.lang.Class[]"/>
+      <param name="nodetype" type="java.lang.Class"/>
+      <param name="cl" type="java.lang.Class"/>
+      <exception name="NoSuchMethodException" type="java.lang.NoSuchMethodException"/>
+      <doc>
+      <![CDATA[For a given identifier, add a mapping to the nodetype for the parse
+ tree and to the ComposableRecordReader to be created, including the
+ formals required to invoke the constructor.
+ The nodetype and constructor signature should be filled in from the
+ child node.]]>
+      </doc>
+    </method>
+    <method name="setID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="id" type="int"/>
+    </method>
+    <method name="setKeyComparator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="cmpcl" type="java.lang.Class"/>
+    </method>
+    <field name="rrCstrMap" type="java.util.Map"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="id" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="ident" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="cmpcl" type="java.lang.Class"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser.Node -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser.NodeToken -->
+  <class name="Parser.NodeToken" extends="org.apache.hadoop.mapreduce.lib.join.Parser.Token"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getNode" return="org.apache.hadoop.mapreduce.lib.join.Parser.Node"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser.NodeToken -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser.NumToken -->
+  <class name="Parser.NumToken" extends="org.apache.hadoop.mapreduce.lib.join.Parser.Token"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NumToken" type="double"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNum" return="double"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser.NumToken -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser.StrToken -->
+  <class name="Parser.StrToken" extends="org.apache.hadoop.mapreduce.lib.join.Parser.Token"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StrToken" type="org.apache.hadoop.mapreduce.lib.join.Parser.TType, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getStr" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser.StrToken -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser.Token -->
+  <class name="Parser.Token" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getType" return="org.apache.hadoop.mapreduce.lib.join.Parser.TType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNode" return="org.apache.hadoop.mapreduce.lib.join.Parser.Node"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getNum" return="double"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getStr" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Tagged-union type for tokens from the join expression.
+ @see Parser.TType]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser.Token -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.Parser.TType -->
+  <class name="Parser.TType" extends="java.lang.Enum"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.lib.join.Parser.TType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.lib.join.Parser.TType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.Parser.TType -->
+  <!-- start interface org.apache.hadoop.mapreduce.lib.join.ResetableIterator -->
+  <interface name="ResetableIterator"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="hasNext" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[True if a call to next may return a value. This is permitted false
+ positives, but not false negatives.]]>
+      </doc>
+    </method>
+    <method name="next" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="T"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Assign next value to actual.
+ It is required that elements added to a ResetableIterator be returned in
+ the same order after a call to {@link #reset} (FIFO).
+
+ Note that a call to this may fail for nested joins (i.e. more elements
+ available, but none satisfying the constraints of the join)]]>
+      </doc>
+    </method>
+    <method name="replay" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="T"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Assign last value returned to actual.]]>
+      </doc>
+    </method>
+    <method name="reset"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set iterator to return to the start of its range. Must be called after
+ calling {@link #add} to avoid a ConcurrentModificationException.]]>
+      </doc>
+    </method>
+    <method name="add"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="item" type="T"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Add an element to the collection of elements to iterate over.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Close datasources and release resources. Calling methods on the iterator
+ after calling close has undefined behavior.]]>
+      </doc>
+    </method>
+    <method name="clear"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Close datasources, but do not release internal resources. Calling this
+ method should permit the object to be reused with a different datasource.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This defines an interface to a stateful Iterator that can replay elements
+ added to it directly.
+ Note that this does not extend {@link java.util.Iterator}.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.lib.join.ResetableIterator -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator -->
+  <class name="StreamBackedIterator" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.join.ResetableIterator"/>
+    <constructor name="StreamBackedIterator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="next" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="X"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="replay" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="val" type="X"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="reset"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="item" type="X"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="clear"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[This class provides an implementation of ResetableIterator. This
+ implementation uses a byte array to store elements added to it.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.StreamBackedIterator -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.TupleWritable -->
+  <class name="TupleWritable" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <implements name="java.lang.Iterable"/>
+    <constructor name="TupleWritable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an empty tuple with no allocated storage for writables.]]>
+      </doc>
+    </constructor>
+    <constructor name="TupleWritable" type="org.apache.hadoop.io.Writable[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Initialize tuple with storage; unknown whether any of them contain
+ &quot;written&quot; values.]]>
+      </doc>
+    </constructor>
+    <method name="has" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Return true if tuple has an element at the position provided.]]>
+      </doc>
+    </method>
+    <method name="get" return="org.apache.hadoop.io.Writable"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="int"/>
+      <doc>
+      <![CDATA[Get ith Writable from Tuple.]]>
+      </doc>
+    </method>
+    <method name="size" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of children in this Tuple.]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="iterator" return="java.util.Iterator"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return an iterator over the elements in this tuple.
+ Note that this doesn't flatten the tuple; one may receive tuples
+ from this iterator.]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Convert Tuple to String as in the following.
+ <tt>[&lt;child1&gt;,&lt;child2&gt;,...,&lt;childn&gt;]</tt>]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Writes each Writable to <code>out</code>.
+ TupleWritable format:
+ {@code
+  <count><type1><type2>...<typen><obj1><obj2>...<objn>
+ }]]>
+      </doc>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <field name="written" type="java.util.BitSet"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Writable type storing multiple {@link org.apache.hadoop.io.Writable}s.
+
+ This is *not* a general-purpose tuple type. In almost all cases, users are
+ encouraged to implement their own serializable types, which can perform
+ better validation and provide more efficient encodings than this class is
+ capable. TupleWritable relies on the join framework for type safety and
+ assumes its instances will rarely be persisted, assumptions not only
+ incompatible with, but contrary to the general case.
+
+ @see org.apache.hadoop.io.Writable]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.TupleWritable -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader -->
+  <class name="WrappedRecordReader" extends="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="WrappedRecordReader" type="int"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="split" type="org.apache.hadoop.mapreduce.InputSplit"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="createKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Request new key from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="createValue" return="U"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="id" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[{@inheritDoc}]]>
+      </doc>
+    </method>
+    <method name="key" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return the key at the head of this RR.]]>
+      </doc>
+    </method>
+    <method name="key"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="qkey" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Clone the key at the head of this RR into the object supplied.]]>
+      </doc>
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return true if the RR- including the k,v pair stored in this object-
+ is exhausted.]]>
+      </doc>
+    </method>
+    <method name="skip"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Skip key-value pairs with keys less than or equal to the key provided.]]>
+      </doc>
+    </method>
+    <method name="accept"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="i" type="org.apache.hadoop.mapreduce.lib.join.CompositeRecordReader.JoinCollector"/>
+      <param name="key" type="K"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Add an iterator to the collector at the position occupied by this
+ RecordReader over the values in this stream paired with the key
+ provided (ie register a stream of values from this source matching K
+ with a collector).]]>
+      </doc>
+    </method>
+    <method name="nextKeyValue" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Read the next k,v pair into the head of this object; return true iff
+ the RR and this are exhausted.]]>
+      </doc>
+    </method>
+    <method name="getCurrentKey" return="K"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get current key]]>
+      </doc>
+    </method>
+    <method name="getCurrentValue" return="U"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get current value]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Request progress from proxied RR.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Forward close request to proxied RR.]]>
+      </doc>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.mapreduce.lib.join.ComposableRecordReader"/>
+      <doc>
+      <![CDATA[Implement Comparable contract (compare key at head of proxied RR
+ with that of another).]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Return true iff compareTo(other) retn true.]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="empty" type="boolean"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="cmp" type="org.apache.hadoop.io.WritableComparator"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Proxy class for a RecordReader participating in the join framework.
+ 
+ This class keeps track of the &quot;head&quot; key-value pair for the
+ provided RecordReader and keeps a store of values matching a key when
+ this source is participating in a join.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.join.WrappedRecordReader -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.map">
+  <!-- start class org.apache.hadoop.mapreduce.lib.map.InverseMapper -->
+  <class name="InverseMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InverseMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[The inverse function.  Input keys and values are swapped.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A {@link Mapper} that swaps keys and values.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.map.InverseMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper -->
+  <class name="MultithreadedMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultithreadedMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNumberOfThreads" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[The number of threads in the thread pool that will run the map function.
+ @param job the job
+ @return the number of threads]]>
+      </doc>
+    </method>
+    <method name="setNumberOfThreads"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="threads" type="int"/>
+      <doc>
+      <![CDATA[Set the number of threads in the pool for running maps.
+ @param job the job to modify
+ @param threads the new number of threads]]>
+      </doc>
+    </method>
+    <method name="getMapperClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the application's mapper class.
+ @param <K1> the map's input key type
+ @param <V1> the map's input value type
+ @param <K2> the map's output key type
+ @param <V2> the map's output value type
+ @param job the job
+ @return the mapper class to run]]>
+      </doc>
+    </method>
+    <method name="setMapperClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="cls" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the application's mapper class.
+ @param <K1> the map input key type
+ @param <V1> the map input value type
+ @param <K2> the map output key type
+ @param <V2> the map output value type
+ @param job the job to modify
+ @param cls the class to use as the mapper]]>
+      </doc>
+    </method>
+    <method name="run"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Run the application's maps using a thread pool.]]>
+      </doc>
+    </method>
+    <field name="NUM_THREADS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAP_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Multithreaded implementation for @link org.apache.hadoop.mapreduce.Mapper.
+ <p>
+ It can be used instead of the default implementation,
+ {@link org.apache.hadoop.mapred.MapRunner}, when the Map operation is not CPU
+ bound in order to improve throughput.
+ <p>
+ Mapper implementations using this MapRunnable must be thread-safe.
+ <p>
+ The Map-Reduce job has to be configured with the mapper to use via 
+ {@link #setMapperClass(Job, Class)} and
+ the number of thread the thread-pool can use with the
+ {@link #getNumberOfThreads(JobContext)} method. The default
+ value is 10 threads.
+ <p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.map.RegexMapper -->
+  <class name="RegexMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RegexMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setup"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+    </method>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <field name="PATTERN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="GROUP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A {@link Mapper} that extracts text matching a regular expression.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.map.RegexMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper -->
+  <class name="TokenCounterMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TokenCounterMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.Object"/>
+      <param name="value" type="org.apache.hadoop.io.Text"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Mapper.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <doc>
+    <![CDATA[Tokenize the input values and emit each word with a count of 1.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.map.TokenCounterMapper -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.map.WrappedMapper -->
+  <class name="WrappedMapper" extends="org.apache.hadoop.mapreduce.Mapper"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="WrappedMapper"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getMapContext" return="org.apache.hadoop.mapreduce.Mapper.Context"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="mapContext" type="org.apache.hadoop.mapreduce.MapContext"/>
+      <doc>
+      <![CDATA[Get a wrapped {@link Mapper.Context} for custom implementations.
+ @param mapContext <code>MapContext</code> to be wrapped
+ @return a wrapped <code>Mapper.Context</code> for custom implementations]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A {@link Mapper} which wraps a given one to allow custom 
+ {@link Mapper.Context} implementations.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.map.WrappedMapper -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.output">
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.BindingPathOutputCommitter -->
+  <class name="BindingPathOutputCommitter" extends="org.apache.hadoop.mapreduce.lib.output.PathOutputCommitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="BindingPathOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.TaskAttemptContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Instantiate.
+ @param outputPath output path (may be null)
+ @param context task context
+ @throws IOException on any failure.]]>
+      </doc>
+    </constructor>
+    <method name="getOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getWorkPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setupTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="needsTaskCommit" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="commitTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="abortTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="cleanupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="commitJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="abortJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="state" type="org.apache.hadoop.mapreduce.JobStatus.State"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isCommitJobRepeatable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobContext" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="recoverTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="taskContext" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="hasOutputPath" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getCommitter" return="org.apache.hadoop.mapreduce.lib.output.PathOutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the inner committer.
+ @return the bonded committer.]]>
+      </doc>
+    </method>
+    <field name="NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The classname for use in configurations.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[This is a special committer which creates the factory for the committer and
+ runs off that. Why does it exist? So that you can explicitly instantiate
+ a committer by classname and yet still have the actual implementation
+ driven dynamically by the factory options and destination filesystem.
+ This simplifies integration
+ with existing code which takes the classname of a committer.
+ There's no factory for this, as that would lead to a loop.
+
+ All commit protocol methods and accessors are delegated to the
+ wrapped committer.
+
+ How to use:
+
+ <ol>
+   <li>
+     In applications which take a classname of committer in
+     a configuration option, set it to the canonical name of this class
+     (see {@link #NAME}). When this class is instantiated, it will
+     use the factory mechanism to locate the configured committer for the
+     destination.
+   </li>
+   <li>
+     In code, explicitly create an instance of this committer through
+     its constructor, then invoke commit lifecycle operations on it.
+     The dynamically configured committer will be created in the constructor
+     and have the lifecycle operations relayed to it.
+   </li>
+ </ol>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.BindingPathOutputCommitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -->
+  <class name="FileOutputCommitter" extends="org.apache.hadoop.mapreduce.lib.output.PathOutputCommitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FileOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.TaskAttemptContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a file output committer
+ @param outputPath the job's output path, or null if you want the output
+ committer to act as a noop.
+ @param context the task's context
+ @throws IOException]]>
+      </doc>
+    </constructor>
+    <constructor name="FileOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.JobContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a file output committer
+ @param outputPath the job's output path, or null if you want the output
+ committer to act as a noop.
+ @param context the task's context
+ @throws IOException]]>
+      </doc>
+    </constructor>
+    <method name="getOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the path where final output of the job should be placed.  This
+ could also be considered the committed application attempt path.]]>
+      </doc>
+    </method>
+    <method name="getJobAttemptPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a given job attempt will be placed. 
+ @param context the context of the job.  This is used to get the
+ application attempt id.
+ @return the path to store job attempt data.]]>
+      </doc>
+    </method>
+    <method name="getJobAttemptPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="out" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a given job attempt will be placed. 
+ @param context the context of the job.  This is used to get the
+ application attempt id.
+ @param out the output path to place these in.
+ @return the path to store job attempt data.]]>
+      </doc>
+    </method>
+    <method name="getJobAttemptPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="int"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a given job attempt will be placed. 
+ @param appAttemptId the ID of the application attempt for this job.
+ @return the path to store job attempt data.]]>
+      </doc>
+    </method>
+    <method name="getTaskAttemptPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a task attempt is stored until
+ that task is committed.
+ 
+ @param context the context of the task attempt.
+ @return the path where a task attempt should be stored.]]>
+      </doc>
+    </method>
+    <method name="getTaskAttemptPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <param name="out" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a task attempt is stored until
+ that task is committed.
+ 
+ @param context the context of the task attempt.
+ @param out The output path to put things in.
+ @return the path where a task attempt should be stored.]]>
+      </doc>
+    </method>
+    <method name="getCommittedTaskPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a committed task is stored until
+ the entire job is committed.
+ @param context the context of the task attempt
+ @return the path where the output of a committed task is stored until
+ the entire job is committed.]]>
+      </doc>
+    </method>
+    <method name="getCommittedTaskPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <param name="out" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="getCommittedTaskPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="int"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <doc>
+      <![CDATA[Compute the path where the output of a committed task is stored until the
+ entire job is committed for a specific application attempt.
+ @param appAttemptId the id of the application attempt to use
+ @param context the context of any task.
+ @return the path where the output of a committed task is stored.]]>
+      </doc>
+    </method>
+    <method name="getWorkPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the directory that the task should write results into.
+ @return the work directory
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="setupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create the temporary directory that is the root of all of the task 
+ work directories.
+ @param context the job's context]]>
+      </doc>
+    </method>
+    <method name="commitJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[The job has completed, so do works in commitJobInternal().
+ Could retry on failure if using algorithm 2.
+ @param context the job's context]]>
+      </doc>
+    </method>
+    <method name="commitJobInternal"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[The job has completed, so do following commit job, include:
+ Move all committed tasks to the final output dir (algorithm 1 only).
+ Delete the temporary directory, including all of the work directories.
+ Create a _SUCCESS file to make it as successful.
+ @param context the job's context]]>
+      </doc>
+    </method>
+    <method name="cleanupJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="abortJob"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="state" type="org.apache.hadoop.mapreduce.JobStatus.State"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Delete the temporary directory, including all of the work directories.
+ @param context the job's context]]>
+      </doc>
+    </method>
+    <method name="setupTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[No task setup required.]]>
+      </doc>
+    </method>
+    <method name="commitTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Move the files from the work directory to the job output directory
+ @param context the task context]]>
+      </doc>
+    </method>
+    <method name="abortTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Delete the work directory
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="needsTaskCommit" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Did this task write any files in the work directory?
+ @param context the task's context]]>
+      </doc>
+    </method>
+    <method name="isRecoverySupported" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isCommitJobRepeatable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="recoverTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="PENDING_DIR_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Name of directory where pending data is placed.  Data that has not been
+ committed yet.]]>
+      </doc>
+    </field>
+    <field name="TEMP_DIR_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Temporary directory name 
+
+ The static variable to be compatible with M/R 1.x]]>
+      </doc>
+    </field>
+    <field name="SUCCEEDED_FILE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SUCCESSFUL_JOB_OUTPUT_DIR_MARKER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_ALGORITHM_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_CLEANUP_SKIPPED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_CLEANUP_SKIPPED_DEFAULT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_CLEANUP_FAILURES_IGNORED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_CLEANUP_FAILURES_IGNORED_DEFAULT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_FAILURE_ATTEMPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_FAILURE_ATTEMPTS_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_TASK_CLEANUP_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILEOUTPUTCOMMITTER_TASK_CLEANUP_ENABLED_DEFAULT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An {@link OutputCommitter} that commits files specified 
+ in job output directory i.e. ${mapreduce.output.fileoutputformat.outputdir}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat -->
+  <class name="FileOutputFormat" extends="org.apache.hadoop.mapreduce.OutputFormat"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setCompressOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="compress" type="boolean"/>
+      <doc>
+      <![CDATA[Set whether the output of the job is compressed.
+ @param job the job to modify
+ @param compress should the output of the job be compressed?]]>
+      </doc>
+    </method>
+    <method name="getCompressOutput" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Is the job output compressed?
+ @param job the Job to look in
+ @return <code>true</code> if the job output should be compressed,
+         <code>false</code> otherwise]]>
+      </doc>
+    </method>
+    <method name="setOutputCompressorClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="codecClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the {@link CompressionCodec} to be used to compress job outputs.
+ @param job the job to modify
+ @param codecClass the {@link CompressionCodec} to be used to
+                   compress the job outputs]]>
+      </doc>
+    </method>
+    <method name="getOutputCompressorClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="defaultValue" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Get the {@link CompressionCodec} for compressing the job outputs.
+ @param job the {@link Job} to look in
+ @param defaultValue the {@link CompressionCodec} to return if not set
+ @return the {@link CompressionCodec} to be used to compress the 
+         job outputs
+ @throws IllegalArgumentException if the class was specified, but not found]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="FileAlreadyExistsException" type="org.apache.hadoop.mapred.FileAlreadyExistsException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="setOutputPath"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="outputDir" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the {@link Path} of the output directory for the map-reduce job.
+
+ @param job The job to modify
+ @param outputDir the {@link Path} of the output directory for 
+ the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the {@link Path} to the output directory for the map-reduce job.
+ 
+ @return the {@link Path} to the output directory for the map-reduce job.
+ @see FileOutputFormat#getWorkOutputPath(TaskInputOutputContext)]]>
+      </doc>
+    </method>
+    <method name="getWorkOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskInputOutputContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Get the {@link Path} to the task's temporary output directory 
+  for the map-reduce job
+  
+ <b id="SideEffectFiles">Tasks' Side-Effect Files</b>
+ 
+ <p>Some applications need to create/write-to side-files, which differ from
+ the actual job-outputs.
+ 
+ <p>In such cases there could be issues with 2 instances of the same TIP 
+ (running simultaneously e.g. speculative tasks) trying to open/write-to the
+ same file (path) on HDFS. Hence the application-writer will have to pick 
+ unique names per task-attempt (e.g. using the attemptid, say 
+ <tt>attempt_200709221812_0001_m_000000_0</tt>), not just per TIP.</p> 
+ 
+ <p>To get around this the Map-Reduce framework helps the application-writer 
+ out by maintaining a special 
+ <tt>${mapreduce.output.fileoutputformat.outputdir}/_temporary/_${taskid}</tt> 
+ sub-directory for each task-attempt on HDFS where the output of the 
+ task-attempt goes. On successful completion of the task-attempt the files 
+ in the <tt>${mapreduce.output.fileoutputformat.outputdir}/_temporary/_${taskid}</tt> (only) 
+ are <i>promoted</i> to <tt>${mapreduce.output.fileoutputformat.outputdir}</tt>. Of course, the 
+ framework discards the sub-directory of unsuccessful task-attempts. This 
+ is completely transparent to the application.</p>
+ 
+ <p>The application-writer can take advantage of this by creating any 
+ side-files required in a work directory during execution 
+ of his task i.e. via 
+ {@link #getWorkOutputPath(TaskInputOutputContext)}, and
+ the framework will move them out similarly - thus she doesn't have to pick 
+ unique paths per task-attempt.</p>
+ 
+ <p>The entire discussion holds true for maps of jobs with 
+ reducer=NONE (i.e. 0 reduces) since output of the map, in that case, 
+ goes directly to HDFS.</p> 
+ 
+ @return the {@link Path} to the task's temporary output directory 
+ for the map-reduce job.]]>
+      </doc>
+    </method>
+    <method name="getPathForWorkFile" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskInputOutputContext"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="extension" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Helper function to generate a {@link Path} for a file that is unique for
+ the task within the job output directory.
+
+ <p>The path can be used to create custom files from within the map and
+ reduce tasks. The path name will be unique for each task. The path parent
+ will be the job output directory.</p>ls
+
+ <p>This method uses the {@link #getUniqueFile} method to make the file name
+ unique for the task.</p>
+
+ @param context the context for the task.
+ @param name the name for the file.
+ @param extension the extension for the file
+ @return a unique path accross all tasks of the job.]]>
+      </doc>
+    </method>
+    <method name="getUniqueFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="true"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="extension" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate a unique filename, based on the task id, name, and extension
+ @param context the task that is calling this
+ @param name the base filename
+ @param extension the filename extension
+ @return a string like $name-[mrsct]-$id$extension]]>
+      </doc>
+    </method>
+    <method name="getDefaultWorkFile" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <param name="extension" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the default path and filename for the output format.
+ @param context the task context
+ @param extension an extension to add to the filename
+ @return a full path $output/_temporary/$taskid/part-[mr]-$id
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getOutputName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the base output name for the output file.]]>
+      </doc>
+    </method>
+    <method name="setOutputName"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the base output name for output file to be created.]]>
+      </doc>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="BASE_OUTPUT_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="PART" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="COMPRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configuration option: should output be compressed? {@value}.]]>
+      </doc>
+    </field>
+    <field name="COMPRESS_CODEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[If compression is enabled, name of codec: {@value}.]]>
+      </doc>
+    </field>
+    <field name="COMPRESS_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Type of compression {@value}: NONE, RECORD, BLOCK.
+ Generally only used in {@code SequenceFileOutputFormat}.]]>
+      </doc>
+    </field>
+    <field name="OUTDIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Destination directory of work: {@value}.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A base class for {@link OutputFormat}s that read from {@link FileSystem}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter -->
+  <class name="FileOutputFormatCounter" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat -->
+  <class name="FilterOutputFormat" extends="org.apache.hadoop.mapreduce.OutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FilterOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FilterOutputFormat" type="org.apache.hadoop.mapreduce.OutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a FilterOutputFormat based on the underlying output format.
+ @param baseOut the underlying OutputFormat]]>
+      </doc>
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <field name="baseOut" type="org.apache.hadoop.mapreduce.OutputFormat"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[FilterOutputFormat is a convenience class that wraps OutputFormat.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat -->
+  <class name="LazyOutputFormat" extends="org.apache.hadoop.mapreduce.lib.output.FilterOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LazyOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setOutputFormatClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the underlying output format for LazyOutputFormat.
+ @param job the {@link Job} to modify
+ @param theClass the underlying class]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <field name="OUTPUT_FORMAT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A Convenience class that creates output lazily.
+ Use in conjuction with org.apache.hadoop.mapreduce.lib.output.MultipleOutputs to recreate the
+ behaviour of org.apache.hadoop.mapred.lib.MultipleTextOutputFormat (etc) of the old Hadoop API.
+ See {@link MultipleOutputs} documentation for more information.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat -->
+  <class name="MapFileOutputFormat" extends="org.apache.hadoop.mapreduce.lib.output.FileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MapFileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getReaders" return="org.apache.hadoop.io.MapFile.Reader[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="dir" type="org.apache.hadoop.fs.Path"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Open the output generated by this format.]]>
+      </doc>
+    </method>
+    <method name="getEntry" return="org.apache.hadoop.io.Writable"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="readers" type="org.apache.hadoop.io.MapFile.Reader[]"/>
+      <param name="partitioner" type="org.apache.hadoop.mapreduce.Partitioner"/>
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get an entry from output generated by this class.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[An {@link org.apache.hadoop.mapreduce.OutputFormat} that writes 
+ {@link MapFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.MultipleOutputs -->
+  <class name="MultipleOutputs" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MultipleOutputs" type="org.apache.hadoop.mapreduce.TaskInputOutputContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Creates and initializes multiple outputs support,
+ it should be instantiated in the Mapper/Reducer setup method.
+
+ @param context the TaskInputOutputContext object]]>
+      </doc>
+    </constructor>
+    <method name="addNamedOutput"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="outputFormatClass" type="java.lang.Class"/>
+      <param name="keyClass" type="java.lang.Class"/>
+      <param name="valueClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Adds a named output for the job.
+
+ @param job               job to add the named output
+ @param namedOutput       named output name, it has to be a word, letters
+                          and numbers only, cannot be the word 'part' as
+                          that is reserved for the default output.
+ @param outputFormatClass OutputFormat class.
+ @param keyClass          key class
+ @param valueClass        value class]]>
+      </doc>
+    </method>
+    <method name="setCountersEnabled"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="enabled" type="boolean"/>
+      <doc>
+      <![CDATA[Enables or disables counters for the named outputs.
+ 
+ The counters group is the {@link MultipleOutputs} class name.
+ The names of the counters are the same as the named outputs. These
+ counters count the number records written to each output name.
+ By default these counters are disabled.
+
+ @param job    job  to enable counters
+ @param enabled indicates if the counters will be enabled or not.]]>
+      </doc>
+    </method>
+    <method name="getCountersEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Returns if the counters for the named outputs are enabled or not.
+ By default these counters are disabled.
+
+ @param job    the job 
+ @return TRUE if the counters are enabled, FALSE if they are disabled.]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Write key and value to the namedOutput.
+
+ Output path is a unique file generated for the namedOutput.
+ For example, {namedOutput}-(m|r)-{part-number}
+ 
+ @param namedOutput the named output name
+ @param key         the key
+ @param value       the value]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="namedOutput" type="java.lang.String"/>
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="baseOutputPath" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Write key and value to baseOutputPath using the namedOutput.
+ 
+ @param namedOutput    the named output name
+ @param key            the key
+ @param value          the value
+ @param baseOutputPath base-output path to write the record to.
+ Note: Framework will generate unique filename for the baseOutputPath
+ <b>Warning</b>: when the baseOutputPath is a path that resolves
+ outside of the final job output directory, the directory is created
+ immediately and then persists through subsequent task retries, breaking
+ the concept of output committing.]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="KEYOUT"/>
+      <param name="value" type="VALUEOUT"/>
+      <param name="baseOutputPath" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Write key value to an output file name.
+ 
+ Gets the record writer from job's output format.  
+ Job's output format should be a FileOutputFormat.
+ 
+ @param key       the key
+ @param value     the value
+ @param baseOutputPath base-output path to write the record to.
+ Note: Framework will generate unique filename for the baseOutputPath
+ <b>Warning</b>: when the baseOutputPath is a path that resolves
+ outside of the final job output directory, the directory is created
+ immediately and then persists through subsequent task retries, breaking
+ the concept of output committing.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Closes all the opened outputs.
+ 
+ This should be called from cleanup method of map/reduce task.
+ If overridden subclasses must invoke <code>super.close()</code> at the
+ end of their <code>close()</code>]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The MultipleOutputs class simplifies writing output data 
+ to multiple outputs
+ 
+ <p> 
+ Case one: writing to additional outputs other than the job default output.
+
+ Each additional output, or named output, may be configured with its own
+ <code>OutputFormat</code>, with its own key class and with its own value
+ class.
+ </p>
+ 
+ <p>
+ Case two: to write data to different files provided by user
+ </p>
+ 
+ <p>
+ MultipleOutputs supports counters, by default they are disabled. The 
+ counters group is the {@link MultipleOutputs} class name. The names of the 
+ counters are the same as the output name. These count the number records 
+ written to each output name.
+ </p>
+ 
+ Usage pattern for job submission:
+ <pre>
+
+ Job job = new Job();
+
+ FileInputFormat.setInputPath(job, inDir);
+ FileOutputFormat.setOutputPath(job, outDir);
+
+ job.setMapperClass(MOMap.class);
+ job.setReducerClass(MOReduce.class);
+ ...
+
+ // Defines additional single text based output 'text' for the job
+ MultipleOutputs.addNamedOutput(job, "text", TextOutputFormat.class,
+ LongWritable.class, Text.class);
+
+ // Defines additional sequence-file based output 'sequence' for the job
+ MultipleOutputs.addNamedOutput(job, "seq",
+   SequenceFileOutputFormat.class,
+   LongWritable.class, Text.class);
+ ...
+
+ job.waitForCompletion(true);
+ ...
+ </pre>
+ <p>
+ Usage in Reducer:
+ <pre>
+ &lt;K, V&gt; String generateFileName(K k, V v) {
+   return k.toString() + "_" + v.toString();
+ }
+ 
+ public class MOReduce extends
+   Reducer&lt;WritableComparable, Writable,WritableComparable, Writable&gt; {
+ private MultipleOutputs mos;
+ public void setup(Context context) {
+ ...
+ mos = new MultipleOutputs(context);
+ }
+
+ public void reduce(WritableComparable key, Iterator&lt;Writable&gt; values,
+ Context context)
+ throws IOException {
+ ...
+ mos.write("text", , key, new Text("Hello"));
+ mos.write("seq", LongWritable(1), new Text("Bye"), "seq_a");
+ mos.write("seq", LongWritable(2), key, new Text("Chau"), "seq_b");
+ mos.write(key, new Text("value"), generateFileName(key, new Text("value")));
+ ...
+ }
+
+ public void cleanup(Context) throws IOException {
+ mos.close();
+ ...
+ }
+
+ }
+ </pre>
+ 
+ <p>
+ When used in conjuction with org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat,
+ MultipleOutputs can mimic the behaviour of MultipleTextOutputFormat and MultipleSequenceFileOutputFormat
+ from the old Hadoop API - ie, output can be written from the Reducer to more than one location.
+ </p>
+ 
+ <p>
+ Use <code>MultipleOutputs.write(KEYOUT key, VALUEOUT value, String baseOutputPath)</code> to write key and 
+ value to a path specified by <code>baseOutputPath</code>, with no need to specify a named output.
+ <b>Warning</b>: when the baseOutputPath passed to MultipleOutputs.write
+ is a path that resolves outside of the final job output directory, the
+ directory is created immediately and then persists through subsequent
+ task retries, breaking the concept of output committing:
+ </p>
+ 
+ <pre>
+ private MultipleOutputs&lt;Text, Text&gt; out;
+ 
+ public void setup(Context context) {
+   out = new MultipleOutputs&lt;Text, Text&gt;(context);
+   ...
+ }
+ 
+ public void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException {
+ for (Text t : values) {
+   out.write(key, t, generateFileName(&lt;<i>parameter list...</i>&gt;));
+   }
+ }
+ 
+ protected void cleanup(Context context) throws IOException, InterruptedException {
+   out.close();
+ }
+ </pre>
+ 
+ <p>
+ Use your own code in <code>generateFileName()</code> to create a custom path to your results. 
+ '/' characters in <code>baseOutputPath</code> will be translated into directory levels in your file system. 
+ Also, append your custom-generated path with "part" or similar, otherwise your output will be -00000, -00001 etc. 
+ No call to <code>context.write()</code> is necessary. See example <code>generateFileName()</code> code below. 
+ </p>
+ 
+ <pre>
+ private String generateFileName(Text k) {
+   // expect Text k in format "Surname|Forename"
+   String[] kStr = k.toString().split("\\|");
+   
+   String sName = kStr[0];
+   String fName = kStr[1];
+
+   // example for k = Smith|John
+   // output written to /user/hadoop/path/to/output/Smith/John-r-00000 (etc)
+   return sName + "/" + fName;
+ }
+ </pre>
+ 
+ <p>
+ Using MultipleOutputs in this way will still create zero-sized default output, eg part-00000.
+ To prevent this use <code>LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class);</code>
+ instead of <code>job.setOutputFormatClass(TextOutputFormat.class);</code> in your Hadoop job configuration.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.MultipleOutputs -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.NullOutputFormat -->
+  <class name="NullOutputFormat" extends="org.apache.hadoop.mapreduce.OutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NullOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.JobContext"/>
+    </method>
+    <method name="getOutputCommitter" return="org.apache.hadoop.mapreduce.OutputCommitter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+    </method>
+    <doc>
+    <![CDATA[Consume all outputs and put them in /dev/null.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.NullOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter -->
+  <class name="PartialFileOutputCommitter" extends="org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.mapreduce.lib.output.PartialOutputCommitter"/>
+    <constructor name="PartialFileOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.TaskAttemptContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <constructor name="PartialFileOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.JobContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="getCommittedTaskPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="int"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+    </method>
+    <method name="cleanUpPartialOutputForTask"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[An {@link OutputCommitter} that commits files specified
+ in job output directory i.e. ${mapreduce.output.fileoutputformat.outputdir}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.PartialFileOutputCommitter -->
+  <!-- start interface org.apache.hadoop.mapreduce.lib.output.PartialOutputCommitter -->
+  <interface name="PartialOutputCommitter"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="cleanUpPartialOutputForTask"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Remove all previously committed outputs from prior executions of this task.
+ @param context Context for cleaning up previously promoted output.
+ @throws IOException If cleanup fails, then the state of the task my not be
+                     well defined.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Interface for an {@link org.apache.hadoop.mapreduce.OutputCommitter}
+ implementing partial commit of task output, as during preemption.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.mapreduce.lib.output.PartialOutputCommitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.PathOutputCommitter -->
+  <class name="PathOutputCommitter" extends="org.apache.hadoop.mapreduce.OutputCommitter"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="PathOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.TaskAttemptContext"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Constructor for a task attempt.
+ Subclasses should provide a public constructor with this signature.
+ @param outputPath output path: may be null
+ @param context task context
+ @throws IOException IO problem]]>
+      </doc>
+    </constructor>
+    <constructor name="PathOutputCommitter" type="org.apache.hadoop.fs.Path, org.apache.hadoop.mapreduce.JobContext"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Constructor for a job attempt.
+ Subclasses should provide a public constructor with this signature.
+ @param outputPath output path: may be null
+ @param context task context
+ @throws IOException IO problem]]>
+      </doc>
+    </constructor>
+    <method name="getOutputPath" return="org.apache.hadoop.fs.Path"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the final directory where work will be placed once the job
+ is committed. This may be null, in which case, there is no output
+ path to write data to.
+ @return the path where final output of the job should be placed.]]>
+      </doc>
+    </method>
+    <method name="hasOutputPath" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Predicate: is there an output path?
+ @return true if we have an output path set, else false.]]>
+      </doc>
+    </method>
+    <method name="getWorkPath" return="org.apache.hadoop.fs.Path"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the directory that the task should write results into.
+ Warning: there's no guarantee that this work path is on the same
+ FS as the final output, or that it's visible across machines.
+ May be null.
+ @return the work directory
+ @throws IOException IO problem]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[A committer which somehow commits data written to a working directory
+ to the final directory during the commit process. The reference
+ implementation of this is the {@link FileOutputCommitter}.
+
+ There are two constructors, both of which do nothing but long and
+ validate their arguments.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.PathOutputCommitter -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat -->
+  <class name="SequenceFileAsBinaryOutputFormat" extends="org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileAsBinaryOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setSequenceFileOutputKeyClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the key class for the {@link SequenceFile}
+ <p>This allows the user to specify the key class to be different 
+ from the actual class ({@link BytesWritable}) used for writing </p>
+ 
+ @param job the {@link Job} to modify
+ @param theClass the SequenceFile output key class.]]>
+      </doc>
+    </method>
+    <method name="setSequenceFileOutputValueClass"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="theClass" type="java.lang.Class"/>
+      <doc>
+      <![CDATA[Set the value class for the {@link SequenceFile}
+ <p>This allows the user to specify the value class to be different 
+ from the actual class ({@link BytesWritable}) used for writing </p>
+ 
+ @param job the {@link Job} to modify
+ @param theClass the SequenceFile output key class.]]>
+      </doc>
+    </method>
+    <method name="getSequenceFileOutputKeyClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the key class for the {@link SequenceFile}
+ 
+ @return the key class of the {@link SequenceFile}]]>
+      </doc>
+    </method>
+    <method name="getSequenceFileOutputValueClass" return="java.lang.Class"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the value class for the {@link SequenceFile}
+ 
+ @return the value class of the {@link SequenceFile}]]>
+      </doc>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="checkOutputSpecs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <field name="KEY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="VALUE_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[An {@link org.apache.hadoop.mapreduce.OutputFormat} that writes keys, 
+ values to {@link SequenceFile}s in binary(raw) format]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat -->
+  <class name="SequenceFileOutputFormat" extends="org.apache.hadoop.mapreduce.lib.output.FileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SequenceFileOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSequenceWriter" return="org.apache.hadoop.io.SequenceFile.Writer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <param name="keyClass" type="java.lang.Class"/>
+      <param name="valueClass" type="java.lang.Class"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="getOutputCompressionType" return="org.apache.hadoop.io.SequenceFile.CompressionType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the {@link CompressionType} for the output {@link SequenceFile}.
+ @param job the {@link Job}
+ @return the {@link CompressionType} for the output {@link SequenceFile}, 
+         defaulting to {@link CompressionType#RECORD}]]>
+      </doc>
+    </method>
+    <method name="setOutputCompressionType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="style" type="org.apache.hadoop.io.SequenceFile.CompressionType"/>
+      <doc>
+      <![CDATA[Set the {@link CompressionType} for the output {@link SequenceFile}.
+ @param job the {@link Job} to modify
+ @param style the {@link CompressionType} for the output
+              {@link SequenceFile}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[An {@link OutputFormat} that writes {@link SequenceFile}s.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat -->
+  <class name="TextOutputFormat" extends="org.apache.hadoop.mapreduce.lib.output.FileOutputFormat"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TextOutputFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecordWriter" return="org.apache.hadoop.mapreduce.RecordWriter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.TaskAttemptContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <field name="SEPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SEPERATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #SEPARATOR}">
+      <doc>
+      <![CDATA[@deprecated Use {@link #SEPARATOR}]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[An {@link OutputFormat} that writes plain text files.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.partition">
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner -->
+  <class name="BinaryPartitioner" extends="org.apache.hadoop.mapreduce.Partitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="BinaryPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setOffsets"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="left" type="int"/>
+      <param name="right" type="int"/>
+      <doc>
+      <![CDATA[Set the subarray to be used for partitioning to 
+ <code>bytes[left:(right+1)]</code> in Python syntax.
+ 
+ @param conf configuration object
+ @param left left Python-style offset
+ @param right right Python-style offset]]>
+      </doc>
+    </method>
+    <method name="setLeftOffset"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="offset" type="int"/>
+      <doc>
+      <![CDATA[Set the subarray to be used for partitioning to 
+ <code>bytes[offset:]</code> in Python syntax.
+ 
+ @param conf configuration object
+ @param offset left Python-style offset]]>
+      </doc>
+    </method>
+    <method name="setRightOffset"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="offset" type="int"/>
+      <doc>
+      <![CDATA[Set the subarray to be used for partitioning to 
+ <code>bytes[:(offset+1)]</code> in Python syntax.
+ 
+ @param conf configuration object
+ @param offset right Python-style offset]]>
+      </doc>
+    </method>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.io.BinaryComparable"/>
+      <param name="value" type="V"/>
+      <param name="numPartitions" type="int"/>
+      <doc>
+      <![CDATA[Use (the specified slice of the array returned by) 
+ {@link BinaryComparable#getBytes()} to partition.]]>
+      </doc>
+    </method>
+    <field name="LEFT_OFFSET_PROPERTY_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RIGHT_OFFSET_PROPERTY_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p>Partition {@link BinaryComparable} keys using a configurable part of 
+ the bytes array returned by {@link BinaryComparable#getBytes()}.</p>
+ 
+ <p>The subarray to be used for the partitioning can be defined by means
+ of the following properties:
+ <ul>
+   <li>
+     <i>mapreduce.partition.binarypartitioner.left.offset</i>:
+     left offset in array (0 by default)
+   </li>
+   <li>
+     <i>mapreduce.partition.binarypartitioner.right.offset</i>: 
+     right offset in array (-1 by default)
+   </li>
+ </ul>
+ Like in Python, both negative and positive offsets are allowed, but
+ the meaning is slightly different. In case of an array of length 5,
+ for instance, the possible offsets are:
+ <pre><code>
+  +---+---+---+---+---+
+  | B | B | B | B | B |
+  +---+---+---+---+---+
+    0   1   2   3   4
+   -5  -4  -3  -2  -1
+ </code></pre>
+ The first row of numbers gives the position of the offsets 0...5 in 
+ the array; the second row gives the corresponding negative offsets. 
+ Contrary to Python, the specified subarray has byte <code>i</code> 
+ and <code>j</code> as first and last element, repectively, when 
+ <code>i</code> and <code>j</code> are the left and right offset.
+ 
+ <p>For Hadoop programs written in Java, it is advisable to use one of 
+ the following static convenience methods for setting the offsets:
+ <ul>
+   <li>{@link #setOffsets}</li>
+   <li>{@link #setLeftOffset}</li>
+   <li>{@link #setRightOffset}</li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.BinaryPartitioner -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.HashPartitioner -->
+  <class name="HashPartitioner" extends="org.apache.hadoop.mapreduce.Partitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="HashPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="numReduceTasks" type="int"/>
+      <doc>
+      <![CDATA[Use {@link Object#hashCode()} to partition.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Partition keys by their {@link Object#hashCode()}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.HashPartitioner -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.InputSampler -->
+  <class name="InputSampler" extends="org.apache.hadoop.conf.Configured"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.util.Tool"/>
+    <constructor name="InputSampler" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="writePartitionFile"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="sampler" type="org.apache.hadoop.mapreduce.lib.partition.InputSampler.Sampler"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="ClassNotFoundException" type="java.lang.ClassNotFoundException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Write a partition file for the given job, using the Sampler provided.
+ Queries the sampler for a sample keyset, sorts by the output key
+ comparator, selects the keys for each rank, and writes to the destination
+ returned from {@link TotalOrderPartitioner#getPartitionFile}.]]>
+      </doc>
+    </method>
+    <method name="run" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+      <doc>
+      <![CDATA[Driver for InputSampler from the command line.
+ Configures a JobConf instance and calls {@link #writePartitionFile}.]]>
+      </doc>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <doc>
+    <![CDATA[Utility for collecting samples and writing a partition file for
+ {@link TotalOrderPartitioner}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.InputSampler -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator -->
+  <class name="KeyFieldBasedComparator" extends="org.apache.hadoop.io.WritableComparator"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="KeyFieldBasedComparator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="compare" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="b1" type="byte[]"/>
+      <param name="s1" type="int"/>
+      <param name="l1" type="int"/>
+      <param name="b2" type="byte[]"/>
+      <param name="s2" type="int"/>
+      <param name="l2" type="int"/>
+    </method>
+    <method name="setKeyFieldComparatorOptions"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="keySpec" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the {@link KeyFieldBasedComparator} options used to compare keys.
+ 
+ @param keySpec the key specification of the form -k pos1[,pos2], where,
+  pos is of the form f[.c][opts], where f is the number
+  of the key field to use, and c is the number of the first character from
+  the beginning of the field. Fields and character posns are numbered 
+  starting with 1; a character position of zero in pos2 indicates the
+  field's last character. If '.c' is omitted from pos1, it defaults to 1
+  (the beginning of the field); if omitted from pos2, it defaults to 0 
+  (the end of the field). opts are ordering options. The supported options
+  are:
+    -n, (Sort numerically)
+    -r, (Reverse the result of comparison)]]>
+      </doc>
+    </method>
+    <method name="getKeyFieldComparatorOption" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the {@link KeyFieldBasedComparator} options]]>
+      </doc>
+    </method>
+    <field name="COMPARATOR_OPTIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This comparator implementation provides a subset of the features provided
+ by the Unix/GNU Sort. In particular, the supported features are:
+ -n, (Sort numerically)
+ -r, (Reverse the result of comparison)
+ -k pos1[,pos2], where pos is of the form f[.c][opts], where f is the number
+  of the field to use, and c is the number of the first character from the
+  beginning of the field. Fields and character posns are numbered starting
+  with 1; a character position of zero in pos2 indicates the field's last
+  character. If '.c' is omitted from pos1, it defaults to 1 (the beginning
+  of the field); if omitted from pos2, it defaults to 0 (the end of the
+  field). opts are ordering options (any of 'nr' as described above). 
+ We assume that the fields in the key are separated by 
+ {@link JobContext#MAP_OUTPUT_KEY_FIELD_SEPARATOR}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner -->
+  <class name="KeyFieldBasedPartitioner" extends="org.apache.hadoop.mapreduce.Partitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="KeyFieldBasedPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K2"/>
+      <param name="value" type="V2"/>
+      <param name="numReduceTasks" type="int"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="b" type="byte[]"/>
+      <param name="start" type="int"/>
+      <param name="end" type="int"/>
+      <param name="currentHash" type="int"/>
+    </method>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="hash" type="int"/>
+      <param name="numReduceTasks" type="int"/>
+    </method>
+    <method name="setKeyFieldPartitionerOptions"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="keySpec" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the {@link KeyFieldBasedPartitioner} options used for 
+ {@link Partitioner}
+ 
+ @param keySpec the key specification of the form -k pos1[,pos2], where,
+  pos is of the form f[.c][opts], where f is the number
+  of the key field to use, and c is the number of the first character from
+  the beginning of the field. Fields and character posns are numbered 
+  starting with 1; a character position of zero in pos2 indicates the
+  field's last character. If '.c' is omitted from pos1, it defaults to 1
+  (the beginning of the field); if omitted from pos2, it defaults to 0 
+  (the end of the field).]]>
+      </doc>
+    </method>
+    <method name="getKeyFieldPartitionerOption" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.JobContext"/>
+      <doc>
+      <![CDATA[Get the {@link KeyFieldBasedPartitioner} options]]>
+      </doc>
+    </method>
+    <field name="PARTITIONER_OPTIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Defines a way to partition keys based on certain key fields (also see
+  {@link KeyFieldBasedComparator}.
+  The key specification supported is of the form -k pos1[,pos2], where,
+  pos is of the form f[.c][opts], where f is the number
+  of the key field to use, and c is the number of the first character from
+  the beginning of the field. Fields and character posns are numbered 
+  starting with 1; a character position of zero in pos2 indicates the
+  field's last character. If '.c' is omitted from pos1, it defaults to 1
+  (the beginning of the field); if omitted from pos2, it defaults to 0 
+  (the end of the field).]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.RehashPartitioner -->
+  <class name="RehashPartitioner" extends="org.apache.hadoop.mapreduce.Partitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RehashPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="numReduceTasks" type="int"/>
+      <doc>
+      <![CDATA[Rehash {@link Object#hashCode()} to partition.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This partitioner rehashes values returned by {@link Object#hashCode()}
+  to get smoother distribution between partitions which may improve
+  reduce reduce time in some cases and should harm things in no cases.
+  This partitioner is suggested with Integer and Long keys with simple
+  patterns in their distributions.
+  @since 2.0.3]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.RehashPartitioner -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner -->
+  <class name="TotalOrderPartitioner" extends="org.apache.hadoop.mapreduce.Partitioner"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.conf.Configurable"/>
+    <constructor name="TotalOrderPartitioner"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="setConf"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Read in the partition file and build indexing data structures.
+ If the keytype is {@link org.apache.hadoop.io.BinaryComparable} and
+ <tt>total.order.partitioner.natural.order</tt> is not false, a trie
+ of the first <tt>total.order.partitioner.max.trie.depth</tt>(2) + 1 bytes
+ will be built. Otherwise, keys will be located using a binary search of
+ the partition keyset using the {@link org.apache.hadoop.io.RawComparator}
+ defined for this job. The input file must be sorted with the same
+ comparator and contain {@link Job#getNumReduceTasks()} - 1 keys.]]>
+      </doc>
+    </method>
+    <method name="getConf" return="org.apache.hadoop.conf.Configuration"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPartition" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="K"/>
+      <param name="value" type="V"/>
+      <param name="numPartitions" type="int"/>
+    </method>
+    <method name="setPartitionFile"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="p" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the path to the SequenceFile storing the sorted partition keyset.
+ It must be the case that for <tt>R</tt> reduces, there are <tt>R-1</tt>
+ keys in the SequenceFile.]]>
+      </doc>
+    </method>
+    <method name="getPartitionFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the path to the SequenceFile storing the sorted partition keyset.
+ @see #setPartitionFile(Configuration, Path)]]>
+      </doc>
+    </method>
+    <field name="DEFAULT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PARTITIONER_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAX_TRIE_DEPTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NATURAL_ORDER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Partitioner effecting a total order by reading split points from
+ an externally generated source.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.partition.TotalOrderPartitioner -->
+</package>
+<package name="org.apache.hadoop.mapreduce.lib.reduce">
+  <!-- start class org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer -->
+  <class name="IntSumReducer" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="IntSumReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="Key"/>
+      <param name="values" type="java.lang.Iterable"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer -->
+  <class name="LongSumReducer" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LongSumReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="reduce"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="KEY"/>
+      <param name="values" type="java.lang.Iterable"/>
+      <param name="context" type="org.apache.hadoop.mapreduce.Reducer.Context"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.reduce.LongSumReducer -->
+  <!-- start class org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer -->
+  <class name="WrappedReducer" extends="org.apache.hadoop.mapreduce.Reducer"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="WrappedReducer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getReducerContext" return="org.apache.hadoop.mapreduce.Reducer.Context"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reduceContext" type="org.apache.hadoop.mapreduce.ReduceContext"/>
+      <doc>
+      <![CDATA[A a wrapped {@link Reducer.Context} for custom implementations.
+ @param reduceContext <code>ReduceContext</code> to be wrapped
+ @return a wrapped <code>Reducer.Context</code> for custom implementations]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A {@link Reducer} which wraps a given one to allow for custom 
+ {@link Reducer.Context} implementations.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer -->
+</package>
+<package name="org.apache.hadoop.mapreduce.server.jobtracker">
+</package>
+<package name="org.apache.hadoop.mapreduce.server.tasktracker">
+</package>
+<package name="org.apache.hadoop.mapreduce.task.annotation">
+  <!-- start class org.apache.hadoop.mapreduce.task.annotation.Checkpointable -->
+  <class name="Checkpointable"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.annotation.Annotation"/>
+    <doc>
+    <![CDATA[Contract representing to the framework that the task can be safely preempted
+ and restarted between invocations of the user-defined function.
+
+ This is often true when the result of a function does not rely on state
+ derived from previous elements in the record stream, but the guarantee is
+ left as an exercise to the implementor.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.task.annotation.Checkpointable -->
+</package>
+<package name="org.apache.hadoop.mapreduce.tools">
+  <!-- start class org.apache.hadoop.mapreduce.tools.CLI -->
+  <class name="CLI" extends="org.apache.hadoop.conf.Configured"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.util.Tool"/>
+    <constructor name="CLI"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="CLI" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="run" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="argv" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="getCounter" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="counters" type="org.apache.hadoop.mapreduce.Counters"/>
+      <param name="counterGroupName" type="java.lang.String"/>
+      <param name="counterName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getTaskLogURL" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="taskId" type="org.apache.hadoop.mapreduce.TaskAttemptID"/>
+      <param name="baseUrl" type="java.lang.String"/>
+    </method>
+    <method name="displayTasks"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="job" type="org.apache.hadoop.mapreduce.Job"/>
+      <param name="type" type="java.lang.String"/>
+      <param name="state" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Display the information about a job's tasks, of a particular type and
+ in a particular state
+ 
+ @param job the job
+ @param type the type of the task (map/reduce/setup/cleanup)
+ @param state the state of the task 
+ (pending/running/completed/failed/killed)
+ @throws IOException when there is an error communicating with the master
+ @throws InterruptedException
+ @throws IllegalArgumentException if an invalid type/state is passed]]>
+      </doc>
+    </method>
+    <method name="displayJobList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="jobs" type="org.apache.hadoop.mapreduce.JobStatus[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="argv" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <field name="cluster" type="org.apache.hadoop.mapreduce.Cluster"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="headerPattern" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="dataPattern" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Interprets the map reduce cli options]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.mapreduce.tools.CLI -->
+</package>
+<package name="org.apache.hadoop.mapreduce.v2">
+</package>
+
+</api>
diff --git a/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_JobClient_3.2.4.xml b/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_JobClient_3.2.4.xml
new file mode 100644
index 000000000000..ed4979ac1fa1
--- /dev/null
+++ b/hadoop-mapreduce-project/dev-support/jdiff/Apache_Hadoop_MapReduce_JobClient_3.2.4.xml
@@ -0,0 +1,16 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:58:05 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop MapReduce JobClient 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/hadoop-annotations.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/jdiff.jar -verbose -classpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/classes:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/hadoop-mapreduce-client-common-3.2.4.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-3.2.4.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/hadoop-yarn-client-3.2.4.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/hadoop-mapreduce-client-core-3.2.4.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.2.4.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/com/google/inject/guice/4.0/guice-4.0.jar:/maven/javax/inject/javax.inject/1/javax.inject-1.jar:/maven/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.5/jackson-module-jaxb-annotations-2.10.5.jar:/maven/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/maven/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.5/jackson-jaxrs-json-provider-2.10.5.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.5/jackson-jaxrs-base-2.10.5.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/slf4j/slf4j-reload4j/1.7.35/slf4j-reload4j-1.7.35.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/maven/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/hadoop-annotations.jar:/build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/jdiff.jar -apidir /build/source/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/site/jdiff/xml -apiname Apache Hadoop MapReduce JobClient 3.2.4 -->
+<package name="org.apache.hadoop.mapred">
+</package>
+
+</api>
diff --git a/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_API_3.2.4.xml b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_API_3.2.4.xml
new file mode 100644
index 000000000000..98c764515499
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_API_3.2.4.xml
@@ -0,0 +1,25332 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:53:54 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop YARN API 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/jdiff.jar -verbose -classpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/classes:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/jdiff.jar -apidir /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/site/jdiff/xml -apiname Apache Hadoop YARN API 3.2.4 -->
+<package name="org.apache.hadoop.yarn.ams">
+</package>
+<package name="org.apache.hadoop.yarn.api">
+  <!-- start interface org.apache.hadoop.yarn.api.ApplicationClientProtocol -->
+  <interface name="ApplicationClientProtocol"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.api.ApplicationBaseProtocol"/>
+    <method name="getNewApplication" return="org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to obtain a new {@link ApplicationId} for 
+ submitting new applications.</p>
+ 
+ <p>The <code>ResourceManager</code> responds with a new, monotonically
+ increasing, {@link ApplicationId} which is used by the client to submit
+ a new application.</p>
+
+ <p>The <code>ResourceManager</code> also responds with details such 
+ as maximum resource capabilities in the cluster as specified in
+ {@link GetNewApplicationResponse}.</p>
+
+ @param request request to get a new <code>ApplicationId</code>
+ @return response containing the new <code>ApplicationId</code> to be used
+ to submit an application
+ @throws YarnException
+ @throws IOException
+ @see #submitApplication(SubmitApplicationRequest)]]>
+      </doc>
+    </method>
+    <method name="submitApplication" return="org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to submit a new application to the
+ <code>ResourceManager.</code></p>
+ 
+ <p>The client is required to provide details such as queue, 
+ {@link Resource} required to run the <code>ApplicationMaster</code>, 
+ the equivalent of {@link ContainerLaunchContext} for launching
+ the <code>ApplicationMaster</code> etc. via the 
+ {@link SubmitApplicationRequest}.</p>
+ 
+ <p>Currently the <code>ResourceManager</code> sends an immediate (empty) 
+ {@link SubmitApplicationResponse} on accepting the submission and throws 
+ an exception if it rejects the submission. However, this call needs to be
+ followed by {@link #getApplicationReport(GetApplicationReportRequest)}
+ to make sure that the application gets properly submitted - obtaining a
+ {@link SubmitApplicationResponse} from ResourceManager doesn't guarantee
+ that RM 'remembers' this application beyond failover or restart. If RM
+ failover or RM restart happens before ResourceManager saves the
+ application's state successfully, the subsequent
+ {@link #getApplicationReport(GetApplicationReportRequest)} will throw
+ a {@link ApplicationNotFoundException}. The Clients need to re-submit
+ the application with the same {@link ApplicationSubmissionContext} when
+ it encounters the {@link ApplicationNotFoundException} on the
+ {@link #getApplicationReport(GetApplicationReportRequest)} call.</p>
+ 
+ <p>During the submission process, it checks whether the application
+ already exists. If the application exists, it will simply return
+ SubmitApplicationResponse</p>
+
+ <p> In secure mode,the <code>ResourceManager</code> verifies access to
+ queues etc. before accepting the application submission.</p>
+ 
+ @param request request to submit a new application
+ @return (empty) response on accepting the submission
+ @throws YarnException
+ @throws IOException
+ @see #getNewApplication(GetNewApplicationRequest)]]>
+      </doc>
+    </method>
+    <method name="failApplicationAttempt" return="org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to request the 
+ <code>ResourceManager</code> to fail an application attempt.</p>
+
+ <p>The client, via {@link FailApplicationAttemptRequest} provides the
+ {@link ApplicationAttemptId} of the attempt to be failed.</p>
+
+ <p> In secure mode,the <code>ResourceManager</code> verifies access to the
+ application, queue etc. before failing the attempt.</p>
+
+ <p>Currently, the <code>ResourceManager</code> returns an empty response
+ on success and throws an exception on rejecting the request.</p>
+
+ @param request request to fail an attempt
+ @return <code>ResourceManager</code> returns an empty response
+         on success and throws an exception on rejecting the request
+ @throws YarnException
+ @throws IOException
+ @see #getQueueUserAcls(GetQueueUserAclsInfoRequest)]]>
+      </doc>
+    </method>
+    <method name="forceKillApplication" return="org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to request the
+ <code>ResourceManager</code> to abort submitted application.</p>
+ 
+ <p>The client, via {@link KillApplicationRequest} provides the
+ {@link ApplicationId} of the application to be aborted.</p>
+ 
+ <p> In secure mode,the <code>ResourceManager</code> verifies access to the
+ application, queue etc. before terminating the application.</p> 
+ 
+ <p>Currently, the <code>ResourceManager</code> returns an empty response
+ on success and throws an exception on rejecting the request.</p>
+ 
+ @param request request to abort a submitted application
+ @return <code>ResourceManager</code> returns an empty response
+         on success and throws an exception on rejecting the request
+ @throws YarnException
+ @throws IOException
+ @see #getQueueUserAcls(GetQueueUserAclsInfoRequest)]]>
+      </doc>
+    </method>
+    <method name="getClusterMetrics" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to get metrics about the cluster from
+ the <code>ResourceManager</code>.</p>
+ 
+ <p>The <code>ResourceManager</code> responds with a
+ {@link GetClusterMetricsResponse} which includes the 
+ {@link YarnClusterMetrics} with details such as number of current
+ nodes in the cluster.</p>
+ 
+ @param request request for cluster metrics
+ @return cluster metrics
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getClusterNodes" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to get a report of all nodes
+ in the cluster from the <code>ResourceManager</code>.</p>
+ 
+ <p>The <code>ResourceManager</code> responds with a 
+ {@link GetClusterNodesResponse} which includes the 
+ {@link NodeReport} for all the nodes in the cluster.</p>
+ 
+ @param request request for report on all nodes
+ @return report on all nodes
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueueInfo" return="org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to get information about <em>queues</em>
+ from the <code>ResourceManager</code>.</p>
+ 
+ <p>The client, via {@link GetQueueInfoRequest}, can ask for details such
+ as used/total resources, child queues, running applications etc.</p>
+
+ <p> In secure mode,the <code>ResourceManager</code> verifies access before
+ providing the information.</p> 
+ 
+ @param request request to get queue information
+ @return queue information
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueueUserAcls" return="org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to get information about <em>queue 
+ acls</em> for <em>current user</em> from the <code>ResourceManager</code>.
+ </p>
+ 
+ <p>The <code>ResourceManager</code> responds with queue acls for all
+ existing queues.</p>
+ 
+ @param request request to get queue acls for <em>current user</em>
+ @return queue acls for <em>current user</em>
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="moveApplicationAcrossQueues" return="org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Move an application to a new queue.
+ 
+ @param request the application ID and the target queue
+ @return an empty response
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getNewReservation" return="org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to obtain a new {@link ReservationId} for
+ submitting new reservations.</p>
+
+ <p>The <code>ResourceManager</code> responds with a new, unique,
+ {@link ReservationId} which is used by the client to submit
+ a new reservation.</p>
+
+ @param request to get a new <code>ReservationId</code>
+ @return response containing the new <code>ReservationId</code> to be used
+ to submit a new reservation
+ @throws YarnException if the reservation system is not enabled.
+ @throws IOException on IO failures.
+ @see #submitReservation(ReservationSubmissionRequest)]]>
+      </doc>
+    </method>
+    <method name="submitReservation" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to submit a new reservation to the
+ {@code ResourceManager}.
+ </p>
+ 
+ <p>
+ The client packages all details of its request in a
+ {@link ReservationSubmissionRequest} object. This contains information
+ about the amount of capacity, temporal constraints, and concurrency needs.
+ Furthermore, the reservation might be composed of multiple stages, with
+ ordering dependencies among them.
+ </p>
+ 
+ <p>
+ In order to respond, a new admission control component in the
+ {@code ResourceManager} performs an analysis of the resources that have
+ been committed over the period of time the user is requesting, verify that
+ the user requests can be fulfilled, and that it respect a sharing policy
+ (e.g., {@code CapacityOverTimePolicy}). Once it has positively determined
+ that the ReservationSubmissionRequest is satisfiable the
+ {@code ResourceManager} answers with a
+ {@link ReservationSubmissionResponse} that include a non-null
+ {@link ReservationId}. Upon failure to find a valid allocation the response
+ is an exception with the reason.
+ 
+ On application submission the client can use this {@link ReservationId} to
+ obtain access to the reserved resources.
+ </p>
+ 
+ <p>
+ The system guarantees that during the time-range specified by the user, the
+ reservationID will be corresponding to a valid reservation. The amount of
+ capacity dedicated to such queue can vary overtime, depending of the
+ allocation that has been determined. But it is guaranteed to satisfy all
+ the constraint expressed by the user in the
+ {@link ReservationSubmissionRequest}.
+ </p>
+ 
+ @param request the request to submit a new Reservation
+ @return response the {@link ReservationId} on accepting the submission
+ @throws YarnException if the request is invalid or reservation cannot be
+           created successfully
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="updateReservation" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to update an existing Reservation. This is
+ referred to as a re-negotiation process, in which a user that has
+ previously submitted a Reservation.
+ </p>
+ 
+ <p>
+ The allocation is attempted by virtually substituting all previous
+ allocations related to this Reservation with new ones, that satisfy the new
+ {@link ReservationUpdateRequest}. Upon success the previous allocation is
+ substituted by the new one, and on failure (i.e., if the system cannot find
+ a valid allocation for the updated request), the previous allocation
+ remains valid.
+ 
+ The {@link ReservationId} is not changed, and applications currently
+ running within this reservation will automatically receive the resources
+ based on the new allocation.
+ </p>
+ 
+ @param request to update an existing Reservation (the ReservationRequest
+          should refer to an existing valid {@link ReservationId})
+ @return response empty on successfully updating the existing reservation
+ @throws YarnException if the request is invalid or reservation cannot be
+           updated successfully
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="deleteReservation" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to remove an existing Reservation.
+ 
+ Upon deletion of a reservation applications running with this reservation,
+ are automatically downgraded to normal jobs running without any dedicated
+ reservation.
+ </p>
+ 
+ @param request to remove an existing Reservation (the ReservationRequest
+          should refer to an existing valid {@link ReservationId})
+ @return response empty on successfully deleting the existing reservation
+ @throws YarnException if the request is invalid or reservation cannot be
+           deleted successfully
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="listReservations" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to get the list of reservations in a plan.
+ The reservationId will be used to search for reservations to list if it is
+ provided. Otherwise, it will select active reservations within the
+ startTime and endTime (inclusive).
+ </p>
+
+ @param request to list reservations in a plan. Contains fields to select
+                String queue, ReservationId reservationId, long startTime,
+                long endTime, and a bool includeReservationAllocations.
+
+                queue: Required. Cannot be null or empty. Refers to the
+                reservable queue in the scheduler that was selected when
+                creating a reservation submission
+                {@link ReservationSubmissionRequest}.
+
+                reservationId: Optional. If provided, other fields will
+                be ignored.
+
+                startTime: Optional. If provided, only reservations that
+                end after the startTime will be selected. This defaults
+                to 0 if an invalid number is used.
+
+                endTime: Optional. If provided, only reservations that
+                start on or before endTime will be selected. This defaults
+                to Long.MAX_VALUE if an invalid number is used.
+
+                includeReservationAllocations: Optional. Flag that
+                determines whether the entire reservation allocations are
+                to be returned. Reservation allocations are subject to
+                change in the event of re-planning as described by
+                {@code ReservationDefinition}.
+
+ @return response that contains information about reservations that are
+                being searched for.
+ @throws YarnException if the request is invalid
+ @throws IOException on IO failures]]>
+      </doc>
+    </method>
+    <method name="getNodeToLabels" return="org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node to labels mappings in existing cluster
+ </p>
+
+ @param request
+ @return node to labels mappings
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getLabelsToNodes" return="org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get labels to nodes mappings
+ in existing cluster
+ </p>
+
+ @param request
+ @return labels to nodes mappings
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getClusterNodeLabels" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node labels in the cluster
+ </p>
+
+ @param request to get node labels collection of this cluster
+ @return node labels collection of this cluster
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="updateApplicationPriority" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to set priority of an application.
+ </p>
+ @param request to set priority of an application
+ @return an empty response
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="signalToContainer" return="org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by clients to request the
+ <code>ResourceManager</code> to signal a container. For example,
+ the client can send command OUTPUT_THREAD_DUMP to dump threads of the
+ container.</p>
+
+ <p>The client, via {@link SignalContainerRequest} provides the
+ id of the container and the signal command. </p>
+
+ <p> In secure mode,the <code>ResourceManager</code> verifies access to the
+ application before signaling the container.
+ The user needs to have <code>MODIFY_APP</code> permission.</p>
+
+ <p>Currently, the <code>ResourceManager</code> returns an empty response
+ on success and throws an exception on rejecting the request.</p>
+
+ @param request request to signal a container
+ @return <code>ResourceManager</code> returns an empty response
+         on success and throws an exception on rejecting the request
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="updateApplicationTimeouts" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to set ApplicationTimeouts of an application.
+ The UpdateApplicationTimeoutsRequest should have timeout value with
+ absolute time with ISO8601 format <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>.
+ </p>
+ <b>Note:</b> If application timeout value is less than or equal to current
+ time then update application throws YarnException.
+ @param request to set ApplicationTimeouts of an application
+ @return a response with updated timeouts.
+ @throws YarnException if update request has empty values or application is
+           in completing states.
+ @throws IOException on IO failures]]>
+      </doc>
+    </method>
+    <method name="getResourceProfiles" return="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to get all the resource profiles that are
+ available on the ResourceManager.
+ </p>
+ @param request request to get all the resource profiles
+ @return Response containing a map of the profile name to Resource
+         capabilities
+ @throws YARNFeatureNotEnabledException if resource-profile is disabled
+ @throws YarnException if any error happens inside YARN
+ @throws IOException in case of other errors]]>
+      </doc>
+    </method>
+    <method name="getResourceProfile" return="org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface to get the details for a specific resource profile.
+ </p>
+ @param request request to get the details of a resource profile
+ @return Response containing the details for a particular resource profile
+ @throws YARNFeatureNotEnabledException if resource-profile is disabled
+ @throws YarnException if any error happens inside YARN
+ @throws IOException in case of other errors]]>
+      </doc>
+    </method>
+    <method name="getResourceTypeInfo" return="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface to get the details for a specific resource profile.
+ </p>
+ @param request request to get the details of a resource profile
+ @return Response containing the details for a particular resource profile
+ @throws YarnException if any error happens inside YARN
+ @throws IOException in case of other errors]]>
+      </doc>
+    </method>
+    <method name="getAttributesToNodes" return="org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get attributes to nodes mappings
+ available in ResourceManager.
+ </p>
+
+ @param request request to get details of attributes to nodes mapping.
+ @return Response containing the details of attributes to nodes mappings.
+ @throws YarnException if any error happens inside YARN
+ @throws IOException   incase of other errors]]>
+      </doc>
+    </method>
+    <method name="getClusterNodeAttributes" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node attributes available in
+ ResourceManager.
+ </p>
+
+ @param request request to get node attributes collection of this cluster.
+ @return Response containing node attributes collection.
+ @throws YarnException if any error happens inside YARN.
+ @throws IOException   incase of other errors.]]>
+      </doc>
+    </method>
+    <method name="getNodesToAttributes" return="org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node to attributes mappings.
+ in existing cluster.
+ </p>
+
+ @param request request to get nodes to attributes mapping.
+ @return nodes to attributes mappings.
+ @throws YarnException if any error happens inside YARN.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The protocol between clients and the <code>ResourceManager</code>
+ to submit/abort jobs and to get information on applications, cluster metrics,
+ nodes, queues and ACLs.</p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.api.ApplicationClientProtocol -->
+  <!-- start interface org.apache.hadoop.yarn.api.ApplicationConstants -->
+  <interface name="ApplicationConstants"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <field name="APP_SUBMIT_TIME_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The environment variable for APP_SUBMIT_TIME. Set in AppMaster environment
+ only]]>
+      </doc>
+    </field>
+    <field name="CONTAINER_TOKEN_FILE_ENV_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The cache file into which container token is written]]>
+      </doc>
+    </field>
+    <field name="APPLICATION_WEB_PROXY_BASE_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The environmental variable for APPLICATION_WEB_PROXY_BASE. Set in
+ ApplicationMaster's environment only. This states that for all non-relative
+ web URLs in the app masters web UI what base should they have.]]>
+      </doc>
+    </field>
+    <field name="LOG_DIR_EXPANSION_VAR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The temporary environmental variable for container log directory. This
+ should be replaced by real container log directory on container launch.]]>
+      </doc>
+    </field>
+    <field name="CLASS_PATH_SEPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This constant is used to construct class path and it will be replaced with
+ real class path separator(':' for Linux and ';' for Windows) by
+ NodeManager on container launch. User has to use this constant to construct
+ class path if user wants cross-platform practice i.e. submit an application
+ from a Windows client to a Linux/Unix server or vice versa.]]>
+      </doc>
+    </field>
+    <field name="PARAMETER_EXPANSION_LEFT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The following two constants are used to expand parameter and it will be
+ replaced with real parameter expansion marker ('%' for Windows and '$' for
+ Linux) by NodeManager on container launch. For example: {{VAR}} will be
+ replaced as $VAR on Linux, and %VAR% on Windows. User has to use this
+ constant to construct class path if user wants cross-platform practice i.e.
+ submit an application from a Windows client to a Linux/Unix server or vice
+ versa.]]>
+      </doc>
+    </field>
+    <field name="PARAMETER_EXPANSION_RIGHT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[User has to use this constant to construct class path if user wants
+ cross-platform practice i.e. submit an application from a Windows client to
+ a Linux/Unix server or vice versa.]]>
+      </doc>
+    </field>
+    <field name="STDERR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="STDOUT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This is the API for the applications comprising of constants that YARN sets
+ up for the applications and the containers.
+
+ TODO: Investigate the semantics and security of each cross-boundary refs.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.api.ApplicationConstants -->
+  <!-- start class org.apache.hadoop.yarn.api.ApplicationConstants.ContainerLaunchType -->
+  <class name="ApplicationConstants.ContainerLaunchType" extends="java.lang.Enum"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.ApplicationConstants.ContainerLaunchType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.ApplicationConstants.ContainerLaunchType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[The type of launch for the container.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.ApplicationConstants.ContainerLaunchType -->
+  <!-- start interface org.apache.hadoop.yarn.api.ApplicationHistoryProtocol -->
+  <interface name="ApplicationHistoryProtocol"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.api.ApplicationBaseProtocol"/>
+    <doc>
+    <![CDATA[<p>
+ The protocol between clients and the <code>ApplicationHistoryServer</code> to
+ get the information of completed applications etc.
+ </p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.api.ApplicationHistoryProtocol -->
+  <!-- start interface org.apache.hadoop.yarn.api.ApplicationMasterProtocol -->
+  <interface name="ApplicationMasterProtocol"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by a new <code>ApplicationMaster</code> to register with
+ the <code>ResourceManager</code>.
+ </p>
+
+ <p>
+ The <code>ApplicationMaster</code> needs to provide details such as RPC
+ Port, HTTP tracking url etc. as specified in
+ {@link RegisterApplicationMasterRequest}.
+ </p>
+
+ <p>
+ The <code>ResourceManager</code> responds with critical details such as
+ maximum resource capabilities in the cluster as specified in
+ {@link RegisterApplicationMasterResponse}.
+ </p>
+
+ <p>
+ Re-register is only allowed for <code>Unmanaged Application Master</code>
+ (UAM) HA, with
+ {@link org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext#getKeepContainersAcrossApplicationAttempts()}
+ set to true.
+ </p>
+
+ @param request registration request
+ @return registration respose
+ @throws YarnException
+ @throws IOException
+ @throws InvalidApplicationMasterRequestException The exception is thrown
+           when an ApplicationMaster tries to register more then once.
+ @see RegisterApplicationMasterRequest
+ @see RegisterApplicationMasterResponse]]>
+      </doc>
+    </method>
+    <method name="finishApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>The interface used by an <code>ApplicationMaster</code> to notify the 
+ <code>ResourceManager</code> about its completion (success or failed).</p>
+ 
+ <p>The <code>ApplicationMaster</code> has to provide details such as 
+ final state, diagnostics (in case of failures) etc. as specified in 
+ {@link FinishApplicationMasterRequest}.</p>
+ 
+ <p>The <code>ResourceManager</code> responds with 
+ {@link FinishApplicationMasterResponse}.</p>
+ 
+ @param request completion request
+ @return completion response
+ @throws YarnException
+ @throws IOException
+ @see FinishApplicationMasterRequest
+ @see FinishApplicationMasterResponse]]>
+      </doc>
+    </method>
+    <method name="allocate" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The main interface between an <code>ApplicationMaster</code> and the
+ <code>ResourceManager</code>.
+ </p>
+ 
+ <p>
+ The <code>ApplicationMaster</code> uses this interface to provide a list of
+ {@link ResourceRequest} and returns unused {@link Container} allocated to
+ it via {@link AllocateRequest}. Optionally, the
+ <code>ApplicationMaster</code> can also <em>blacklist</em> resources which
+ it doesn't want to use.
+ </p>
+ 
+ <p>
+ This also doubles up as a <em>heartbeat</em> to let the
+ <code>ResourceManager</code> know that the <code>ApplicationMaster</code>
+ is alive. Thus, applications should periodically make this call to be kept
+ alive. The frequency depends on
+ {@link YarnConfiguration#RM_AM_EXPIRY_INTERVAL_MS} which defaults to
+ {@link YarnConfiguration#DEFAULT_RM_AM_EXPIRY_INTERVAL_MS}.
+ </p>
+ 
+ <p>
+ The <code>ResourceManager</code> responds with list of allocated
+ {@link Container}, status of completed containers and headroom information
+ for the application.
+ </p>
+ 
+ <p>
+ The <code>ApplicationMaster</code> can use the available headroom
+ (resources) to decide how to utilized allocated resources and make informed
+ decisions about future resource requests.
+ </p>
+ 
+ @param request
+          allocation request
+ @return allocation response
+ @throws YarnException
+ @throws IOException
+ @throws InvalidApplicationMasterRequestException
+           This exception is thrown when an ApplicationMaster calls allocate
+           without registering first.
+ @throws InvalidResourceBlacklistRequestException
+           This exception is thrown when an application provides an invalid
+           specification for blacklist of resources.
+ @throws InvalidResourceRequestException
+           This exception is thrown when a {@link ResourceRequest} is out of
+           the range of the configured lower and upper limits on the
+           resources.
+ @see AllocateRequest
+ @see AllocateResponse]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The protocol between a live instance of <code>ApplicationMaster</code> 
+ and the <code>ResourceManager</code>.</p>
+ 
+ <p>This is used by the <code>ApplicationMaster</code> to register/unregister
+ and to request and obtain resources in the cluster from the
+ <code>ResourceManager</code>.</p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.api.ApplicationMasterProtocol -->
+  <!-- start interface org.apache.hadoop.yarn.api.ClientSCMProtocol -->
+  <interface name="ClientSCMProtocol"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="use" return="org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to claim a resource with the
+ <code>SharedCacheManager.</code> The client uses a checksum to identify the
+ resource and an {@link ApplicationId} to identify which application will be
+ using the resource.
+ </p>
+
+ <p>
+ The <code>SharedCacheManager</code> responds with whether or not the
+ resource exists in the cache. If the resource exists, a <code>Path</code>
+ to the resource in the shared cache is returned. If the resource does not
+ exist, the response is empty.
+ </p>
+
+ @param request request to claim a resource in the shared cache
+ @return response indicating if the resource is already in the cache
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="release" return="org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to release a resource with the
+ <code>SharedCacheManager.</code> This method is called once an application
+ is no longer using a claimed resource in the shared cache. The client uses
+ a checksum to identify the resource and an {@link ApplicationId} to
+ identify which application is releasing the resource.
+ </p>
+
+ <p>
+ Note: This method is an optimization and the client is not required to call
+ it for correctness.
+ </p>
+
+ <p>
+ Currently the <code>SharedCacheManager</code> sends an empty response.
+ </p>
+
+ @param request request to release a resource in the shared cache
+ @return (empty) response on releasing the resource
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The protocol between clients and the <code>SharedCacheManager</code> to claim
+ and release resources in the shared cache.
+ </p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.api.ClientSCMProtocol -->
+  <!-- start interface org.apache.hadoop.yarn.api.ContainerManagementProtocol -->
+  <interface name="ContainerManagementProtocol"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="startContainers" return="org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The <code>ApplicationMaster</code> provides a list of
+ {@link StartContainerRequest}s to a <code>NodeManager</code> to
+ <em>start</em> {@link Container}s allocated to it using this interface.
+ </p>
+ 
+ <p>
+ The <code>ApplicationMaster</code> has to provide details such as allocated
+ resource capability, security tokens (if enabled), command to be executed
+ to start the container, environment for the process, necessary
+ binaries/jar/shared-objects etc. via the {@link ContainerLaunchContext} in
+ the {@link StartContainerRequest}.
+ </p>
+ 
+ <p>
+ The <code>NodeManager</code> sends a response via
+ {@link StartContainersResponse} which includes a list of
+ {@link Container}s of successfully launched {@link Container}s, a
+ containerId-to-exception map for each failed {@link StartContainerRequest} in
+ which the exception indicates errors from per container and a
+ allServicesMetaData map between the names of auxiliary services and their
+ corresponding meta-data. Note: None-container-specific exceptions will
+ still be thrown by the API method itself.
+ </p>
+ <p>
+ The <code>ApplicationMaster</code> can use
+ {@link #getContainerStatuses(GetContainerStatusesRequest)} to get updated
+ statuses of the to-be-launched or launched containers.
+ </p>
+ 
+ @param request
+          request to start a list of containers
+ @return response including conatinerIds of all successfully launched
+         containers, a containerId-to-exception map for failed requests and
+         a allServicesMetaData map.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="stopContainers" return="org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The <code>ApplicationMaster</code> requests a <code>NodeManager</code> to
+ <em>stop</em> a list of {@link Container}s allocated to it using this
+ interface.
+ </p>
+ 
+ <p>
+ The <code>ApplicationMaster</code> sends a {@link StopContainersRequest}
+ which includes the {@link ContainerId}s of the containers to be stopped.
+ </p>
+ 
+ <p>
+ The <code>NodeManager</code> sends a response via
+ {@link StopContainersResponse} which includes a list of {@link ContainerId}
+ s of successfully stopped containers, a containerId-to-exception map for
+ each failed request in which the exception indicates errors from per
+ container. Note: None-container-specific exceptions will still be thrown by
+ the API method itself. <code>ApplicationMaster</code> can use
+ {@link #getContainerStatuses(GetContainerStatusesRequest)} to get updated
+ statuses of the containers.
+ </p>
+ 
+ @param request
+          request to stop a list of containers
+ @return response which includes a list of containerIds of successfully
+         stopped containers, a containerId-to-exception map for failed
+         requests.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainerStatuses" return="org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The API used by the <code>ApplicationMaster</code> to request for current
+ statuses of <code>Container</code>s from the <code>NodeManager</code>.
+ </p>
+ 
+ <p>
+ The <code>ApplicationMaster</code> sends a
+ {@link GetContainerStatusesRequest} which includes the {@link ContainerId}s
+ of all containers whose statuses are needed.
+ </p>
+ 
+ <p>
+ The <code>NodeManager</code> responds with
+ {@link GetContainerStatusesResponse} which includes a list of
+ {@link ContainerStatus} of the successfully queried containers and a
+ containerId-to-exception map for each failed request in which the exception
+ indicates errors from per container. Note: None-container-specific
+ exceptions will still be thrown by the API method itself.
+ </p>
+ 
+ @param request
+          request to get <code>ContainerStatus</code>es of containers with
+          the specified <code>ContainerId</code>s
+ @return response containing the list of <code>ContainerStatus</code> of the
+         successfully queried containers and a containerId-to-exception map
+         for failed requests.
+ 
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="increaseContainersResource" return="org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The API used by the <code>ApplicationMaster</code> to request for
+ resource increase of running containers on the <code>NodeManager</code>.
+ </p>
+
+ @param request
+         request to increase resource of a list of containers
+ @return response which includes a list of containerIds of containers
+         whose resource has been successfully increased and a
+         containerId-to-exception map for failed requests.
+
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="updateContainer" return="org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The API used by the <code>ApplicationMaster</code> to request for
+ resource update of running containers on the <code>NodeManager</code>.
+ </p>
+
+ @param request
+         request to update resource of a list of containers
+ @return response which includes a list of containerIds of containers
+         whose resource has been successfully updated and a
+         containerId-to-exception map for failed requests.
+
+ @throws YarnException Exception specific to YARN
+ @throws IOException IOException thrown from NodeManager]]>
+      </doc>
+    </method>
+    <method name="signalToContainer" return="org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="localize" return="org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Localize resources required by the container.
+ Currently, this API only works for running containers.
+
+ @param request Specify the resources to be localized.
+ @return Response that the localize request is accepted.
+ @throws YarnException Exception specific to YARN
+ @throws IOException IOException thrown from the RPC layer.]]>
+      </doc>
+    </method>
+    <method name="reInitializeContainer" return="org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[ReInitialize the Container with a new Launch Context.
+ @param request Specify the new ContainerLaunchContext.
+ @return Response that the ReInitialize request is accepted.
+ @throws YarnException Exception specific to YARN.
+ @throws IOException IOException thrown from the RPC layer.]]>
+      </doc>
+    </method>
+    <method name="restartContainer" return="org.apache.hadoop.yarn.api.protocolrecords.RestartContainerResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Restart the container.
+ @param containerId Container Id.
+ @return Response that the restart request is accepted.
+ @throws YarnException Exception specific to YARN.
+ @throws IOException IOException thrown from the RPC layer.]]>
+      </doc>
+    </method>
+    <method name="rollbackLastReInitialization" return="org.apache.hadoop.yarn.api.protocolrecords.RollbackResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Rollback the Last ReInitialization if possible.
+ @param containerId Container Id.
+ @return Response that the rollback request is accepted.
+ @throws YarnException Exception specific to YARN.
+ @throws IOException IOException thrown from the RPC layer.]]>
+      </doc>
+    </method>
+    <method name="commitLastReInitialization" return="org.apache.hadoop.yarn.api.protocolrecords.CommitResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Commit the Last ReInitialization if possible. Once the reinitialization
+ has been committed, It cannot be rolled back.
+ @param containerId Container Id.
+ @return Response that the commit request is accepted.
+ @throws YarnException Exception specific to YARN.
+ @throws IOException IOException thrown from the RPC layer.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The protocol between an <code>ApplicationMaster</code> and a 
+ <code>NodeManager</code> to start/stop and increase resource of containers
+ and to get status of running containers.</p>
+
+ <p>If security is enabled the <code>NodeManager</code> verifies that the
+ <code>ApplicationMaster</code> has truly been allocated the container
+ by the <code>ResourceManager</code> and also verifies all interactions such 
+ as stopping the container or obtaining status information for the container.
+ </p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.api.ContainerManagementProtocol -->
+</package>
+<package name="org.apache.hadoop.yarn.api.protocolrecords">
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest -->
+  <class name="AllocateRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AllocateRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="responseID" type="int"/>
+      <param name="appProgress" type="float"/>
+      <param name="resourceAsk" type="java.util.List"/>
+      <param name="containersToBeReleased" type="java.util.List"/>
+      <param name="resourceBlacklistRequest" type="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="responseID" type="int"/>
+      <param name="appProgress" type="float"/>
+      <param name="resourceAsk" type="java.util.List"/>
+      <param name="containersToBeReleased" type="java.util.List"/>
+      <param name="resourceBlacklistRequest" type="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"/>
+      <param name="trackingUrl" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="responseID" type="int"/>
+      <param name="appProgress" type="float"/>
+      <param name="resourceAsk" type="java.util.List"/>
+      <param name="containersToBeReleased" type="java.util.List"/>
+      <param name="updateRequests" type="java.util.List"/>
+      <param name="resourceBlacklistRequest" type="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"/>
+    </method>
+    <method name="getResponseId" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>response id</em> used to track duplicate responses.
+ @return <em>response id</em>]]>
+      </doc>
+    </method>
+    <method name="setResponseId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="int"/>
+      <doc>
+      <![CDATA[Set the <em>response id</em> used to track duplicate responses.
+ @param id <em>response id</em>]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>current progress</em> of application. 
+ @return <em>current progress</em> of application]]>
+      </doc>
+    </method>
+    <method name="setProgress"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="progress" type="float"/>
+      <doc>
+      <![CDATA[Set the <em>current progress</em> of application
+ @param progress <em>current progress</em> of application]]>
+      </doc>
+    </method>
+    <method name="getAskList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <code>ResourceRequest</code> to update the 
+ <code>ResourceManager</code> about the application's resource requirements.
+ @return the list of <code>ResourceRequest</code>
+ @see ResourceRequest]]>
+      </doc>
+    </method>
+    <method name="setAskList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceRequests" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set list of <code>ResourceRequest</code> to update the
+ <code>ResourceManager</code> about the application's resource requirements.
+ @param resourceRequests list of <code>ResourceRequest</code> to update the 
+                        <code>ResourceManager</code> about the application's 
+                        resource requirements
+ @see ResourceRequest]]>
+      </doc>
+    </method>
+    <method name="getReleaseList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <code>ContainerId</code> of containers being 
+ released by the <code>ApplicationMaster</code>.
+ @return list of <code>ContainerId</code> of containers being 
+         released by the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="setReleaseList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="releaseContainers" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list of <code>ContainerId</code> of containers being
+ released by the <code>ApplicationMaster</code>
+ @param releaseContainers list of <code>ContainerId</code> of 
+                          containers being released by the 
+                          <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="getResourceBlacklistRequest" return="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ResourceBlacklistRequest</code> being sent by the 
+ <code>ApplicationMaster</code>.
+ @return the <code>ResourceBlacklistRequest</code> being sent by the 
+         <code>ApplicationMaster</code>
+ @see ResourceBlacklistRequest]]>
+      </doc>
+    </method>
+    <method name="setResourceBlacklistRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceBlacklistRequest" type="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"/>
+      <doc>
+      <![CDATA[Set the <code>ResourceBlacklistRequest</code> to inform the 
+ <code>ResourceManager</code> about the blacklist additions and removals
+ per the <code>ApplicationMaster</code>.
+ 
+ @param resourceBlacklistRequest the <code>ResourceBlacklistRequest</code>  
+                         to inform the <code>ResourceManager</code> about  
+                         the blacklist additions and removals
+                         per the <code>ApplicationMaster</code>
+ @see ResourceBlacklistRequest]]>
+      </doc>
+    </method>
+    <method name="getUpdateRequests" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of container update requests being sent by the
+ <code>ApplicationMaster</code>.
+ @return list of {@link UpdateContainerRequest}
+         being sent by the
+         <code>ApplicationMaster</code>.]]>
+      </doc>
+    </method>
+    <method name="setUpdateRequests"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateRequests" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list of container update requests to inform the
+ <code>ResourceManager</code> about the containers that need to be
+ updated.
+ @param updateRequests list of <code>UpdateContainerRequest</code> for
+                       containers to be updated]]>
+      </doc>
+    </method>
+    <method name="getSchedulingRequests" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of Scheduling requests being sent by the
+ <code>ApplicationMaster</code>.
+ @return list of {@link SchedulingRequest} being sent by the
+         <code>ApplicationMaster</code>.]]>
+      </doc>
+    </method>
+    <method name="setSchedulingRequests"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="schedulingRequests" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list of Scheduling requests to inform the
+ <code>ResourceManager</code> about the application's resource requirements
+ (potentially including allocation tags and placement constraints).
+ @param schedulingRequests list of {@link SchedulingRequest} to update
+          the <code>ResourceManager</code> about the application's resource
+          requirements.]]>
+      </doc>
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the tracking url update for this heartbeat.
+ @return tracking url to update this application with]]>
+      </doc>
+    </method>
+    <method name="setTrackingUrl"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the new tracking url for this application.
+ @param trackingUrl the new tracking url]]>
+      </doc>
+    </method>
+    <method name="newBuilder" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p>The core request sent by the <code>ApplicationMaster</code> to the 
+ <code>ResourceManager</code> to obtain resources in the cluster.</p> 
+
+ <p>The request includes:
+ <ul>
+   <li>A response id to track duplicate responses.</li>
+   <li>Progress information.</li>
+   <li>
+     A list of {@link ResourceRequest} to inform the
+     <code>ResourceManager</code> about the application's
+     resource requirements.
+   </li>
+   <li>
+     A list of unused {@link Container} which are being returned.
+   </li>
+   <li>
+     A list of {@link UpdateContainerRequest} to inform
+     the <code>ResourceManager</code> about the change in
+     requirements of running containers.
+   </li>
+ </ul>
+ 
+ @see ApplicationMasterProtocol#allocate(AllocateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder -->
+  <class name="AllocateRequest.AllocateRequestBuilder" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="responseId" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="responseId" type="int"/>
+      <doc>
+      <![CDATA[Set the <code>responseId</code> of the request.
+ @see AllocateRequest#setResponseId(int)
+ @param responseId <code>responseId</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="progress" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="progress" type="float"/>
+      <doc>
+      <![CDATA[Set the <code>progress</code> of the request.
+ @see AllocateRequest#setProgress(float)
+ @param progress <code>progress</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="askList" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="askList" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the <code>askList</code> of the request.
+ @see AllocateRequest#setAskList(List)
+ @param askList <code>askList</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="releaseList" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="releaseList" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the <code>releaseList</code> of the request.
+ @see AllocateRequest#setReleaseList(List)
+ @param releaseList <code>releaseList</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="resourceBlacklistRequest" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceBlacklistRequest" type="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"/>
+      <doc>
+      <![CDATA[Set the <code>resourceBlacklistRequest</code> of the request.
+ @see AllocateRequest#setResourceBlacklistRequest(
+ ResourceBlacklistRequest)
+ @param resourceBlacklistRequest
+     <code>resourceBlacklistRequest</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="updateRequests" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateRequests" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the <code>updateRequests</code> of the request.
+ @see AllocateRequest#setUpdateRequests(List)
+ @param updateRequests <code>updateRequests</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="schedulingRequests" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="schedulingRequests" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the <code>schedulingRequests</code> of the request.
+ @see AllocateRequest#setSchedulingRequests(List)
+ @param schedulingRequests <code>SchedulingRequest</code> of the request
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="trackingUrl" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <code>trackingUrl</code> of the request.
+ @see AllocateRequest#setTrackingUrl(String)
+ @param trackingUrl new tracking url
+ @return {@link AllocateRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="build" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return generated {@link AllocateRequest} object.
+ @return {@link AllocateRequest}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Class to construct instances of {@link AllocateRequest} with specific
+ options.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest.AllocateRequestBuilder -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse -->
+  <class name="AllocateResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AllocateResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="responseId" type="int"/>
+      <param name="completedContainers" type="java.util.List"/>
+      <param name="allocatedContainers" type="java.util.List"/>
+      <param name="updatedNodes" type="java.util.List"/>
+      <param name="availResources" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="command" type="org.apache.hadoop.yarn.api.records.AMCommand"/>
+      <param name="numClusterNodes" type="int"/>
+      <param name="preempt" type="org.apache.hadoop.yarn.api.records.PreemptionMessage"/>
+      <param name="nmTokens" type="java.util.List"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="responseId" type="int"/>
+      <param name="completedContainers" type="java.util.List"/>
+      <param name="allocatedContainers" type="java.util.List"/>
+      <param name="updatedNodes" type="java.util.List"/>
+      <param name="availResources" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="command" type="org.apache.hadoop.yarn.api.records.AMCommand"/>
+      <param name="numClusterNodes" type="int"/>
+      <param name="preempt" type="org.apache.hadoop.yarn.api.records.PreemptionMessage"/>
+      <param name="nmTokens" type="java.util.List"/>
+      <param name="amRMToken" type="org.apache.hadoop.yarn.api.records.Token"/>
+      <param name="updatedContainers" type="java.util.List"/>
+      <param name="collectorInfo" type="org.apache.hadoop.yarn.api.records.CollectorInfo"/>
+    </method>
+    <method name="getAMCommand" return="org.apache.hadoop.yarn.api.records.AMCommand"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[If the <code>ResourceManager</code> needs the
+ <code>ApplicationMaster</code> to take some action then it will send an
+ AMCommand to the <code>ApplicationMaster</code>. See <code>AMCommand</code> 
+ for details on commands and actions for them.
+ @return <code>AMCommand</code> if the <code>ApplicationMaster</code> should
+         take action, <code>null</code> otherwise
+ @see AMCommand]]>
+      </doc>
+    </method>
+    <method name="getResponseId" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>last response id</em>.
+ @return <em>last response id</em>]]>
+      </doc>
+    </method>
+    <method name="getAllocatedContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <em>newly allocated</em> <code>Container</code> by the
+ <code>ResourceManager</code>.
+ @return list of <em>newly allocated</em> <code>Container</code>]]>
+      </doc>
+    </method>
+    <method name="getAvailableResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>available headroom</em> for resources in the cluster for the
+ application.
+ @return limit of available headroom for resources in the cluster for the
+ application]]>
+      </doc>
+    </method>
+    <method name="getCompletedContainersStatuses" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <em>completed containers' statuses</em>.
+ @return the list of <em>completed containers' statuses</em>]]>
+      </doc>
+    </method>
+    <method name="getUpdatedNodes" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <em>updated <code>NodeReport</code>s</em>. Updates could
+ be changes in health, availability etc of the nodes.
+ @return The delta of updated nodes since the last response]]>
+      </doc>
+    </method>
+    <method name="getNumClusterNodes" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of hosts available on the cluster.
+ @return the available host count.]]>
+      </doc>
+    </method>
+    <method name="getPreemptionMessage" return="org.apache.hadoop.yarn.api.records.PreemptionMessage"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the description of containers owned by the AM, but requested back by
+ the cluster. Note that the RM may have an inconsistent view of the
+ resources owned by the AM. These messages are advisory, and the AM may
+ elect to ignore them.
+ <p>
+ The message is a snapshot of the resources the RM wants back from the AM.
+ While demand persists, the RM will repeat its request; applications should
+ not interpret each message as a request for <em>additional</em>
+ resources on top of previous messages. Resources requested consistently
+ over some duration may be forcibly killed by the RM.
+
+ @return A specification of the resources to reclaim from this AM.]]>
+      </doc>
+    </method>
+    <method name="getNMTokens" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of NMTokens required for communicating with NM. New NMTokens
+ issued only if
+ <p>
+ 1) AM is receiving first container on underlying NodeManager.<br>
+ OR<br>
+ 2) NMToken master key rolled over in ResourceManager and AM is getting new
+ container on the same underlying NodeManager.
+ <p>
+ AM will receive one NMToken per NM irrespective of the number of containers
+ issued on same NM. AM is expected to store these tokens until issued a
+ new token for the same NM.
+ @return list of NMTokens required for communicating with NM]]>
+      </doc>
+    </method>
+    <method name="getUpdatedContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of newly updated containers by
+ <code>ResourceManager</code>.
+ @return list of newly increased containers]]>
+      </doc>
+    </method>
+    <method name="getAMRMToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The AMRMToken that belong to this attempt
+
+ @return The AMRMToken that belong to this attempt]]>
+      </doc>
+    </method>
+    <method name="getApplicationPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Priority of the application
+
+ @return get application priority]]>
+      </doc>
+    </method>
+    <method name="getCollectorInfo" return="org.apache.hadoop.yarn.api.records.CollectorInfo"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The data associated with the collector that belongs to this app. Contains
+ address and token alongwith identification information.
+
+ @return The data of collector that belong to this attempt]]>
+      </doc>
+    </method>
+    <method name="getUpdateErrors" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of container update errors to inform the
+ Application Master about the container updates that could not be
+ satisfied due to error.
+
+ @return List of Update Container Errors.]]>
+      </doc>
+    </method>
+    <method name="setUpdateErrors"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateErrors" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list of container update errors to inform the
+ Application Master about the container updates that could not be
+ satisfied due to error.
+ @param updateErrors list of <code>UpdateContainerError</code> for
+                       containers updates requests that were in error]]>
+      </doc>
+    </method>
+    <method name="getContainersFromPreviousAttempts" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of running containers as viewed by
+ <code>ResourceManager</code> from previous application attempts which
+ have not been reported to the Application Master yet.
+ <br>
+ These containers were recovered by the RM after the application master
+ had already registered. This may happen after RM restart when some NMs get
+ delayed in connecting to the RM and reporting the active containers.
+ Since they were not reported in the registration
+ response, they are reported in the response to the AM heartbeat.
+
+ @return the list of running containers as viewed by
+         <code>ResourceManager</code> from previous application attempts.]]>
+      </doc>
+    </method>
+    <method name="getRejectedSchedulingRequests" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of all SchedulingRequests that the RM has rejected between
+ this allocate call and the previous one.
+ @return List of RejectedSchedulingRequests.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the <code>ResourceManager</code> the
+ <code>ApplicationMaster</code> during resource negotiation.
+ <p>
+ The response, includes:
+ <ul>
+   <li>Response ID to track duplicate responses.</li>
+   <li>
+     An AMCommand sent by ResourceManager to let the
+     {@code ApplicationMaster} take some actions (resync, shutdown etc.).
+   </li>
+   <li>A list of newly allocated {@link Container}.</li>
+   <li>A list of completed {@link Container}s' statuses.</li>
+   <li>
+     The available headroom for resources in the cluster for the
+     application.
+   </li>
+   <li>A list of nodes whose status has been updated.</li>
+   <li>The number of available nodes in a cluster.</li>
+   <li>A description of resources requested back by the cluster</li>
+   <li>AMRMToken, if AMRMToken has been rolled over</li>
+   <li>
+     A list of {@link Container} representing the containers
+     whose resource has been increased.
+   </li>
+   <li>
+     A list of {@link Container} representing the containers
+     whose resource has been decreased.
+   </li>
+ </ul>
+ 
+ @see ApplicationMasterProtocol#allocate(AllocateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope -->
+  <class name="ApplicationsRequestScope" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration that controls the scope of applications fetched]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.CommitResponse -->
+  <class name="CommitResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CommitResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Response to Commit Container Request.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.CommitResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest -->
+  <class name="ContainerUpdateRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerUpdateRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containersToIncrease" type="java.util.List"/>
+    </method>
+    <method name="getContainersToUpdate" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of container tokens to be used for authorization during
+ container resource update.
+ <p>
+ Note: {@link NMToken} will be used for authenticating communication with
+ {@code NodeManager}.
+ @return the list of container tokens to be used for authorization during
+ container resource update.
+ @see NMToken]]>
+      </doc>
+    </method>
+    <method name="setContainersToUpdate"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containersToUpdate" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set container tokens to be used during container resource increase.
+ The token is acquired from
+ <code>AllocateResponse.getUpdatedContainers</code>.
+ The token contains the container id and resource capability required for
+ container resource update.
+ @param containersToUpdate the list of container tokens to be used
+                             for container resource increase.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by <code>Application Master</code> to the
+ <code>Node Manager</code> to change the resource quota of a container.</p>
+
+ @see ContainerManagementProtocol#updateContainer(ContainerUpdateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse -->
+  <class name="ContainerUpdateResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerUpdateResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="successfullyUpdatedContainers" type="java.util.List"/>
+      <param name="failedRequests" type="java.util.Map"/>
+    </method>
+    <method name="getSuccessfullyUpdatedContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of containerIds of containers whose resource
+ have been successfully update.
+
+ @return the list of containerIds of containers whose resource have
+ been successfully updated.]]>
+      </doc>
+    </method>
+    <method name="getFailedRequests" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the containerId-to-exception map in which the exception indicates
+ error from each container for failed requests.
+ @return map of containerId-to-exception]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>NodeManager</code> to the
+ <code>ApplicationMaster</code> when asked to update container resource.
+ </p>
+
+ @see ContainerManagementProtocol#updateContainer(ContainerUpdateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ContainerUpdateResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest -->
+  <class name="FailApplicationAttemptRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FailApplicationAttemptRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+    </method>
+    <method name="getApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptId</code> of the attempt to be failed.
+ @return <code>ApplicationAttemptId</code> of the attempt.]]>
+      </doc>
+    </method>
+    <method name="setApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by the client to the <code>ResourceManager</code>
+ to fail an application attempt.</p>
+
+ <p>The request includes the {@link ApplicationAttemptId} of the attempt to
+ be failed.</p>
+
+ @see ApplicationClientProtocol#failApplicationAttempt(FailApplicationAttemptRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse -->
+  <class name="FailApplicationAttemptResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FailApplicationAttemptResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to the client
+ failing an application attempt.</p>
+
+ <p>Currently it's empty.</p>
+
+ @see ApplicationClientProtocol#failApplicationAttempt(FailApplicationAttemptRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest -->
+  <class name="FinishApplicationMasterRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FinishApplicationMasterRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="finalAppStatus" type="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"/>
+      <param name="diagnostics" type="java.lang.String"/>
+      <param name="url" type="java.lang.String"/>
+    </method>
+    <method name="getFinalApplicationStatus" return="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>final state</em> of the <code>ApplicationMaster</code>.
+ @return <em>final state</em> of the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="setFinalApplicationStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="finalState" type="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"/>
+      <doc>
+      <![CDATA[Set the <em>final state</em> of the <code>ApplicationMaster</code>
+ @param finalState <em>final state</em> of the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="getDiagnostics" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>diagnostic information</em> on application failure.
+ @return <em>diagnostic information</em> on application failure]]>
+      </doc>
+    </method>
+    <method name="setDiagnostics"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="diagnostics" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set <em>diagnostic information</em> on application failure.
+ @param diagnostics <em>diagnostic information</em> on application failure]]>
+      </doc>
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>tracking URL</em> for the <code>ApplicationMaster</code>.
+ This url if contains scheme then that will be used by resource manager
+ web application proxy otherwise it will default to http.
+ @return <em>tracking URL</em>for the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="setTrackingUrl"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="url" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>final tracking URL</em>for the <code>ApplicationMaster</code>.
+ This is the web-URL to which ResourceManager or web-application proxy will
+ redirect client/users once the application is finished and the
+ <code>ApplicationMaster</code> is gone.
+ <p>
+ If the passed url has a scheme then that will be used by the
+ ResourceManager and web-application proxy, otherwise the scheme will
+ default to http.
+ </p>
+ <p>
+ Empty, null, "N/A" strings are all valid besides a real URL. In case an url
+ isn't explicitly passed, it defaults to "N/A" on the ResourceManager.
+ <p>
+
+ @param url
+          <em>tracking URL</em>for the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The finalization request sent by the {@code ApplicationMaster} to
+ inform the {@code ResourceManager} about its completion.
+ <p>
+ The final request includes details such:
+ <ul>
+   <li>Final state of the {@code ApplicationMaster}</li>
+   <li>
+     Diagnostic information in case of failure of the
+     {@code ApplicationMaster}
+   </li>
+   <li>Tracking URL</li>
+ </ul>
+
+ @see ApplicationMasterProtocol#finishApplicationMaster(FinishApplicationMasterRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse -->
+  <class name="FinishApplicationMasterResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FinishApplicationMasterResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getIsUnregistered" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the flag which indicates that the application has successfully
+ unregistered with the RM and the application can safely stop.
+ @return true if the application has unregistered with the RM,
+         false otherwise]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the <code>ResourceManager</code> to a
+ <code>ApplicationMaster</code> on it's completion.
+ <p>
+ The response, includes:
+ <ul>
+ <li>A flag which indicates that the application has successfully unregistered
+ with the RM and the application can safely stop.</li>
+ </ul>
+ <p>
+ Note: The flag indicates whether the application has successfully
+ unregistered and is safe to stop. The application may stop after the flag is
+ true. If the application stops before the flag is true then the RM may retry
+ the application.
+ 
+ @see ApplicationMasterProtocol#finishApplicationMaster(FinishApplicationMasterRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest -->
+  <class name="GetAllResourceProfilesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetAllResourceProfilesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Request class for getting all the resource profiles from the RM.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse -->
+  <class name="GetAllResourceProfilesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetAllResourceProfilesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setResourceProfiles"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="profiles" type="java.util.Map"/>
+    </method>
+    <method name="getResourceProfiles" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Response class for getting all the resource profiles from the RM.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest -->
+  <class name="GetAllResourceTypeInfoRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetAllResourceTypeInfoRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Request class for getting all the resource profiles from the RM.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse -->
+  <class name="GetAllResourceTypeInfoResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetAllResourceTypeInfoResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setResourceTypeInfo"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceTypes" type="java.util.List"/>
+    </method>
+    <method name="getResourceTypeInfo" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Response class for getting all the resource profiles from the RM.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest -->
+  <class name="GetApplicationAttemptReportRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationAttemptReportRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+    </method>
+    <method name="getApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptId</code> of an application attempt.
+ 
+ @return <code>ApplicationAttemptId</code> of an application attempt]]>
+      </doc>
+    </method>
+    <method name="setApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationAttemptId</code> of an application attempt
+ 
+ @param applicationAttemptId
+          <code>ApplicationAttemptId</code> of an application attempt]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request sent by a client to the <code>ResourceManager</code> to get an
+ {@link ApplicationAttemptReport} for an application attempt.
+ </p>
+ 
+ <p>
+ The request should include the {@link ApplicationAttemptId} of the
+ application attempt.
+ </p>
+ 
+ @see ApplicationAttemptReport
+ @see ApplicationHistoryProtocol#getApplicationAttemptReport(GetApplicationAttemptReportRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse -->
+  <class name="GetApplicationAttemptReportResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationAttemptReportResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ApplicationAttemptReport" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"/>
+    </method>
+    <method name="getApplicationAttemptReport" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptReport</code> for the application attempt.
+ 
+ @return <code>ApplicationAttemptReport</code> for the application attempt]]>
+      </doc>
+    </method>
+    <method name="setApplicationAttemptReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptReport" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"/>
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptReport</code> for the application attempt.
+ 
+ @param applicationAttemptReport
+          <code>ApplicationAttemptReport</code> for the application attempt]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ an application attempt report.
+ </p>
+ 
+ <p>
+ The response includes an {@link ApplicationAttemptReport} which has the
+ details about the particular application attempt
+ </p>
+ 
+ @see ApplicationAttemptReport
+ @see ApplicationHistoryProtocol#getApplicationAttemptReport(GetApplicationAttemptReportRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest -->
+  <class name="GetApplicationAttemptsRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationAttemptsRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of an application
+ 
+ @return <code>ApplicationId</code> of an application]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of an application
+ 
+ @param applicationId
+          <code>ApplicationId</code> of an application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request from clients to get a list of application attempt reports of an
+ application from the <code>ResourceManager</code>.
+ </p>
+ 
+ @see ApplicationHistoryProtocol#getApplicationAttempts(GetApplicationAttemptsRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse -->
+  <class name="GetApplicationAttemptsResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationAttemptsResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttempts" type="java.util.List"/>
+    </method>
+    <method name="getApplicationAttemptList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of <code>ApplicationReport</code> of an application.
+ 
+ @return a list of <code>ApplicationReport</code> of an application]]>
+      </doc>
+    </method>
+    <method name="setApplicationAttemptList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttempts" type="java.util.List"/>
+      <doc>
+      <![CDATA[Get a list of <code>ApplicationReport</code> of an application.
+ 
+ @param applicationAttempts
+          a list of <code>ApplicationReport</code> of an application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ a list of {@link ApplicationAttemptReport} for application attempts.
+ </p>
+ 
+ <p>
+ The <code>ApplicationAttemptReport</code> for each application includes the
+ details of an application attempt.
+ </p>
+ 
+ @see ApplicationAttemptReport
+ @see ApplicationHistoryProtocol#getApplicationAttempts(GetApplicationAttemptsRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest -->
+  <class name="GetApplicationReportRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationReportRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the application.
+ @return <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the application
+ @param applicationId <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by a client to the <code>ResourceManager</code> to 
+ get an {@link ApplicationReport} for an application.</p>
+ 
+ <p>The request should include the {@link ApplicationId} of the 
+ application.</p>
+ 
+ @see ApplicationClientProtocol#getApplicationReport(GetApplicationReportRequest)
+ @see ApplicationReport]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse -->
+  <class name="GetApplicationReportResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationReportResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getApplicationReport" return="org.apache.hadoop.yarn.api.records.ApplicationReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationReport</code> for the application.
+ @return <code>ApplicationReport</code> for the application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to a client
+ requesting an application report.</p>
+ 
+ <p>The response includes an {@link ApplicationReport} which has details such 
+ as user, queue, name, host on which the <code>ApplicationMaster</code> is 
+ running, RPC port, tracking URL, diagnostics, start time etc.</p>
+ 
+ @see ApplicationClientProtocol#getApplicationReport(GetApplicationReportRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest -->
+  <class name="GetApplicationsRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationsRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope"/>
+      <param name="users" type="java.util.Set"/>
+      <param name="queues" type="java.util.Set"/>
+      <param name="applicationTypes" type="java.util.Set"/>
+      <param name="applicationTags" type="java.util.Set"/>
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <param name="startRange" type="org.apache.commons.lang3.Range"/>
+      <param name="finishRange" type="org.apache.commons.lang3.Range"/>
+      <param name="limit" type="java.lang.Long"/>
+      <doc>
+      <![CDATA[<p>
+ The request from clients to get a report of Applications matching the
+ giving application types in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)
+
+ <p>Setting any of the parameters to null, would just disable that
+ filter</p>
+
+ @param scope {@link ApplicationsRequestScope} to filter by
+ @param users list of users to filter by
+ @param queues list of scheduler queues to filter by
+ @param applicationTypes types of applications
+ @param applicationTags application tags to filter by
+ @param applicationStates application states to filter by
+ @param startRange range of application start times to filter by
+ @param finishRange range of application finish times to filter by
+ @param limit number of applications to limit to
+ @return {@link GetApplicationsRequest} to be used with
+ {@link ApplicationClientProtocol#getApplications(GetApplicationsRequest)}]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="org.apache.hadoop.yarn.api.protocolrecords.ApplicationsRequestScope"/>
+      <doc>
+      <![CDATA[<p>
+ The request from clients to get a report of Applications matching the
+ giving application types in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+ @param scope {@link ApplicationsRequestScope} to filter by
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)
+ @return a report of Applications in {@link GetApplicationsRequest}]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTypes" type="java.util.Set"/>
+      <doc>
+      <![CDATA[<p>
+ The request from clients to get a report of Applications matching the
+ giving application types in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)
+ @return a report of Applications in {@link GetApplicationsRequest}]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <doc>
+      <![CDATA[<p>
+ The request from clients to get a report of Applications matching the
+ giving application states in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)
+ @return  a report of Applications in {@link GetApplicationsRequest}]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTypes" type="java.util.Set"/>
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <doc>
+      <![CDATA[<p>
+ The request from clients to get a report of Applications matching the
+ giving and application types and application types in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)
+ @return  a report of Applications in <code>GetApplicationsRequest</code>]]>
+      </doc>
+    </method>
+    <method name="getApplicationTypes" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application types to filter applications on
+
+ @return Set of Application Types to filter on]]>
+      </doc>
+    </method>
+    <method name="getApplicationStates" return="java.util.EnumSet"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application states to filter applications on
+
+ @return Set of Application states to filter on]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request from clients to get a report of Applications
+ in the cluster from the <code>ResourceManager</code>.</p>
+
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse -->
+  <class name="GetApplicationsResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetApplicationsResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getApplicationList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>ApplicationReport</code> for applications.
+ @return <code>ApplicationReport</code> for applications]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to a client
+ requesting an {@link ApplicationReport} for applications.</p>
+
+ <p>The <code>ApplicationReport</code> for each application includes details
+ such as user, queue, name, host on which the <code>ApplicationMaster</code>
+ is running, RPC port, tracking URL, diagnostics, start time etc.</p>
+
+ @see ApplicationReport
+ @see ApplicationClientProtocol#getApplications(GetApplicationsRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest -->
+  <class name="GetAttributesToNodesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetAttributesToNodesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributes" type="java.util.Set"/>
+    </method>
+    <method name="setNodeAttributes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributes" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set node attributeKeys for which the mapping of hostname to attribute value
+ is required.
+
+ @param attributes Set of NodeAttributeKey provided.]]>
+      </doc>
+    </method>
+    <method name="getNodeAttributes" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get node attributeKeys for which mapping of hostname to attribute value is
+ required.
+
+ @return Set of NodeAttributeKey]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request from clients to get node to attribute value mapping for all or
+ given set of Node AttributeKey's in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+ @see ApplicationClientProtocol#getAttributesToNodes
+      (GetAttributesToNodesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse -->
+  <class name="GetAttributesToNodesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetAttributesToNodesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="map" type="java.util.Map"/>
+    </method>
+    <method name="setAttributeToNodes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="map" type="java.util.Map"/>
+    </method>
+    <method name="getAttributesToNodes" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get mapping of NodeAttributeKey to its associated mapping of list of
+ NodeToAttributeValue associated with attribute.
+
+ @return Map of node attributes to list of NodeToAttributeValue.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ node to attribute value mapping for all or given set of Node AttributeKey's.
+ </p>
+
+ @see ApplicationClientProtocol#getAttributesToNodes
+      (GetAttributesToNodesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest -->
+  <class name="GetClusterMetricsRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterMetricsRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by clients to get cluster metrics from the 
+ <code>ResourceManager</code>.</p>
+ 
+ <p>Currently, this is empty.</p>
+
+ @see ApplicationClientProtocol#getClusterMetrics(GetClusterMetricsRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse -->
+  <class name="GetClusterMetricsResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterMetricsResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getClusterMetrics" return="org.apache.hadoop.yarn.api.records.YarnClusterMetrics"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>YarnClusterMetrics</code> for the cluster.
+ @return <code>YarnClusterMetrics</code> for the cluster]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the <code>ResourceManager</code> to a client
+ requesting cluster metrics.
+ 
+ @see YarnClusterMetrics
+ @see ApplicationClientProtocol#getClusterMetrics(GetClusterMetricsRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest -->
+  <class name="GetClusterNodeAttributesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterNodeAttributesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create new instance of GetClusterNodeAttributesRequest.
+
+ @return GetClusterNodeAttributesRequest is returned.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request from clients to get node attributes in the cluster from the
+ <code>ResourceManager</code>.
+ </p>
+
+ @see ApplicationClientProtocol#getClusterNodeAttributes
+ (GetClusterNodeAttributesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse -->
+  <class name="GetClusterNodeAttributesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterNodeAttributesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributes" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Create instance of GetClusterNodeAttributesResponse.
+
+ @param attributes
+ @return GetClusterNodeAttributesResponse.]]>
+      </doc>
+    </method>
+    <method name="setNodeAttributes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributes" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set node attributes to the response.
+
+ @param attributes Map of Node attributeKey to Type.]]>
+      </doc>
+    </method>
+    <method name="getNodeAttributes" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get node attributes from the response.
+
+ @return Node attributes.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ a node attributes in cluster.
+ </p>
+
+ @see ApplicationClientProtocol#getClusterNodeAttributes
+ (GetClusterNodeAttributesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest -->
+  <class name="GetClusterNodeLabelsRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterNodeLabelsRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse -->
+  <class name="GetClusterNodeLabelsResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterNodeLabelsResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #newInstance(List)} instead.">
+      <param name="labels" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Creates a new instance.
+
+ @param labels Node labels
+ @return response
+ @deprecated Use {@link #newInstance(List)} instead.]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="labels" type="java.util.List"/>
+    </method>
+    <method name="setNodeLabelList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="labels" type="java.util.List"/>
+    </method>
+    <method name="getNodeLabelList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setNodeLabels"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #setNodeLabelList(List)} instead.">
+      <param name="labels" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set node labels to the response.
+
+ @param labels Node labels
+ @deprecated Use {@link #setNodeLabelList(List)} instead.]]>
+      </doc>
+    </method>
+    <method name="getNodeLabels" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="Use {@link #getNodeLabelList()} instead.">
+      <doc>
+      <![CDATA[Get node labels of the response.
+
+ @return Node labels
+ @deprecated Use {@link #getNodeLabelList()} instead.]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest -->
+  <class name="GetClusterNodesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterNodesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="states" type="java.util.EnumSet"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNodeStates" return="java.util.EnumSet"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The state to filter the cluster nodes with.
+ @return the set of {@link NodeState}]]>
+      </doc>
+    </method>
+    <method name="setNodeStates"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="states" type="java.util.EnumSet"/>
+      <doc>
+      <![CDATA[The state to filter the cluster nodes with.
+ @param states the set of {@link NodeState}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request from clients to get a report of all nodes
+ in the cluster from the <code>ResourceManager</code>.</p>
+
+ The request will ask for all nodes in the given {@link NodeState}s.
+
+ @see ApplicationClientProtocol#getClusterNodes(GetClusterNodesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse -->
+  <class name="GetClusterNodesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetClusterNodesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNodeReports" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>NodeReport</code> for all nodes in the cluster.
+ @return <code>NodeReport</code> for all nodes in the cluster]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to a client
+ requesting a {@link NodeReport} for all nodes.</p>
+ 
+ <p>The <code>NodeReport</code> contains per-node information such as 
+ available resources, number of containers, tracking url, rack name, health
+ status etc.
+ 
+ @see NodeReport
+ @see ApplicationClientProtocol#getClusterNodes(GetClusterNodesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest -->
+  <class name="GetContainerReportRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetContainerReportRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+    </method>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the Container.
+ 
+ @return <code>ContainerId</code> of the Container]]>
+      </doc>
+    </method>
+    <method name="setContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerId</code> of the container
+ 
+ @param containerId
+          <code>ContainerId</code> of the container]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request sent by a client to the <code>ResourceManager</code> to get an
+ {@link ContainerReport} for a container.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse -->
+  <class name="GetContainerReportResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetContainerReportResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerReport" type="org.apache.hadoop.yarn.api.records.ContainerReport"/>
+    </method>
+    <method name="getContainerReport" return="org.apache.hadoop.yarn.api.records.ContainerReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerReport</code> for the container.
+ 
+ @return <code>ContainerReport</code> for the container]]>
+      </doc>
+    </method>
+    <method name="setContainerReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerReport" type="org.apache.hadoop.yarn.api.records.ContainerReport"/>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ a container report.
+ </p>
+ 
+ <p>
+ The response includes a {@link ContainerReport} which has details of a
+ container.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest -->
+  <class name="GetContainersRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetContainersRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+    </method>
+    <method name="getApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptId</code> of an application attempt.
+ 
+ @return <code>ApplicationAttemptId</code> of an application attempt]]>
+      </doc>
+    </method>
+    <method name="setApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationAttemptId</code> of an application attempt
+ 
+ @param applicationAttemptId
+          <code>ApplicationAttemptId</code> of an application attempt]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request from clients to get a list of container reports, which belong to
+ an application attempt from the <code>ResourceManager</code>.
+ </p>
+ 
+ @see ApplicationHistoryProtocol#getContainers(GetContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse -->
+  <class name="GetContainersResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetContainersResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containers" type="java.util.List"/>
+    </method>
+    <method name="getContainerList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of <code>ContainerReport</code> for all the containers of an
+ application attempt.
+ 
+ @return a list of <code>ContainerReport</code> for all the containers of an
+         application attempt]]>
+      </doc>
+    </method>
+    <method name="setContainerList"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containers" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set a list of <code>ContainerReport</code> for all the containers of an
+ application attempt.
+ 
+ @param containers
+          a list of <code>ContainerReport</code> for all the containers of
+          an application attempt]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ a list of {@link ContainerReport} for containers.
+ </p>
+ 
+ <p>
+ The <code>ContainerReport</code> for each container includes the container
+ details.
+ </p>
+ 
+ @see ContainerReport
+ @see ApplicationHistoryProtocol#getContainers(GetContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest -->
+  <class name="GetContainerStatusesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetContainerStatusesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerIds" type="java.util.List"/>
+    </method>
+    <method name="getContainerIds" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <code>ContainerId</code>s of containers for which to obtain
+ the <code>ContainerStatus</code>.
+ 
+ @return the list of <code>ContainerId</code>s of containers for which to
+         obtain the <code>ContainerStatus</code>.]]>
+      </doc>
+    </method>
+    <method name="setContainerIds"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerIds" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set a list of <code>ContainerId</code>s of containers for which to obtain
+ the <code>ContainerStatus</code>
+ 
+ @param containerIds
+          a list of <code>ContainerId</code>s of containers for which to
+          obtain the <code>ContainerStatus</code>]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The request sent by the <code>ApplicationMaster</code> to the
+ <code>NodeManager</code> to get {@link ContainerStatus} of requested
+ containers.
+ 
+ @see ContainerManagementProtocol#getContainerStatuses(GetContainerStatusesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse -->
+  <class name="GetContainerStatusesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetContainerStatusesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getContainerStatuses" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerStatus</code>es of the requested containers.
+ 
+ @return <code>ContainerStatus</code>es of the requested containers.]]>
+      </doc>
+    </method>
+    <method name="getFailedRequests" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the containerId-to-exception map in which the exception indicates error
+ from per container for failed requests
+ @return map of containerId-to-exception]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the <code>NodeManager</code> to the
+ <code>ApplicationMaster</code> when asked to obtain the
+ <code>ContainerStatus</code> of requested containers.
+ 
+ @see ContainerManagementProtocol#getContainerStatuses(GetContainerStatusesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetContainerStatusesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest -->
+  <class name="GetDelegationTokenRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetDelegationTokenRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="java.lang.String"/>
+    </method>
+    <method name="getRenewer" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setRenewer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[The request issued by the client to get a delegation token from
+ the {@code ResourceManager}.
+ for more information.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse -->
+  <class name="GetDelegationTokenResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetDelegationTokenResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRMDelegationToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The Delegation tokens have a identifier which maps to
+ {@link AbstractDelegationTokenIdentifier}.
+ @return the delegation tokens]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Response to a {@link GetDelegationTokenRequest} request 
+ from the client. The response contains the token that 
+ can be used by the containers to talk to  ClientRMService.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest -->
+  <class name="GetNewApplicationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetNewApplicationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by clients to get a new {@link ApplicationId} for
+ submitting an application.</p>
+ 
+ <p>Currently, this is empty.</p>
+ 
+ @see ApplicationClientProtocol#getNewApplication(GetNewApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse -->
+  <class name="GetNewApplicationResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetNewApplicationResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>new</em> <code>ApplicationId</code> allocated by the 
+ <code>ResourceManager</code>.
+ @return <em>new</em> <code>ApplicationId</code> allocated by the 
+          <code>ResourceManager</code>]]>
+      </doc>
+    </method>
+    <method name="getMaximumResourceCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the maximum capability for any {@link Resource} allocated by the 
+ <code>ResourceManager</code> in the cluster.
+ @return maximum capability of allocated resources in the cluster]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to the client for 
+ a request to get a new {@link ApplicationId} for submitting applications.</p>
+ 
+ <p>Clients can submit an application with the returned
+ {@link ApplicationId}.</p>
+
+ @see ApplicationClientProtocol#getNewApplication(GetNewApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest -->
+  <class name="GetNewReservationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetNewReservationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by clients to get a new {@code ReservationId} for
+ submitting an reservation.</p>
+
+ {@code ApplicationClientProtocol#getNewReservation(GetNewReservationRequest)}]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse -->
+  <class name="GetNewReservationResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetNewReservationResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a new {@link ReservationId} to be used to submit a reservation.
+
+ @return a {@link ReservationId} representing the unique id to identify
+ a reservation with which it was submitted.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to the client for
+ a request to get a new {@link ReservationId} for submitting reservations.</p>
+
+ <p>Clients can submit an reservation with the returned
+ {@link ReservationId}.</p>
+
+ {@code ApplicationClientProtocol#getNewReservation(GetNewReservationRequest)}]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest -->
+  <class name="GetNodesToAttributesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetNodesToAttributesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hostNames" type="java.util.Set"/>
+    </method>
+    <method name="setHostNames"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hostnames" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set hostnames for which mapping is required.
+
+ @param hostnames]]>
+      </doc>
+    </method>
+    <method name="getHostNames" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get hostnames for which mapping is required.
+
+ @return Set of hostnames.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request from clients to get nodes to attributes mapping
+ in the cluster from the <code>ResourceManager</code>.
+ </p>
+
+ @see ApplicationClientProtocol#getNodesToAttributes
+ (GetNodesToAttributesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse -->
+  <class name="GetNodesToAttributesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetNodesToAttributesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="map" type="java.util.Map"/>
+    </method>
+    <method name="setNodeToAttributes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="map" type="java.util.Map"/>
+    </method>
+    <method name="getNodeToAttributes" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get hostnames to NodeAttributes mapping.
+
+ @return Map of host to attributes.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to a client requesting
+ nodes to attributes mapping.
+ </p>
+
+ @see ApplicationClientProtocol#getNodesToAttributes
+ (GetNodesToAttributesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest -->
+  <class name="GetQueueInfoRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetQueueInfoRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <param name="includeApplications" type="boolean"/>
+      <param name="includeChildQueues" type="boolean"/>
+      <param name="recursive" type="boolean"/>
+    </method>
+    <method name="getQueueName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>queue name</em> for which to get queue information.
+ @return <em>queue name</em> for which to get queue information]]>
+      </doc>
+    </method>
+    <method name="setQueueName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>queue name</em> for which to get queue information
+ @param queueName <em>queue name</em> for which to get queue information]]>
+      </doc>
+    </method>
+    <method name="getIncludeApplications" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Is information about <em>active applications</em> required?
+ @return <code>true</code> if applications' information is to be included,
+         else <code>false</code>]]>
+      </doc>
+    </method>
+    <method name="setIncludeApplications"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includeApplications" type="boolean"/>
+      <doc>
+      <![CDATA[Should we get fetch information about <em>active applications</em>?
+ @param includeApplications fetch information about <em>active 
+                            applications</em>?]]>
+      </doc>
+    </method>
+    <method name="getIncludeChildQueues" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Is information about <em>child queues</em> required?
+ @return <code>true</code> if information about child queues is required,
+         else <code>false</code>]]>
+      </doc>
+    </method>
+    <method name="setIncludeChildQueues"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includeChildQueues" type="boolean"/>
+      <doc>
+      <![CDATA[Should we fetch information about <em>child queues</em>?
+ @param includeChildQueues fetch information about <em>child queues</em>?]]>
+      </doc>
+    </method>
+    <method name="getRecursive" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Is information on the entire <em>child queue hierarchy</em> required?
+ @return <code>true</code> if information about entire hierarchy is 
+         required, <code>false</code> otherwise]]>
+      </doc>
+    </method>
+    <method name="setRecursive"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="recursive" type="boolean"/>
+      <doc>
+      <![CDATA[Should we fetch information on the entire <em>child queue hierarchy</em>?
+ @param recursive fetch information on the entire <em>child queue 
+                  hierarchy</em>?]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by clients to get <em>queue information</em>
+ from the <code>ResourceManager</code>.</p>
+
+ @see ApplicationClientProtocol#getQueueInfo(GetQueueInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse -->
+  <class name="GetQueueInfoResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetQueueInfoResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getQueueInfo" return="org.apache.hadoop.yarn.api.records.QueueInfo"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>QueueInfo</code> for the specified queue.
+ @return <code>QueueInfo</code> for the specified queue]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the {@code ResourceManager} to a client
+ requesting information about queues in the system.
+ <p>
+ The response includes a {@link QueueInfo} which has details such as
+ queue name, used/total capacities, running applications, child queues etc.
+ 
+ @see QueueInfo
+ @see ApplicationClientProtocol#getQueueInfo(GetQueueInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest -->
+  <class name="GetQueueUserAclsInfoRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetQueueUserAclsInfoRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by clients to the <code>ResourceManager</code> to 
+ get queue acls for the <em>current user</em>.</p>
+
+ <p>Currently, this is empty.</p>
+ 
+ @see ApplicationClientProtocol#getQueueUserAcls(GetQueueUserAclsInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse -->
+  <class name="GetQueueUserAclsInfoResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetQueueUserAclsInfoResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getUserAclsInfoList" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>QueueUserACLInfo</code> per queue for the user.
+ @return <code>QueueUserACLInfo</code> per queue for the user]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to clients
+ seeking queue acls for the user.</p>
+
+ <p>The response contains a list of {@link QueueUserACLInfo} which
+ provides information about {@link QueueACL} per queue.</p>
+ 
+ @see QueueACL
+ @see QueueUserACLInfo
+ @see ApplicationClientProtocol#getQueueUserAcls(GetQueueUserAclsInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest -->
+  <class name="GetResourceProfileRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetResourceProfileRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="profile" type="java.lang.String"/>
+    </method>
+    <method name="setProfileName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="profileName" type="java.lang.String"/>
+    </method>
+    <method name="getProfileName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Request class for getting the details for a particular resource profile.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse -->
+  <class name="GetResourceProfileResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="GetResourceProfileResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getResource" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the resources that will be allocated if the profile was used.
+
+ @return the resources that will be allocated if the profile was used.]]>
+      </doc>
+    </method>
+    <method name="setResource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="r" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Set the resources that will be allocated if the profile is used.
+
+ @param r Set the resources that will be allocated if the profile is used.]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Response class for getting the details for a particular resource profile.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest -->
+  <class name="IncreaseContainersResourceRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="IncreaseContainersResourceRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containersToIncrease" type="java.util.List"/>
+    </method>
+    <method name="getContainersToIncrease" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of container tokens to be used for authorization during
+ container resource increase.
+ <p>
+ Note: {@link NMToken} will be used for authenticating communication with
+ {@code NodeManager}.
+ @return the list of container tokens to be used for authorization during
+ container resource increase.
+ @see NMToken]]>
+      </doc>
+    </method>
+    <method name="setContainersToIncrease"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containersToIncrease" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set container tokens to be used during container resource increase.
+ The token is acquired from
+ <code>AllocateResponse.getIncreasedContainers</code>.
+ The token contains the container id and resource capability required for
+ container resource increase.
+ @param containersToIncrease the list of container tokens to be used
+                             for container resource increase.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by <code>Application Master</code> to the
+ <code>Node Manager</code> to change the resource quota of a container.</p>
+
+ @see ContainerManagementProtocol#increaseContainersResource(IncreaseContainersResourceRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse -->
+  <class name="IncreaseContainersResourceResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="IncreaseContainersResourceResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSuccessfullyIncreasedContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of containerIds of containers whose resource
+ have been successfully increased.
+
+ @return the list of containerIds of containers whose resource have
+ been successfully increased.]]>
+      </doc>
+    </method>
+    <method name="getFailedRequests" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the containerId-to-exception map in which the exception indicates
+ error from each container for failed requests.
+ @return map of containerId-to-exception]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>NodeManager</code> to the
+ <code>ApplicationMaster</code> when asked to increase container resource.
+ </p>
+
+ @see ContainerManagementProtocol#increaseContainersResource(IncreaseContainersResourceRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.IncreaseContainersResourceResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest -->
+  <class name="KillApplicationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="KillApplicationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the application to be aborted.
+ @return <code>ApplicationId</code> of the application to be aborted]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="getDiagnostics" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>diagnostics</em> to which the application is being killed.
+ @return <em>diagnostics</em> to which the application is being killed]]>
+      </doc>
+    </method>
+    <method name="setDiagnostics"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="diagnostics" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>diagnostics</em> to which the application is being killed.
+ @param diagnostics <em>diagnostics</em> to which the application is being
+          killed]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by the client to the <code>ResourceManager</code>
+ to abort a submitted application.</p>
+ 
+ <p>The request includes the {@link ApplicationId} of the application to be
+ aborted.</p>
+ 
+ @see ApplicationClientProtocol#forceKillApplication(KillApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse -->
+  <class name="KillApplicationResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="KillApplicationResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getIsKillCompleted" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the flag which indicates that the process of killing application is completed or not.
+ @return true if the process of killing application has completed,
+         false otherwise]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the <code>ResourceManager</code> to the client aborting
+ a submitted application.
+ <p>
+ The response, includes:
+ <ul>
+   <li>
+     A flag which indicates that the process of killing the application is
+     completed or not.
+   </li>
+ </ul>
+ Note: user is recommended to wait until this flag becomes true, otherwise if
+ the <code>ResourceManager</code> crashes before the process of killing the
+ application is completed, the <code>ResourceManager</code> may retry this
+ application on recovery.
+ 
+ @see ApplicationClientProtocol#forceKillApplication(KillApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest -->
+  <class name="MoveApplicationAcrossQueuesRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MoveApplicationAcrossQueuesRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="queue" type="java.lang.String"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the application to be moved.
+ @return <code>ApplicationId</code> of the application to be moved]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the application to be moved.
+ @param appId <code>ApplicationId</code> of the application to be moved]]>
+      </doc>
+    </method>
+    <method name="getTargetQueue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the queue to place the application in.
+ @return the name of the queue to place the application in]]>
+      </doc>
+    </method>
+    <method name="setTargetQueue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get the queue to place the application in.
+ @param queue the name of the queue to place the application in]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by the client to the <code>ResourceManager</code>
+ to move a submitted application to a different queue.</p>
+ 
+ <p>The request includes the {@link ApplicationId} of the application to be
+ moved and the queue to place it in.</p>
+ 
+ @see ApplicationClientProtocol#moveApplicationAcrossQueues(MoveApplicationAcrossQueuesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse -->
+  <class name="MoveApplicationAcrossQueuesResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="MoveApplicationAcrossQueuesResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to the client moving
+ a submitted application to a different queue.
+ </p>
+ <p>
+ A response without exception means that the move has completed successfully.
+ </p>
+ 
+ @see ApplicationClientProtocol#moveApplicationAcrossQueues(MoveApplicationAcrossQueuesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest -->
+  <class name="RegisterApplicationMasterRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RegisterApplicationMasterRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="host" type="java.lang.String"/>
+      <param name="port" type="int"/>
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Create a new instance of <code>RegisterApplicationMasterRequest</code>.
+ If <em>port, trackingUrl</em> is not used, use the following default value:
+ <ul>
+  <li>port: -1</li>
+  <li>trackingUrl: null</li>
+ </ul>
+ The port is allowed to be any integer larger than or equal to -1.
+ @return the new instance of <code>RegisterApplicationMasterRequest</code>]]>
+      </doc>
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>host</em> on which the <code>ApplicationMaster</code> is 
+ running.
+ @return <em>host</em> on which the <code>ApplicationMaster</code> is running]]>
+      </doc>
+    </method>
+    <method name="setHost"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="host" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>host</em> on which the <code>ApplicationMaster</code> is 
+ running.
+ @param host <em>host</em> on which the <code>ApplicationMaster</code> 
+             is running]]>
+      </doc>
+    </method>
+    <method name="getRpcPort" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>RPC port</em> on which the {@code ApplicationMaster} is
+ responding.
+ @return the <em>RPC port</em> on which the {@code ApplicationMaster}
+         is responding]]>
+      </doc>
+    </method>
+    <method name="setRpcPort"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="port" type="int"/>
+      <doc>
+      <![CDATA[Set the <em>RPC port</em> on which the {@code ApplicationMaster} is
+ responding.
+ @param port <em>RPC port</em> on which the {@code ApplicationMaster}
+             is responding]]>
+      </doc>
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>tracking URL</em> for the <code>ApplicationMaster</code>.
+ This url if contains scheme then that will be used by resource manager
+ web application proxy otherwise it will default to http.
+ @return <em>tracking URL</em> for the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="setTrackingUrl"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>tracking URL</em>for the <code>ApplicationMaster</code> while
+ it is running. This is the web-URL to which ResourceManager or
+ web-application proxy will redirect client/users while the application and
+ the <code>ApplicationMaster</code> are still running.
+ <p>
+ If the passed url has a scheme then that will be used by the
+ ResourceManager and web-application proxy, otherwise the scheme will
+ default to http.
+ </p>
+ <p>
+ Empty, null, "N/A" strings are all valid besides a real URL. In case an url
+ isn't explicitly passed, it defaults to "N/A" on the ResourceManager.
+ <p>
+
+ @param trackingUrl
+          <em>tracking URL</em>for the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="getPlacementConstraints" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return all Placement Constraints specified at the Application level. The
+ mapping is from a set of allocation tags to a
+ <code>PlacementConstraint</code> associated with the tags, i.e., each
+ {@link org.apache.hadoop.yarn.api.records.SchedulingRequest} that has those
+ tags will be placed taking into account the corresponding constraint.
+
+ @return A map of Placement Constraints.]]>
+      </doc>
+    </method>
+    <method name="setPlacementConstraints"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="placementConstraints" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set Placement Constraints applicable to the
+ {@link org.apache.hadoop.yarn.api.records.SchedulingRequest}s
+ of this application.
+ The mapping is from a set of allocation tags to a
+ <code>PlacementConstraint</code> associated with the tags.
+ For example:
+  Map &lt;
+   &lt;hb_regionserver&gt; -&gt; node_anti_affinity,
+   &lt;hb_regionserver, hb_master&gt; -&gt; rack_affinity,
+   ...
+  &gt;
+ @param placementConstraints Placement Constraint Mapping.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The request sent by the {@code ApplicationMaster} to {@code ResourceManager}
+ on registration.
+ <p>
+ The registration includes details such as:
+ <ul>
+   <li>Hostname on which the AM is running.</li>
+   <li>RPC Port</li>
+   <li>Tracking URL</li>
+ </ul>
+ 
+ @see ApplicationMasterProtocol#registerApplicationMaster(RegisterApplicationMasterRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse -->
+  <class name="RegisterApplicationMasterResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RegisterApplicationMasterResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getMaximumResourceCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the maximum capability for any {@link Resource} allocated by the 
+ <code>ResourceManager</code> in the cluster.
+ @return maximum capability of allocated resources in the cluster]]>
+      </doc>
+    </method>
+    <method name="getApplicationACLs" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationACL</code>s for the application. 
+ @return all the <code>ApplicationACL</code>s]]>
+      </doc>
+    </method>
+    <method name="getClientToAMTokenMasterKey" return="java.nio.ByteBuffer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>Get ClientToAMToken master key.</p>
+ <p>The ClientToAMToken master key is sent to <code>ApplicationMaster</code>
+ by <code>ResourceManager</code> via {@link RegisterApplicationMasterResponse}
+ , used to verify corresponding ClientToAMToken.</p>
+ @return ClientToAMToken master key]]>
+      </doc>
+    </method>
+    <method name="setClientToAMTokenMasterKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.nio.ByteBuffer"/>
+      <doc>
+      <![CDATA[Set ClientToAMToken master key.]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>Get the queue that the application was placed in.<p>
+ @return the queue that the application was placed in.]]>
+      </doc>
+    </method>
+    <method name="setQueue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[<p>Set the queue that the application was placed in.<p>]]>
+      </doc>
+    </method>
+    <method name="getContainersFromPreviousAttempts" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>
+ Get the list of running containers as viewed by
+ <code>ResourceManager</code> from previous application attempts.
+ </p>
+ 
+ @return the list of running containers as viewed by
+         <code>ResourceManager</code> from previous application attempts
+ @see RegisterApplicationMasterResponse#getNMTokensFromPreviousAttempts()]]>
+      </doc>
+    </method>
+    <method name="getNMTokensFromPreviousAttempts" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of NMTokens for communicating with the NMs where the
+ containers of previous application attempts are running.
+ 
+ @return the list of NMTokens for communicating with the NMs where the
+         containers of previous application attempts are running.
+ 
+ @see RegisterApplicationMasterResponse#getContainersFromPreviousAttempts()]]>
+      </doc>
+    </method>
+    <method name="getSchedulerResourceTypes" return="java.util.EnumSet"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a set of the resource types considered by the scheduler.
+
+ @return a Map of RM settings]]>
+      </doc>
+    </method>
+    <method name="getResourceProfiles" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get list of supported resource profiles from RM.
+
+ @return a map of resource profiles and its capabilities.]]>
+      </doc>
+    </method>
+    <method name="getResourceTypes" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get available resource types supported by RM.
+
+ @return a Map of RM settings]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The response sent by the {@code ResourceManager} to a new
+ {@code ApplicationMaster} on registration.
+ <p>
+ The response contains critical details such as:
+ <ul>
+   <li>Maximum capability for allocated resources in the cluster.</li>
+   <li>{@code ApplicationACL}s for the application.</li>
+   <li>ClientToAMToken master key.</li>
+ </ul>
+ 
+ @see ApplicationMasterProtocol#registerApplicationMaster(RegisterApplicationMasterRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest -->
+  <class name="ReInitializeContainerRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReInitializeContainerRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="containerLaunchContext" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="autoCommit" type="boolean"/>
+      <doc>
+      <![CDATA[Creates a new instance of the ReInitializationContainerRequest.
+ @param containerId Container Id.
+ @param containerLaunchContext Container Launch Context.
+ @param autoCommit AutoCommit.
+ @return ReInitializationContainerRequest.]]>
+      </doc>
+    </method>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container to re-initialize.
+
+ @return <code>ContainerId</code> of the container to re-initialize.]]>
+      </doc>
+    </method>
+    <method name="getContainerLaunchContext" return="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerLaunchContext</code> to re-initialize the container
+ with.
+
+ @return <code>ContainerLaunchContext</code> of to re-initialize the
+ container with.]]>
+      </doc>
+    </method>
+    <method name="getAutoCommit" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Check if AutoCommit is set for this ReInitialization.
+ @return If AutoCommit is set for this ReInitialization.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This encapsulates all the required fields needed for a Container
+ ReInitialization.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerResponse -->
+  <class name="ReInitializeContainerResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReInitializeContainerResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[The response to the {@link ReInitializeContainerRequest}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReInitializeContainerResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest -->
+  <class name="ReleaseSharedCacheResourceRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReleaseSharedCacheResourceRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAppId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the resource to be released.
+
+ @return <code>ApplicationId</code>]]>
+      </doc>
+    </method>
+    <method name="setAppId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the resource to be released.
+
+ @param id <code>ApplicationId</code>]]>
+      </doc>
+    </method>
+    <method name="getResourceKey" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>key</code> of the resource to be released.
+
+ @return <code>key</code>]]>
+      </doc>
+    </method>
+    <method name="setResourceKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <code>key</code> of the resource to be released.
+
+ @param key unique identifier for the resource]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request from clients to release a resource in the shared cache.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceResponse -->
+  <class name="ReleaseSharedCacheResourceResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReleaseSharedCacheResourceResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[<p>
+ The response to clients from the <code>SharedCacheManager</code> when
+ releasing a resource in the shared cache.
+ </p>
+
+ <p>
+ Currently, this is empty.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReleaseSharedCacheResourceResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest -->
+  <class name="ReservationDeleteRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationDeleteRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+    </method>
+    <method name="getReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link ReservationId}, that corresponds to a valid resource
+ allocation in the scheduler (between start and end time of this
+ reservation)
+ 
+ @return the {@link ReservationId} representing the unique id of the
+         corresponding reserved resource allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="setReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+      <doc>
+      <![CDATA[Set the {@link ReservationId}, that correspond to a valid resource
+ allocation in the scheduler (between start and end time of this
+ reservation)
+ 
+ @param reservationId the {@link ReservationId} representing the the unique
+          id of the corresponding reserved resource allocation in the
+          scheduler]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationDeleteRequest} captures the set of requirements the user
+ has to delete an existing reservation.
+ 
+ @see ReservationDefinition]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse -->
+  <class name="ReservationDeleteResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationDeleteResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[{@link ReservationDeleteResponse} contains the answer of the admission
+ control system in the {@code ResourceManager} to a reservation delete
+ operation. Currently response is empty if the operation was successful, if
+ not an exception reporting reason for a failure.
+ 
+ @see ReservationDefinition]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest -->
+  <class name="ReservationListRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationListRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <param name="reservationId" type="java.lang.String"/>
+      <param name="startTime" type="long"/>
+      <param name="endTime" type="long"/>
+      <param name="includeReservationAllocations" type="boolean"/>
+      <doc>
+      <![CDATA[The {@link ReservationListRequest} will use the reservationId to search for
+ reservations to list if it is provided. Otherwise, it will select active
+ reservations within the startTime and endTime (inclusive).
+
+ @param queue Required. Cannot be null or empty. Refers to the reservable
+              queue in the scheduler that was selected when creating a
+              reservation submission {@link ReservationSubmissionRequest}.
+ @param reservationId Optional. String representation of
+                     {@code ReservationId} If provided, other fields will
+                     be ignored.
+ @param startTime Optional. If provided, only reservations that
+                end after the startTime will be selected. This defaults
+                to 0 if an invalid number is used.
+ @param endTime Optional. If provided, only reservations that
+                start on or before endTime will be selected. This defaults
+                to Long.MAX_VALUE if an invalid number is used.
+ @param includeReservationAllocations Optional. Flag that
+                determines whether the entire reservation allocations are
+                to be returned. Reservation allocations are subject to
+                change in the event of re-planning as described by
+                {@code ReservationDefinition}.
+ @return the list of reservations via  {@link ReservationListRequest}]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <param name="reservationId" type="java.lang.String"/>
+      <param name="includeReservationAllocations" type="boolean"/>
+      <doc>
+      <![CDATA[The {@link ReservationListRequest} will use the reservationId to search for
+ reservations to list if it is provided. Otherwise, it will select active
+ reservations within the startTime and endTime (inclusive).
+
+ @param queue Required. Cannot be null or empty. Refers to the reservable
+              queue in the scheduler that was selected when creating a
+              reservation submission {@link ReservationSubmissionRequest}.
+ @param reservationId Optional. String representation of
+                     {@code ReservationId} If provided, other fields will
+                     be ignored.
+ @param includeReservationAllocations Optional. Flag that
+                determines whether the entire reservation allocations are
+                to be returned. Reservation allocations are subject to
+                change in the event of re-planning as described by
+                {@code ReservationDefinition}.
+ @return the list of reservations via {@link ReservationListRequest}]]>
+      </doc>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <param name="reservationId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[The {@link ReservationListRequest} will use the reservationId to search for
+ reservations to list if it is provided. Otherwise, it will select active
+ reservations within the startTime and endTime (inclusive).
+
+ @param queue Required. Cannot be null or empty. Refers to the reservable
+              queue in the scheduler that was selected when creating a
+              reservation submission {@link ReservationSubmissionRequest}.
+ @param reservationId Optional. String representation of
+                     {@code ReservationId} If provided, other fields will
+                     be ignored.
+ @return the list of reservations via {@link ReservationListRequest}]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get queue name to use to find reservations.
+
+ @return the queue name to use to find reservations.]]>
+      </doc>
+    </method>
+    <method name="setQueue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set queue name to use to find resource allocations.
+
+ @param queue Required. Cannot be null or empty.]]>
+      </doc>
+    </method>
+    <method name="getReservationId" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reservation id to use to find a reservation.
+
+ @return the reservation id of the reservation.]]>
+      </doc>
+    </method>
+    <method name="setReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the reservation id to use to find a reservation.
+
+ @param reservationId Optional. String representation of
+                     {@code ReservationId} If provided, other fields will
+                     be ignored.]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the start time to use to search for reservations.
+ When this is set, reservations that start before this start
+ time are ignored.
+
+ @return the start time to use to search for reservations.]]>
+      </doc>
+    </method>
+    <method name="setStartTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startTime" type="long"/>
+      <doc>
+      <![CDATA[Set the start time to use to search for reservations.
+ When this is set, reservations that start before this start
+ time are ignored.
+
+ @param startTime Optional. If provided, only reservations that
+                end after the startTime will be selected. This defaults
+                to 0 if an invalid number is used.]]>
+      </doc>
+    </method>
+    <method name="getEndTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the end time to use to search for reservations.
+ When this is set, reservations that start after this end
+ time are ignored.
+
+ @return the end time to use to search for reservations.]]>
+      </doc>
+    </method>
+    <method name="setEndTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="endTime" type="long"/>
+      <doc>
+      <![CDATA[Set the end time to use to search for reservations.
+ When this is set, reservations that start after this end
+ time are ignored.
+
+ @param endTime Optional. If provided, only reservations that
+                start before endTime will be selected. This defaults
+                to Long.MAX_VALUE if an invalid number is used.]]>
+      </doc>
+    </method>
+    <method name="getIncludeResourceAllocations" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the boolean representing whether or not the user
+ is requesting the full resource allocation.
+ If this is true, the full resource allocation will
+ be included in the response.
+
+ @return the end time to use to search for reservations.]]>
+      </doc>
+    </method>
+    <method name="setIncludeResourceAllocations"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includeReservationAllocations" type="boolean"/>
+      <doc>
+      <![CDATA[Set the boolean representing whether or not the user
+ is requesting the full resource allocation.
+ If this is true, the full resource allocation will
+ be included in the response.
+
+ @param includeReservationAllocations Optional. Flag that
+                determines whether the entire list of
+                {@code ResourceAllocationRequest} will be returned.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationListRequest} captures the set of requirements the
+ user has to list reservations.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse -->
+  <class name="ReservationListResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationListResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getReservationAllocationState" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of {@link ReservationAllocationState}, that corresponds
+ to a reservation in the scheduler.
+
+ @return the list of {@link ReservationAllocationState} which holds
+ information of a particular reservation]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationListResponse} captures the list of reservations that the
+ user has queried.
+
+ The resulting list of {@link ReservationAllocationState} contains a list of
+ {@code ResourceAllocationRequest} representing the current state of the
+ reservation resource allocations will be returned. This is subject to change
+ in the event of re-planning a described by {@code ReservationDefinition}
+
+ @see ReservationAllocationState]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest -->
+  <class name="ReservationSubmissionRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationSubmissionRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationDefinition" type="org.apache.hadoop.yarn.api.records.ReservationDefinition"/>
+      <param name="queueName" type="java.lang.String"/>
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+    </method>
+    <method name="getReservationDefinition" return="org.apache.hadoop.yarn.api.records.ReservationDefinition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link ReservationDefinition} representing the user constraints for
+ this reservation
+ 
+ @return the reservation definition representing user constraints]]>
+      </doc>
+    </method>
+    <method name="setReservationDefinition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationDefinition" type="org.apache.hadoop.yarn.api.records.ReservationDefinition"/>
+      <doc>
+      <![CDATA[Set the {@link ReservationDefinition} representing the user constraints for
+ this reservation
+ 
+ @param reservationDefinition the reservation request representing the
+          reservation]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the name of the {@code Plan} that corresponds to the name of the
+ {@link QueueInfo} in the scheduler to which the reservation will be
+ submitted to.
+ 
+ @return the name of the {@code Plan} that corresponds to the name of the
+         {@link QueueInfo} in the scheduler to which the reservation will be
+         submitted to]]>
+      </doc>
+    </method>
+    <method name="setQueue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the name of the {@code Plan} that corresponds to the name of the
+ {@link QueueInfo} in the scheduler to which the reservation will be
+ submitted to
+ 
+ @param queueName the name of the parent {@code Plan} that corresponds to
+          the name of the {@link QueueInfo} in the scheduler to which the
+          reservation will be submitted to]]>
+      </doc>
+    </method>
+    <method name="getReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reservation id that corresponds to the reservation submission.
+
+ @return reservation id that will be used to identify the reservation
+ submission.]]>
+      </doc>
+    </method>
+    <method name="setReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+      <doc>
+      <![CDATA[Set the reservation id that corresponds to the reservation submission.
+
+ @param reservationId reservation id that will be used to identify the
+                      reservation submission.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationSubmissionRequest} captures the set of requirements the
+ user has to create a reservation.
+ 
+ @see ReservationDefinition]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse -->
+  <class name="ReservationSubmissionResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationSubmissionResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to a client on
+ reservation submission.</p>
+
+ <p>Currently, this is empty.</p>
+
+ {@code ApplicationClientProtocol#submitReservation(
+ ReservationSubmissionRequest)}]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest -->
+  <class name="ReservationUpdateRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationUpdateRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationDefinition" type="org.apache.hadoop.yarn.api.records.ReservationDefinition"/>
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+    </method>
+    <method name="getReservationDefinition" return="org.apache.hadoop.yarn.api.records.ReservationDefinition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link ReservationDefinition} representing the updated user
+ constraints for this reservation
+ 
+ @return the reservation definition representing user constraints]]>
+      </doc>
+    </method>
+    <method name="setReservationDefinition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationDefinition" type="org.apache.hadoop.yarn.api.records.ReservationDefinition"/>
+      <doc>
+      <![CDATA[Set the {@link ReservationDefinition} representing the updated user
+ constraints for this reservation
+ 
+ @param reservationDefinition the reservation request representing the
+          reservation]]>
+      </doc>
+    </method>
+    <method name="getReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link ReservationId}, that corresponds to a valid resource
+ allocation in the scheduler (between start and end time of this
+ reservation)
+ 
+ @return the {@link ReservationId} representing the unique id of the
+         corresponding reserved resource allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="setReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+      <doc>
+      <![CDATA[Set the {@link ReservationId}, that correspond to a valid resource
+ allocation in the scheduler (between start and end time of this
+ reservation)
+ 
+ @param reservationId the {@link ReservationId} representing the the unique
+          id of the corresponding reserved resource allocation in the
+          scheduler]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationUpdateRequest} captures the set of requirements the user
+ has to update an existing reservation.
+ 
+ @see ReservationDefinition]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse -->
+  <class name="ReservationUpdateResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationUpdateResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[{@link ReservationUpdateResponse} contains the answer of the admission
+ control system in the {@code ResourceManager} to a reservation update
+ operation. Currently response is empty if the operation was successful, if
+ not an exception reporting reason for a failure.
+ 
+ @see ReservationDefinition]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest -->
+  <class name="ResourceLocalizationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceLocalizationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="localResources" type="java.util.Map"/>
+    </method>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container to localize resources.
+
+ @return <code>ContainerId</code> of the container to localize resources.]]>
+      </doc>
+    </method>
+    <method name="getLocalResources" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>LocalResource</code> required by the container.
+
+ @return all <code>LocalResource</code> required by the container]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The request sent by the ApplicationMaster to ask for localizing resources.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationResponse -->
+  <class name="ResourceLocalizationResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceLocalizationResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[The response to the {@link ResourceLocalizationRequest}]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.ResourceLocalizationResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.RestartContainerResponse -->
+  <class name="RestartContainerResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RestartContainerResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[The response to a restart Container request.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.RestartContainerResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.RollbackResponse -->
+  <class name="RollbackResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RollbackResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Response to a Rollback request.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.RollbackResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest -->
+  <class name="SignalContainerRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SignalContainerRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="signalContainerCommand" type="org.apache.hadoop.yarn.api.records.SignalContainerCommand"/>
+    </method>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container to signal.
+ @return <code>ContainerId</code> of the container to signal.]]>
+      </doc>
+    </method>
+    <method name="setContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerId</code> of the container to signal.]]>
+      </doc>
+    </method>
+    <method name="getCommand" return="org.apache.hadoop.yarn.api.records.SignalContainerCommand"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>SignalContainerCommand</code> of the signal request.
+ @return <code>SignalContainerCommand</code> of the signal request.]]>
+      </doc>
+    </method>
+    <method name="setCommand"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="command" type="org.apache.hadoop.yarn.api.records.SignalContainerCommand"/>
+      <doc>
+      <![CDATA[Set the <code>SignalContainerCommand</code> of the signal request.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by the client to the <code>ResourceManager</code>
+ or by the <code>ApplicationMaster</code> to the <code>NodeManager</code>
+ to signal a container.
+ @see SignalContainerCommand </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse -->
+  <class name="SignalContainerResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SignalContainerResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to the client
+ signalling a container.</p>
+
+ <p>Currently it's empty.</p>
+
+ @see ApplicationClientProtocol#signalToContainer(SignalContainerRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest -->
+  <class name="StartContainerRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StartContainerRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <method name="getContainerLaunchContext" return="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerLaunchContext</code> for the container to be started
+ by the <code>NodeManager</code>.
+ 
+ @return <code>ContainerLaunchContext</code> for the container to be started
+         by the <code>NodeManager</code>]]>
+      </doc>
+    </method>
+    <method name="setContainerLaunchContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerLaunchContext</code> for the container to be started
+ by the <code>NodeManager</code>
+ @param context <code>ContainerLaunchContext</code> for the container to be 
+                started by the <code>NodeManager</code>]]>
+      </doc>
+    </method>
+    <method name="getContainerToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the container token to be used for authorization during starting
+ container.
+ <p>
+ Note: {@link NMToken} will be used for authenticating communication with
+ {@code NodeManager}.
+ @return the container token to be used for authorization during starting
+ container.
+ @see NMToken
+ @see ContainerManagementProtocol#startContainers(StartContainersRequest)]]>
+      </doc>
+    </method>
+    <method name="setContainerToken"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by the <code>ApplicationMaster</code> to the
+ <code>NodeManager</code> to <em>start</em> a container.</p>
+ 
+ <p>The <code>ApplicationMaster</code> has to provide details such as
+ allocated resource capability, security tokens (if enabled), command
+ to be executed to start the container, environment for the process, 
+ necessary binaries/jar/shared-objects etc. via the 
+ {@link ContainerLaunchContext}.</p>
+
+ @see ContainerManagementProtocol#startContainers(StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.StartContainerRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest -->
+  <class name="StartContainersRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StartContainersRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="requests" type="java.util.List"/>
+    </method>
+    <method name="getStartContainerRequests" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of {@link StartContainerRequest} to start containers.
+ @return a list of {@link StartContainerRequest} to start containers.]]>
+      </doc>
+    </method>
+    <method name="setStartContainerRequests"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set a list of {@link StartContainerRequest} to start containers.
+ @param request a list of {@link StartContainerRequest} to start containers]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request which contains a list of {@link StartContainerRequest} sent by
+ the <code>ApplicationMaster</code> to the <code>NodeManager</code> to
+ <em>start</em> containers.
+ </p>
+ 
+ <p>
+ In each {@link StartContainerRequest}, the <code>ApplicationMaster</code> has
+ to provide details such as allocated resource capability, security tokens (if
+ enabled), command to be executed to start the container, environment for the
+ process, necessary binaries/jar/shared-objects etc. via the
+ {@link ContainerLaunchContext}.
+ </p>
+ 
+ @see ContainerManagementProtocol#startContainers(StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse -->
+  <class name="StartContainersResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StartContainersResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSuccessfullyStartedContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <code>ContainerId</code> s of the containers that are
+ started successfully.
+ 
+ @return the list of <code>ContainerId</code> s of the containers that are
+         started successfully.
+ @see ContainerManagementProtocol#startContainers(StartContainersRequest)]]>
+      </doc>
+    </method>
+    <method name="getFailedRequests" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the containerId-to-exception map in which the exception indicates error
+ from per container for failed requests
+ @return map of containerId-to-exception]]>
+      </doc>
+    </method>
+    <method name="getAllServicesMetaData" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>
+ Get the meta-data from all auxiliary services running on the
+ <code>NodeManager</code>.
+ </p>
+ <p>
+ The meta-data is returned as a Map between the auxiliary service names and
+ their corresponding per service meta-data as an opaque blob
+ <code>ByteBuffer</code>
+ </p>
+ 
+ <p>
+ To be able to interpret the per-service meta-data, you should consult the
+ documentation for the Auxiliary-service configured on the NodeManager
+ </p>
+ 
+ @return a Map between the names of auxiliary services and their
+         corresponding meta-data]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>NodeManager</code> to the
+ <code>ApplicationMaster</code> when asked to <em>start</em> an allocated
+ container.
+ </p>
+ 
+ @see ContainerManagementProtocol#startContainers(StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.StartContainersResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest -->
+  <class name="StopContainersRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StopContainersRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerIds" type="java.util.List"/>
+    </method>
+    <method name="getContainerIds" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code>s of the containers to be stopped.
+ @return <code>ContainerId</code>s of containers to be stopped]]>
+      </doc>
+    </method>
+    <method name="setContainerIds"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerIds" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerId</code>s of the containers to be stopped.
+ @param containerIds <code>ContainerId</code>s of the containers to be stopped]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by the <code>ApplicationMaster</code> to the
+ <code>NodeManager</code> to <em>stop</em> containers.</p>
+ 
+ @see ContainerManagementProtocol#stopContainers(StopContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse -->
+  <class name="StopContainersResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StopContainersResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getSuccessfullyStoppedContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of containerIds of successfully stopped containers.
+ 
+ @return the list of containerIds of successfully stopped containers.]]>
+      </doc>
+    </method>
+    <method name="getFailedRequests" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the containerId-to-exception map in which the exception indicates error
+ from per container for failed requests
+ @return map of containerId-to-exception]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>NodeManager</code> to the
+ <code>ApplicationMaster</code> when asked to <em>stop</em> allocated
+ containers.
+ </p>
+ 
+ @see ContainerManagementProtocol#stopContainers(StopContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.StopContainersResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest -->
+  <class name="SubmitApplicationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SubmitApplicationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"/>
+    </method>
+    <method name="getApplicationSubmissionContext" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationSubmissionContext</code> for the application.
+ @return <code>ApplicationSubmissionContext</code> for the application]]>
+      </doc>
+    </method>
+    <method name="setApplicationSubmissionContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationSubmissionContext</code> for the application.
+ @param context <code>ApplicationSubmissionContext</code> for the 
+                application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>The request sent by a client to <em>submit an application</em> to the 
+ <code>ResourceManager</code>.</p>
+ 
+ <p>The request, via {@link ApplicationSubmissionContext}, contains
+ details such as queue, {@link Resource} required to run the 
+ <code>ApplicationMaster</code>, the equivalent of 
+ {@link ContainerLaunchContext} for launching the 
+ <code>ApplicationMaster</code> etc.
+ 
+ @see ApplicationClientProtocol#submitApplication(SubmitApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse -->
+  <class name="SubmitApplicationResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SubmitApplicationResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[<p>The response sent by the <code>ResourceManager</code> to a client on
+ application submission.</p>
+ 
+ <p>Currently, this is empty.</p>
+ 
+ @see ApplicationClientProtocol#submitApplication(SubmitApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest -->
+  <class name="UpdateApplicationPriorityRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdateApplicationPriorityRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the application.
+ 
+ @return <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the application.
+ 
+ @param applicationId <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <method name="getApplicationPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Priority</code> of the application to be set.
+ 
+ @return <code>Priority</code> of the application to be set.]]>
+      </doc>
+    </method>
+    <method name="setApplicationPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <doc>
+      <![CDATA[Set the <code>Priority</code> of the application.
+ 
+ @param priority <code>Priority</code> of the application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request sent by the client to the <code>ResourceManager</code> to set or
+ update the application priority.
+ </p>
+ <p>
+ The request includes the {@link ApplicationId} of the application and
+ {@link Priority} to be set for an application
+ </p>
+ 
+ @see ApplicationClientProtocol#updateApplicationPriority(UpdateApplicationPriorityRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse -->
+  <class name="UpdateApplicationPriorityResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdateApplicationPriorityResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+    </method>
+    <method name="getApplicationPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Priority</code> of the application to be set.
+ @return Updated <code>Priority</code> of the application.]]>
+      </doc>
+    </method>
+    <method name="setApplicationPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <doc>
+      <![CDATA[Set the <code>Priority</code> of the application.
+
+ @param priority <code>Priority</code> of the application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to the client on update
+ the application priority.
+ </p>
+ <p>
+ A response without exception means that the move has completed successfully.
+ </p>
+ 
+ @see ApplicationClientProtocol#updateApplicationPriority(UpdateApplicationPriorityRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest -->
+  <class name="UpdateApplicationTimeoutsRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdateApplicationTimeoutsRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationTimeouts" type="java.util.Map"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the application.
+ @return <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the application.
+ @param applicationId <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <method name="getApplicationTimeouts" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>ApplicationTimeouts</code> of the application. Timeout value is
+ in ISO8601 standard with format <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>.
+ @return all <code>ApplicationTimeouts</code> of the application.]]>
+      </doc>
+    </method>
+    <method name="setApplicationTimeouts"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTimeouts" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationTimeouts</code> for the application. Timeout value
+ is absolute. Timeout value should meet ISO8601 format. Support ISO8601
+ format is <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>. All pre-existing Map entries
+ are cleared before adding the new Map.
+ @param applicationTimeouts <code>ApplicationTimeouts</code>s for the
+          application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request sent by the client to the <code>ResourceManager</code> to set or
+ update the application timeout.
+ </p>
+ <p>
+ The request includes the {@link ApplicationId} of the application and timeout
+ to be set for an application
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse -->
+  <class name="UpdateApplicationTimeoutsResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdateApplicationTimeoutsResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getApplicationTimeouts" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>ApplicationTimeouts</code> of the application. Timeout value is
+ in ISO8601 standard with format <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>.
+ @return all <code>ApplicationTimeouts</code> of the application.]]>
+      </doc>
+    </method>
+    <method name="setApplicationTimeouts"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTimeouts" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationTimeouts</code> for the application. Timeout value
+ is absolute. Timeout value should meet ISO8601 format. Support ISO8601
+ format is <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>. All pre-existing Map entries
+ are cleared before adding the new Map.
+ @param applicationTimeouts <code>ApplicationTimeouts</code>s for the
+          application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response sent by the <code>ResourceManager</code> to the client on update
+ application timeout.
+ </p>
+ <p>
+ A response without exception means that the update has completed
+ successfully.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest -->
+  <class name="UseSharedCacheResourceRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UseSharedCacheResourceRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAppId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the resource to be used.
+
+ @return <code>ApplicationId</code>]]>
+      </doc>
+    </method>
+    <method name="setAppId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the resource to be used.
+
+ @param id <code>ApplicationId</code>]]>
+      </doc>
+    </method>
+    <method name="getResourceKey" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>key</code> of the resource to be used.
+
+ @return <code>key</code>]]>
+      </doc>
+    </method>
+    <method name="setResourceKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <code>key</code> of the resource to be used.
+
+ @param key unique identifier for the resource]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The request from clients to the <code>SharedCacheManager</code> that claims a
+ resource in the shared cache.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse -->
+  <class name="UseSharedCacheResourceResponse" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UseSharedCacheResourceResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getPath" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Path</code> corresponding to the requested resource in the
+ shared cache.
+
+ @return String A <code>Path</code> if the resource exists in the shared
+         cache, <code>null</code> otherwise]]>
+      </doc>
+    </method>
+    <method name="setPath"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="p" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <code>Path</code> corresponding to a resource in the shared cache.
+
+ @param p A <code>Path</code> corresponding to a resource in the shared
+          cache]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The response from the SharedCacheManager to the client that indicates whether
+ a requested resource exists in the cache.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.protocolrecords.UseSharedCacheResourceResponse -->
+</package>
+<package name="org.apache.hadoop.yarn.api.records">
+  <!-- start class org.apache.hadoop.yarn.api.records.AMCommand -->
+  <class name="AMCommand" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.AMCommand[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.AMCommand"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Command sent by the Resource Manager to the Application Master in the 
+ AllocateResponse 
+ @see AllocateResponse]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.AMCommand -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationAccessType -->
+  <class name="ApplicationAccessType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ApplicationAccessType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ApplicationAccessType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Application access types.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationAccessType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationAttemptId -->
+  <class name="ApplicationAttemptId" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ApplicationAttemptId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="attemptId" type="int"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the <code>ApplicationAttempId</code>. 
+ @return <code>ApplicationId</code> of the <code>ApplicationAttempId</code>]]>
+      </doc>
+    </method>
+    <method name="getAttemptId" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>attempt id</code> of the <code>Application</code>.
+ @return <code>attempt id</code> of the <code>Application</code>]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="build"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="fromString" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptIdStr" type="java.lang.String"/>
+    </method>
+    <field name="appAttemptIdStrPrefix" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p><code>ApplicationAttemptId</code> denotes the particular <em>attempt</em>
+ of an <code>ApplicationMaster</code> for a given {@link ApplicationId}.</p>
+ 
+ <p>Multiple attempts might be needed to run an application to completion due
+ to temporal failures of the <code>ApplicationMaster</code> such as hardware
+ failures, connectivity issues etc. on the node on which it was scheduled.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationAttemptId -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationAttemptReport -->
+  <class name="ApplicationAttemptReport" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationAttemptReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="host" type="java.lang.String"/>
+      <param name="rpcPort" type="int"/>
+      <param name="url" type="java.lang.String"/>
+      <param name="oUrl" type="java.lang.String"/>
+      <param name="diagnostics" type="java.lang.String"/>
+      <param name="state" type="org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState"/>
+      <param name="amContainerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+    </method>
+    <method name="getYarnApplicationAttemptState" return="org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>YarnApplicationAttemptState</em> of the application attempt.
+ 
+ @return <em>YarnApplicationAttemptState</em> of the application attempt]]>
+      </doc>
+    </method>
+    <method name="getRpcPort" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>RPC port</em> of this attempt <code>ApplicationMaster</code>.
+ 
+ @return <em>RPC port</em> of this attempt <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>host</em> on which this attempt of
+ <code>ApplicationMaster</code> is running.
+ 
+ @return <em>host</em> on which this attempt of
+         <code>ApplicationMaster</code> is running]]>
+      </doc>
+    </method>
+    <method name="getDiagnostics" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>diagnositic information</em> of the application attempt in case
+ of errors.
+ 
+ @return <em>diagnositic information</em> of the application attempt in case
+         of errors]]>
+      </doc>
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>tracking url</em> for the application attempt.
+ 
+ @return <em>tracking url</em> for the application attempt]]>
+      </doc>
+    </method>
+    <method name="getOriginalTrackingUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>original tracking url</em> for the application attempt.
+ 
+ @return <em>original tracking url</em> for the application attempt]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptId</code> of this attempt of the
+ application
+ 
+ @return <code>ApplicationAttemptId</code> of the attempt]]>
+      </doc>
+    </method>
+    <method name="getAMContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of AMContainer for this attempt
+ 
+ @return <code>ContainerId</code> of the attempt]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFinishTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>finish time</em> of the application.
+ 
+ @return <em>finish time</em> of the application]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ApplicationAttemptReport} is a report of an application attempt.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link ApplicationAttemptId} of the application.</li>
+   <li>Host on which the <code>ApplicationMaster</code> of this attempt is
+   running.</li>
+   <li>RPC port of the <code>ApplicationMaster</code> of this attempt.</li>
+   <li>Tracking URL.</li>
+   <li>Diagnostic information in case of errors.</li>
+   <li>{@link YarnApplicationAttemptState} of the application attempt.</li>
+   <li>{@link ContainerId} of the master Container.</li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationAttemptReport -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationId -->
+  <class name="ApplicationId" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ApplicationId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="clusterTimestamp" type="long"/>
+      <param name="id" type="int"/>
+    </method>
+    <method name="getId" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the short integer identifier of the <code>ApplicationId</code>
+ which is unique for all applications started by a particular instance
+ of the <code>ResourceManager</code>.
+ @return short integer identifier of the <code>ApplicationId</code>]]>
+      </doc>
+    </method>
+    <method name="getClusterTimestamp" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>start time</em> of the <code>ResourceManager</code> which is 
+ used to generate globally unique <code>ApplicationId</code>.
+ @return <em>start time</em> of the <code>ResourceManager</code>]]>
+      </doc>
+    </method>
+    <method name="build"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="fromString" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appIdStr" type="java.lang.String"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <field name="appIdStrPrefix" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p><code>ApplicationId</code> represents the <em>globally unique</em> 
+ identifier for an application.</p>
+ 
+ <p>The globally unique nature of the identifier is achieved by using the 
+ <em>cluster timestamp</em> i.e. start-time of the 
+ <code>ResourceManager</code> along with a monotonically increasing counter
+ for the application.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationId -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationReport -->
+  <class name="ApplicationReport" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the application.
+ @return <code>ApplicationId</code> of the application]]>
+      </doc>
+    </method>
+    <method name="getCurrentApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptId</code> of the current
+ attempt of the application
+ @return <code>ApplicationAttemptId</code> of the attempt]]>
+      </doc>
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>user</em> who submitted the application.
+ @return <em>user</em> who submitted the application]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>queue</em> to which the application was submitted.
+ @return <em>queue</em> to which the application was submitted]]>
+      </doc>
+    </method>
+    <method name="getName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-defined <em>name</em> of the application.
+ @return <em>name</em> of the application]]>
+      </doc>
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>host</em> on which the <code>ApplicationMaster</code>
+ is running.
+ @return <em>host</em> on which the <code>ApplicationMaster</code>
+         is running]]>
+      </doc>
+    </method>
+    <method name="getRpcPort" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>RPC port</em> of the <code>ApplicationMaster</code>.
+ @return <em>RPC port</em> of the <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="getClientToAMToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>client token</em> for communicating with the
+ <code>ApplicationMaster</code>.
+ <p>
+ <em>ClientToAMToken</em> is the security token used by the AMs to verify
+ authenticity of any <code>client</code>.
+ </p>
+
+ <p>
+ The <code>ResourceManager</code>, provides a secure token (via
+ {@link ApplicationReport#getClientToAMToken()}) which is verified by the
+ ApplicationMaster when the client directly talks to an AM.
+ </p>
+ @return <em>client token</em> for communicating with the
+ <code>ApplicationMaster</code>]]>
+      </doc>
+    </method>
+    <method name="getYarnApplicationState" return="org.apache.hadoop.yarn.api.records.YarnApplicationState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>YarnApplicationState</code> of the application.
+ @return <code>YarnApplicationState</code> of the application]]>
+      </doc>
+    </method>
+    <method name="getDiagnostics" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get  the <em>diagnositic information</em> of the application in case of
+ errors.
+ @return <em>diagnositic information</em> of the application in case
+         of errors]]>
+      </doc>
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>tracking url</em> for the application.
+ @return <em>tracking url</em> for the application]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>start time</em> of the application.
+ @return <em>start time</em> of the application]]>
+      </doc>
+    </method>
+    <method name="getSubmitTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getLaunchTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFinishTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>finish time</em> of the application.
+ @return <em>finish time</em> of the application]]>
+      </doc>
+    </method>
+    <method name="getFinalApplicationStatus" return="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>final finish status</em> of the application.
+ @return <em>final finish status</em> of the application]]>
+      </doc>
+    </method>
+    <method name="getApplicationResourceUsageReport" return="org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Retrieve the structure containing the job resources for this application
+ @return the job resources structure for this application]]>
+      </doc>
+    </method>
+    <method name="getProgress" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application's progress ( range 0.0 to 1.0 )
+ @return application's progress]]>
+      </doc>
+    </method>
+    <method name="getApplicationType" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application's Type 
+ @return application's Type]]>
+      </doc>
+    </method>
+    <method name="getApplicationTags" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get all tags corresponding to the application
+ @return Application's tags]]>
+      </doc>
+    </method>
+    <method name="getAMRMToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the AMRM token of the application.
+ <p>
+ The AMRM token is required for AM to RM scheduling operations. For 
+ managed Application Masters YARN takes care of injecting it. For unmanaged
+ Applications Masters, the token must be obtained via this method and set
+ in the {@link org.apache.hadoop.security.UserGroupInformation} of the
+ current user.
+ <p>
+ The AMRM token will be returned only if all the following conditions are
+ met:
+ <ul>
+   <li>the requester is the owner of the ApplicationMaster</li>
+   <li>the application master is an unmanaged ApplicationMaster</li>
+   <li>the application master is in ACCEPTED state</li>
+ </ul>
+ Else this method returns NULL.
+ 
+ @return the AM to RM token if available.]]>
+      </doc>
+    </method>
+    <method name="getLogAggregationStatus" return="org.apache.hadoop.yarn.api.records.LogAggregationStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get log aggregation status for the application
+ @return Application's log aggregation status]]>
+      </doc>
+    </method>
+    <method name="isUnmanagedApp" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return true if the AM is not managed by the RM]]>
+      </doc>
+    </method>
+    <method name="setUnmanagedApp"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="unmanagedApplication" type="boolean"/>
+      <doc>
+      <![CDATA[@param unmanagedApplication true if RM should not manage the AM]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get priority of the application
+
+ @return Application's priority]]>
+      </doc>
+    </method>
+    <method name="getAppNodeLabelExpression" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the default Node Label expression for all the application's containers
+
+ @return Application's NodeLabelExpression]]>
+      </doc>
+    </method>
+    <method name="setAppNodeLabelExpression"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appNodeLabelExpression" type="java.lang.String"/>
+    </method>
+    <method name="getAmNodeLabelExpression" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the default Node Label expression for all the application's containers
+
+ @return Application's NodeLabelExpression]]>
+      </doc>
+    </method>
+    <method name="setAmNodeLabelExpression"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="amNodeLabelExpression" type="java.lang.String"/>
+    </method>
+    <method name="getApplicationTimeouts" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[{@code ApplicationReport} is a report of an application.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link ApplicationId} of the application.</li>
+   <li>Applications user.</li>
+   <li>Application queue.</li>
+   <li>Application name.</li>
+   <li>Host on which the <code>ApplicationMaster</code> is running.</li>
+   <li>RPC port of the <code>ApplicationMaster</code>.</li>
+   <li>Tracking URL.</li>
+   <li>{@link YarnApplicationState} of the application.</li>
+   <li>Diagnostic information in case of errors.</li>
+   <li>Start time of the application.</li>
+   <li>Client {@link Token} of the application (if security is enabled).</li>
+ </ul>
+
+ @see ApplicationClientProtocol#getApplicationReport(org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationReport -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport -->
+  <class name="ApplicationResourceUsageReport" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationResourceUsageReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNumUsedContainers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of used containers.  -1 for invalid/inaccessible reports.
+ @return the number of used containers]]>
+      </doc>
+    </method>
+    <method name="getUsedResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the used <code>Resource</code>.  -1 for invalid/inaccessible reports.
+ @return the used <code>Resource</code>]]>
+      </doc>
+    </method>
+    <method name="getReservedResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reserved <code>Resource</code>.  -1 for invalid/inaccessible reports.
+ @return the reserved <code>Resource</code>]]>
+      </doc>
+    </method>
+    <method name="getNeededResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the needed <code>Resource</code>.  -1 for invalid/inaccessible reports.
+ @return the needed <code>Resource</code>]]>
+      </doc>
+    </method>
+    <method name="getMemorySeconds" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the aggregated amount of memory (in megabytes) the application has
+ allocated times the number of seconds the application has been running.
+ @return the aggregated amount of memory seconds]]>
+      </doc>
+    </method>
+    <method name="getVcoreSeconds" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the aggregated number of vcores that the application has allocated
+ times the number of seconds the application has been running.
+ @return the aggregated number of vcore seconds]]>
+      </doc>
+    </method>
+    <method name="getQueueUsagePercentage" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the percentage of resources of the queue that the app is using.
+ @return the percentage of resources of the queue that the app is using.]]>
+      </doc>
+    </method>
+    <method name="getClusterUsagePercentage" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the percentage of resources of the cluster that the app is using.
+ @return the percentage of resources of the cluster that the app is using.]]>
+      </doc>
+    </method>
+    <method name="getPreemptedMemorySeconds" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the aggregated amount of memory preempted(in megabytes)
+ the application has allocated times the number of
+ seconds the application has been running.
+ @return the aggregated amount of memory seconds]]>
+      </doc>
+    </method>
+    <method name="getPreemptedVcoreSeconds" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the aggregated number of vcores preempted that the application has
+ allocated times the number of seconds the application has been running.
+ @return the aggregated number of vcore seconds]]>
+      </doc>
+    </method>
+    <method name="getResourceSecondsMap" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the aggregated number of resources that the application has
+ allocated times the number of seconds the application has been running.
+ @return map containing the resource name and aggregated resource-seconds]]>
+      </doc>
+    </method>
+    <method name="getPreemptedResourceSecondsMap" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the aggregated number of resources preempted that the application has
+ allocated times the number of seconds the application has been running.
+ @return map containing the resource name and aggregated preempted
+ resource-seconds]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Contains various scheduling metrics to be reported by UI and CLI.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext -->
+  <class name="ApplicationSubmissionContext" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationSubmissionContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="applicationType" type="java.lang.String"/>
+      <param name="keepContainers" type="boolean"/>
+      <param name="appLabelExpression" type="java.lang.String"/>
+      <param name="amContainerLabelExpression" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="applicationType" type="java.lang.String"/>
+      <param name="keepContainers" type="boolean"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="applicationType" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="applicationType" type="java.lang.String"/>
+      <param name="keepContainers" type="boolean"/>
+      <param name="appLabelExpression" type="java.lang.String"/>
+      <param name="resourceRequest" type="org.apache.hadoop.yarn.api.records.ResourceRequest"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="applicationType" type="java.lang.String"/>
+      <param name="keepContainers" type="boolean"/>
+      <param name="attemptFailuresValidityInterval" type="long"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="applicationName" type="java.lang.String"/>
+      <param name="queue" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="isUnmanagedAM" type="boolean"/>
+      <param name="cancelTokensWhenComplete" type="boolean"/>
+      <param name="maxAppAttempts" type="int"/>
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="applicationType" type="java.lang.String"/>
+      <param name="keepContainers" type="boolean"/>
+      <param name="logAggregationContext" type="org.apache.hadoop.yarn.api.records.LogAggregationContext"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the submitted application.
+ @return <code>ApplicationId</code> of the submitted application]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationId</code> of the submitted application.
+ @param applicationId <code>ApplicationId</code> of the submitted
+                      application]]>
+      </doc>
+    </method>
+    <method name="getApplicationName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application <em>name</em>.
+ @return application name]]>
+      </doc>
+    </method>
+    <method name="setApplicationName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the application <em>name</em>.
+ @param applicationName application name]]>
+      </doc>
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>queue</em> to which the application is being submitted.
+ @return <em>queue</em> to which the application is being submitted]]>
+      </doc>
+    </method>
+    <method name="setQueue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>queue</em> to which the application is being submitted
+ @param queue <em>queue</em> to which the application is being submitted]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Priority</code> of the application.
+ @return <code>Priority</code> of the application]]>
+      </doc>
+    </method>
+    <method name="getAMContainerSpec" return="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerLaunchContext</code> to describe the 
+ <code>Container</code> with which the <code>ApplicationMaster</code> is
+ launched.
+ @return <code>ContainerLaunchContext</code> for the 
+         <code>ApplicationMaster</code> container]]>
+      </doc>
+    </method>
+    <method name="setAMContainerSpec"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="amContainer" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerLaunchContext</code> to describe the 
+ <code>Container</code> with which the <code>ApplicationMaster</code> is
+ launched.
+ @param amContainer <code>ContainerLaunchContext</code> for the 
+                    <code>ApplicationMaster</code> container]]>
+      </doc>
+    </method>
+    <method name="getUnmanagedAM" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get if the RM should manage the execution of the AM. 
+ If true, then the RM 
+ will not allocate a container for the AM and start it. It will expect the 
+ AM to be launched and connect to the RM within the AM liveliness period and 
+ fail the app otherwise. The client should launch the AM only after the RM 
+ has ACCEPTED the application and changed the <code>YarnApplicationState</code>.
+ Such apps will not be retried by the RM on app attempt failure.
+ The default value is false.
+ @return true if the AM is not managed by the RM]]>
+      </doc>
+    </method>
+    <method name="setUnmanagedAM"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="value" type="boolean"/>
+      <doc>
+      <![CDATA[@param value true if RM should not manage the AM]]>
+      </doc>
+    </method>
+    <method name="getMaxAppAttempts" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return the number of max attempts of the application to be submitted]]>
+      </doc>
+    </method>
+    <method name="setMaxAppAttempts"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="maxAppAttempts" type="int"/>
+      <doc>
+      <![CDATA[Set the number of max attempts of the application to be submitted. WARNING:
+ it should be no larger than the global number of max attempts in the Yarn
+ configuration.
+ @param maxAppAttempts the number of max attempts of the application
+ to be submitted.]]>
+      </doc>
+    </method>
+    <method name="getResource" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the resource required by the <code>ApplicationMaster</code> for this
+ application. Please note this will be DEPRECATED, use <em>getResource</em>
+ in <em>getAMContainerResourceRequest</em> instead.
+ 
+ @return the resource required by the <code>ApplicationMaster</code> for
+         this application.]]>
+      </doc>
+    </method>
+    <method name="setResource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Set the resource required by the <code>ApplicationMaster</code> for this
+ application.
+
+ @param resource the resource required by the <code>ApplicationMaster</code>
+ for this application.]]>
+      </doc>
+    </method>
+    <method name="getApplicationType" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application type
+ 
+ @return the application type]]>
+      </doc>
+    </method>
+    <method name="setApplicationType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationType" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the application type
+ 
+ @param applicationType the application type]]>
+      </doc>
+    </method>
+    <method name="getKeepContainersAcrossApplicationAttempts" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the flag which indicates whether to keep containers across application
+ attempts or not.
+ 
+ @return the flag which indicates whether to keep containers across
+         application attempts or not.]]>
+      </doc>
+    </method>
+    <method name="setKeepContainersAcrossApplicationAttempts"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="keepContainers" type="boolean"/>
+      <doc>
+      <![CDATA[Set the flag which indicates whether to keep containers across application
+ attempts.
+ <p>
+ For managed AM, if the flag is true, running containers will not be killed
+ when application attempt fails and these containers will be retrieved by
+ the new application attempt on registration via
+ {@link ApplicationMasterProtocol#registerApplicationMaster(RegisterApplicationMasterRequest)}.
+ </p>
+ <p>
+ For unmanaged AM, if the flag is true, RM allows re-register and returns
+ the running containers in the same attempt back to the UAM for HA.
+ </p>
+
+ @param keepContainers the flag which indicates whether to keep containers
+          across application attempts.]]>
+      </doc>
+    </method>
+    <method name="getApplicationTags" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get tags for the application
+
+ @return the application tags]]>
+      </doc>
+    </method>
+    <method name="setApplicationTags"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="tags" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set tags for the application. A maximum of
+ {@link YarnConfiguration#RM_APPLICATION_MAX_TAGS} are allowed
+ per application. Each tag can be at most
+ {@link YarnConfiguration#RM_APPLICATION_MAX_TAG_LENGTH}
+ characters, and can contain only ASCII characters.
+
+ @param tags tags to set]]>
+      </doc>
+    </method>
+    <method name="getNodeLabelExpression" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get node-label-expression for this app. If this is set, all containers of
+ this application without setting node-label-expression in ResurceRequest
+ will get allocated resources on only those nodes that satisfy this
+ node-label-expression.
+ 
+ If different node-label-expression of this app and ResourceRequest are set
+ at the same time, the one set in ResourceRequest will be used when
+ allocating container
+ 
+ @return node-label-expression for this app]]>
+      </doc>
+    </method>
+    <method name="setNodeLabelExpression"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeLabelExpression" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set node-label-expression for this app
+ @param nodeLabelExpression node-label-expression of this app]]>
+      </doc>
+    </method>
+    <method name="getAMContainerResourceRequest" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="See {@link #getAMContainerResourceRequests()}">
+      <doc>
+      <![CDATA[Get the ResourceRequest of the AM container.
+
+ If this is not null, scheduler will use this to acquire resource for AM
+ container.
+
+ If this is null, scheduler will assemble a ResourceRequest by using
+ <em>getResource</em> and <em>getPriority</em> of
+ <em>ApplicationSubmissionContext</em>.
+
+ Number of containers and Priority will be ignored.
+
+ @return ResourceRequest of the AM container
+ @deprecated See {@link #getAMContainerResourceRequests()}]]>
+      </doc>
+    </method>
+    <method name="setAMContainerResourceRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="See {@link #setAMContainerResourceRequests(List)}">
+      <param name="request" type="org.apache.hadoop.yarn.api.records.ResourceRequest"/>
+      <doc>
+      <![CDATA[Set ResourceRequest of the AM container
+ @param request of the AM container
+ @deprecated See {@link #setAMContainerResourceRequests(List)}]]>
+      </doc>
+    </method>
+    <method name="getAMContainerResourceRequests" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the ResourceRequests of the AM container.
+
+ If this is not null, scheduler will use this to acquire resource for AM
+ container.
+
+ If this is null, scheduler will use the ResourceRequest as determined by
+ <em>getAMContainerResourceRequest</em> and its behavior.
+
+ Number of containers and Priority will be ignored.
+
+ @return List of ResourceRequests of the AM container]]>
+      </doc>
+    </method>
+    <method name="setAMContainerResourceRequests"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="requests" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set ResourceRequests of the AM container.
+ @param requests of the AM container]]>
+      </doc>
+    </method>
+    <method name="getAttemptFailuresValidityInterval" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the attemptFailuresValidityInterval in milliseconds for the application
+
+ @return the attemptFailuresValidityInterval]]>
+      </doc>
+    </method>
+    <method name="setAttemptFailuresValidityInterval"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attemptFailuresValidityInterval" type="long"/>
+      <doc>
+      <![CDATA[Set the attemptFailuresValidityInterval in milliseconds for the application
+ @param attemptFailuresValidityInterval]]>
+      </doc>
+    </method>
+    <method name="getLogAggregationContext" return="org.apache.hadoop.yarn.api.records.LogAggregationContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>LogAggregationContext</code> of the application
+
+ @return <code>LogAggregationContext</code> of the application]]>
+      </doc>
+    </method>
+    <method name="setLogAggregationContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logAggregationContext" type="org.apache.hadoop.yarn.api.records.LogAggregationContext"/>
+      <doc>
+      <![CDATA[Set <code>LogAggregationContext</code> for the application
+
+ @param logAggregationContext
+          for the application]]>
+      </doc>
+    </method>
+    <method name="getReservationID" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reservation id, that corresponds to a valid resource allocation in
+ the scheduler (between start and end time of the corresponding reservation)
+ 
+ @return the reservation id representing the unique id of the corresponding
+         reserved resource allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="setReservationID"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationID" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+      <doc>
+      <![CDATA[Set the reservation id, that correspond to a valid resource allocation in
+ the scheduler (between start and end time of the corresponding reservation)
+ 
+ @param reservationID representing the unique id of the
+          corresponding reserved resource allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="getApplicationTimeouts" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>ApplicationTimeouts</code> of the application. Timeout value is
+ in seconds.
+ @return all <code>ApplicationTimeouts</code> of the application.]]>
+      </doc>
+    </method>
+    <method name="setApplicationTimeouts"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTimeouts" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationTimeouts</code> for the application in seconds.
+ All pre-existing Map entries are cleared before adding the new Map.
+ <p>
+ <b>Note:</b> If application timeout value is less than or equal to zero
+ then application submission will throw an exception.
+ </p>
+ @param applicationTimeouts <code>ApplicationTimeouts</code>s for the
+          application]]>
+      </doc>
+    </method>
+    <method name="getApplicationSchedulingPropertiesMap" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get application scheduling environment variables stored as a key value
+ pair map for application.
+
+ @return placement envs for application.]]>
+      </doc>
+    </method>
+    <method name="setApplicationSchedulingPropertiesMap"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="schedulingEnvMap" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the scheduling envs for the application.
+
+ @param schedulingEnvMap
+          A map of env's for the application scheduling preferences.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ApplicationSubmissionContext} represents all of the
+ information needed by the {@code ResourceManager} to launch
+ the {@code ApplicationMaster} for an application.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link ApplicationId} of the application.</li>
+   <li>Application user.</li>
+   <li>Application name.</li>
+   <li>{@link Priority} of the application.</li>
+   <li>
+     {@link ContainerLaunchContext} of the container in which the
+     <code>ApplicationMaster</code> is executed.
+   </li>
+   <li>
+     maxAppAttempts. The maximum number of application attempts.
+     It should be no larger than the global number of max attempts in the
+     YARN configuration.
+   </li>
+   <li>
+     attemptFailuresValidityInterval. The default value is -1.
+     when attemptFailuresValidityInterval in milliseconds is set to
+     {@literal >} 0, the failure number will no take failures which happen
+     out of the validityInterval into failure count. If failure count
+     reaches to maxAppAttempts, the application will be failed.
+   </li>
+   <li>Optional, application-specific {@link LogAggregationContext}</li>
+ </ul>
+ 
+ @see ContainerLaunchContext
+ @see ApplicationClientProtocol#submitApplication(org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationTimeout -->
+  <class name="ApplicationTimeout" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationTimeout"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ApplicationTimeout"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="org.apache.hadoop.yarn.api.records.ApplicationTimeoutType"/>
+      <param name="expiryTime" type="java.lang.String"/>
+      <param name="remainingTime" type="long"/>
+    </method>
+    <method name="getTimeoutType" return="org.apache.hadoop.yarn.api.records.ApplicationTimeoutType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the application timeout type.
+ @return timeoutType of an application timeout.]]>
+      </doc>
+    </method>
+    <method name="setTimeoutType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timeoutType" type="org.apache.hadoop.yarn.api.records.ApplicationTimeoutType"/>
+      <doc>
+      <![CDATA[Set the application timeout type.
+ @param timeoutType of an application timeout.]]>
+      </doc>
+    </method>
+    <method name="getExpiryTime" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>expiryTime</code> for given timeout type.
+ @return expiryTime in ISO8601 standard with format
+         <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>.]]>
+      </doc>
+    </method>
+    <method name="setExpiryTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="expiryTime" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set <code>expiryTime</code> for given timeout type.
+ @param expiryTime in ISO8601 standard with format
+          <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b>.]]>
+      </doc>
+    </method>
+    <method name="getRemainingTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>Remaining Time</code> of an application for given timeout type.
+ @return Remaining Time in seconds.]]>
+      </doc>
+    </method>
+    <method name="setRemainingTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="remainingTime" type="long"/>
+      <doc>
+      <![CDATA[Set <code>Remaining Time</code> of an application for given timeout type.
+ @param remainingTime in seconds.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ApplicationTimeout} is a report for configured application timeouts.
+ It includes details such as:
+ <ul>
+ <li>{@link ApplicationTimeoutType} of the timeout type.</li>
+ <li>Expiry time in ISO8601 standard with format
+ <b>yyyy-MM-dd'T'HH:mm:ss.SSSZ</b> or "UNLIMITED".</li>
+ <li>Remaining time in seconds.</li>
+ </ul>
+ The possible values for {ExpiryTime, RemainingTimeInSeconds} are
+ <ul>
+ <li>{UNLIMITED,-1} : Timeout is not configured for given timeout type
+ (LIFETIME).</li>
+ <li>{ISO8601 date string, 0} : Timeout is configured and application has
+ completed.</li>
+ <li>{ISO8601 date string, greater than zero} : Timeout is configured and
+ application is RUNNING. Application will be timed out after configured
+ value.</li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationTimeout -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ApplicationTimeoutType -->
+  <class name="ApplicationTimeoutType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ApplicationTimeoutType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ApplicationTimeoutType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Application timeout type.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ApplicationTimeoutType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.CollectorInfo -->
+  <class name="CollectorInfo" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="CollectorInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.CollectorInfo"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="collectorAddr" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.CollectorInfo"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="collectorAddr" type="java.lang.String"/>
+      <param name="token" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <method name="getCollectorAddr" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setCollectorAddr"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="addr" type="java.lang.String"/>
+    </method>
+    <method name="getCollectorToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get delegation token for app collector which AM will use to publish
+ entities.
+ @return the delegation token for app collector.]]>
+      </doc>
+    </method>
+    <method name="setCollectorToken"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="token" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <field name="DEFAULT_TIMESTAMP_VALUE" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Collector info containing collector address and collector token passed from
+ RM to AM in Allocate Response.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.CollectorInfo -->
+  <!-- start class org.apache.hadoop.yarn.api.records.Container -->
+  <class name="Container" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="Container"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the globally unique identifier for the container.
+ @return globally unique identifier for the container]]>
+      </doc>
+    </method>
+    <method name="getNodeId" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the identifier of the node on which the container is allocated.
+ @return identifier of the node on which the container is allocated]]>
+      </doc>
+    </method>
+    <method name="getNodeHttpAddress" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the http uri of the node on which the container is allocated.
+ @return http uri of the node on which the container is allocated]]>
+      </doc>
+    </method>
+    <method name="getResource" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Resource</code> allocated to the container.
+ @return <code>Resource</code> allocated to the container]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Priority</code> at which the <code>Container</code> was
+ allocated.
+ @return <code>Priority</code> at which the <code>Container</code> was
+         allocated]]>
+      </doc>
+    </method>
+    <method name="getContainerToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerToken</code> for the container.
+ <p><code>ContainerToken</code> is the security token used by the framework
+ to verify authenticity of any <code>Container</code>.</p>
+
+ <p>The <code>ResourceManager</code>, on container allocation provides a
+ secure token which is verified by the <code>NodeManager</code> on
+ container launch.</p>
+
+ <p>Applications do not need to care about <code>ContainerToken</code>, they
+ are transparently handled by the framework - the allocated
+ <code>Container</code> includes the <code>ContainerToken</code>.</p>
+
+ @see ApplicationMasterProtocol#allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)
+ @see ContainerManagementProtocol#startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)
+
+ @return <code>ContainerToken</code> for the container]]>
+      </doc>
+    </method>
+    <method name="getAllocationRequestId" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the optional <em>ID</em> corresponding to the original {@code
+ ResourceRequest{@link #getAllocationRequestId()}}s which is satisfied by
+ this allocated {@code Container}.
+ <p>
+ The scheduler may return multiple {@code AllocateResponse}s corresponding
+ to the same ID as and when scheduler allocates {@code Container}s.
+ <b>Applications</b> can continue to completely ignore the returned ID in
+ the response and use the allocation for any of their outstanding requests.
+ <p>
+
+ @return the <em>ID</em> corresponding to the original  allocation request
+ which is satisfied by this allocation.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code Container} represents an allocated resource in the cluster.
+ <p>
+ The {@code ResourceManager} is the sole authority to allocate any
+ {@code Container} to applications. The allocated {@code Container}
+ is always on a single node and has a unique {@link ContainerId}. It has
+ a specific amount of {@link Resource} allocated.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link ContainerId} for the container, which is globally unique.</li>
+   <li>
+     {@link NodeId} of the node on which it is allocated.
+   </li>
+   <li>HTTP uri of the node.</li>
+   <li>{@link Resource} allocated to the container.</li>
+   <li>{@link Priority} at which the container was allocated.</li>
+   <li>
+     Container {@link Token} of the container, used to securely verify
+     authenticity of the allocation.
+   </li>
+ </ul>
+ 
+ Typically, an {@code ApplicationMaster} receives the {@code Container}
+ from the {@code ResourceManager} during resource-negotiation and then
+ talks to the {@code NodeManager} to start/stop containers.
+ 
+ @see ApplicationMasterProtocol#allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)
+ @see ContainerManagementProtocol#startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)
+ @see ContainerManagementProtocol#stopContainers(org.apache.hadoop.yarn.api.protocolrecords.StopContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.Container -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerExitStatus -->
+  <class name="ContainerExitStatus" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerExitStatus"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <field name="SUCCESS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="INVALID" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ABORTED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Containers killed by the framework, either due to being released by
+ the application or being 'lost' due to node failures etc.]]>
+      </doc>
+    </field>
+    <field name="DISKS_FAILED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[When threshold number of the nodemanager-local-directories or
+ threshold number of the nodemanager-log-directories become bad.]]>
+      </doc>
+    </field>
+    <field name="PREEMPTED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Containers preempted by the framework.]]>
+      </doc>
+    </field>
+    <field name="KILLED_EXCEEDED_VMEM" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container terminated because of exceeding allocated virtual memory.]]>
+      </doc>
+    </field>
+    <field name="KILLED_EXCEEDED_PMEM" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container terminated because of exceeding allocated physical memory.]]>
+      </doc>
+    </field>
+    <field name="KILLED_BY_APPMASTER" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container was terminated by stop request by the app master.]]>
+      </doc>
+    </field>
+    <field name="KILLED_BY_RESOURCEMANAGER" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container was terminated by the resource manager.]]>
+      </doc>
+    </field>
+    <field name="KILLED_AFTER_APP_COMPLETION" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container was terminated after the application finished.]]>
+      </doc>
+    </field>
+    <field name="KILLED_BY_CONTAINER_SCHEDULER" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container was terminated by the ContainerScheduler to make room
+ for another container...]]>
+      </doc>
+    </field>
+    <field name="KILLED_FOR_EXCESS_LOGS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container was terminated for generating excess log data.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[Container exit statuses indicating special exit circumstances.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerExitStatus -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerId -->
+  <class name="ContainerId" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ContainerId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="containerId" type="long"/>
+    </method>
+    <method name="getApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationAttemptId</code> of the application to which the
+ <code>Container</code> was assigned.
+ <p>
+ Note: If containers are kept alive across application attempts via
+ {@link ApplicationSubmissionContext#setKeepContainersAcrossApplicationAttempts(boolean)}
+ the <code>ContainerId</code> does not necessarily contain the current
+ running application attempt's <code>ApplicationAttemptId</code> This
+ container can be allocated by previously exited application attempt and
+ managed by the current running attempt thus have the previous application
+ attempt's <code>ApplicationAttemptId</code>.
+ </p>
+ 
+ @return <code>ApplicationAttemptId</code> of the application to which the
+         <code>Container</code> was assigned]]>
+      </doc>
+    </method>
+    <method name="getId" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the lower 32 bits of identifier of the <code>ContainerId</code>,
+ which doesn't include epoch. Note that this method will be marked as
+ deprecated, so please use <code>getContainerId</code> instead.
+ @return lower 32 bits of identifier of the <code>ContainerId</code>]]>
+      </doc>
+    </method>
+    <method name="getContainerId" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the identifier of the <code>ContainerId</code>. Upper 24 bits are
+ reserved as epoch of cluster, and lower 40 bits are reserved as
+ sequential number of containers.
+ @return identifier of the <code>ContainerId</code>]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return A string representation of containerId. The format is
+ container_e*epoch*_*clusterTimestamp*_*appId*_*attemptId*_*containerId*
+ when epoch is larger than 0
+ (e.g. container_e17_1410901177871_0001_01_000005).
+ *epoch* is increased when RM restarts or fails over.
+ When epoch is 0, epoch is omitted
+ (e.g. container_1410901177871_0001_01_000005).]]>
+      </doc>
+    </method>
+    <method name="fromString" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerIdStr" type="java.lang.String"/>
+    </method>
+    <method name="build"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <field name="CONTAINER_ID_BITMASK" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p><code>ContainerId</code> represents a globally unique identifier
+ for a {@link Container} in the cluster.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerId -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerLaunchContext -->
+  <class name="ContainerLaunchContext" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerLaunchContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="localResources" type="java.util.Map"/>
+      <param name="environment" type="java.util.Map"/>
+      <param name="commands" type="java.util.List"/>
+      <param name="serviceData" type="java.util.Map"/>
+      <param name="tokens" type="java.nio.ByteBuffer"/>
+      <param name="acls" type="java.util.Map"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="localResources" type="java.util.Map"/>
+      <param name="environment" type="java.util.Map"/>
+      <param name="commands" type="java.util.List"/>
+      <param name="serviceData" type="java.util.Map"/>
+      <param name="tokens" type="java.nio.ByteBuffer"/>
+      <param name="acls" type="java.util.Map"/>
+      <param name="containerRetryContext" type="org.apache.hadoop.yarn.api.records.ContainerRetryContext"/>
+    </method>
+    <method name="getTokens" return="java.nio.ByteBuffer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get all the tokens needed by this container. It may include file-system
+ tokens, ApplicationMaster related tokens if this container is an
+ ApplicationMaster or framework level tokens needed by this container to
+ communicate to various services in a secure manner.
+ 
+ @return tokens needed by this container.]]>
+      </doc>
+    </method>
+    <method name="setTokens"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="tokens" type="java.nio.ByteBuffer"/>
+      <doc>
+      <![CDATA[Set security tokens needed by this container.
+ @param tokens security tokens]]>
+      </doc>
+    </method>
+    <method name="getTokensConf" return="java.nio.ByteBuffer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the configuration used by RM to renew tokens.
+ @return The configuration used by RM to renew the tokens.]]>
+      </doc>
+    </method>
+    <method name="setTokensConf"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="tokensConf" type="java.nio.ByteBuffer"/>
+      <doc>
+      <![CDATA[Set the configuration used by RM to renew the tokens.
+ @param tokensConf The configuration used by RM to renew the tokens]]>
+      </doc>
+    </method>
+    <method name="getLocalResources" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>LocalResource</code> required by the container.
+ @return all <code>LocalResource</code> required by the container]]>
+      </doc>
+    </method>
+    <method name="setLocalResources"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="localResources" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set <code>LocalResource</code> required by the container. All pre-existing
+ Map entries are cleared before adding the new Map
+ @param localResources <code>LocalResource</code> required by the container]]>
+      </doc>
+    </method>
+    <method name="getServiceData" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>
+ Get application-specific binary <em>service data</em>. This is a map keyed
+ by the name of each {@link AuxiliaryService} that is configured on a
+ NodeManager and value correspond to the application specific data targeted
+ for the keyed {@link AuxiliaryService}.
+ </p>
+ 
+ <p>
+ This will be used to initialize this application on the specific
+ {@link AuxiliaryService} running on the NodeManager by calling
+ {@link AuxiliaryService#initializeApplication(ApplicationInitializationContext)}
+ </p>
+ 
+ @return application-specific binary <em>service data</em>]]>
+      </doc>
+    </method>
+    <method name="setServiceData"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="serviceData" type="java.util.Map"/>
+      <doc>
+      <![CDATA[<p>
+ Set application-specific binary <em>service data</em>. This is a map keyed
+ by the name of each {@link AuxiliaryService} that is configured on a
+ NodeManager and value correspond to the application specific data targeted
+ for the keyed {@link AuxiliaryService}. All pre-existing Map entries are
+ preserved.
+ </p>
+ 
+ @param serviceData
+          application-specific binary <em>service data</em>]]>
+      </doc>
+    </method>
+    <method name="getEnvironment" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>environment variables</em> for the container.
+ @return <em>environment variables</em> for the container]]>
+      </doc>
+    </method>
+    <method name="setEnvironment"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="environment" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Add <em>environment variables</em> for the container. All pre-existing Map
+ entries are cleared before adding the new Map
+ @param environment <em>environment variables</em> for the container]]>
+      </doc>
+    </method>
+    <method name="getCommands" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <em>commands</em> for launching the container.
+ @return the list of <em>commands</em> for launching the container]]>
+      </doc>
+    </method>
+    <method name="setCommands"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="commands" type="java.util.List"/>
+      <doc>
+      <![CDATA[Add the list of <em>commands</em> for launching the container. All
+ pre-existing List entries are cleared before adding the new List
+ @param commands the list of <em>commands</em> for launching the container]]>
+      </doc>
+    </method>
+    <method name="getApplicationACLs" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationACL</code>s for the application. 
+ @return all the <code>ApplicationACL</code>s]]>
+      </doc>
+    </method>
+    <method name="setApplicationACLs"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="acls" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the <code>ApplicationACL</code>s for the application. All pre-existing
+ Map entries are cleared before adding the new Map
+ @param acls <code>ApplicationACL</code>s for the application]]>
+      </doc>
+    </method>
+    <method name="getContainerRetryContext" return="org.apache.hadoop.yarn.api.records.ContainerRetryContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerRetryContext</code> to relaunch container.
+ @return <code>ContainerRetryContext</code> to relaunch container.]]>
+      </doc>
+    </method>
+    <method name="setContainerRetryContext"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerRetryContext" type="org.apache.hadoop.yarn.api.records.ContainerRetryContext"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerRetryContext</code> to relaunch container.
+ @param containerRetryContext <code>ContainerRetryContext</code> to
+                              relaunch container.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ContainerLaunchContext} represents all of the information
+ needed by the {@code NodeManager} to launch a container.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link ContainerId} of the container.</li>
+   <li>{@link Resource} allocated to the container.</li>
+   <li>User to whom the container is allocated.</li>
+   <li>Security tokens (if security is enabled).</li>
+   <li>
+     {@link LocalResource} necessary for running the container such
+     as binaries, jar, shared-objects, side-files etc.
+   </li>
+   <li>Optional, application-specific binary service data.</li>
+   <li>Environment variables for the launched process.</li>
+   <li>Command to launch the container.</li>
+   <li>Retry strategy when container exits with failure.</li>
+ </ul>
+ 
+ @see ContainerManagementProtocol#startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerLaunchContext -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerReport -->
+  <class name="ContainerReport" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container.
+ 
+ @return <code>ContainerId</code> of the container.]]>
+      </doc>
+    </method>
+    <method name="setContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+    </method>
+    <method name="getAllocatedResource" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the allocated <code>Resource</code> of the container.
+ 
+ @return allocated <code>Resource</code> of the container.]]>
+      </doc>
+    </method>
+    <method name="setAllocatedResource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="getAssignedNode" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the allocated <code>NodeId</code> where container is running.
+ 
+ @return allocated <code>NodeId</code> where container is running.]]>
+      </doc>
+    </method>
+    <method name="setAssignedNode"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the allocated <code>Priority</code> of the container.
+ 
+ @return allocated <code>Priority</code> of the container.]]>
+      </doc>
+    </method>
+    <method name="setPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+    </method>
+    <method name="getCreationTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the creation time of the container.
+ 
+ @return creation time of the container]]>
+      </doc>
+    </method>
+    <method name="setCreationTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="creationTime" type="long"/>
+    </method>
+    <method name="getFinishTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the Finish time of the container.
+ 
+ @return Finish time of the container]]>
+      </doc>
+    </method>
+    <method name="setFinishTime"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="finishTime" type="long"/>
+    </method>
+    <method name="getDiagnosticsInfo" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the DiagnosticsInfo of the container.
+ 
+ @return DiagnosticsInfo of the container]]>
+      </doc>
+    </method>
+    <method name="setDiagnosticsInfo"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="diagnosticsInfo" type="java.lang.String"/>
+    </method>
+    <method name="getLogUrl" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the LogURL of the container.
+ 
+ @return LogURL of the container]]>
+      </doc>
+    </method>
+    <method name="setLogUrl"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logUrl" type="java.lang.String"/>
+    </method>
+    <method name="getContainerState" return="org.apache.hadoop.yarn.api.records.ContainerState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the final <code>ContainerState</code> of the container.
+ 
+ @return final <code>ContainerState</code> of the container.]]>
+      </doc>
+    </method>
+    <method name="setContainerState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerState" type="org.apache.hadoop.yarn.api.records.ContainerState"/>
+    </method>
+    <method name="getContainerExitStatus" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the final <code>exit status</code> of the container.
+ 
+ @return final <code>exit status</code> of the container.]]>
+      </doc>
+    </method>
+    <method name="setContainerExitStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerExitStatus" type="int"/>
+    </method>
+    <method name="getNodeHttpAddress" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the Node Http address of the container
+ 
+ @return the node http address of the container]]>
+      </doc>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the execution type of the container.
+
+ @return the execution type of the container]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ContainerReport} is a report of an container.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link ContainerId} of the container.</li>
+   <li>Allocated Resources to the container.</li>
+   <li>Assigned Node id.</li>
+   <li>Assigned Priority.</li>
+   <li>Creation Time.</li>
+   <li>Finish Time.</li>
+   <li>Container Exit Status.</li>
+   <li>{@link ContainerState} of the container.</li>
+   <li>Diagnostic information in case of errors.</li>
+   <li>Log URL.</li>
+   <li>nodeHttpAddress</li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerReport -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerRetryContext -->
+  <class name="ContainerRetryContext" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerRetryContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRetryPolicy" return="org.apache.hadoop.yarn.api.records.ContainerRetryPolicy"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setRetryPolicy"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="retryPolicy" type="org.apache.hadoop.yarn.api.records.ContainerRetryPolicy"/>
+    </method>
+    <method name="getErrorCodes" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setErrorCodes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="errorCodes" type="java.util.Set"/>
+    </method>
+    <method name="getMaxRetries" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setMaxRetries"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="maxRetries" type="int"/>
+    </method>
+    <method name="getRetryInterval" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setRetryInterval"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="retryInterval" type="int"/>
+    </method>
+    <method name="getFailuresValidityInterval" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setFailuresValidityInterval"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="failuresValidityInterval" type="long"/>
+    </method>
+    <field name="RETRY_FOREVER" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RETRY_INVALID" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NEVER_RETRY_CONTEXT" type="org.apache.hadoop.yarn.api.records.ContainerRetryContext"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[{@code ContainerRetryContext} indicates how container retry after it fails
+ to run.
+ <p>
+ It provides details such as:
+ <ul>
+   <li>
+     {@link ContainerRetryPolicy} :
+     - NEVER_RETRY(DEFAULT value): no matter what error code is when container
+       fails to run, just do not retry.
+     - RETRY_ON_ALL_ERRORS: no matter what error code is, when container fails
+       to run, just retry.
+     - RETRY_ON_SPECIFIC_ERROR_CODES: when container fails to run, do retry if
+       the error code is one of <em>errorCodes</em>, otherwise do not retry.
+
+     Note: if error code is 137(SIGKILL) or 143(SIGTERM), it will not retry
+     because it is usually killed on purpose.
+   </li>
+   <li>
+     <em>maxRetries</em> specifies how many times to retry if need to retry.
+     If the value is -1, it means retry forever.
+   </li>
+   <li><em>retryInterval</em> specifies delaying some time before relaunch
+   container, the unit is millisecond.</li>
+   <li>
+     <em>failuresValidityInterval</em>: default value is -1.
+     When failuresValidityInterval in milliseconds is set to {@literal >} 0,
+     the failure number will not take failures which happen out of the
+     failuresValidityInterval into failure count. If failure count
+     reaches to <em>maxRetries</em>, the container will be failed.
+   </li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerRetryContext -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerRetryPolicy -->
+  <class name="ContainerRetryPolicy" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ContainerRetryPolicy[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ContainerRetryPolicy"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[<p>Retry policy for relaunching a <code>Container</code>.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerRetryPolicy -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerState -->
+  <class name="ContainerState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ContainerState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ContainerState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[<p>State of a <code>Container</code>.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerStatus -->
+  <class name="ContainerStatus" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerStatus"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container.
+ @return <code>ContainerId</code> of the container]]>
+      </doc>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ExecutionType</code> of the container.
+ @return <code>ExecutionType</code> of the container]]>
+      </doc>
+    </method>
+    <method name="getState" return="org.apache.hadoop.yarn.api.records.ContainerState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerState</code> of the container.
+ @return <code>ContainerState</code> of the container]]>
+      </doc>
+    </method>
+    <method name="getExitStatus" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>Get the <em>exit status</em> for the container.</p>
+  
+ <p>Note: This is valid only for completed containers i.e. containers
+ with state {@link ContainerState#COMPLETE}. 
+ Otherwise, it returns an ContainerExitStatus.INVALID.
+ </p>
+ 
+ <p>Containers killed by the framework, either due to being released by
+ the application or being 'lost' due to node failures etc. have a special
+ exit code of ContainerExitStatus.ABORTED.</p>
+ 
+ <p>When threshold number of the nodemanager-local-directories or
+ threshold number of the nodemanager-log-directories become bad, then
+ container is not launched and is exited with ContainersExitStatus.DISKS_FAILED.
+ </p>
+  
+ @return <em>exit status</em> for the container]]>
+      </doc>
+    </method>
+    <method name="getDiagnostics" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>diagnostic messages</em> for failed containers.
+ @return <em>diagnostic messages</em> for failed containers]]>
+      </doc>
+    </method>
+    <method name="getCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Resource</code> allocated to the container.
+ @return <code>Resource</code> allocated to the container]]>
+      </doc>
+    </method>
+    <method name="getIPs" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get all the IP addresses with which the container run.
+ @return The IP address where the container runs.]]>
+      </doc>
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the hostname where the container runs.
+ @return The hostname where the container runs.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ContainerStatus} represents the current status of a
+ {@code Container}.
+ <p>
+ It provides details such as:
+ <ul>
+   <li>{@code ContainerId} of the container.</li>
+   <li>{@code ExecutionType} of the container.</li>
+   <li>{@code ContainerState} of the container.</li>
+   <li><em>Exit status</em> of a completed container.</li>
+   <li><em>Diagnostic</em> message for a failed container.</li>
+   <li>{@link Resource} allocated to the container.</li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerStatus -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerSubState -->
+  <class name="ContainerSubState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ContainerSubState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ContainerSubState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Container Sub-State.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerSubState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ContainerUpdateType -->
+  <class name="ContainerUpdateType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ContainerUpdateType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ContainerUpdateType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Encodes the type of Container Update.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ContainerUpdateType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ExecutionType -->
+  <class name="ExecutionType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ExecutionType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Container property encoding execution semantics.
+
+ <p>
+ The execution types are the following:
+ <ul>
+   <li>{@link #GUARANTEED} - this container is guaranteed to start its
+   execution, once the corresponding start container request is received by
+   an NM.
+   <li>{@link #OPPORTUNISTIC} - the execution of this container may not start
+   immediately at the NM that receives the corresponding start container
+   request (depending on the NM's available resources). Moreover, it may be
+   preempted if it blocks a GUARANTEED container from being executed.
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ExecutionType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ExecutionTypeRequest -->
+  <class name="ExecutionTypeRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ExecutionTypeRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="execType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="execType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <param name="ensureExecutionType" type="boolean"/>
+    </method>
+    <method name="setExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="execType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <doc>
+      <![CDATA[Set the <code>ExecutionType</code> of the requested container.
+
+ @param execType
+          ExecutionType of the requested container]]>
+      </doc>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <code>ExecutionType</code>.
+
+ @return <code>ExecutionType</code>.]]>
+      </doc>
+    </method>
+    <method name="setEnforceExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="enforceExecutionType" type="boolean"/>
+      <doc>
+      <![CDATA[Set to true to explicitly ask that the Scheduling Authority return
+ Containers of exactly the Execution Type requested.
+ @param enforceExecutionType whether ExecutionType request should be
+                            strictly honored.]]>
+      </doc>
+    </method>
+    <method name="getEnforceExecutionType" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether Scheduling Authority should return Containers of exactly the
+ Execution Type requested for this <code>ResourceRequest</code>.
+ Defaults to false.
+ @return whether ExecutionType request should be strictly honored]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[An object of this class represents a specification of the execution
+ guarantee of the Containers associated with a ResourceRequest. It consists
+ of an <code>ExecutionType</code> as well as flag that explicitly asks the
+ configuredScheduler to return Containers of exactly the Execution Type
+ requested.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ExecutionTypeRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.FinalApplicationStatus -->
+  <class name="FinalApplicationStatus" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.FinalApplicationStatus[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of various final states of an <code>Application</code>.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.FinalApplicationStatus -->
+  <!-- start class org.apache.hadoop.yarn.api.records.LocalResource -->
+  <class name="LocalResource" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LocalResource"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LocalResource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="url" type="org.apache.hadoop.yarn.api.records.URL"/>
+      <param name="type" type="org.apache.hadoop.yarn.api.records.LocalResourceType"/>
+      <param name="visibility" type="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"/>
+      <param name="size" type="long"/>
+      <param name="timestamp" type="long"/>
+      <param name="pattern" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LocalResource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="url" type="org.apache.hadoop.yarn.api.records.URL"/>
+      <param name="type" type="org.apache.hadoop.yarn.api.records.LocalResourceType"/>
+      <param name="visibility" type="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"/>
+      <param name="size" type="long"/>
+      <param name="timestamp" type="long"/>
+      <param name="pattern" type="java.lang.String"/>
+      <param name="shouldBeUploadedToSharedCache" type="boolean"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LocalResource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="url" type="org.apache.hadoop.yarn.api.records.URL"/>
+      <param name="type" type="org.apache.hadoop.yarn.api.records.LocalResourceType"/>
+      <param name="visibility" type="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"/>
+      <param name="size" type="long"/>
+      <param name="timestamp" type="long"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LocalResource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="url" type="org.apache.hadoop.yarn.api.records.URL"/>
+      <param name="type" type="org.apache.hadoop.yarn.api.records.LocalResourceType"/>
+      <param name="visibility" type="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"/>
+      <param name="size" type="long"/>
+      <param name="timestamp" type="long"/>
+      <param name="shouldBeUploadedToSharedCache" type="boolean"/>
+    </method>
+    <method name="getResource" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>location</em> of the resource to be localized.
+ @return <em>location</em> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="setResource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.URL"/>
+      <doc>
+      <![CDATA[Set <em>location</em> of the resource to be localized.
+ @param resource <em>location</em> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="getSize" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>size</em> of the resource to be localized.
+ @return <em>size</em> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="setSize"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="size" type="long"/>
+      <doc>
+      <![CDATA[Set the <em>size</em> of the resource to be localized.
+ @param size <em>size</em> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="getTimestamp" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the original <em>timestamp</em> of the resource to be localized, used
+ for verification.
+ @return <em>timestamp</em> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="setTimestamp"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timestamp" type="long"/>
+      <doc>
+      <![CDATA[Set the <em>timestamp</em> of the resource to be localized, used
+ for verification.
+ @param timestamp <em>timestamp</em> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="getType" return="org.apache.hadoop.yarn.api.records.LocalResourceType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>LocalResourceType</code> of the resource to be localized.
+ @return <code>LocalResourceType</code> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="setType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="org.apache.hadoop.yarn.api.records.LocalResourceType"/>
+      <doc>
+      <![CDATA[Set the <code>LocalResourceType</code> of the resource to be localized.
+ @param type <code>LocalResourceType</code> of the resource to be localized]]>
+      </doc>
+    </method>
+    <method name="getVisibility" return="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>LocalResourceVisibility</code> of the resource to be 
+ localized.
+ @return <code>LocalResourceVisibility</code> of the resource to be 
+         localized]]>
+      </doc>
+    </method>
+    <method name="setVisibility"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="visibility" type="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"/>
+      <doc>
+      <![CDATA[Set the <code>LocalResourceVisibility</code> of the resource to be 
+ localized.
+ @param visibility <code>LocalResourceVisibility</code> of the resource to be 
+                   localized]]>
+      </doc>
+    </method>
+    <method name="getPattern" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>pattern</em> that should be used to extract entries from the
+ archive (only used when type is <code>PATTERN</code>).
+ @return <em>pattern</em> that should be used to extract entries from the 
+ archive.]]>
+      </doc>
+    </method>
+    <method name="setPattern"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pattern" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <em>pattern</em> that should be used to extract entries from the
+ archive (only used when type is <code>PATTERN</code>).
+ @param pattern <em>pattern</em> that should be used to extract entries 
+ from the archive.]]>
+      </doc>
+    </method>
+    <method name="getShouldBeUploadedToSharedCache" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[NM uses it to decide whether if it is necessary to upload the resource to
+ the shared cache
+ @return true if it is necessary to upload the resource
+                 to the shared cache,
+         false otherwise]]>
+      </doc>
+    </method>
+    <method name="setShouldBeUploadedToSharedCache"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="shouldBeUploadedToSharedCache" type="boolean"/>
+      <doc>
+      <![CDATA[Inform NM whether upload to SCM is needed.
+
+ @param shouldBeUploadedToSharedCache <em>shouldBeUploadedToSharedCache</em>
+          of this request]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p><code>LocalResource</code> represents a local resource required to
+ run a container.</p>
+ 
+ <p>The <code>NodeManager</code> is responsible for localizing the resource 
+ prior to launching the container.</p>
+ 
+ <p>Applications can specify {@link LocalResourceType} and 
+ {@link LocalResourceVisibility}.</p>
+ 
+ @see LocalResourceType
+ @see LocalResourceVisibility
+ @see ContainerLaunchContext
+ @see ApplicationSubmissionContext
+ @see ContainerManagementProtocol#startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.LocalResource -->
+  <!-- start class org.apache.hadoop.yarn.api.records.LocalResourceType -->
+  <class name="LocalResourceType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.LocalResourceType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.LocalResourceType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[{@code LocalResourceType} specifies the <em>type</em>
+ of a resource localized by the {@code NodeManager}.
+ <p>
+ The <em>type</em> can be one of:
+ <ul>
+   <li>
+     {@link #FILE} - Regular file i.e. uninterpreted bytes.
+   </li>
+   <li>
+     {@link #ARCHIVE} - Archive, which is automatically unarchived by the
+     <code>NodeManager</code>.
+   </li>
+   <li>
+     {@link #PATTERN} - A hybrid between {@link #ARCHIVE} and {@link #FILE}.
+   </li>
+ </ul>
+
+ @see LocalResource
+ @see ContainerLaunchContext
+ @see ApplicationSubmissionContext
+ @see ContainerManagementProtocol#startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.LocalResourceType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.LocalResourceVisibility -->
+  <class name="LocalResourceVisibility" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.LocalResourceVisibility[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.LocalResourceVisibility"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[{@code LocalResourceVisibility} specifies the <em>visibility</em>
+ of a resource localized by the {@code NodeManager}.
+ <p>
+ The <em>visibility</em> can be one of:
+ <ul>
+   <li>{@link #PUBLIC} - Shared by all users on the node.</li>
+   <li>
+     {@link #PRIVATE} - Shared among all applications of the
+     <em>same user</em> on the node.
+   </li>
+   <li>
+     {@link #APPLICATION} - Shared only among containers of the
+     <em>same application</em> on the node.
+   </li>
+ </ul>
+ 
+ @see LocalResource
+ @see ContainerLaunchContext
+ @see ApplicationSubmissionContext
+ @see ContainerManagementProtocol#startContainers(org.apache.hadoop.yarn.api.protocolrecords.StartContainersRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.LocalResourceVisibility -->
+  <!-- start class org.apache.hadoop.yarn.api.records.LogAggregationContext -->
+  <class name="LogAggregationContext" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LogAggregationContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LogAggregationContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includePattern" type="java.lang.String"/>
+      <param name="excludePattern" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LogAggregationContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includePattern" type="java.lang.String"/>
+      <param name="excludePattern" type="java.lang.String"/>
+      <param name="rolledLogsIncludePattern" type="java.lang.String"/>
+      <param name="rolledLogsExcludePattern" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.LogAggregationContext"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includePattern" type="java.lang.String"/>
+      <param name="excludePattern" type="java.lang.String"/>
+      <param name="rolledLogsIncludePattern" type="java.lang.String"/>
+      <param name="rolledLogsExcludePattern" type="java.lang.String"/>
+      <param name="policyClassName" type="java.lang.String"/>
+      <param name="policyParameters" type="java.lang.String"/>
+    </method>
+    <method name="getIncludePattern" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get include pattern. This includePattern only takes affect
+ on logs that exist at the time of application finish.
+
+ @return include pattern]]>
+      </doc>
+    </method>
+    <method name="setIncludePattern"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="includePattern" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set include pattern. This includePattern only takes affect
+ on logs that exist at the time of application finish.
+
+ @param includePattern]]>
+      </doc>
+    </method>
+    <method name="getExcludePattern" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get exclude pattern. This excludePattern only takes affect
+ on logs that exist at the time of application finish.
+
+ @return exclude pattern]]>
+      </doc>
+    </method>
+    <method name="setExcludePattern"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="excludePattern" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set exclude pattern. This excludePattern only takes affect
+ on logs that exist at the time of application finish.
+
+ @param excludePattern]]>
+      </doc>
+    </method>
+    <method name="getRolledLogsIncludePattern" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get include pattern in a rolling fashion.
+ 
+ @return include pattern]]>
+      </doc>
+    </method>
+    <method name="setRolledLogsIncludePattern"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rolledLogsIncludePattern" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set include pattern in a rolling fashion.
+ 
+ @param rolledLogsIncludePattern]]>
+      </doc>
+    </method>
+    <method name="getRolledLogsExcludePattern" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get exclude pattern for aggregation in a rolling fashion.
+ 
+ @return exclude pattern]]>
+      </doc>
+    </method>
+    <method name="setRolledLogsExcludePattern"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rolledLogsExcludePattern" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set exclude pattern for in a rolling fashion.
+ 
+ @param rolledLogsExcludePattern]]>
+      </doc>
+    </method>
+    <method name="getLogAggregationPolicyClassName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the log aggregation policy class.
+
+ @return log aggregation policy class]]>
+      </doc>
+    </method>
+    <method name="setLogAggregationPolicyClassName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="className" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the log aggregation policy class.
+
+ @param className]]>
+      </doc>
+    </method>
+    <method name="getLogAggregationPolicyParameters" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the log aggregation policy parameters.
+
+ @return log aggregation policy parameters]]>
+      </doc>
+    </method>
+    <method name="setLogAggregationPolicyParameters"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="parameters" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the log aggregation policy parameters.
+ There is no schema defined for the parameters string.
+ It is up to the log aggregation policy class to decide how to parse
+ the parameters string.
+
+ @param parameters]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code LogAggregationContext} represents all of the
+ information needed by the {@code NodeManager} to handle
+ the logs for an application.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>
+     includePattern. It uses Java Regex to filter the log files
+     which match the defined include pattern and those log files
+     will be uploaded when the application finishes.
+   </li>
+   <li>
+     excludePattern. It uses Java Regex to filter the log files
+     which match the defined exclude pattern and those log files
+     will not be uploaded when application finishes. If the log file
+     name matches both the include and the exclude pattern, this file
+     will be excluded eventually.
+   </li>
+   <li>
+     rolledLogsIncludePattern. It uses Java Regex to filter the log files
+     which match the defined include pattern and those log files
+     will be aggregated in a rolling fashion.
+   </li>
+   <li>
+     rolledLogsExcludePattern. It uses Java Regex to filter the log files
+     which match the defined exclude pattern and those log files
+     will not be aggregated in a rolling fashion. If the log file
+     name matches both the include and the exclude pattern, this file
+     will be excluded eventually.
+   </li>
+   <li>
+     policyClassName. The policy class name that implements
+     ContainerLogAggregationPolicy. At runtime, nodemanager will the policy
+     if a given container's log should be aggregated based on the
+     ContainerType and other runtime state such as exit code by calling
+     ContainerLogAggregationPolicy#shouldDoLogAggregation.
+     This is useful when the app only wants to aggregate logs of a subset of
+     containers. Here are the available policies. Please make sure to specify
+     the canonical name by prefixing org.apache.hadoop.yarn.server.
+     nodemanager.containermanager.logaggregation.
+     to the class simple name below.
+     NoneContainerLogAggregationPolicy: skip aggregation for all containers.
+     AllContainerLogAggregationPolicy: aggregate all containers.
+     AMOrFailedContainerLogAggregationPolicy: aggregate application master
+         or failed containers.
+     FailedOrKilledContainerLogAggregationPolicy: aggregate failed or killed
+         containers
+     FailedContainerLogAggregationPolicy: aggregate failed containers
+     AMOnlyLogAggregationPolicy: aggregate application master containers
+     SampleContainerLogAggregationPolicy: sample logs of successful worker
+         containers, in addition to application master and failed/killed
+         containers.
+     If it isn't specified, it will use the cluster-wide default policy
+     defined by configuration yarn.nodemanager.log-aggregation.policy.class.
+     The default value of yarn.nodemanager.log-aggregation.policy.class is
+     AllContainerLogAggregationPolicy.
+   </li>
+   <li>
+     policyParameters. The parameters passed to the policy class via
+     ContainerLogAggregationPolicy#parseParameters during the policy object
+     initialization. This is optional. Some policy class might use parameters
+     to adjust its settings. It is up to policy class to define the scheme of
+     parameters.
+     For example, SampleContainerLogAggregationPolicy supports the format of
+     "SR:0.5,MIN:50", which means sample rate of 50% beyond the first 50
+     successful worker containers.
+   </li>
+ </ul>
+
+ @see ApplicationSubmissionContext]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.LogAggregationContext -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NMToken -->
+  <class name="NMToken" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NMToken"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNodeId" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link NodeId} of the <code>NodeManager</code> for which the NMToken
+ is used to authenticate.
+ @return the {@link NodeId} of the <code>NodeManager</code> for which the
+ NMToken is used to authenticate.]]>
+      </doc>
+    </method>
+    <method name="setNodeId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+    </method>
+    <method name="getToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link Token} used for authenticating with <code>NodeManager</code>
+ @return the {@link Token} used for authenticating with <code>NodeManager</code>]]>
+      </doc>
+    </method>
+    <method name="setToken"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="token" type="org.apache.hadoop.yarn.api.records.Token"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[<p>The NMToken is used for authenticating communication with
+ <code>NodeManager</code></p>
+ <p>It is issued by <code>ResourceMananger</code> when <code>ApplicationMaster</code>
+ negotiates resource with <code>ResourceManager</code> and
+ validated on <code>NodeManager</code> side.</p>
+ @see  AllocateResponse#getNMTokens()]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NMToken -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeAttribute -->
+  <class name="NodeAttribute" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NodeAttribute"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeAttribute"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeName" type="java.lang.String"/>
+      <param name="attributeType" type="org.apache.hadoop.yarn.api.records.NodeAttributeType"/>
+      <param name="attributeValue" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeAttribute"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributePrefix" type="java.lang.String"/>
+      <param name="attributeName" type="java.lang.String"/>
+      <param name="attributeType" type="org.apache.hadoop.yarn.api.records.NodeAttributeType"/>
+      <param name="attributeValue" type="java.lang.String"/>
+    </method>
+    <method name="getAttributeKey" return="org.apache.hadoop.yarn.api.records.NodeAttributeKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeKey" type="org.apache.hadoop.yarn.api.records.NodeAttributeKey"/>
+    </method>
+    <method name="getAttributeValue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeValue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeValue" type="java.lang.String"/>
+    </method>
+    <method name="getAttributeType" return="org.apache.hadoop.yarn.api.records.NodeAttributeType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeType" type="org.apache.hadoop.yarn.api.records.NodeAttributeType"/>
+    </method>
+    <field name="PREFIX_DISTRIBUTED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PREFIX_CENTRALIZED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p>
+ Node Attribute is a kind of a label which represents one of the
+ attribute/feature of a Node. Its different from node partition label as
+ resource guarantees across the queues will not be maintained for these type
+ of labels.
+ </p>
+ <p>
+ A given Node can be mapped with any kind of attribute, few examples are
+ HAS_SSD=true, JAVA_VERSION=JDK1.8, OS_TYPE=WINDOWS.
+ </p>
+ <p>
+ Its not compulsory for all the attributes to have value, empty string is the
+ default value of the <code>NodeAttributeType.STRING</code>
+ </p>
+ <p>
+ Node Attribute Prefix is used as namespace to segregate the attributes.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeAttribute -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeAttributeInfo -->
+  <class name="NodeAttributeInfo" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NodeAttributeInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeAttributeInfo"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAttribute" type="org.apache.hadoop.yarn.api.records.NodeAttribute"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeAttributeInfo"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAttributeKey" type="org.apache.hadoop.yarn.api.records.NodeAttributeKey"/>
+      <param name="attributeType" type="org.apache.hadoop.yarn.api.records.NodeAttributeType"/>
+    </method>
+    <method name="getAttributeKey" return="org.apache.hadoop.yarn.api.records.NodeAttributeKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeKey"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeKey" type="org.apache.hadoop.yarn.api.records.NodeAttributeKey"/>
+    </method>
+    <method name="getAttributeType" return="org.apache.hadoop.yarn.api.records.NodeAttributeType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeType" type="org.apache.hadoop.yarn.api.records.NodeAttributeType"/>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ Node Attribute Info describes a NodeAttribute.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeAttributeInfo -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeAttributeKey -->
+  <class name="NodeAttributeKey" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NodeAttributeKey"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeAttributeKey"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeName" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeAttributeKey"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributePrefix" type="java.lang.String"/>
+      <param name="attributeName" type="java.lang.String"/>
+    </method>
+    <method name="getAttributePrefix" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributePrefix"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributePrefix" type="java.lang.String"/>
+    </method>
+    <method name="getAttributeName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeName" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ Node AttributeKey uniquely identifies a given Node Attribute. Node Attribute
+ is identified based on attribute prefix and name.
+ </p>
+ <p>
+ Node Attribute Prefix is used as namespace to segregate the attributes.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeAttributeKey -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeAttributeOpCode -->
+  <class name="NodeAttributeOpCode" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.NodeAttributeOpCode[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.NodeAttributeOpCode"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of various node attribute op codes.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeAttributeOpCode -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeAttributeType -->
+  <class name="NodeAttributeType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.NodeAttributeType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.NodeAttributeType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ Type of a <code>node Attribute</code>.
+ </p>
+ Based on this attribute expressions and values will be evaluated.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeAttributeType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeId -->
+  <class name="NodeId" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="NodeId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="host" type="java.lang.String"/>
+      <param name="port" type="int"/>
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>hostname</em> of the node.
+ @return <em>hostname</em> of the node]]>
+      </doc>
+    </method>
+    <method name="getPort" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>port</em> for communicating with the node.
+ @return <em>port</em> for communicating with the node]]>
+      </doc>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+    </method>
+    <method name="fromString" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeIdStr" type="java.lang.String"/>
+    </method>
+    <method name="build"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p><code>NodeId</code> is the unique identifier for a node.</p>
+ 
+ <p>It includes the <em>hostname</em> and <em>port</em> to uniquely 
+ identify the node. Thus, it is unique across restarts of any 
+ <code>NodeManager</code>.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeId -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeLabel -->
+  <class name="NodeLabel" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="NodeLabel"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isExclusive" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.NodeLabel"/>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="DEFAULT_NODE_LABEL_PARTITION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default node label partition used for displaying.]]>
+      </doc>
+    </field>
+    <field name="NODE_LABEL_EXPRESSION_NOT_SET" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Node Label expression not set .]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NODE_LABEL_EXCLUSIVITY" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[By default, node label is exclusive or not]]>
+      </doc>
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeLabel -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeReport -->
+  <class name="NodeReport" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NodeReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNodeId" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>NodeId</code> of the node.
+ @return <code>NodeId</code> of the node]]>
+      </doc>
+    </method>
+    <method name="getNodeState" return="org.apache.hadoop.yarn.api.records.NodeState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>NodeState</code> of the node.
+ @return <code>NodeState</code> of the node]]>
+      </doc>
+    </method>
+    <method name="getHttpAddress" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>http address</em> of the node.
+ @return <em>http address</em> of the node]]>
+      </doc>
+    </method>
+    <method name="getRackName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>rack name</em> for the node.
+ @return <em>rack name</em> for the node]]>
+      </doc>
+    </method>
+    <method name="getUsed" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>used</em> <code>Resource</code> on the node.
+ @return <em>used</em> <code>Resource</code> on the node]]>
+      </doc>
+    </method>
+    <method name="getCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>total</em> <code>Resource</code> on the node.
+ @return <em>total</em> <code>Resource</code> on the node]]>
+      </doc>
+    </method>
+    <method name="getHealthReport" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>diagnostic health report</em> of the node.
+ @return <em>diagnostic health report</em> of the node]]>
+      </doc>
+    </method>
+    <method name="getLastHealthReportTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>last timestamp</em> at which the health report was received.
+ @return <em>last timestamp</em> at which the health report was received]]>
+      </doc>
+    </method>
+    <method name="getNodeLabels" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get labels of this node.
+ @return labels of this node.]]>
+      </doc>
+    </method>
+    <method name="getAggregatedContainersUtilization" return="org.apache.hadoop.yarn.api.records.ResourceUtilization"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get containers aggregated resource utilization in a node.
+ @return containers resource utilization.]]>
+      </doc>
+    </method>
+    <method name="getNodeUtilization" return="org.apache.hadoop.yarn.api.records.ResourceUtilization"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get node resource utilization.
+ @return node resource utilization.]]>
+      </doc>
+    </method>
+    <method name="getDecommissioningTimeout" return="java.lang.Integer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Optional decommissioning timeout in seconds (null indicates absent
+ timeout).
+ @return the decommissioning timeout in second.]]>
+      </doc>
+    </method>
+    <method name="setDecommissioningTimeout"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="decommissioningTimeout" type="java.lang.Integer"/>
+      <doc>
+      <![CDATA[Set the decommissioning timeout in seconds (null indicates absent timeout).]]>
+      </doc>
+    </method>
+    <method name="getNodeUpdateType" return="org.apache.hadoop.yarn.api.records.NodeUpdateType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Optional node update type (null indicates absent update type).
+ @return the node update.]]>
+      </doc>
+    </method>
+    <method name="setNodeUpdateType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeUpdateType" type="org.apache.hadoop.yarn.api.records.NodeUpdateType"/>
+      <doc>
+      <![CDATA[Set the node update type (null indicates absent node update type).]]>
+      </doc>
+    </method>
+    <method name="setNodeAttributes"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAttributes" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set the node attributes of node.
+
+ @param nodeAttributes set of node attributes.]]>
+      </doc>
+    </method>
+    <method name="getNodeAttributes" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get node attributes of node.
+ @return the set of node attributes.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code NodeReport} is a summary of runtime information of a node
+ in the cluster.
+ <p>
+ It includes details such as:
+ <ul>
+   <li>{@link NodeId} of the node.</li>
+   <li>HTTP Tracking URL of the node.</li>
+   <li>Rack name for the node.</li>
+   <li>Used {@link Resource} on the node.</li>
+   <li>Total available {@link Resource} of the node.</li>
+   <li>Number of running containers on the node.</li>
+ </ul>
+
+ @see ApplicationClientProtocol#getClusterNodes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeReport -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeState -->
+  <class name="NodeState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.NodeState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.NodeState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <method name="isUnusable" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isInactiveState" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isActiveState" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[<p>State of a <code>Node</code>.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.NodeToAttributeValue -->
+  <class name="NodeToAttributeValue" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NodeToAttributeValue"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.NodeToAttributeValue"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hostname" type="java.lang.String"/>
+      <param name="attributeValue" type="java.lang.String"/>
+    </method>
+    <method name="getAttributeValue" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAttributeValue"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributeValue" type="java.lang.String"/>
+    </method>
+    <method name="getHostname" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setHostname"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hostname" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ Mapping of Attribute Value to a Node.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.NodeToAttributeValue -->
+  <!-- start class org.apache.hadoop.yarn.api.records.PreemptionContainer -->
+  <class name="PreemptionContainer" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="PreemptionContainer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Container referenced by this handle.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Specific container requested back by the <code>ResourceManager</code>.
+ @see PreemptionContract
+ @see StrictPreemptionContract]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.PreemptionContainer -->
+  <!-- start class org.apache.hadoop.yarn.api.records.PreemptionContract -->
+  <class name="PreemptionContract" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="PreemptionContract"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getResourceRequest" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[If the AM releases resources matching these requests, then the {@link
+ PreemptionContainer}s enumerated in {@link #getContainers()} should not be
+ evicted from the cluster. Due to delays in propagating cluster state and
+ sending these messages, there are conditions where satisfied contracts may
+ not prevent the platform from killing containers.
+ @return List of {@link PreemptionResourceRequest} to update the
+ <code>ApplicationMaster</code> about resources requested back by the
+ <code>ResourceManager</code>.
+ @see AllocateRequest#setAskList(List)]]>
+      </doc>
+    </method>
+    <method name="getContainers" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Assign the set of {@link PreemptionContainer} specifying which containers
+ owned by the <code>ApplicationMaster</code> that may be reclaimed by the
+ <code>ResourceManager</code>. If the AM prefers a different set of
+ containers, then it may checkpoint or kill containers matching the
+ description in {@link #getResourceRequest}.
+ @return Set of containers at risk if the contract is not met.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Description of resources requested back by the <code>ResourceManager</code>.
+ The <code>ApplicationMaster</code> (AM) can satisfy this request according
+ to its own priorities to prevent containers from being forcibly killed by
+ the platform.
+ @see PreemptionMessage]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.PreemptionContract -->
+  <!-- start class org.apache.hadoop.yarn.api.records.PreemptionMessage -->
+  <class name="PreemptionMessage" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="PreemptionMessage"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getStrictContract" return="org.apache.hadoop.yarn.api.records.StrictPreemptionContract"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Specific resources that may be killed by the
+ <code>ResourceManager</code>]]>
+      </doc>
+    </method>
+    <method name="getContract" return="org.apache.hadoop.yarn.api.records.PreemptionContract"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Contract describing resources to return to the cluster.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A {@link PreemptionMessage} is part of the RM-AM protocol, and it is used by
+ the RM to specify resources that the RM wants to reclaim from this
+ {@code ApplicationMaster} (AM). The AM receives a {@link
+ StrictPreemptionContract} message encoding which containers the platform may
+ forcibly kill, granting it an opportunity to checkpoint state or adjust its
+ execution plan. The message may also include a {@link PreemptionContract}
+ granting the AM more latitude in selecting which resources to return to the
+ cluster.
+ <p>
+ The AM should decode both parts of the message. The {@link
+ StrictPreemptionContract} specifies particular allocations that the RM
+ requires back. The AM can checkpoint containers' state, adjust its execution
+ plan to move the computation, or take no action and hope that conditions that
+ caused the RM to ask for the container will change.
+ <p>
+ In contrast, the {@link PreemptionContract} also includes a description of
+ resources with a set of containers. If the AM releases containers matching
+ that profile, then the containers enumerated in {@link
+ PreemptionContract#getContainers()} may not be killed.
+ <p>
+ Each preemption message reflects the RM's current understanding of the
+ cluster state, so a request to return <em>N</em> containers may not
+ reflect containers the AM is releasing, recently exited containers the RM has
+ yet to learn about, or new containers allocated before the message was
+ generated. Conversely, an RM may request a different profile of containers in
+ subsequent requests.
+ <p>
+ The policy enforced by the RM is part of the scheduler. Generally, only
+ containers that have been requested consistently should be killed, but the
+ details are not specified.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.PreemptionMessage -->
+  <!-- start class org.apache.hadoop.yarn.api.records.PreemptionResourceRequest -->
+  <class name="PreemptionResourceRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="PreemptionResourceRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getResourceRequest" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return Resource described in this request, to be matched against running
+ containers.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Description of resources requested back by the cluster.
+ @see PreemptionContract
+ @see AllocateRequest#setAskList(java.util.List)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.PreemptionResourceRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.Priority -->
+  <class name="Priority" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="Priority"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="p" type="int"/>
+    </method>
+    <method name="getPriority" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the assigned priority
+ @return the assigned priority]]>
+      </doc>
+    </method>
+    <method name="setPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="int"/>
+      <doc>
+      <![CDATA[Set the assigned priority
+ @param priority the assigned priority]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.Priority"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="UNDEFINED" type="org.apache.hadoop.yarn.api.records.Priority"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[The priority assigned to a ResourceRequest or Application or Container 
+ allocation]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.Priority -->
+  <!-- start class org.apache.hadoop.yarn.api.records.QueueACL -->
+  <class name="QueueACL" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.QueueACL[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.QueueACL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[{@code QueueACL} enumerates the various ACLs for queues.
+ <p>
+ The ACL is one of:
+ <ul>
+   <li>
+     {@link #SUBMIT_APPLICATIONS} - ACL to submit applications to the queue.
+   </li>
+   <li>{@link #ADMINISTER_QUEUE} - ACL to administer the queue.</li>
+ </ul>
+ 
+ @see QueueInfo
+ @see ApplicationClientProtocol#getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.QueueACL -->
+  <!-- start class org.apache.hadoop.yarn.api.records.QueueInfo -->
+  <class name="QueueInfo" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="QueueInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getQueueName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>name</em> of the queue.
+ @return <em>name</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getCapacity" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>configured capacity</em> of the queue.
+ @return <em>configured capacity</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getMaximumCapacity" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>maximum capacity</em> of the queue.
+ @return <em>maximum capacity</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getCurrentCapacity" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>current capacity</em> of the queue.
+ @return <em>current capacity</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getChildQueues" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>child queues</em> of the queue.
+ @return <em>child queues</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>running applications</em> of the queue.
+ @return <em>running applications</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getQueueState" return="org.apache.hadoop.yarn.api.records.QueueState"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>QueueState</code> of the queue.
+ @return <code>QueueState</code> of the queue]]>
+      </doc>
+    </method>
+    <method name="getAccessibleNodeLabels" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>accessible node labels</code> of the queue.
+ @return <code>accessible node labels</code> of the queue]]>
+      </doc>
+    </method>
+    <method name="getDefaultNodeLabelExpression" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>default node label expression</code> of the queue, this takes
+ affect only when the <code>ApplicationSubmissionContext</code> and
+ <code>ResourceRequest</code> don't specify their
+ <code>NodeLabelExpression</code>.
+ 
+ @return <code>default node label expression</code> of the queue]]>
+      </doc>
+    </method>
+    <method name="setDefaultNodeLabelExpression"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="defaultLabelExpression" type="java.lang.String"/>
+    </method>
+    <method name="getQueueStatistics" return="org.apache.hadoop.yarn.api.records.QueueStatistics"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>queue stats</code> for the queue
+
+ @return <code>queue stats</code> of the queue]]>
+      </doc>
+    </method>
+    <method name="setQueueStatistics"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueStatistics" type="org.apache.hadoop.yarn.api.records.QueueStatistics"/>
+      <doc>
+      <![CDATA[Set the queue statistics for the queue
+ 
+ @param queueStatistics
+          the queue statistics]]>
+      </doc>
+    </method>
+    <method name="getPreemptionDisabled" return="java.lang.Boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>preemption status</em> of the queue.
+ @return if property is not in proto, return null;
+        otherwise, return <em>preemption status</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getQueueConfigurations" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the per-node-label queue configurations of the queue.
+
+ @return the per-node-label queue configurations of the queue.]]>
+      </doc>
+    </method>
+    <method name="getIntraQueuePreemptionDisabled" return="java.lang.Boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the intra-queue preemption status of the queue.
+ @return if property is not in proto, return null;
+        otherwise, return intra-queue preemption status of the queue]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[QueueInfo is a report of the runtime information of the queue.
+ <p>
+ It includes information such as:
+ <ul>
+   <li>Queue name.</li>
+   <li>Capacity of the queue.</li>
+   <li>Maximum capacity of the queue.</li>
+   <li>Current capacity of the queue.</li>
+   <li>Child queues.</li>
+   <li>Running applications.</li>
+   <li>{@link QueueState} of the queue.</li>
+   <li>{@link QueueConfigurations} of the queue.</li>
+ </ul>
+
+ @see QueueState
+ @see QueueConfigurations
+ @see ApplicationClientProtocol#getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.QueueInfo -->
+  <!-- start class org.apache.hadoop.yarn.api.records.QueueState -->
+  <class name="QueueState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.QueueState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.QueueState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[State of a Queue.
+ <p>
+ A queue is in one of:
+ <ul>
+   <li>{@link #RUNNING} - normal state.</li>
+   <li>{@link #STOPPED} - not accepting new application submissions.</li>
+   <li>
+     {@link #DRAINING} - not accepting new application submissions
+     and waiting for applications finish.
+   </li>
+ </ul>
+ 
+ @see QueueInfo
+ @see ApplicationClientProtocol#getQueueInfo(org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.QueueState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.QueueStatistics -->
+  <class name="QueueStatistics" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="QueueStatistics"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNumAppsSubmitted" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of apps submitted
+ 
+ @return the number of apps submitted]]>
+      </doc>
+    </method>
+    <method name="setNumAppsSubmitted"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAppsSubmitted" type="long"/>
+      <doc>
+      <![CDATA[Set the number of apps submitted
+ 
+ @param numAppsSubmitted
+          the number of apps submitted]]>
+      </doc>
+    </method>
+    <method name="getNumAppsRunning" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of running apps
+ 
+ @return the number of running apps]]>
+      </doc>
+    </method>
+    <method name="setNumAppsRunning"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAppsRunning" type="long"/>
+      <doc>
+      <![CDATA[Set the number of running apps
+ 
+ @param numAppsRunning
+          the number of running apps]]>
+      </doc>
+    </method>
+    <method name="getNumAppsPending" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of pending apps
+ 
+ @return the number of pending apps]]>
+      </doc>
+    </method>
+    <method name="setNumAppsPending"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAppsPending" type="long"/>
+      <doc>
+      <![CDATA[Set the number of pending apps
+ 
+ @param numAppsPending
+          the number of pending apps]]>
+      </doc>
+    </method>
+    <method name="getNumAppsCompleted" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of completed apps
+ 
+ @return the number of completed apps]]>
+      </doc>
+    </method>
+    <method name="setNumAppsCompleted"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAppsCompleted" type="long"/>
+      <doc>
+      <![CDATA[Set the number of completed apps
+ 
+ @param numAppsCompleted
+          the number of completed apps]]>
+      </doc>
+    </method>
+    <method name="getNumAppsKilled" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of killed apps
+ 
+ @return the number of killed apps]]>
+      </doc>
+    </method>
+    <method name="setNumAppsKilled"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAppsKilled" type="long"/>
+      <doc>
+      <![CDATA[Set the number of killed apps
+ 
+ @param numAppsKilled
+          the number of killed apps]]>
+      </doc>
+    </method>
+    <method name="getNumAppsFailed" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of failed apps
+ 
+ @return the number of failed apps]]>
+      </doc>
+    </method>
+    <method name="setNumAppsFailed"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAppsFailed" type="long"/>
+      <doc>
+      <![CDATA[Set the number of failed apps
+ 
+ @param numAppsFailed
+          the number of failed apps]]>
+      </doc>
+    </method>
+    <method name="getNumActiveUsers" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of active users
+ 
+ @return the number of active users]]>
+      </doc>
+    </method>
+    <method name="setNumActiveUsers"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numActiveUsers" type="long"/>
+      <doc>
+      <![CDATA[Set the number of active users
+ 
+ @param numActiveUsers
+          the number of active users]]>
+      </doc>
+    </method>
+    <method name="getAvailableMemoryMB" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the available memory in MB
+ 
+ @return the available memory]]>
+      </doc>
+    </method>
+    <method name="setAvailableMemoryMB"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="availableMemoryMB" type="long"/>
+      <doc>
+      <![CDATA[Set the available memory in MB
+ 
+ @param availableMemoryMB
+          the available memory]]>
+      </doc>
+    </method>
+    <method name="getAllocatedMemoryMB" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the allocated memory in MB
+ 
+ @return the allocated memory]]>
+      </doc>
+    </method>
+    <method name="setAllocatedMemoryMB"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocatedMemoryMB" type="long"/>
+      <doc>
+      <![CDATA[Set the allocated memory in MB
+ 
+ @param allocatedMemoryMB
+          the allocate memory]]>
+      </doc>
+    </method>
+    <method name="getPendingMemoryMB" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the pending memory in MB
+ 
+ @return the pending memory]]>
+      </doc>
+    </method>
+    <method name="setPendingMemoryMB"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pendingMemoryMB" type="long"/>
+      <doc>
+      <![CDATA[Set the pending memory in MB
+ 
+ @param pendingMemoryMB
+          the pending memory]]>
+      </doc>
+    </method>
+    <method name="getReservedMemoryMB" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reserved memory in MB
+ 
+ @return the reserved memory]]>
+      </doc>
+    </method>
+    <method name="setReservedMemoryMB"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservedMemoryMB" type="long"/>
+      <doc>
+      <![CDATA[Set the reserved memory in MB
+ 
+ @param reservedMemoryMB
+          the reserved memory]]>
+      </doc>
+    </method>
+    <method name="getAvailableVCores" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the available vcores
+ 
+ @return the available vcores]]>
+      </doc>
+    </method>
+    <method name="setAvailableVCores"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="availableVCores" type="long"/>
+      <doc>
+      <![CDATA[Set the available vcores
+ 
+ @param availableVCores
+          the available vcores]]>
+      </doc>
+    </method>
+    <method name="getAllocatedVCores" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the allocated vcores
+ 
+ @return the allocated vcores]]>
+      </doc>
+    </method>
+    <method name="setAllocatedVCores"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocatedVCores" type="long"/>
+      <doc>
+      <![CDATA[Set the allocated vcores
+ 
+ @param allocatedVCores
+          the allocated vcores]]>
+      </doc>
+    </method>
+    <method name="getPendingVCores" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the pending vcores
+ 
+ @return the pending vcores]]>
+      </doc>
+    </method>
+    <method name="setPendingVCores"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pendingVCores" type="long"/>
+      <doc>
+      <![CDATA[Set the pending vcores
+ 
+ @param pendingVCores
+          the pending vcores]]>
+      </doc>
+    </method>
+    <method name="getPendingContainers" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of pending containers.
+ @return the number of pending containers.]]>
+      </doc>
+    </method>
+    <method name="setPendingContainers"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pendingContainers" type="long"/>
+      <doc>
+      <![CDATA[Set the number of pending containers.
+ @param pendingContainers the pending containers.]]>
+      </doc>
+    </method>
+    <method name="getAllocatedContainers" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of allocated containers.
+ @return the number of allocated containers.]]>
+      </doc>
+    </method>
+    <method name="setAllocatedContainers"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocatedContainers" type="long"/>
+      <doc>
+      <![CDATA[Set the number of allocated containers.
+ @param allocatedContainers the allocated containers.]]>
+      </doc>
+    </method>
+    <method name="getReservedContainers" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of reserved containers.
+ @return the number of reserved containers.]]>
+      </doc>
+    </method>
+    <method name="setReservedContainers"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservedContainers" type="long"/>
+      <doc>
+      <![CDATA[Set the number of reserved containers.
+ @param reservedContainers the reserved containers.]]>
+      </doc>
+    </method>
+    <method name="getReservedVCores" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reserved vcores
+ 
+ @return the reserved vcores]]>
+      </doc>
+    </method>
+    <method name="setReservedVCores"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservedVCores" type="long"/>
+      <doc>
+      <![CDATA[Set the reserved vcores
+ 
+ @param reservedVCores
+          the reserved vcores]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.QueueStatistics -->
+  <!-- start class org.apache.hadoop.yarn.api.records.QueueUserACLInfo -->
+  <class name="QueueUserACLInfo" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="QueueUserACLInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getQueueName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>queue name</em> of the queue.
+ @return <em>queue name</em> of the queue]]>
+      </doc>
+    </method>
+    <method name="getUserAcls" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of <code>QueueACL</code> for the given user.
+ @return list of <code>QueueACL</code> for the given user]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p><code>QueueUserACLInfo</code> provides information {@link QueueACL} for
+ the given user.</p>
+ 
+ @see QueueACL
+ @see ApplicationClientProtocol#getQueueUserAcls(org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.QueueUserACLInfo -->
+  <!-- start class org.apache.hadoop.yarn.api.records.RejectedSchedulingRequest -->
+  <class name="RejectedSchedulingRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RejectedSchedulingRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.RejectedSchedulingRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reason" type="org.apache.hadoop.yarn.api.records.RejectionReason"/>
+      <param name="request" type="org.apache.hadoop.yarn.api.records.SchedulingRequest"/>
+      <doc>
+      <![CDATA[Create new RejectedSchedulingRequest.
+ @param reason Rejection Reason.
+ @param request Rejected Scheduling Request.
+ @return RejectedSchedulingRequest.]]>
+      </doc>
+    </method>
+    <method name="getReason" return="org.apache.hadoop.yarn.api.records.RejectionReason"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get Rejection Reason.
+ @return Rejection reason.]]>
+      </doc>
+    </method>
+    <method name="setReason"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reason" type="org.apache.hadoop.yarn.api.records.RejectionReason"/>
+      <doc>
+      <![CDATA[Set Rejection Reason.
+ @param reason Rejection Reason.]]>
+      </doc>
+    </method>
+    <method name="getRequest" return="org.apache.hadoop.yarn.api.records.SchedulingRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the Rejected Scheduling Request.
+ @return SchedulingRequest.]]>
+      </doc>
+    </method>
+    <method name="setRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.records.SchedulingRequest"/>
+      <doc>
+      <![CDATA[Set the SchedulingRequest.
+ @param request SchedulingRequest.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This encapsulates a Rejected SchedulingRequest. It contains the offending
+ Scheduling Request along with the reason for rejection.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.RejectedSchedulingRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.RejectionReason -->
+  <class name="RejectionReason" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.RejectionReason[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.RejectionReason"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Reason for rejecting a Scheduling Request.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.RejectionReason -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationACL -->
+  <class name="ReservationACL" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ReservationACL[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ReservationACL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[{@code ReservationACL} enumerates the various ACLs for reservations.
+ <p>
+ The ACL is one of:
+ <ul>
+   <li>
+     {@link #ADMINISTER_RESERVATIONS} - ACL to create, list, update and
+     delete reservations.
+   </li>
+   <li> {@link #LIST_RESERVATIONS} - ACL to list reservations. </li>
+   <li> {@link #SUBMIT_RESERVATIONS} - ACL to create reservations. </li>
+ </ul>
+ Users can always list, update and delete their own reservations.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationACL -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationAllocationState -->
+  <class name="ReservationAllocationState" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationAllocationState"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ReservationAllocationState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="acceptanceTime" type="long"/>
+      <param name="user" type="java.lang.String"/>
+      <param name="resourceAllocations" type="java.util.List"/>
+      <param name="reservationId" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+      <param name="reservationDefinition" type="org.apache.hadoop.yarn.api.records.ReservationDefinition"/>
+      <doc>
+      <![CDATA[@param acceptanceTime The acceptance time of the reservation.
+ @param user The username of the user who made the reservation.
+ @param resourceAllocations List of {@link ResourceAllocationRequest}
+                            representing the current state of the
+                            reservation resource allocations. This is
+                            subject to change in the event of re-planning.
+ @param reservationId {@link ReservationId } of the reservation being
+                                            listed.
+ @param reservationDefinition {@link ReservationDefinition} used to make
+                              the reservation.
+ @return {@code ReservationAllocationState} that represents the state of
+ the reservation.]]>
+      </doc>
+    </method>
+    <method name="getAcceptanceTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the acceptance time of the reservation.
+
+ @return the time that the reservation was accepted.]]>
+      </doc>
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user who made the reservation.
+
+ @return the name of the user who made the reservation.]]>
+      </doc>
+    </method>
+    <method name="getResourceAllocationRequests" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the Resource allocations of the reservation based on the current state
+ of the plan. This is subject to change in the event of re-planning.
+ The allocations will be constraint to the user contract as described by
+ the {@link ReservationDefinition}
+
+ @return a list of resource allocations for the reservation.]]>
+      </doc>
+    </method>
+    <method name="getReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the id of the reservation.
+
+ @return the reservation id corresponding to the reservation.]]>
+      </doc>
+    </method>
+    <method name="getReservationDefinition" return="org.apache.hadoop.yarn.api.records.ReservationDefinition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reservation definition used to make the reservation.
+
+ @return the reservation definition used to make the reservation.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ReservationAllocationState} represents the reservation that is
+ made by a user.
+ <p>
+ It includes:
+ <ul>
+   <li>Duration of the reservation.</li>
+   <li>Acceptance time of the duration.</li>
+   <li>
+       List of {@link ResourceAllocationRequest}, which includes the time
+       interval, and capability of the allocation.
+       {@code ResourceAllocationRequest} represents an allocation
+       made for a reservation for the current state of the queue. This can be
+       changed for reasons such as re-planning, but will always be subject to
+       the constraints of the user contract as described by
+       {@link ReservationDefinition}
+   </li>
+   <li>{@link ReservationId} of the reservation.</li>
+   <li>{@link ReservationDefinition} used to make the reservation.</li>
+ </ul>
+
+ @see ResourceAllocationRequest
+ @see ReservationId
+ @see ReservationDefinition]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationAllocationState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationDefinition -->
+  <class name="ReservationDefinition" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationDefinition"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ReservationDefinition"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="arrival" type="long"/>
+      <param name="deadline" type="long"/>
+      <param name="reservationRequests" type="org.apache.hadoop.yarn.api.records.ReservationRequests"/>
+      <param name="name" type="java.lang.String"/>
+      <param name="recurrenceExpression" type="java.lang.String"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ReservationDefinition"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="arrival" type="long"/>
+      <param name="deadline" type="long"/>
+      <param name="reservationRequests" type="org.apache.hadoop.yarn.api.records.ReservationRequests"/>
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <method name="getArrival" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the arrival time or the earliest time from which the resource(s) can be
+ allocated. Time expressed as UTC.
+ 
+ @return the earliest valid time for this reservation]]>
+      </doc>
+    </method>
+    <method name="setArrival"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="earliestStartTime" type="long"/>
+      <doc>
+      <![CDATA[Set the arrival time or the earliest time from which the resource(s) can be
+ allocated. Time expressed as UTC.
+ 
+ @param earliestStartTime the earliest valid time for this reservation]]>
+      </doc>
+    </method>
+    <method name="getDeadline" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the deadline or the latest time by when the resource(s) must be
+ allocated. Time expressed as UTC.
+ 
+ @return the deadline or the latest time by when the resource(s) must be
+         allocated]]>
+      </doc>
+    </method>
+    <method name="setDeadline"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="latestEndTime" type="long"/>
+      <doc>
+      <![CDATA[Set the deadline or the latest time by when the resource(s) must be
+ allocated. Time expressed as UTC.
+ 
+ @param latestEndTime the deadline or the latest time by when the
+          resource(s) should be allocated]]>
+      </doc>
+    </method>
+    <method name="getReservationRequests" return="org.apache.hadoop.yarn.api.records.ReservationRequests"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of {@link ReservationRequests} representing the resources
+ required by the application
+ 
+ @return the list of {@link ReservationRequests}]]>
+      </doc>
+    </method>
+    <method name="setReservationRequests"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationRequests" type="org.apache.hadoop.yarn.api.records.ReservationRequests"/>
+      <doc>
+      <![CDATA[Set the list of {@link ReservationRequests} representing the resources
+ required by the application
+ 
+ @param reservationRequests the list of {@link ReservationRequests}]]>
+      </doc>
+    </method>
+    <method name="getReservationName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the name for this reservation. The name need-not be unique, and it is
+ just a mnemonic for the user (akin to job names). Accepted reservations are
+ uniquely identified by a system-generated ReservationId.
+ 
+ @return string representing the name of the corresponding reserved resource
+         allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="setReservationName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the name for this reservation. The name need-not be unique, and it is
+ just a mnemonic for the user (akin to job names). Accepted reservations are
+ uniquely identified by a system-generated ReservationId.
+ 
+ @param name representing the name of the corresponding reserved resource
+          allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="getRecurrenceExpression" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the recurrence of this reservation representing the time period of
+ the periodic job. Currently, only long values are supported. Later,
+ support for regular expressions denoting arbitrary recurrence patterns
+ (e.g., every Tuesday and Thursday) will be added.
+ Recurrence is represented in milliseconds for periodic jobs.
+ Recurrence is 0 for non-periodic jobs. Periodic jobs are valid until they
+ are explicitly cancelled and have higher priority than non-periodic jobs
+ (during initial placement and replanning). Periodic job allocations are
+ consistent across runs (flexibility in allocation is leveraged only during
+ initial placement, allocations remain consistent thereafter). Note that
+ as a long, the recurrence expression must be greater than the duration of
+ the reservation (deadline - arrival). Also note that the configured max
+ period must be divisible by the recurrence expression if expressed as a
+ long.
+
+ @return recurrence of this reservation]]>
+      </doc>
+    </method>
+    <method name="setRecurrenceExpression"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="recurrenceExpression" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the recurrence of this reservation representing the time period of
+ the periodic job. Currently, only long values are supported. Later,
+ support for regular expressions denoting arbitrary recurrence patterns
+ (e.g., every Tuesday and Thursday) will be added.
+ Recurrence is represented in milliseconds for periodic jobs.
+ Recurrence is 0 for non-periodic jobs. Periodic jobs are valid until they
+ are explicitly cancelled and have higher priority than non-periodic jobs
+ (during initial placement and replanning). Periodic job allocations are
+ consistent across runs (flexibility in allocation is leveraged only during
+ initial placement, allocations remain consistent thereafter). Note that
+ as a long, the recurrence expression must be greater than the duration of
+ the reservation (deadline - arrival). Also note that the configured max
+ period must be divisible by the recurrence expression if expressed as a
+ long.
+
+ @param recurrenceExpression recurrence interval of this reservation]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the priority for this reservation. A lower number for priority
+ indicates a higher priority reservation. Recurring reservations are
+ always higher priority than non-recurring reservations. Priority for
+ non-recurring reservations are only compared with non-recurring
+ reservations. Likewise for recurring reservations.
+
+ @return int representing the priority of the reserved resource
+         allocation in the scheduler]]>
+      </doc>
+    </method>
+    <method name="setPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <doc>
+      <![CDATA[Set the priority for this reservation. A lower number for priority
+ indicates a higher priority reservation. Recurring reservations are
+ always higher priority than non-recurring reservations. Priority for
+ non-recurring reservations are only compared with non-recurring
+ reservations. Likewise for recurring reservations.
+
+ @param priority representing the priority of the reserved resource
+          allocation in the scheduler]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationDefinition} captures the set of resource and time
+ constraints the user cares about regarding a reservation.
+ 
+ @see ResourceRequest]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationDefinition -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationId -->
+  <class name="ReservationId" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ReservationId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the long identifier of the {@link ReservationId} which is unique for
+ all Reservations started by a particular instance of the
+ {@code ResourceManager}.
+
+ @return long identifier of the {@link ReservationId}]]>
+      </doc>
+    </method>
+    <method name="getClusterTimestamp" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>start time</em> of the {@code ResourceManager} which is used to
+ generate globally unique {@link ReservationId}.
+
+ @return <em>start time</em> of the {@code ResourceManager}]]>
+      </doc>
+    </method>
+    <method name="build"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.ReservationId"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="parseReservationId" return="org.apache.hadoop.yarn.api.records.ReservationId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Parse the string argument as a {@link ReservationId}
+
+ @param reservationId the string representation of the {@link ReservationId}
+ @return the {@link ReservationId} corresponding to the input string if
+         valid, null if input is null
+ @throws IOException if unable to parse the input string]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <field name="reserveIdStrPrefix" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="clusterTimestamp" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="id" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p>
+ {@link ReservationId} represents the <em>globally unique</em> identifier for
+ a reservation.
+ </p>
+
+ <p>
+ The globally unique nature of the identifier is achieved by using the
+ <em>cluster timestamp</em> i.e. start-time of the {@code ResourceManager}
+ along with a monotonically increasing counter for the reservation.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationId -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationRequest -->
+  <class name="ReservationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ReservationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ReservationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="numContainers" type="int"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ReservationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="numContainers" type="int"/>
+      <param name="concurrency" type="int"/>
+      <param name="duration" type="long"/>
+    </method>
+    <method name="getCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link Resource} capability of the request.
+ 
+ @return {@link Resource} capability of the request]]>
+      </doc>
+    </method>
+    <method name="setCapability"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Set the {@link Resource} capability of the request
+ 
+ @param capability {@link Resource} capability of the request]]>
+      </doc>
+    </method>
+    <method name="getNumContainers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of containers required with the given specifications.
+ 
+ @return number of containers required with the given specifications]]>
+      </doc>
+    </method>
+    <method name="setNumContainers"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numContainers" type="int"/>
+      <doc>
+      <![CDATA[Set the number of containers required with the given specifications
+ 
+ @param numContainers number of containers required with the given
+          specifications]]>
+      </doc>
+    </method>
+    <method name="getConcurrency" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of containers that need to be scheduled concurrently. The
+ default value of 1 would fall back to the current non concurrency
+ constraints on the scheduling behavior.
+ 
+ @return the number of containers to be concurrently scheduled]]>
+      </doc>
+    </method>
+    <method name="setConcurrency"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numContainers" type="int"/>
+      <doc>
+      <![CDATA[Set the number of containers that need to be scheduled concurrently. The
+ default value of 1 would fall back to the current non concurrency
+ constraints on the scheduling behavior.
+ 
+ @param numContainers the number of containers to be concurrently scheduled]]>
+      </doc>
+    </method>
+    <method name="getDuration" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the duration in milliseconds for which the resource is required. A
+ default value of -1, indicates an unspecified lease duration, and fallback
+ to current behavior.
+ 
+ @return the duration in milliseconds for which the resource is required]]>
+      </doc>
+    </method>
+    <method name="setDuration"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="duration" type="long"/>
+      <doc>
+      <![CDATA[Set the duration in milliseconds for which the resource is required.
+ 
+ @param duration the duration in milliseconds for which the resource is
+          required]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.ReservationRequest"/>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationRequest} represents the request made by an application to
+ the {@code ResourceManager} to reserve {@link Resource}s.
+ <p>
+ It includes:
+ <ul>
+   <li>{@link Resource} required for each request.</li>
+   <li>
+     Number of containers, of above specifications, which are required by the
+     application.
+   </li>
+   <li>Concurrency that indicates the gang size of the request.</li>
+ </ul>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationRequest.ReservationRequestComparator -->
+  <class name="ReservationRequest.ReservationRequestComparator" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.util.Comparator"/>
+    <implements name="java.io.Serializable"/>
+    <constructor name="ReservationRequestComparator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="compare" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="r1" type="org.apache.hadoop.yarn.api.records.ReservationRequest"/>
+      <param name="r2" type="org.apache.hadoop.yarn.api.records.ReservationRequest"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationRequest.ReservationRequestComparator -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter -->
+  <class name="ReservationRequestInterpreter" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of various types of dependencies among multiple
+ {@link ReservationRequests} within one {@link ReservationDefinition} (from
+ least constraining to most constraining).]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ReservationRequests -->
+  <class name="ReservationRequests" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ReservationRequests"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ReservationRequests"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationResources" type="java.util.List"/>
+      <param name="type" type="org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter"/>
+    </method>
+    <method name="getReservationResources" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of {@link ReservationRequest} representing the resources
+ required by the application
+ 
+ @return the list of {@link ReservationRequest}]]>
+      </doc>
+    </method>
+    <method name="setReservationResources"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reservationResources" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list of {@link ReservationRequest} representing the resources
+ required by the application
+ 
+ @param reservationResources the list of {@link ReservationRequest}]]>
+      </doc>
+    </method>
+    <method name="getInterpreter" return="org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@link ReservationRequestInterpreter}, representing how the list of
+ resources should be allocated, this captures temporal ordering and other
+ constraints.
+ 
+ @return the list of {@link ReservationRequestInterpreter}]]>
+      </doc>
+    </method>
+    <method name="setInterpreter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="interpreter" type="org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter"/>
+      <doc>
+      <![CDATA[Set the {@link ReservationRequestInterpreter}, representing how the list of
+ resources should be allocated, this captures temporal ordering and other
+ constraints.
+ 
+ @param interpreter the {@link ReservationRequestInterpreter} for this
+          reservation]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ReservationRequests} captures the set of resource and constraints the
+ user cares about regarding a reservation.
+ 
+ @see ReservationRequest]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ReservationRequests -->
+  <!-- start class org.apache.hadoop.yarn.api.records.Resource -->
+  <class name="Resource" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="Resource"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="memory" type="int"/>
+      <param name="vCores" type="int"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="memory" type="long"/>
+      <param name="vCores" type="int"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="memory" type="long"/>
+      <param name="vCores" type="int"/>
+      <param name="others" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Create a new {@link Resource} instance with the given CPU and memory
+ values and additional resource values as set in the {@code others}
+ parameter. Note that the CPU and memory settings in the {@code others}
+ parameter will be ignored.
+
+ @param memory the memory value
+ @param vCores the CPU value
+ @param others a map of other resource values indexed by resource name
+ @return a {@link Resource} instance with the given resource values]]>
+      </doc>
+    </method>
+    <method name="getMemory" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This method is DEPRECATED:
+ Use {@link Resource#getMemorySize()} instead
+
+ Get <em>memory</em> of the resource. Note - while memory has
+ never had a unit specified, all YARN configurations have specified memory
+ in MB. The assumption has been that the daemons and applications are always
+ using the same units. With the introduction of the ResourceInformation
+ class we have support for units - so this function will continue to return
+ memory but in the units of MB
+
+ @return <em>memory</em>(in MB) of the resource]]>
+      </doc>
+    </method>
+    <method name="getMemorySize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>memory</em> of the resource. Note - while memory has
+ never had a unit specified, all YARN configurations have specified memory
+ in MB. The assumption has been that the daemons and applications are always
+ using the same units. With the introduction of the ResourceInformation
+ class we have support for units - so this function will continue to return
+ memory but in the units of MB
+
+ @return <em>memory</em> of the resource]]>
+      </doc>
+    </method>
+    <method name="setMemory"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="memory" type="int"/>
+      <doc>
+      <![CDATA[Set <em>memory</em> of the resource. Note - while memory has
+ never had a unit specified, all YARN configurations have specified memory
+ in MB. The assumption has been that the daemons and applications are always
+ using the same units. With the introduction of the ResourceInformation
+ class we have support for units - so this function will continue to set
+ memory but the assumption is that the value passed is in units of MB.
+
+ @param memory <em>memory</em>(in MB) of the resource]]>
+      </doc>
+    </method>
+    <method name="setMemorySize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="memory" type="long"/>
+      <doc>
+      <![CDATA[Set <em>memory</em> of the resource.
+ @param memory <em>memory</em> of the resource]]>
+      </doc>
+    </method>
+    <method name="getVirtualCores" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>number of virtual cpu cores</em> of the resource.
+ 
+ Virtual cores are a unit for expressing CPU parallelism. A node's capacity
+ should be configured with virtual cores equal to its number of physical
+ cores. A container should be requested with the number of cores it can
+ saturate, i.e. the average number of threads it expects to have runnable
+ at a time.
+
+ @return <em>num of virtual cpu cores</em> of the resource]]>
+      </doc>
+    </method>
+    <method name="setVirtualCores"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="vCores" type="int"/>
+      <doc>
+      <![CDATA[Set <em>number of virtual cpu cores</em> of the resource.
+ 
+ Virtual cores are a unit for expressing CPU parallelism. A node's capacity
+ should be configured with virtual cores equal to its number of physical
+ cores. A container should be requested with the number of cores it can
+ saturate, i.e. the average number of threads it expects to have runnable
+ at a time.
+
+ @param vCores <em>number of virtual cpu cores</em> of the resource]]>
+      </doc>
+    </method>
+    <method name="getResourceInformation" return="org.apache.hadoop.yarn.api.records.ResourceInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get ResourceInformation for a specified resource.
+
+ @param resource name of the resource
+ @return the ResourceInformation object for the resource]]>
+      </doc>
+    </method>
+    <method name="getResourceValue" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Get the value for a specified resource. No information about the units is
+ returned.
+
+ @param resource name of the resource
+ @return the value for the resource]]>
+      </doc>
+    </method>
+    <method name="setResourceInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.lang.String"/>
+      <param name="resourceInformation" type="org.apache.hadoop.yarn.api.records.ResourceInformation"/>
+      <doc>
+      <![CDATA[Set the ResourceInformation object for a particular resource.
+
+ @param resource the resource for which the ResourceInformation is provided
+ @param resourceInformation ResourceInformation object]]>
+      </doc>
+    </method>
+    <method name="setResourceValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="java.lang.String"/>
+      <param name="value" type="long"/>
+      <doc>
+      <![CDATA[Set the value of a resource in the ResourceInformation object. The unit of
+ the value is assumed to be the one in the ResourceInformation object.
+
+ @param resource the resource for which the value is provided.
+ @param value    the value to set]]>
+      </doc>
+    </method>
+    <method name="throwExceptionWhenArrayOutOfBound"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="index" type="int"/>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFormattedString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This method is to get memory in terms of KB|MB|GB.
+ @return string containing all resources]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="castToIntSafely" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="value" type="long"/>
+      <doc>
+      <![CDATA[Convert long to int for a resource value safely. This method assumes
+ resource value is positive.
+
+ @param value long resource value
+ @return int resource value]]>
+      </doc>
+    </method>
+    <method name="newDefaultInformation" return="org.apache.hadoop.yarn.api.records.ResourceInformation"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <param name="unit" type="java.lang.String"/>
+      <param name="value" type="long"/>
+      <doc>
+      <![CDATA[Create ResourceInformation with basic fields.
+ @param name Resource Type Name
+ @param unit Default unit of provided resource type
+ @param value Value associated with giveb resource
+ @return ResourceInformation object]]>
+      </doc>
+    </method>
+    <field name="resources" type="org.apache.hadoop.yarn.api.records.ResourceInformation[]"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="NUM_MANDATORY_RESOURCES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="MEMORY_INDEX" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="VCORES_INDEX" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p><code>Resource</code> models a set of computer resources in the 
+ cluster.</p>
+ 
+ <p>Currently it models both <em>memory</em> and <em>CPU</em>.</p>
+ 
+ <p>The unit for memory is megabytes. CPU is modeled with virtual cores
+ (vcores), a unit for expressing parallelism. A node's capacity should
+ be configured with virtual cores equal to its number of physical cores. A
+ container should be requested with the number of cores it can saturate, i.e.
+ the average number of threads it expects to have runnable at a time.</p>
+ 
+ <p>Virtual cores take integer values and thus currently CPU-scheduling is
+ very coarse.  A complementary axis for CPU requests that represents
+ processing power will likely be added in the future to enable finer-grained
+ resource configuration.</p>
+
+ <p>Typically, applications request <code>Resource</code> of suitable
+ capability to run their component tasks.</p>
+ 
+ @see ResourceRequest
+ @see ApplicationMasterProtocol#allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.Resource -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceAllocationRequest -->
+  <class name="ResourceAllocationRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceAllocationRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceAllocationRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startTime" type="long"/>
+      <param name="endTime" type="long"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[@param startTime The start time that the capability is reserved for.
+ @param endTime The end time that the capability is reserved for.
+ @param capability {@link Resource} representing the capability of the
+                                   resource allocation.
+ @return {ResourceAllocationRequest} which represents the capability of
+ the resource allocation for a time interval.]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the start time that the resource is allocated.
+
+ @return the start time that the resource is allocated.]]>
+      </doc>
+    </method>
+    <method name="getEndTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the end time that the resource is allocated.
+
+ @return the end time that the resource is allocated.]]>
+      </doc>
+    </method>
+    <method name="getCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the allocated resource.
+
+ @return the allocated resource.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code ResourceAllocationRequest} represents an allocation
+ made for a reservation for the current state of the plan. This can be
+ changed for reasons such as re-planning, but will always be subject to the
+ constraints of the user contract as described by
+ {@link ReservationDefinition}
+ {@link Resource}
+
+ <p>
+ It includes:
+ <ul>
+   <li>StartTime of the allocation.</li>
+   <li>EndTime of the allocation.</li>
+   <li>{@link Resource} reserved for the allocation.</li>
+ </ul>
+
+ @see Resource]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceAllocationRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest -->
+  <class name="ResourceBlacklistRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceBlacklistRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="additions" type="java.util.List"/>
+      <param name="removals" type="java.util.List"/>
+    </method>
+    <method name="getBlacklistAdditions" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of resource-names which should be added to the 
+ application blacklist.
+ 
+ @return list of resource-names which should be added to the 
+         application blacklist]]>
+      </doc>
+    </method>
+    <method name="setBlacklistAdditions"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceNames" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set list of resource-names which should be added to the application blacklist.
+ 
+ @param resourceNames list of resource-names which should be added to the 
+                  application blacklist]]>
+      </doc>
+    </method>
+    <method name="getBlacklistRemovals" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the list of resource-names which should be removed from the 
+ application blacklist.
+ 
+ @return list of resource-names which should be removed from the 
+         application blacklist]]>
+      </doc>
+    </method>
+    <method name="setBlacklistRemovals"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceNames" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set list of resource-names which should be removed from the 
+ application blacklist.
+ 
+ @param resourceNames list of resource-names which should be removed from the 
+                  application blacklist]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@link ResourceBlacklistRequest} encapsulates the list of resource-names 
+ which should be added or removed from the <em>blacklist</em> of resources 
+ for the application.
+ 
+ @see ResourceRequest
+ @see ApplicationMasterProtocol#allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceBlacklistRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceOption -->
+  <class name="ResourceOption" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceOption"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceOption"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resource" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="overCommitTimeout" type="int"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="OVER_COMMIT_TIMEOUT_MILLIS_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Negative value means no timeout.]]>
+      </doc>
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceOption -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceRequest -->
+  <class name="ResourceRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ResourceRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="hostName" type="java.lang.String"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="numContainers" type="int"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="hostName" type="java.lang.String"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="numContainers" type="int"/>
+      <param name="relaxLocality" type="boolean"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="hostName" type="java.lang.String"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="numContainers" type="int"/>
+      <param name="relaxLocality" type="boolean"/>
+      <param name="labelExpression" type="java.lang.String"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="hostName" type="java.lang.String"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="numContainers" type="int"/>
+      <param name="relaxLocality" type="boolean"/>
+      <param name="labelExpression" type="java.lang.String"/>
+      <param name="executionTypeRequest" type="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"/>
+    </method>
+    <method name="clone" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="rr" type="org.apache.hadoop.yarn.api.records.ResourceRequest"/>
+      <doc>
+      <![CDATA[Clone a ResourceRequest object (shallow copy). Please keep it loaded with
+ all (new) fields
+
+ @param rr the object to copy from
+ @return the copied object]]>
+      </doc>
+    </method>
+    <method name="newBuilder" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isAnyLocation" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hostName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Check whether the given <em>host/rack</em> string represents an arbitrary
+ host name.
+
+ @param hostName <em>host/rack</em> on which the allocation is desired
+ @return whether the given <em>host/rack</em> string represents an arbitrary
+ host name]]>
+      </doc>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Priority</code> of the request.
+ @return <code>Priority</code> of the request]]>
+      </doc>
+    </method>
+    <method name="setPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <doc>
+      <![CDATA[Set the <code>Priority</code> of the request
+ @param priority <code>Priority</code> of the request]]>
+      </doc>
+    </method>
+    <method name="getResourceName" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the resource (e.g. <em>host/rack</em>) on which the allocation 
+ is desired.
+ 
+ A special value of <em>*</em> signifies that <em>any</em> resource 
+ (host/rack) is acceptable.
+ 
+ @return resource (e.g. <em>host/rack</em>) on which the allocation 
+                  is desired]]>
+      </doc>
+    </method>
+    <method name="setResourceName"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the resource name (e.g. <em>host/rack</em>) on which the allocation 
+ is desired.
+ 
+ A special value of <em>*</em> signifies that <em>any</em> resource name
+ (e.g. host/rack) is acceptable. 
+ 
+ @param resourceName (e.g. <em>host/rack</em>) on which the 
+                     allocation is desired]]>
+      </doc>
+    </method>
+    <method name="getNumContainers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of containers required with the given specifications.
+ @return number of containers required with the given specifications]]>
+      </doc>
+    </method>
+    <method name="setNumContainers"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numContainers" type="int"/>
+      <doc>
+      <![CDATA[Set the number of containers required with the given specifications
+ @param numContainers number of containers required with the given 
+                      specifications]]>
+      </doc>
+    </method>
+    <method name="getRelaxLocality" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether locality relaxation is enabled with this
+ <code>ResourceRequest</code>. Defaults to true.
+ 
+ @return whether locality relaxation is enabled with this
+ <code>ResourceRequest</code>.]]>
+      </doc>
+    </method>
+    <method name="setExecutionTypeRequest"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="execSpec" type="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"/>
+      <doc>
+      <![CDATA[Set the <code>ExecutionTypeRequest</code> of the requested container.
+
+ @param execSpec
+          ExecutionTypeRequest of the requested container]]>
+      </doc>
+    </method>
+    <method name="getExecutionTypeRequest" return="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get whether locality relaxation is enabled with this
+ <code>ResourceRequest</code>. Defaults to true.
+
+ @return whether locality relaxation is enabled with this
+ <code>ResourceRequest</code>.]]>
+      </doc>
+    </method>
+    <method name="setRelaxLocality"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="relaxLocality" type="boolean"/>
+      <doc>
+      <![CDATA[<p>For a request at a network hierarchy level, set whether locality can be relaxed
+ to that level and beyond.<p>
+ 
+ <p>If the flag is off on a rack-level <code>ResourceRequest</code>,
+ containers at that request's priority will not be assigned to nodes on that
+ request's rack unless requests specifically for those nodes have also been
+ submitted.<p>
+ 
+ <p>If the flag is off on an {@link ResourceRequest#ANY}-level
+ <code>ResourceRequest</code>, containers at that request's priority will
+ only be assigned on racks for which specific requests have also been
+ submitted.<p>
+ 
+ <p>For example, to request a container strictly on a specific node, the
+ corresponding rack-level and any-level requests should have locality
+ relaxation set to false.  Similarly, to request a container strictly on a
+ specific rack, the corresponding any-level request should have locality
+ relaxation set to false.<p>
+ 
+ @param relaxLocality whether locality relaxation is enabled with this
+ <code>ResourceRequest</code>.]]>
+      </doc>
+    </method>
+    <method name="getNodeLabelExpression" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get node-label-expression for this Resource Request. If this is set, all
+ containers allocated to satisfy this resource-request will be only on those
+ nodes that satisfy this node-label-expression.
+  
+ Please note that node label expression now can only take effect when the
+ resource request has resourceName = ANY
+ 
+ @return node-label-expression]]>
+      </doc>
+    </method>
+    <method name="setNodeLabelExpression"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodelabelExpression" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set node label expression of this resource request. Now only support
+ specifying a single node label. In the future we will support more complex
+ node label expression specification like {@code AND(&&), OR(||)}, etc.
+ 
+ Any please note that node label expression now can only take effect when
+ the resource request has resourceName = ANY
+ 
+ @param nodelabelExpression
+          node-label-expression of this ResourceRequest]]>
+      </doc>
+    </method>
+    <method name="getAllocationRequestId" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the optional <em>ID</em> corresponding to this allocation request. This
+ ID is an identifier for different {@code ResourceRequest}s from the <b>same
+ application</b>. The allocated {@code Container}(s) received as part of the
+ {@code AllocateResponse} response will have the ID corresponding to the
+ original {@code ResourceRequest} for which the RM made the allocation.
+ <p>
+ The scheduler may return multiple {@code AllocateResponse}s corresponding
+ to the same ID as and when scheduler allocates {@code Container}(s).
+ <b>Applications</b> can continue to completely ignore the returned ID in
+ the response and use the allocation for any of their outstanding requests.
+ <p>
+ If one wishes to replace an entire {@code ResourceRequest} corresponding to
+ a specific ID, they can simply cancel the corresponding {@code
+ ResourceRequest} and submit a new one afresh.
+
+ @return the <em>ID</em> corresponding to this allocation request.]]>
+      </doc>
+    </method>
+    <method name="setAllocationRequestId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestID" type="long"/>
+      <doc>
+      <![CDATA[Set the optional <em>ID</em> corresponding to this allocation request. This
+ ID is an identifier for different {@code ResourceRequest}s from the <b>same
+ application</b>. The allocated {@code Container}(s) received as part of the
+ {@code AllocateResponse} response will have the ID corresponding to the
+ original {@code ResourceRequest} for which the RM made the allocation.
+ <p>
+ The scheduler may return multiple {@code AllocateResponse}s corresponding
+ to the same ID as and when scheduler allocates {@code Container}(s).
+ <b>Applications</b> can continue to completely ignore the returned ID in
+ the response and use the allocation for any of their outstanding requests.
+ <p>
+ If one wishes to replace an entire {@code ResourceRequest} corresponding to
+ a specific ID, they can simply cancel the corresponding {@code
+ ResourceRequest} and submit a new one afresh.
+ <p>
+ If the ID is not set, scheduler will continue to work as previously and all
+ allocated {@code Container}(s) will have the default ID, -1.
+
+ @param allocationRequestID the <em>ID</em> corresponding to this allocation
+                            request.]]>
+      </doc>
+    </method>
+    <method name="setCapability"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Set the <code>Resource</code> capability of the request.
+ @param capability <code>Resource</code> capability of the request]]>
+      </doc>
+    </method>
+    <method name="getCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Resource</code> capability of the request.
+ @return <code>Resource</code> capability of the request]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.ResourceRequest"/>
+    </method>
+    <field name="ANY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The constant string representing no locality.
+ It should be used by all references that want to pass an arbitrary host
+ name in.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[{@code ResourceRequest} represents the request made
+ by an application to the {@code ResourceManager}
+ to obtain various {@code Container} allocations.
+ <p>
+ It includes:
+ <ul>
+   <li>{@link Priority} of the request.</li>
+   <li>
+     The <em>name</em> of the host or rack on which the allocation is
+     desired. A special value of <em>*</em> signifies that
+     <em>any</em> host/rack is acceptable to the application.
+   </li>
+   <li>{@link Resource} required for each request.</li>
+   <li>
+     Number of containers, of above specifications, which are required
+     by the application.
+   </li>
+   <li>
+     A boolean <em>relaxLocality</em> flag, defaulting to {@code true},
+     which tells the {@code ResourceManager} if the application wants
+     locality to be loose (i.e. allows fall-through to rack or <em>any</em>)
+     or strict (i.e. specify hard constraint on resource allocation).
+   </li>
+ </ul>
+ 
+ @see Resource
+ @see ApplicationMasterProtocol#allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder -->
+  <class name="ResourceRequest.ResourceRequestBuilder" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="priority" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <doc>
+      <![CDATA[Set the <code>priority</code> of the request.
+ @see ResourceRequest#setPriority(Priority)
+ @param priority <code>priority</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="resourceName" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <code>resourceName</code> of the request.
+ @see ResourceRequest#setResourceName(String)
+ @param resourceName <code>resourceName</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="capability" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Set the <code>capability</code> of the request.
+ @see ResourceRequest#setCapability(Resource)
+ @param capability <code>capability</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="numContainers" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numContainers" type="int"/>
+      <doc>
+      <![CDATA[Set the <code>numContainers</code> of the request.
+ @see ResourceRequest#setNumContainers(int)
+ @param numContainers <code>numContainers</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="relaxLocality" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="relaxLocality" type="boolean"/>
+      <doc>
+      <![CDATA[Set the <code>relaxLocality</code> of the request.
+ @see ResourceRequest#setRelaxLocality(boolean)
+ @param relaxLocality <code>relaxLocality</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="nodeLabelExpression" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeLabelExpression" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the <code>nodeLabelExpression</code> of the request.
+ @see ResourceRequest#setNodeLabelExpression(String)
+ @param nodeLabelExpression
+          <code>nodeLabelExpression</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="executionTypeRequest" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="executionTypeRequest" type="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"/>
+      <doc>
+      <![CDATA[Set the <code>executionTypeRequest</code> of the request.
+ @see ResourceRequest#setExecutionTypeRequest(
+ ExecutionTypeRequest)
+ @param executionTypeRequest
+          <code>executionTypeRequest</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="executionType" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <doc>
+      <![CDATA[Set the <code>executionTypeRequest</code> of the request with 'ensure
+ execution type' flag set to true.
+ @see ResourceRequest#setExecutionTypeRequest(
+ ExecutionTypeRequest)
+ @param executionType <code>executionType</code> of the request.
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="allocationRequestId" return="org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestId" type="long"/>
+      <doc>
+      <![CDATA[Set the <code>allocationRequestId</code> of the request.
+ @see ResourceRequest#setAllocationRequestId(long)
+ @param allocationRequestId
+          <code>allocationRequestId</code> of the request
+ @return {@link ResourceRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="build" return="org.apache.hadoop.yarn.api.records.ResourceRequest"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return generated {@link ResourceRequest} object.
+ @return {@link ResourceRequest}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Class to construct instances of {@link ResourceRequest} with specific
+ options.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestBuilder -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestComparator -->
+  <class name="ResourceRequest.ResourceRequestComparator" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.util.Comparator"/>
+    <implements name="java.io.Serializable"/>
+    <constructor name="ResourceRequestComparator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="compare" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="r1" type="org.apache.hadoop.yarn.api.records.ResourceRequest"/>
+      <param name="r2" type="org.apache.hadoop.yarn.api.records.ResourceRequest"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceRequest.ResourceRequestComparator -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceSizing -->
+  <class name="ResourceSizing" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceSizing"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceSizing"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resources" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceSizing"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAllocations" type="int"/>
+      <param name="resources" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="getNumAllocations" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setNumAllocations"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="numAllocations" type="int"/>
+    </method>
+    <method name="getResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setResources"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resources" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[{@code ResourceSizing} contains information for the size of a
+ {@link SchedulingRequest}, such as the number of requested allocations and
+ the resources for each allocation.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceSizing -->
+  <!-- start class org.apache.hadoop.yarn.api.records.ResourceUtilization -->
+  <class name="ResourceUtilization" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="ResourceUtilization"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceUtilization"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pmem" type="int"/>
+      <param name="vmem" type="int"/>
+      <param name="cpu" type="float"/>
+    </method>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.ResourceUtilization"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceUtil" type="org.apache.hadoop.yarn.api.records.ResourceUtilization"/>
+    </method>
+    <method name="getVirtualMemory" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get used <em>virtual memory</em>.
+
+ @return <em>virtual memory</em> in MB]]>
+      </doc>
+    </method>
+    <method name="setVirtualMemory"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="vmem" type="int"/>
+      <doc>
+      <![CDATA[Set used <em>virtual memory</em>.
+
+ @param vmem <em>virtual memory</em> in MB]]>
+      </doc>
+    </method>
+    <method name="getPhysicalMemory" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>physical memory</em>.
+
+ @return <em>physical memory</em> in MB]]>
+      </doc>
+    </method>
+    <method name="setPhysicalMemory"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pmem" type="int"/>
+      <doc>
+      <![CDATA[Set <em>physical memory</em>.
+
+ @param pmem <em>physical memory</em> in MB]]>
+      </doc>
+    </method>
+    <method name="getCPU" return="float"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get <em>CPU</em> utilization.
+
+ @return <em>CPU utilization</em> normalized to 1 CPU]]>
+      </doc>
+    </method>
+    <method name="setCPU"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cpu" type="float"/>
+      <doc>
+      <![CDATA[Set <em>CPU</em> utilization.
+
+ @param cpu <em>CPU utilization</em> normalized to 1 CPU]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="addTo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pmem" type="int"/>
+      <param name="vmem" type="int"/>
+      <param name="cpu" type="float"/>
+      <doc>
+      <![CDATA[Add utilization to the current one.
+ @param pmem Physical memory used to add.
+ @param vmem Virtual memory used to add.
+ @param cpu CPU utilization to add.]]>
+      </doc>
+    </method>
+    <method name="subtractFrom"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pmem" type="int"/>
+      <param name="vmem" type="int"/>
+      <param name="cpu" type="float"/>
+      <doc>
+      <![CDATA[Subtract utilization from the current one.
+ @param pmem Physical memory to be subtracted.
+ @param vmem Virtual memory to be subtracted.
+ @param cpu CPU utilization to be subtracted.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ <code>ResourceUtilization</code> models the utilization of a set of computer
+ resources in the cluster.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.ResourceUtilization -->
+  <!-- start class org.apache.hadoop.yarn.api.records.SchedulingRequest -->
+  <class name="SchedulingRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SchedulingRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.SchedulingRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestId" type="long"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"/>
+      <param name="allocationTags" type="java.util.Set"/>
+      <param name="resourceSizing" type="org.apache.hadoop.yarn.api.records.ResourceSizing"/>
+      <param name="placementConstraintExpression" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint"/>
+    </method>
+    <method name="newBuilder" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocationRequestId" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAllocationRequestId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestId" type="long"/>
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setPriority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"/>
+    </method>
+    <method name="getAllocationTags" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAllocationTags"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationTags" type="java.util.Set"/>
+    </method>
+    <method name="getResourceSizing" return="org.apache.hadoop.yarn.api.records.ResourceSizing"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setResourceSizing"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceSizing" type="org.apache.hadoop.yarn.api.records.ResourceSizing"/>
+    </method>
+    <method name="getPlacementConstraint" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setPlacementConstraint"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="placementConstraint" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint"/>
+    </method>
+    <doc>
+    <![CDATA[{@code SchedulingRequest} represents a request made by an application to the
+ {@code ResourceManager} to obtain an allocation. It is similar to the
+ {@link ResourceRequest}. However, it is more complete than the latter, as it
+ allows applications to specify allocation tags (e.g., to express that an
+ allocation belongs to {@code Spark} or is an {@code HBase-master}), as well
+ as involved {@link PlacementConstraint}s (e.g., anti-affinity between Spark
+ and HBase allocations).
+
+ The size specification of the allocation is in {@code ResourceSizing}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.SchedulingRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder -->
+  <class name="SchedulingRequest.SchedulingRequestBuilder" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="allocationRequestId" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestId" type="long"/>
+      <doc>
+      <![CDATA[Set the <code>allocationRequestId</code> of the request.
+
+ @see SchedulingRequest#setAllocationRequestId(long)
+ @param allocationRequestId <code>allocationRequestId</code> of the
+          request
+ @return {@link SchedulingRequest.SchedulingRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="priority" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <doc>
+      <![CDATA[Set the <code>priority</code> of the request.
+
+ @param priority <code>priority</code> of the request
+ @return {@link SchedulingRequest.SchedulingRequestBuilder}
+ @see SchedulingRequest#setPriority(Priority)]]>
+      </doc>
+    </method>
+    <method name="executionType" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionTypeRequest"/>
+      <doc>
+      <![CDATA[Set the <code>executionType</code> of the request.
+
+ @see SchedulingRequest#setExecutionType(ExecutionTypeRequest)
+ @param executionType <code>executionType</code> of the request
+ @return {@link SchedulingRequest.SchedulingRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="allocationTags" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationTags" type="java.util.Set"/>
+      <doc>
+      <![CDATA[Set the <code>allocationTags</code> of the request.
+
+ @see SchedulingRequest#setAllocationTags(Set)
+ @param allocationTags <code>allocationsTags</code> of the request
+ @return {@link SchedulingRequest.SchedulingRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="resourceSizing" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="resourceSizing" type="org.apache.hadoop.yarn.api.records.ResourceSizing"/>
+      <doc>
+      <![CDATA[Set the <code>executionType</code> of the request.
+
+ @see SchedulingRequest#setResourceSizing(ResourceSizing)
+ @param resourceSizing <code>resourceSizing</code> of the request
+ @return {@link SchedulingRequest.SchedulingRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="placementConstraintExpression" return="org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="placementConstraintExpression" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint"/>
+      <doc>
+      <![CDATA[Set the <code>placementConstraintExpression</code> of the request.
+
+ @see SchedulingRequest#setPlacementConstraint(
+      PlacementConstraint)
+ @param placementConstraintExpression <code>placementConstraints</code> of
+          the request
+ @return {@link SchedulingRequest.SchedulingRequestBuilder}]]>
+      </doc>
+    </method>
+    <method name="build" return="org.apache.hadoop.yarn.api.records.SchedulingRequest"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return generated {@link SchedulingRequest} object.
+
+ @return {@link SchedulingRequest}]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Class to construct instances of {@link SchedulingRequest} with specific
+ options.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.SchedulingRequest.SchedulingRequestBuilder -->
+  <!-- start class org.apache.hadoop.yarn.api.records.SignalContainerCommand -->
+  <class name="SignalContainerCommand" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.SignalContainerCommand[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.SignalContainerCommand"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of various signal container commands.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.SignalContainerCommand -->
+  <!-- start class org.apache.hadoop.yarn.api.records.StrictPreemptionContract -->
+  <class name="StrictPreemptionContract" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StrictPreemptionContract"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getContainers" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the set of {@link PreemptionContainer} specifying containers owned by
+ the <code>ApplicationMaster</code> that may be reclaimed by the
+ <code>ResourceManager</code>.
+ @return the set of {@link ContainerId} to be preempted.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of particular allocations to be reclaimed. The platform will
+ reclaim exactly these resources, so the <code>ApplicationMaster</code> (AM)
+ may attempt to checkpoint work or adjust its execution plan to accommodate
+ it. In contrast to {@link PreemptionContract}, the AM has no flexibility in
+ selecting which resources to return to the cluster.
+ @see PreemptionMessage]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.StrictPreemptionContract -->
+  <!-- start class org.apache.hadoop.yarn.api.records.Token -->
+  <class name="Token" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="Token"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getIdentifier" return="java.nio.ByteBuffer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the token identifier.
+ @return token identifier]]>
+      </doc>
+    </method>
+    <method name="getPassword" return="java.nio.ByteBuffer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the token password
+ @return token password]]>
+      </doc>
+    </method>
+    <method name="getKind" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the token kind.
+ @return token kind]]>
+      </doc>
+    </method>
+    <method name="getService" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the service to which the token is allocated.
+ @return service to which the token is allocated]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p><code>Token</code> is the security entity used by the framework
+ to verify authenticity of any resource.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.Token -->
+  <!-- start class org.apache.hadoop.yarn.api.records.UpdateContainerError -->
+  <class name="UpdateContainerError" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdateContainerError"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.UpdateContainerError"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reason" type="java.lang.String"/>
+      <param name="updateContainerRequest" type="org.apache.hadoop.yarn.api.records.UpdateContainerRequest"/>
+    </method>
+    <method name="getReason" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get reason why the update request was not satisfiable.
+ @return Reason]]>
+      </doc>
+    </method>
+    <method name="setReason"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="reason" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set reason why the update request was not satisfiable.
+ @param reason Reason]]>
+      </doc>
+    </method>
+    <method name="getCurrentContainerVersion" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get current container version.
+ @return Current container Version.]]>
+      </doc>
+    </method>
+    <method name="setCurrentContainerVersion"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="currentVersion" type="int"/>
+      <doc>
+      <![CDATA[Set current container version.
+ @param currentVersion Current container version.]]>
+      </doc>
+    </method>
+    <method name="getUpdateContainerRequest" return="org.apache.hadoop.yarn.api.records.UpdateContainerRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the {@code UpdateContainerRequest} that was not satisfiable.
+ @return UpdateContainerRequest]]>
+      </doc>
+    </method>
+    <method name="setUpdateContainerRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateContainerRequest" type="org.apache.hadoop.yarn.api.records.UpdateContainerRequest"/>
+      <doc>
+      <![CDATA[Set the {@code UpdateContainerRequest} that was not satisfiable.
+ @param updateContainerRequest Update Container Request]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[{@code UpdateContainerError} is used by the Scheduler to notify the
+ ApplicationMaster of an UpdateContainerRequest it cannot satisfy due to
+ an error in the request. It includes the update request as well as
+ a reason for why the request was not satisfiable.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.UpdateContainerError -->
+  <!-- start class org.apache.hadoop.yarn.api.records.UpdateContainerRequest -->
+  <class name="UpdateContainerRequest" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdateContainerRequest"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.UpdateContainerRequest"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="version" type="int"/>
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="updateType" type="org.apache.hadoop.yarn.api.records.ContainerUpdateType"/>
+      <param name="targetCapability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="targetExecutionType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+    </method>
+    <method name="getContainerVersion" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container.
+ @return <code>ContainerId</code> of the container]]>
+      </doc>
+    </method>
+    <method name="setContainerVersion"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerVersion" type="int"/>
+      <doc>
+      <![CDATA[Set the current version of the container.
+ @param containerVersion of the container]]>
+      </doc>
+    </method>
+    <method name="getContainerUpdateType" return="org.apache.hadoop.yarn.api.records.ContainerUpdateType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerUpdateType</code> of the container.
+ @return <code>ContainerUpdateType</code> of the container.]]>
+      </doc>
+    </method>
+    <method name="setContainerUpdateType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateType" type="org.apache.hadoop.yarn.api.records.ContainerUpdateType"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerUpdateType</code> of the container.
+ @param updateType of the Container]]>
+      </doc>
+    </method>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerId</code> of the container.
+ @return <code>ContainerId</code> of the container]]>
+      </doc>
+    </method>
+    <method name="setContainerId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerId</code> of the container.
+ @param containerId <code>ContainerId</code> of the container]]>
+      </doc>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the target <code>ExecutionType</code> of the container.
+ @return <code>ExecutionType</code> of the container]]>
+      </doc>
+    </method>
+    <method name="setExecutionType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <doc>
+      <![CDATA[Set the target <code>ExecutionType</code> of the container.
+ @param executionType <code>ExecutionType</code> of the container]]>
+      </doc>
+    </method>
+    <method name="setCapability"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Set the <code>Resource</code> capability of the request.
+ @param capability <code>Resource</code> capability of the request]]>
+      </doc>
+    </method>
+    <method name="getCapability" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Resource</code> capability of the request.
+ @return <code>Resource</code> capability of the request]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[{@code UpdateContainerRequest} represents the request made by an
+ application to the {@code ResourceManager} to update an attribute of a
+ {@code Container} such as its Resource allocation or (@code ExecutionType}
+ <p>
+ It includes:
+ <ul>
+   <li>version for the container.</li>
+   <li>{@link ContainerId} for the container.</li>
+   <li>
+     {@link Resource} capability of the container after the update request
+     is completed.
+   </li>
+   <li>
+     {@link ExecutionType} of the container after the update request is
+     completed.
+   </li>
+ </ul>
+
+ Update rules:
+ <ul>
+   <li>
+     Currently only ONE aspect of the container can be updated per request
+     (user can either update Capability OR ExecutionType in one request..
+     not both).
+   </li>
+   <li>
+     There must be only 1 update request per container in an allocate call.
+   </li>
+   <li>
+     If a new update request is sent for a container (in a subsequent allocate
+     call) before the first one is satisfied by the Scheduler, it will
+     overwrite the previous request.
+   </li>
+ </ul>
+ @see ApplicationMasterProtocol#allocate(org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.UpdateContainerRequest -->
+  <!-- start class org.apache.hadoop.yarn.api.records.UpdatedContainer -->
+  <class name="UpdatedContainer" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UpdatedContainer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.UpdatedContainer"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateType" type="org.apache.hadoop.yarn.api.records.ContainerUpdateType"/>
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <doc>
+      <![CDATA[Static Factory method.
+
+ @param updateType ContainerUpdateType
+ @param container Container
+ @return UpdatedContainer]]>
+      </doc>
+    </method>
+    <method name="getUpdateType" return="org.apache.hadoop.yarn.api.records.ContainerUpdateType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ContainerUpdateType</code>.
+ @return ContainerUpdateType]]>
+      </doc>
+    </method>
+    <method name="setUpdateType"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="updateType" type="org.apache.hadoop.yarn.api.records.ContainerUpdateType"/>
+      <doc>
+      <![CDATA[Set the <code>ContainerUpdateType</code>.
+ @param updateType ContainerUpdateType]]>
+      </doc>
+    </method>
+    <method name="getContainer" return="org.apache.hadoop.yarn.api.records.Container"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>Container</code>.
+ @return Container]]>
+      </doc>
+    </method>
+    <method name="setContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <doc>
+      <![CDATA[Set the <code>Container</code>.
+ @param container Container]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[An object that encapsulates an updated container and the
+ type of Update.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.UpdatedContainer -->
+  <!-- start class org.apache.hadoop.yarn.api.records.URL -->
+  <class name="URL" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="URL"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scheme" type="java.lang.String"/>
+      <param name="host" type="java.lang.String"/>
+      <param name="port" type="int"/>
+      <param name="file" type="java.lang.String"/>
+    </method>
+    <method name="getScheme" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the scheme of the URL.
+ @return scheme of the URL]]>
+      </doc>
+    </method>
+    <method name="setScheme"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scheme" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the scheme of the URL
+ @param scheme scheme of the URL]]>
+      </doc>
+    </method>
+    <method name="getUserInfo" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user info of the URL.
+ @return user info of the URL]]>
+      </doc>
+    </method>
+    <method name="setUserInfo"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="userInfo" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the user info of the URL.
+ @param userInfo user info of the URL]]>
+      </doc>
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the host of the URL.
+ @return host of the URL]]>
+      </doc>
+    </method>
+    <method name="setHost"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="host" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the host of the URL.
+ @param host host of the URL]]>
+      </doc>
+    </method>
+    <method name="getPort" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the port of the URL.
+ @return port of the URL]]>
+      </doc>
+    </method>
+    <method name="setPort"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="port" type="int"/>
+      <doc>
+      <![CDATA[Set the port of the URL
+ @param port port of the URL]]>
+      </doc>
+    </method>
+    <method name="getFile" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the file of the URL.
+ @return file of the URL]]>
+      </doc>
+    </method>
+    <method name="setFile"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="file" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the file of the URL.
+ @param file file of the URL]]>
+      </doc>
+    </method>
+    <method name="toPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="URISyntaxException" type="java.net.URISyntaxException"/>
+    </method>
+    <method name="fromURI" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uri" type="java.net.URI"/>
+    </method>
+    <method name="fromPath" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <doc>
+    <![CDATA[<p><code>URL</code> represents a serializable {@link java.net.URL}.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.URL -->
+  <!-- start class org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState -->
+  <class name="YarnApplicationAttemptState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of various states of a <code>RMAppAttempt</code>.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.YarnApplicationState -->
+  <class name="YarnApplicationState" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.YarnApplicationState[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.YarnApplicationState"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[Enumeration of various states of an <code>ApplicationMaster</code>.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.YarnApplicationState -->
+  <!-- start class org.apache.hadoop.yarn.api.records.YarnClusterMetrics -->
+  <class name="YarnClusterMetrics" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="YarnClusterMetrics"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNumNodeManagers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of <code>NodeManager</code>s in the cluster.
+ @return number of <code>NodeManager</code>s in the cluster]]>
+      </doc>
+    </method>
+    <method name="getNumDecommissionedNodeManagers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of <code>DecommissionedNodeManager</code>s in the cluster.
+ 
+ @return number of <code>DecommissionedNodeManager</code>s in the cluster]]>
+      </doc>
+    </method>
+    <method name="getNumActiveNodeManagers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of <code>ActiveNodeManager</code>s in the cluster.
+ 
+ @return number of <code>ActiveNodeManager</code>s in the cluster]]>
+      </doc>
+    </method>
+    <method name="getNumLostNodeManagers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of <code>LostNodeManager</code>s in the cluster.
+ 
+ @return number of <code>LostNodeManager</code>s in the cluster]]>
+      </doc>
+    </method>
+    <method name="getNumUnhealthyNodeManagers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of <code>UnhealthyNodeManager</code>s in the cluster.
+ 
+ @return number of <code>UnhealthyNodeManager</code>s in the cluster]]>
+      </doc>
+    </method>
+    <method name="getNumRebootedNodeManagers" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the number of <code>RebootedNodeManager</code>s in the cluster.
+ 
+ @return number of <code>RebootedNodeManager</code>s in the cluster]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p><code>YarnClusterMetrics</code> represents cluster metrics.</p>
+ 
+ <p>Currently only number of <code>NodeManager</code>s is provided.</p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.YarnClusterMetrics -->
+</package>
+<package name="org.apache.hadoop.yarn.api.records.impl">
+</package>
+<package name="org.apache.hadoop.yarn.api.records.timeline">
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineAbout -->
+  <class name="TimelineAbout" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineAbout"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TimelineAbout" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAbout" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setAbout"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="about" type="java.lang.String"/>
+    </method>
+    <method name="getTimelineServiceVersion" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setTimelineServiceVersion"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineServiceVersion" type="java.lang.String"/>
+    </method>
+    <method name="getTimelineServiceBuildVersion" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setTimelineServiceBuildVersion"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineServiceBuildVersion" type="java.lang.String"/>
+    </method>
+    <method name="getTimelineServiceVersionBuiltOn" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setTimelineServiceVersionBuiltOn"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineServiceVersionBuiltOn" type="java.lang.String"/>
+    </method>
+    <method name="getHadoopVersion" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setHadoopVersion"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hadoopVersion" type="java.lang.String"/>
+    </method>
+    <method name="getHadoopBuildVersion" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setHadoopBuildVersion"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hadoopBuildVersion" type="java.lang.String"/>
+    </method>
+    <method name="getHadoopVersionBuiltOn" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setHadoopVersionBuiltOn"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hadoopVersionBuiltOn" type="java.lang.String"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineAbout -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse -->
+  <class name="TimelineDelegationTokenResponse" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineDelegationTokenResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+    </method>
+    <method name="getContent" return="java.lang.Object"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setContent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="content" type="java.lang.Object"/>
+    </method>
+    <doc>
+    <![CDATA[The response of delegation token related request]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineDelegationTokenResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineDomain -->
+  <class name="TimelineDomain" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineDomain"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the domain ID
+ 
+ @return the domain ID]]>
+      </doc>
+    </method>
+    <method name="setId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the domain ID
+ 
+ @param id the domain ID]]>
+      </doc>
+    </method>
+    <method name="getDescription" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the domain description
+ 
+ @return the domain description]]>
+      </doc>
+    </method>
+    <method name="setDescription"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="description" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the domain description
+ 
+ @param description the domain description]]>
+      </doc>
+    </method>
+    <method name="getOwner" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the domain owner
+ 
+ @return the domain owner]]>
+      </doc>
+    </method>
+    <method name="setOwner"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="owner" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the domain owner. The user doesn't need to set it, which will
+ automatically set to the user who puts the domain.
+ 
+ @param owner the domain owner]]>
+      </doc>
+    </method>
+    <method name="getReaders" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reader (and/or reader group) list string
+ 
+ @return the reader (and/or reader group) list string]]>
+      </doc>
+    </method>
+    <method name="setReaders"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="readers" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the reader (and/or reader group) list string
+ 
+ @param readers the reader (and/or reader group) list string]]>
+      </doc>
+    </method>
+    <method name="getWriters" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the writer (and/or writer group) list string
+ 
+ @return the writer (and/or writer group) list string]]>
+      </doc>
+    </method>
+    <method name="setWriters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="writers" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the writer (and/or writer group) list string
+ 
+ @param writers the writer (and/or writer group) list string]]>
+      </doc>
+    </method>
+    <method name="getCreatedTime" return="java.lang.Long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the created time of the domain
+ 
+ @return the created time of the domain]]>
+      </doc>
+    </method>
+    <method name="setCreatedTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="createdTime" type="java.lang.Long"/>
+      <doc>
+      <![CDATA[Set the created time of the domain
+ 
+ @param createdTime the created time of the domain]]>
+      </doc>
+    </method>
+    <method name="getModifiedTime" return="java.lang.Long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the modified time of the domain
+ 
+ @return the modified time of the domain]]>
+      </doc>
+    </method>
+    <method name="setModifiedTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="modifiedTime" type="java.lang.Long"/>
+      <doc>
+      <![CDATA[Set the modified time of the domain
+ 
+ @param modifiedTime the modified time of the domain]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ This class contains the information about a timeline domain, which is used
+ to a user to host a number of timeline entities, isolating them from others'.
+ The user can also define the reader and writer users/groups for the the
+ domain, which is used to control the access to its entities.
+ </p>
+ 
+ <p>
+ The reader and writer users/groups pattern that the user can supply is the
+ same as what <code>AccessControlList</code> takes.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineDomain -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineDomains -->
+  <class name="TimelineDomains" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineDomains"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getDomains" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of domains
+ 
+ @return a list of domains]]>
+      </doc>
+    </method>
+    <method name="addDomain"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="domain" type="org.apache.hadoop.yarn.api.records.timeline.TimelineDomain"/>
+      <doc>
+      <![CDATA[Add a single domain into the existing domain list
+ 
+ @param domain
+          a single domain]]>
+      </doc>
+    </method>
+    <method name="addDomains"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="domains" type="java.util.List"/>
+      <doc>
+      <![CDATA[All a list of domains into the existing domain list
+ 
+ @param domains
+          a list of domains]]>
+      </doc>
+    </method>
+    <method name="setDomains"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="domains" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the domain list to the given list of domains
+ 
+ @param domains
+          a list of domains]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The class that hosts a list of timeline domains.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineDomains -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineEntities -->
+  <class name="TimelineEntities" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineEntities"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getEntities" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of entities
+ 
+ @return a list of entities]]>
+      </doc>
+    </method>
+    <method name="addEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entity" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEntity"/>
+      <doc>
+      <![CDATA[Add a single entity into the existing entity list
+ 
+ @param entity
+          a single entity]]>
+      </doc>
+    </method>
+    <method name="addEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entities" type="java.util.List"/>
+      <doc>
+      <![CDATA[All a list of entities into the existing entity list
+ 
+ @param entities
+          a list of entities]]>
+      </doc>
+    </method>
+    <method name="setEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entities" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the entity list to the given list of entities
+ 
+ @param entities
+          a list of entities]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The class that hosts a list of timeline entities.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineEntities -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineEntity -->
+  <class name="TimelineEntity" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getEntityType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity type
+ 
+ @return the entity type]]>
+      </doc>
+    </method>
+    <method name="setEntityType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityType" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity type
+ 
+ @param entityType
+          the entity type]]>
+      </doc>
+    </method>
+    <method name="getEntityId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity Id
+ 
+ @return the entity Id]]>
+      </doc>
+    </method>
+    <method name="setEntityId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity Id
+ 
+ @param entityId
+          the entity Id]]>
+      </doc>
+    </method>
+    <method name="getStartTime" return="java.lang.Long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the start time of the entity
+ 
+ @return the start time of the entity]]>
+      </doc>
+    </method>
+    <method name="setStartTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startTime" type="java.lang.Long"/>
+      <doc>
+      <![CDATA[Set the start time of the entity
+ 
+ @param startTime
+          the start time of the entity]]>
+      </doc>
+    </method>
+    <method name="getEvents" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of events related to the entity
+ 
+ @return a list of events related to the entity]]>
+      </doc>
+    </method>
+    <method name="addEvent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="event" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEvent"/>
+      <doc>
+      <![CDATA[Add a single event related to the entity to the existing event list
+ 
+ @param event
+          a single event related to the entity]]>
+      </doc>
+    </method>
+    <method name="addEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="events" type="java.util.List"/>
+      <doc>
+      <![CDATA[Add a list of events related to the entity to the existing event list
+ 
+ @param events
+          a list of events related to the entity]]>
+      </doc>
+    </method>
+    <method name="setEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="events" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the event list to the given list of events related to the entity
+ 
+ @param events
+          events a list of events related to the entity]]>
+      </doc>
+    </method>
+    <method name="getRelatedEntities" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the related entities
+ 
+ @return the related entities]]>
+      </doc>
+    </method>
+    <method name="addRelatedEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityType" type="java.lang.String"/>
+      <param name="entityId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Add an entity to the existing related entity map
+ 
+ @param entityType
+          the entity type
+ @param entityId
+          the entity Id]]>
+      </doc>
+    </method>
+    <method name="addRelatedEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="relatedEntities" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Add a map of related entities to the existing related entity map
+ 
+ @param relatedEntities
+          a map of related entities]]>
+      </doc>
+    </method>
+    <method name="setRelatedEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="relatedEntities" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the related entity map to the given map of related entities
+ 
+ @param relatedEntities
+          a map of related entities]]>
+      </doc>
+    </method>
+    <method name="getPrimaryFilters" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the primary filters
+ 
+ @return the primary filters]]>
+      </doc>
+    </method>
+    <method name="addPrimaryFilter"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="value" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Add a single piece of primary filter to the existing primary filter map
+ 
+ @param key
+          the primary filter key
+ @param value
+          the primary filter value]]>
+      </doc>
+    </method>
+    <method name="addPrimaryFilters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="primaryFilters" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Add a map of primary filters to the existing primary filter map
+ 
+ @param primaryFilters
+          a map of primary filters]]>
+      </doc>
+    </method>
+    <method name="setPrimaryFilters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="primaryFilters" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the primary filter map to the given map of primary filters
+ 
+ @param primaryFilters
+          a map of primary filters]]>
+      </doc>
+    </method>
+    <method name="getOtherInfo" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the other information of the entity
+ 
+ @return the other information of the entity]]>
+      </doc>
+    </method>
+    <method name="addOtherInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="value" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Add one piece of other information of the entity to the existing other info
+ map
+ 
+ @param key
+          the other information key
+ @param value
+          the other information value]]>
+      </doc>
+    </method>
+    <method name="addOtherInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="otherInfo" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Add a map of other information of the entity to the existing other info map
+ 
+ @param otherInfo
+          a map of other information]]>
+      </doc>
+    </method>
+    <method name="setOtherInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="otherInfo" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the other info map to the given map of other information
+ 
+ @param otherInfo
+          a map of other information]]>
+      </doc>
+    </method>
+    <method name="getDomainId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the ID of the domain that the entity is to be put
+ 
+ @return the domain ID]]>
+      </doc>
+    </method>
+    <method name="setDomainId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="domainId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the ID of the domain that the entity is to be put
+ 
+ @param domainId
+          the name space ID]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEntity"/>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The class that contains the the meta information of some conceptual entity
+ and its related events. The entity can be an application, an application
+ attempt, a container or whatever the user-defined object.
+ </p>
+ 
+ <p>
+ Primary filters will be used to index the entities in
+ <code>TimelineStore</code>, such that users should carefully choose the
+ information they want to store as the primary filters. The remaining can be
+ stored as other information.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId -->
+  <class name="TimelineEntityGroupId" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="TimelineEntityGroupId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="newInstance" return="org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="id" type="java.lang.String"/>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>ApplicationId</code> of the
+ <code>TimelineEntityGroupId</code>.
+
+ @return <code>ApplicationId</code> of the
+         <code>TimelineEntityGroupId</code>]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appID" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="getTimelineEntityGroupId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <code>timelineEntityGroupId</code>.
+
+ @return <code>timelineEntityGroupId</code>]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="fromString" return="org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineEntityGroupIdStr" type="java.lang.String"/>
+    </method>
+    <field name="TIMELINE_ENTITY_GROUPID_STR_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<p><code>TimelineEntityGroupId</code> is an abstract way for
+ timeline service users to represent #a group of related timeline data.
+ For example, all entities that represents one data flow DAG execution
+ can be grouped into one timeline entity group. </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineEvent -->
+  <class name="TimelineEvent" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="TimelineEvent"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getTimestamp" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the timestamp of the event
+ 
+ @return the timestamp of the event]]>
+      </doc>
+    </method>
+    <method name="setTimestamp"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timestamp" type="long"/>
+      <doc>
+      <![CDATA[Set the timestamp of the event
+ 
+ @param timestamp
+          the timestamp of the event]]>
+      </doc>
+    </method>
+    <method name="getEventType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the event type
+ 
+ @return the event type]]>
+      </doc>
+    </method>
+    <method name="setEventType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventType" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the event type
+ 
+ @param eventType
+          the event type]]>
+      </doc>
+    </method>
+    <method name="getEventInfo" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set the information of the event
+ 
+ @return the information of the event]]>
+      </doc>
+    </method>
+    <method name="addEventInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="value" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Add one piece of the information of the event to the existing information
+ map
+ 
+ @param key
+          the information key
+ @param value
+          the information value]]>
+      </doc>
+    </method>
+    <method name="addEventInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventInfo" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Add a map of the information of the event to the existing information map
+ 
+ @param eventInfo
+          a map of of the information of the event]]>
+      </doc>
+    </method>
+    <method name="setEventInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventInfo" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Set the information map to the given map of the information of the event
+ 
+ @param eventInfo
+          a map of of the information of the event]]>
+      </doc>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEvent"/>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[The class that contains the information of an event that is related to some
+ conceptual entity of an application. Users are free to define what the event
+ means, such as starting an application, getting allocated a container and
+ etc.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineEvent -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineEvents -->
+  <class name="TimelineEvents" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineEvents"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAllEvents" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of {@link EventsOfOneEntity} instances
+ 
+ @return a list of {@link EventsOfOneEntity} instances]]>
+      </doc>
+    </method>
+    <method name="addEvent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventsOfOneEntity" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEvents.EventsOfOneEntity"/>
+      <doc>
+      <![CDATA[Add a single {@link EventsOfOneEntity} instance into the existing list
+ 
+ @param eventsOfOneEntity
+          a single {@link EventsOfOneEntity} instance]]>
+      </doc>
+    </method>
+    <method name="addEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allEvents" type="java.util.List"/>
+      <doc>
+      <![CDATA[Add a list of {@link EventsOfOneEntity} instances into the existing list
+ 
+ @param allEvents
+          a list of {@link EventsOfOneEntity} instances]]>
+      </doc>
+    </method>
+    <method name="setEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allEvents" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list to the given list of {@link EventsOfOneEntity} instances
+ 
+ @param allEvents
+          a list of {@link EventsOfOneEntity} instances]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The class that hosts a list of events, which are categorized according to
+ their related entities.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineEvents -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineEvents.EventsOfOneEntity -->
+  <class name="TimelineEvents.EventsOfOneEntity" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="EventsOfOneEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getEntityId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity Id
+ 
+ @return the entity Id]]>
+      </doc>
+    </method>
+    <method name="setEntityId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity Id
+ 
+ @param entityId
+          the entity Id]]>
+      </doc>
+    </method>
+    <method name="getEntityType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity type
+ 
+ @return the entity type]]>
+      </doc>
+    </method>
+    <method name="setEntityType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityType" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity type
+ 
+ @param entityType
+          the entity type]]>
+      </doc>
+    </method>
+    <method name="getEvents" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of events
+ 
+ @return a list of events]]>
+      </doc>
+    </method>
+    <method name="addEvent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="event" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEvent"/>
+      <doc>
+      <![CDATA[Add a single event to the existing event list
+ 
+ @param event
+          a single event]]>
+      </doc>
+    </method>
+    <method name="addEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="events" type="java.util.List"/>
+      <doc>
+      <![CDATA[Add a list of event to the existing event list
+ 
+ @param events
+          a list of events]]>
+      </doc>
+    </method>
+    <method name="setEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="events" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the event list to the given list of events
+ 
+ @param events
+          a list of events]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[The class that hosts a list of events that are only related to one entity.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineEvents.EventsOfOneEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelineHealth -->
+  <class name="TimelineHealth" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineHealth" type="org.apache.hadoop.yarn.api.records.timeline.TimelineHealth.TimelineHealthStatus, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TimelineHealth"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getHealthStatus" return="org.apache.hadoop.yarn.api.records.timeline.TimelineHealth.TimelineHealthStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDiagnosticsInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setHealthStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="healthStatus" type="org.apache.hadoop.yarn.api.records.timeline.TimelineHealth.TimelineHealthStatus"/>
+    </method>
+    <method name="setDiagnosticsInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="diagnosticsInfo" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[This class holds health information for ATS.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelineHealth -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse -->
+  <class name="TimelinePutResponse" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelinePutResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getErrors" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of {@link TimelinePutError} instances
+ 
+ @return a list of {@link TimelinePutError} instances]]>
+      </doc>
+    </method>
+    <method name="addError"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="error" type="org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse.TimelinePutError"/>
+      <doc>
+      <![CDATA[Add a single {@link TimelinePutError} instance into the existing list
+ 
+ @param error
+          a single {@link TimelinePutError} instance]]>
+      </doc>
+    </method>
+    <method name="addErrors"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="errors" type="java.util.List"/>
+      <doc>
+      <![CDATA[Add a list of {@link TimelinePutError} instances into the existing list
+ 
+ @param errors
+          a list of {@link TimelinePutError} instances]]>
+      </doc>
+    </method>
+    <method name="setErrors"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="errors" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list to the given list of {@link TimelinePutError} instances
+ 
+ @param errors
+          a list of {@link TimelinePutError} instances]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A class that holds a list of put errors. This is the response returned when a
+ list of {@link TimelineEntity} objects is added to the timeline. If there are errors
+ in storing individual entity objects, they will be indicated in the list of
+ errors.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse.TimelinePutError -->
+  <class name="TimelinePutResponse.TimelinePutError" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelinePutError"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getEntityId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity Id
+ 
+ @return the entity Id]]>
+      </doc>
+    </method>
+    <method name="setEntityId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity Id
+ 
+ @param entityId
+          the entity Id]]>
+      </doc>
+    </method>
+    <method name="getEntityType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity type
+ 
+ @return the entity type]]>
+      </doc>
+    </method>
+    <method name="setEntityType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityType" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity type
+ 
+ @param entityType
+          the entity type]]>
+      </doc>
+    </method>
+    <method name="getErrorCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the error code
+ 
+ @return an error code]]>
+      </doc>
+    </method>
+    <method name="setErrorCode"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="errorCode" type="int"/>
+      <doc>
+      <![CDATA[Set the error code to the given error code
+ 
+ @param errorCode
+          an error code]]>
+      </doc>
+    </method>
+    <field name="NO_START_TIME" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned when no start time can be found when putting an
+ entity. This occurs when the entity does not already exist in the store
+ and it is put with no start time or events specified.]]>
+      </doc>
+    </field>
+    <field name="IO_EXCEPTION" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if an IOException is encountered when putting an
+ entity.]]>
+      </doc>
+    </field>
+    <field name="SYSTEM_FILTER_CONFLICT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if the user specifies the timeline system reserved
+ filter key]]>
+      </doc>
+    </field>
+    <field name="ACCESS_DENIED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if the user is denied to access the timeline data]]>
+      </doc>
+    </field>
+    <field name="NO_DOMAIN" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if the entity doesn't have an valid domain ID]]>
+      </doc>
+    </field>
+    <field name="FORBIDDEN_RELATION" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if the user is denied to relate the entity to another
+ one in different domain]]>
+      </doc>
+    </field>
+    <field name="EXPIRED_ENTITY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if the entity start time is before the eviction
+ period of old data.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A class that holds the error code for one entity.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse.TimelinePutError -->
+</package>
+<package name="org.apache.hadoop.yarn.api.records.timelineservice">
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.ApplicationAttemptEntity -->
+  <class name="ApplicationAttemptEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationAttemptEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationAttemptEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This entity represents an application attempt.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.ApplicationAttemptEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.ApplicationEntity -->
+  <class name="ApplicationEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getQueue" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setQueue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queue" type="java.lang.String"/>
+    </method>
+    <method name="isApplicationEntity" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="te" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"/>
+      <doc>
+      <![CDATA[Checks if the input TimelineEntity object is an ApplicationEntity.
+
+ @param te TimelineEntity object.
+ @return true if input is an ApplicationEntity, false otherwise]]>
+      </doc>
+    </method>
+    <method name="getApplicationEvent" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="te" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"/>
+      <param name="eventId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[@param te TimelineEntity object.
+ @param eventId event with this id needs to be fetched
+ @return TimelineEvent if TimelineEntity contains the desired event.]]>
+      </doc>
+    </method>
+    <field name="QUEUE_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This entity represents an application.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.ApplicationEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.ClusterEntity -->
+  <class name="ClusterEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ClusterEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ClusterEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This entity represents a YARN cluster.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.ClusterEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.ContainerEntity -->
+  <class name="ContainerEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This entity represents a container belonging to an application attempt.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.ContainerEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.FlowActivityEntity -->
+  <class name="FlowActivityEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FlowActivityEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FlowActivityEntity" type="java.lang.String, long, java.lang.String, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FlowActivityEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"/>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+      <doc>
+      <![CDATA[Reuse the base class equals method.]]>
+      </doc>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Reuse the base class hashCode method.]]>
+      </doc>
+    </method>
+    <method name="getCluster" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setCluster"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cluster" type="java.lang.String"/>
+    </method>
+    <method name="getDate" return="java.util.Date"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setDate"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="time" type="long"/>
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setUser"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="user" type="java.lang.String"/>
+    </method>
+    <method name="getFlowName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setFlowName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flowName" type="java.lang.String"/>
+    </method>
+    <method name="addFlowRun"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="run" type="org.apache.hadoop.yarn.api.records.timelineservice.FlowRunEntity"/>
+    </method>
+    <method name="addFlowRuns"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="runs" type="java.util.Collection"/>
+    </method>
+    <method name="getFlowRuns" return="java.util.NavigableSet"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNumberOfRuns" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="CLUSTER_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DATE_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="USER_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_NAME_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Entity that represents a record for flow activity. It's essentially a
+ container entity for flow runs with limited information.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.FlowActivityEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.FlowRunEntity -->
+  <class name="FlowRunEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="FlowRunEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="FlowRunEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setUser"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="user" type="java.lang.String"/>
+    </method>
+    <method name="getName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setName"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <method name="getVersion" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setVersion"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="version" type="java.lang.String"/>
+    </method>
+    <method name="getRunId" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setRunId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="runId" type="long"/>
+    </method>
+    <method name="getStartTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setStartTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="startTime" type="long"/>
+    </method>
+    <method name="getMaxEndTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setMaxEndTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="endTime" type="long"/>
+    </method>
+    <field name="USER_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_NAME_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_VERSION_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_RUN_ID_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_RUN_END_TIME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This entity represents a flow run.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.FlowRunEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity -->
+  <class name="HierarchicalTimelineEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getParent" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity.Identifier"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setParent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="parent" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity.Identifier"/>
+    </method>
+    <method name="setParent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="id" type="java.lang.String"/>
+    </method>
+    <method name="getChildren" return="java.util.Set"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setChildren"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="children" type="java.util.Set"/>
+    </method>
+    <method name="addChildren"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="children" type="java.util.Set"/>
+    </method>
+    <method name="addChild"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="child" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity.Identifier"/>
+    </method>
+    <method name="addChild"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="id" type="java.lang.String"/>
+    </method>
+    <field name="PARENT_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CHILDREN_INFO_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class extends timeline entity and defines parent-child relationships
+ with other entities.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.QueueEntity -->
+  <class name="QueueEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="QueueEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="QueueEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This entity represents a queue.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.QueueEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.SubApplicationEntity -->
+  <class name="SubApplicationEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.HierarchicalTimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SubApplicationEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="isSubApplicationEntity" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="te" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"/>
+      <doc>
+      <![CDATA[Checks if the input TimelineEntity object is an SubApplicationEntity.
+
+ @param te TimelineEntity object.
+ @return true if input is an SubApplicationEntity, false otherwise]]>
+      </doc>
+    </method>
+    <method name="setApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="java.lang.String"/>
+    </method>
+    <field name="YARN_APPLICATION_ID" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This entity represents a user defined entities to be stored under sub
+ application table.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.SubApplicationEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain -->
+  <class name="TimelineDomain" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineDomain"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the domain ID.
+ @return the domain ID]]>
+      </doc>
+    </method>
+    <method name="setId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the domain ID.
+ @param id the domain ID]]>
+      </doc>
+    </method>
+    <method name="getDescription" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the domain description.
+ @return the domain description]]>
+      </doc>
+    </method>
+    <method name="setDescription"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="description" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the domain description.
+ @param description the domain description]]>
+      </doc>
+    </method>
+    <method name="getOwner" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the domain owner.
+ @return the domain owner]]>
+      </doc>
+    </method>
+    <method name="setOwner"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="owner" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the domain owner. The user doesn't need to set it, which will
+ automatically set to the user who puts the domain.
+ @param owner the domain owner]]>
+      </doc>
+    </method>
+    <method name="getReaders" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the reader (and/or reader group) list string.
+ @return the reader (and/or reader group) list string]]>
+      </doc>
+    </method>
+    <method name="setReaders"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="readers" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the reader (and/or reader group) list string.
+ @param readers the reader (and/or reader group) list string]]>
+      </doc>
+    </method>
+    <method name="getWriters" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the writer (and/or writer group) list string.
+ @return the writer (and/or writer group) list string]]>
+      </doc>
+    </method>
+    <method name="setWriters"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="writers" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the writer (and/or writer group) list string.
+ @param writers the writer (and/or writer group) list string]]>
+      </doc>
+    </method>
+    <method name="getCreatedTime" return="java.lang.Long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the created time of the domain.
+ @return the created time of the domain]]>
+      </doc>
+    </method>
+    <method name="setCreatedTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="createdTime" type="java.lang.Long"/>
+      <doc>
+      <![CDATA[Set the created time of the domain.
+ @param createdTime the created time of the domain]]>
+      </doc>
+    </method>
+    <method name="getModifiedTime" return="java.lang.Long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the modified time of the domain.
+ @return the modified time of the domain]]>
+      </doc>
+    </method>
+    <method name="setModifiedTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="modifiedTime" type="java.lang.Long"/>
+      <doc>
+      <![CDATA[Set the modified time of the domain.
+ @param modifiedTime the modified time of the domain]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ This class contains the information about a timeline service domain, which is
+ used to a user to host a number of timeline entities, isolating them from
+ others'. The user can also define the reader and writer users/groups for
+ the domain, which is used to control the access to its entities.
+ </p>
+ <p>
+ The reader and writer users/groups pattern that the user can supply is the
+ same as what <code>AccessControlList</code> takes.
+ </p>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineDomain -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities -->
+  <class name="TimelineEntities" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineEntities"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getEntities" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineEntities" type="java.util.List"/>
+    </method>
+    <method name="addEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineEntities" type="java.util.List"/>
+    </method>
+    <method name="addEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"/>
+    </method>
+    <doc>
+    <![CDATA[This class hosts a set of timeline entities.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntities -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity -->
+  <class name="TimelineEntity" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TimelineEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>
+ The constuctor is used to construct a proxy {@link TimelineEntity} or its
+ subclass object from the real entity object that carries information.
+ </p>
+
+ <p>
+ It is usually used in the case where we want to recover class polymorphism
+ after deserializing the entity from its JSON form.
+ </p>
+ @param entity the real entity that carries information]]>
+      </doc>
+    </constructor>
+    <constructor name="TimelineEntity" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+    </method>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="java.lang.String"/>
+    </method>
+    <method name="getIdentifier" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity.Identifier"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setIdentifier"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityIdentifier" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity.Identifier"/>
+    </method>
+    <method name="getInfo" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityInfos" type="java.util.Map"/>
+    </method>
+    <method name="addInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityInfos" type="java.util.Map"/>
+    </method>
+    <method name="addInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="value" type="java.lang.Object"/>
+    </method>
+    <method name="getConfigs" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setConfigs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityConfigs" type="java.util.Map"/>
+    </method>
+    <method name="addConfigs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityConfigs" type="java.util.Map"/>
+    </method>
+    <method name="addConfig"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="value" type="java.lang.String"/>
+    </method>
+    <method name="getMetrics" return="java.util.Set"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setMetrics"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityMetrics" type="java.util.Set"/>
+    </method>
+    <method name="addMetrics"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityMetrics" type="java.util.Set"/>
+    </method>
+    <method name="addMetric"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="metric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"/>
+    </method>
+    <method name="getEvents" return="java.util.NavigableSet"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityEvents" type="java.util.NavigableSet"/>
+    </method>
+    <method name="addEvents"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityEvents" type="java.util.Set"/>
+    </method>
+    <method name="addEvent"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="event" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent"/>
+    </method>
+    <method name="getIsRelatedToEntities" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setIsRelatedToEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isRelatedTo" type="java.util.Map"/>
+    </method>
+    <method name="addIsRelatedToEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="isRelatedTo" type="java.util.Map"/>
+    </method>
+    <method name="addIsRelatedToEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="id" type="java.lang.String"/>
+    </method>
+    <method name="getRelatesToEntities" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="addRelatesToEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="relatesTo" type="java.util.Map"/>
+    </method>
+    <method name="addRelatesToEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <param name="id" type="java.lang.String"/>
+    </method>
+    <method name="setRelatesToEntities"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="relatesTo" type="java.util.Map"/>
+    </method>
+    <method name="getCreatedTime" return="java.lang.Long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setCreatedTime"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="createdTs" type="java.lang.Long"/>
+    </method>
+    <method name="setUID"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uidKey" type="java.lang.String"/>
+      <param name="uId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set UID in info which will be then used for query by UI.
+ @param uidKey key for UID in info.
+ @param uId UID to be set for the key.]]>
+      </doc>
+    </method>
+    <method name="isValid" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"/>
+    </method>
+    <method name="getReal" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getIdPrefix" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setIdPrefix"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entityIdPrefix" type="long"/>
+      <doc>
+      <![CDATA[Sets idPrefix for an entity.
+ <p>
+ <b>Note</b>: Entities will be stored in the order of idPrefix specified.
+ If users decide to set idPrefix for an entity, they <b>MUST</b> provide
+ the same prefix for every update of this entity.
+ </p>
+ Example: <blockquote><pre>
+ TimelineEntity entity = new TimelineEntity();
+ entity.setIdPrefix(value);
+ </pre></blockquote>
+ Users can use {@link TimelineServiceHelper#invertLong(long)} to invert
+ the prefix if necessary.
+
+ @param entityIdPrefix prefix for an entity.]]>
+      </doc>
+    </method>
+    <field name="SYSTEM_INFO_KEY_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ENTITY_PREFIX" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[The basic timeline entity data structure for timeline service v2. Timeline
+ entity objects are not thread safe and should not be accessed concurrently.
+ All collection members will be initialized into empty collections. Two
+ timeline entities are equal iff. their type and id are identical.
+
+ All non-primitive type, non-collection members will be initialized into null.
+ User should set the type and id of a timeline entity to make it valid (can be
+ checked by using the {@link #isValid()} method). Callers to the getters
+ should perform null checks for non-primitive type, non-collection members.
+
+ Callers are recommended not to alter the returned collection objects from the
+ getters.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntityType -->
+  <class name="TimelineEntityType" extends="java.lang.Enum"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="values" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntityType[]"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="valueOf" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntityType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+    </method>
+    <method name="isParent" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntityType"/>
+      <doc>
+      <![CDATA[Whether the input type can be a parent of this entity.
+
+ @param type entity type.
+ @return true, if this entity type is parent of passed entity type, false
+     otherwise.]]>
+      </doc>
+    </method>
+    <method name="isChild" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntityType"/>
+      <doc>
+      <![CDATA[Whether the input type can be a child of this entity.
+
+ @param type entity type.
+ @return true, if this entity type is child of passed entity type, false
+     otherwise.]]>
+      </doc>
+    </method>
+    <method name="matches" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="typeString" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Whether the type of this entity matches the type indicated by the input
+ argument.
+
+ @param typeString entity type represented as a string.
+ @return true, if string representation of this entity type matches the
+     entity type passed.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Defines type of entity.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntityType -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent -->
+  <class name="TimelineEvent" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Comparable"/>
+    <constructor name="TimelineEvent"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventId" type="java.lang.String"/>
+    </method>
+    <method name="getInfo" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="infos" type="java.util.Map"/>
+    </method>
+    <method name="addInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="infos" type="java.util.Map"/>
+    </method>
+    <method name="addInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="java.lang.String"/>
+      <param name="value" type="java.lang.Object"/>
+    </method>
+    <method name="getTimestamp" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setTimestamp"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ts" type="long"/>
+    </method>
+    <method name="isValid" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="compareTo" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent"/>
+    </method>
+    <field name="INVALID_TIMESTAMP" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class contains the information of an event that belongs to an entity.
+ Users are free to define what the event means, such as starting an
+ application, container being allocated, etc.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric -->
+  <class name="TimelineMetric" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineMetric"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TimelineMetric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric.Type"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getType" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric.Type"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="metricType" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric.Type"/>
+    </method>
+    <method name="getId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="metricId" type="java.lang.String"/>
+    </method>
+    <method name="getRealtimeAggregationOp" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetricOperation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the real time aggregation operation of this metric.
+
+ @return Real time aggregation operation]]>
+      </doc>
+    </method>
+    <method name="setRealtimeAggregationOp"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetricOperation"/>
+      <doc>
+      <![CDATA[Set the real time aggregation operation of this metric.
+
+ @param op A timeline metric operation that the metric should perform on
+           real time aggregations]]>
+      </doc>
+    </method>
+    <method name="getValues" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setValues"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="vals" type="java.util.Map"/>
+    </method>
+    <method name="addValues"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="vals" type="java.util.Map"/>
+    </method>
+    <method name="addValue"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timestamp" type="long"/>
+      <param name="value" type="java.lang.Number"/>
+    </method>
+    <method name="isValid" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getLatestSingleValueMetric" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="metric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"/>
+      <doc>
+      <![CDATA[Get the latest timeline metric as single value type.
+
+ @param metric Incoming timeline metric
+ @return The latest metric in the incoming metric]]>
+      </doc>
+    </method>
+    <method name="getSingleDataTimestamp" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get single data timestamp of the metric.
+
+ @return the single data timestamp]]>
+      </doc>
+    </method>
+    <method name="getSingleDataValue" return="java.lang.Number"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get single data value of the metric.
+
+ @return the single data value]]>
+      </doc>
+    </method>
+    <method name="aggregateTo" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="incomingMetric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"/>
+      <param name="baseAggregatedMetric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"/>
+      <doc>
+      <![CDATA[Aggregate an incoming metric to the base aggregated metric with the given
+ operation state in a stateless fashion. The assumption here is
+ baseAggregatedMetric and latestMetric should be single value data if not
+ null.
+
+ @param incomingMetric Incoming timeline metric to aggregate
+ @param baseAggregatedMetric Base timeline metric
+ @return Result metric after aggregation]]>
+      </doc>
+    </method>
+    <method name="aggregateTo" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="incomingMetric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"/>
+      <param name="baseAggregatedMetric" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric"/>
+      <param name="state" type="java.util.Map"/>
+      <doc>
+      <![CDATA[Aggregate an incoming metric to the base aggregated metric with the given
+ operation state. The assumption here is baseAggregatedMetric and
+ latestMetric should be single value data if not null.
+
+ @param incomingMetric Incoming timeline metric to aggregate
+ @param baseAggregatedMetric Base timeline metric
+ @param state Operation state
+ @return Result metric after aggregation]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This class contains the information of a metric that is related to some
+ entity. Metric can either be a time series or single value.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse -->
+  <class name="TimelineWriteResponse" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineWriteResponse"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getErrors" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a list of {@link TimelineWriteError} instances.
+
+ @return a list of {@link TimelineWriteError} instances]]>
+      </doc>
+    </method>
+    <method name="addError"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="error" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse.TimelineWriteError"/>
+      <doc>
+      <![CDATA[Add a single {@link TimelineWriteError} instance into the existing list.
+
+ @param error
+          a single {@link TimelineWriteError} instance]]>
+      </doc>
+    </method>
+    <method name="addErrors"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="writeErrors" type="java.util.List"/>
+      <doc>
+      <![CDATA[Add a list of {@link TimelineWriteError} instances into the existing list.
+
+ @param writeErrors
+          a list of {@link TimelineWriteError} instances]]>
+      </doc>
+    </method>
+    <method name="setErrors"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="writeErrors" type="java.util.List"/>
+      <doc>
+      <![CDATA[Set the list to the given list of {@link TimelineWriteError} instances.
+
+ @param writeErrors
+          a list of {@link TimelineWriteError} instances]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A class that holds a list of put errors. This is the response returned when a
+ list of {@link TimelineEntity} objects is added to the timeline. If there are
+ errors in storing individual entity objects, they will be indicated in the
+ list of errors.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse.TimelineWriteError -->
+  <class name="TimelineWriteResponse.TimelineWriteError" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineWriteError"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getEntityId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity Id.
+
+ @return the entity Id]]>
+      </doc>
+    </method>
+    <method name="setEntityId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="id" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity Id.
+
+ @param id the entity Id.]]>
+      </doc>
+    </method>
+    <method name="getEntityType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the entity type.
+
+ @return the entity type]]>
+      </doc>
+    </method>
+    <method name="setEntityType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="type" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Set the entity type.
+
+ @param type the entity type.]]>
+      </doc>
+    </method>
+    <method name="getErrorCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the error code.
+
+ @return an error code]]>
+      </doc>
+    </method>
+    <method name="setErrorCode"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="code" type="int"/>
+      <doc>
+      <![CDATA[Set the error code to the given error code.
+
+ @param code an error code.]]>
+      </doc>
+    </method>
+    <field name="IO_EXCEPTION" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Error code returned if an IOException is encountered when storing an
+ entity.]]>
+      </doc>
+    </field>
+    <doc>
+    <![CDATA[A class that holds the error code for one entity.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.TimelineWriteResponse.TimelineWriteError -->
+  <!-- start class org.apache.hadoop.yarn.api.records.timelineservice.UserEntity -->
+  <class name="UserEntity" extends="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UserEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="UserEntity" type="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This entity represents a user.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.records.timelineservice.UserEntity -->
+</package>
+<package name="org.apache.hadoop.yarn.api.resource">
+  <!-- start class org.apache.hadoop.yarn.api.resource.PlacementConstraint -->
+  <class name="PlacementConstraint" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="PlacementConstraint" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getConstraintExpr" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the constraint expression of the placement constraint.
+
+ @return the constraint expression]]>
+      </doc>
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[{@code PlacementConstraint} represents a placement constraint for a resource
+ allocation.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.resource.PlacementConstraint -->
+  <!-- start class org.apache.hadoop.yarn.api.resource.PlacementConstraints -->
+  <class name="PlacementConstraints" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="targetIn" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="targetExpressions" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TargetExpression[]"/>
+      <doc>
+      <![CDATA[Creates a constraint that requires allocations to be placed on nodes that
+ satisfy all target expressions within the given scope (e.g., node or rack).
+
+ For example, {@code targetIn(RACK, allocationTag("hbase-m"))}, allows
+ allocations on nodes that belong to a rack that has at least one tag with
+ value "hbase-m".
+
+ @param scope the scope within which the target expressions should be
+          satisfied
+ @param targetExpressions the expressions that need to be satisfied within
+          the scope
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="targetNotIn" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="targetExpressions" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TargetExpression[]"/>
+      <doc>
+      <![CDATA[Creates a constraint that requires allocations to be placed on nodes that
+ belong to a scope (e.g., node or rack) that does not satisfy any of the
+ target expressions.
+
+ @param scope the scope within which the target expressions should not be
+          true
+ @param targetExpressions the expressions that need to not be true within
+          the scope
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="targetNodeAttribute" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="opCode" type="org.apache.hadoop.yarn.api.records.NodeAttributeOpCode"/>
+      <param name="targetExpressions" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TargetExpression[]"/>
+      <doc>
+      <![CDATA[Creates a constraint that requires allocations to be placed on nodes that
+ belong to a scope (e.g., node or rack) that satisfy any of the
+ target expressions based on node attribute op code.
+
+ @param scope the scope within which the target expressions should not be
+          true
+ @param opCode Node Attribute code which could be equals, not equals.
+ @param targetExpressions the expressions that need to not be true within
+          the scope
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="cardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="minCardinality" type="int"/>
+      <param name="maxCardinality" type="int"/>
+      <param name="allocationTags" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Creates a constraint that restricts the number of allocations within a
+ given scope (e.g., node or rack).
+
+ For example, {@code cardinality(NODE, 3, 10, "zk")} is satisfied on nodes
+ where there are no less than 3 allocations with tag "zk" and no more than
+ 10.
+
+ @param scope the scope of the constraint
+ @param minCardinality determines the minimum number of allocations within
+          the scope
+ @param maxCardinality determines the maximum number of allocations within
+          the scope
+ @param allocationTags the constraint targets allocations with these tags
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="cardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="namespace" type="java.lang.String"/>
+      <param name="minCardinality" type="int"/>
+      <param name="maxCardinality" type="int"/>
+      <param name="allocationTags" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Similar to {@link #cardinality(String, int, int, String...)}, but let you
+ attach a namespace to the given allocation tags.
+
+ @param scope the scope of the constraint
+ @param namespace the namespace of the allocation tags
+ @param minCardinality determines the minimum number of allocations within
+                       the scope
+ @param maxCardinality determines the maximum number of allocations within
+                       the scope
+ @param allocationTags allocation tags
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="minCardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="minCardinality" type="int"/>
+      <param name="allocationTags" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Similar to {@link #cardinality(String, int, int, String...)}, but
+ determines only the minimum cardinality (the maximum cardinality is
+ unbound).
+
+ @param scope the scope of the constraint
+ @param minCardinality determines the minimum number of allocations within
+          the scope
+ @param allocationTags the constraint targets allocations with these tags
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="minCardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="namespace" type="java.lang.String"/>
+      <param name="minCardinality" type="int"/>
+      <param name="allocationTags" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Similar to {@link #minCardinality(String, int, String...)}, but let you
+ attach a namespace to the allocation tags.
+
+ @param scope the scope of the constraint
+ @param namespace the namespace of these tags
+ @param minCardinality determines the minimum number of allocations within
+                       the scope
+ @param allocationTags the constraint targets allocations with these tags
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="maxCardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="maxCardinality" type="int"/>
+      <param name="allocationTags" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Similar to {@link #cardinality(String, int, int, String...)}, but
+ determines only the maximum cardinality (the minimum cardinality is 0).
+
+ @param scope the scope of the constraint
+ @param maxCardinality determines the maximum number of allocations within
+          the scope
+ @param allocationTags the constraint targets allocations with these tags
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="maxCardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="tagNamespace" type="java.lang.String"/>
+      <param name="maxCardinality" type="int"/>
+      <param name="allocationTags" type="java.lang.String[]"/>
+      <doc>
+      <![CDATA[Similar to {@link #maxCardinality(String, int, String...)}, but let you
+ specify a namespace for the tags, see supported namespaces in
+ {@link AllocationTagNamespaceType}.
+
+ @param scope the scope of the constraint
+ @param tagNamespace the namespace of these tags
+ @param maxCardinality determines the maximum number of allocations within
+          the scope
+ @param allocationTags allocation tags
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="targetCardinality" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="scope" type="java.lang.String"/>
+      <param name="minCardinality" type="int"/>
+      <param name="maxCardinality" type="int"/>
+      <param name="targetExpressions" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TargetExpression[]"/>
+      <doc>
+      <![CDATA[This constraint generalizes the cardinality and target constraints.
+
+ Consider a set of nodes N that belongs to the scope specified in the
+ constraint. If the target expressions are satisfied at least minCardinality
+ times and at most maxCardinality times in the node set N, then the
+ constraint is satisfied.
+
+ For example, {@code targetCardinality(RACK, 2, 10, allocationTag("zk"))},
+ requires an allocation to be placed within a rack that has at least 2 and
+ at most 10 other allocations with tag "zk".
+
+ @param scope the scope of the constraint
+ @param minCardinality the minimum number of times the target expressions
+          have to be satisfied with the given scope
+ @param maxCardinality the maximum number of times the target expressions
+          have to be satisfied with the given scope
+ @param targetExpressions the target expressions
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="and" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.And"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="children" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint[]"/>
+      <doc>
+      <![CDATA[A conjunction of constraints.
+
+ @param children the children constraints that should all be satisfied
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="or" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.Or"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="children" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint[]"/>
+      <doc>
+      <![CDATA[A disjunction of constraints.
+
+ @param children the children constraints, one of which should be satisfied
+ @return the resulting placement constraint]]>
+      </doc>
+    </method>
+    <method name="delayedOr" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.DelayedOr"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="children" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TimedPlacementConstraint[]"/>
+      <doc>
+      <![CDATA[Creates a composite constraint that includes a list of timed placement
+ constraints. The scheduler should try to satisfy first the first timed
+ child constraint within the specified time window. If this is not possible,
+ it should attempt to satisfy the second, and so on.
+
+ @param children the timed children constraints
+ @return the resulting composite constraint]]>
+      </doc>
+    </method>
+    <method name="timedClockConstraint" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TimedPlacementConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="constraint" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"/>
+      <param name="delay" type="long"/>
+      <param name="timeUnit" type="java.util.concurrent.TimeUnit"/>
+      <doc>
+      <![CDATA[Creates a placement constraint that has to be satisfied within a time
+ window.
+
+ @param constraint the placement constraint
+ @param delay the length of the time window within which the constraint has
+          to be satisfied
+ @param timeUnit the unit of time of the time window
+ @return the resulting timed placement constraint]]>
+      </doc>
+    </method>
+    <method name="timedOpportunitiesConstraint" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.TimedPlacementConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="constraint" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"/>
+      <param name="delay" type="long"/>
+      <doc>
+      <![CDATA[Creates a placement constraint that has to be satisfied within a number of
+ placement opportunities (invocations of the scheduler).
+
+ @param constraint the placement constraint
+ @param delay the number of scheduling opportunities within which the
+          constraint has to be satisfied
+ @return the resulting timed placement constraint]]>
+      </doc>
+    </method>
+    <method name="build" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="constraintExpr" type="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"/>
+      <doc>
+      <![CDATA[Creates a {@link PlacementConstraint} given a constraint expression.
+
+ @param constraintExpr the constraint expression
+ @return the placement constraint]]>
+      </doc>
+    </method>
+    <field name="NODE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RACK" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NODE_PARTITION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class contains various static methods for the applications to create
+ placement constraints (see also {@link PlacementConstraint}).]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.api.resource.PlacementConstraints -->
+</package>
+<package name="org.apache.hadoop.yarn.conf">
+  <!-- start class org.apache.hadoop.yarn.conf.YarnConfiguration -->
+  <class name="YarnConfiguration" extends="org.apache.hadoop.conf.Configuration"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="YarnConfiguration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="YarnConfiguration" type="org.apache.hadoop.conf.Configuration"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="isAclEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getSocketAddr" return="java.net.InetSocketAddress"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <param name="defaultAddress" type="java.lang.String"/>
+      <param name="defaultPort" type="int"/>
+      <doc>
+      <![CDATA[Get the socket address for <code>name</code> property as a
+ <code>InetSocketAddress</code>. On an HA cluster,
+ this fetches the address corresponding to the RM identified by
+ {@link #RM_HA_ID}.
+ @param name property name.
+ @param defaultAddress the default value
+ @param defaultPort the default port
+ @return InetSocketAddress]]>
+      </doc>
+    </method>
+    <method name="updateConnectAddr" return="java.net.InetSocketAddress"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <param name="addr" type="java.net.InetSocketAddress"/>
+    </method>
+    <method name="useHttps" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="shouldRMFailFast" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="isDistSchedulingEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="isOpportunisticContainerAllocationEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="timelineServiceEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the timeline service is enabled via configuration.
+
+ @param conf the configuration
+ @return whether the timeline service is enabled.]]>
+      </doc>
+    </method>
+    <method name="getTimelineServiceVersion" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns the timeline service version. It does not check whether the
+ timeline service itself is enabled.
+
+ @param conf the configuration
+ @return the timeline service version as a float.]]>
+      </doc>
+    </method>
+    <method name="timelineServiceV2Enabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the timeline service v.2 is enabled via configuration.
+
+ @param conf the configuration
+ @return whether the timeline service v.2 is enabled. V.2 refers to a
+ version greater than equal to 2 but smaller than 3.]]>
+      </doc>
+    </method>
+    <method name="timelineServiceV1Enabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the timeline service v.1 is enabled via configuration.
+
+ @param conf the configuration
+ @return whether the timeline service v.1 is enabled. V.1 refers to a
+ version greater than equal to 1 but smaller than 2.]]>
+      </doc>
+    </method>
+    <method name="timelineServiceV15Enabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the timeline service v.1,5 is enabled via configuration.
+
+ @param conf the configuration
+ @return whether the timeline service v.1.5 is enabled. V.1.5 refers to a
+ version equal to 1.5.]]>
+      </doc>
+    </method>
+    <method name="systemMetricsPublisherEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the system publisher is enabled.
+
+ @param conf the configuration
+ @return whether the system publisher is enabled.]]>
+      </doc>
+    </method>
+    <method name="numaAwarenessEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the NUMA awareness is enabled.
+
+ @param conf the configuration
+ @return whether the NUMA awareness is enabled.]]>
+      </doc>
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <field name="DR_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CS_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="HADOOP_POLICY_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SITE_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CORE_SITE_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RESOURCE_TYPES_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NODE_RESOURCES_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CONFIGURATION_FILES" type="java.util.List"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONFIGURATION_FILES" type="java.util.List"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_MAX_TAGS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_MAX_TAG_LENGTH" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RESOURCE_TYPES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RESOURCES_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEBUG_NM_DELETE_DELAY_SEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Delay before deleting resource to ease debugging of NM issues]]>
+      </doc>
+    </field>
+    <field name="NM_LOG_CONTAINER_DEBUG_INFO" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_LOG_CONTAINER_DEBUG_INFO" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IPC_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IPC_CLIENT_FACTORY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Factory to create client IPC classes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IPC_CLIENT_FACTORY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IPC_SERVER_FACTORY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Factory to create server IPC classes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IPC_SERVER_FACTORY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IPC_RECORD_FACTORY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Factory to create serializable records.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IPC_RECORD_FACTORY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IPC_RPC_IMPL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[RPC class implementation]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IPC_RPC_IMPL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CLUSTER_ID" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_CLUSTER_ID" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_HOSTNAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_EPOCH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_EPOCH" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_EPOCH_RANGE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The epoch range before wrap around. 0 disables wrap around]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_EPOCH_RANGE" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the applications manager interface in the RM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_APPLICATION_MAX_TAGS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max number of application tags.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_APPLICATION_MAX_TAGS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_APPLICATION_MAX_TAG_LENGTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max length of each application tag.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_APPLICATION_MAX_TAG_LENGTH" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_APPLICATION_MASTER_SERVICE_PROCESSORS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_AUTO_UPDATE_CONTAINERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_AUTO_UPDATE_CONTAINERS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The actual bind address for the RM.]]>
+      </doc>
+    </field>
+    <field name="RM_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of threads used to handle applications manager requests.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_AMLAUNCHER_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads used to launch/cleanup AM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_AMLAUNCHER_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODEMANAGER_CONNECT_RETRIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Retry times to connect with NM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NODEMANAGER_CONNECT_RETRIES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PRINCIPAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The Kerberos principal for the resource manager.]]>
+      </doc>
+    </field>
+    <field name="RM_SCHEDULER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the scheduler interface.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_MINIMUM_ALLOCATION_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Minimum request grant-able by the RM scheduler.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_VCORES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_MAXIMUM_ALLOCATION_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Maximum request grant-able by the RM scheduler.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_MB" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads to handle scheduler interface.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_INCLUDE_PORT_IN_NODE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[If the port should be included or not in the node name. The node name
+ is used by the scheduler for resource requests allocation location 
+ matching. Typically this is just the hostname, using the port is needed
+ when using minicluster and specific NM are required.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_USE_PORT_FOR_NODE_NAME" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="QUEUE_PLACEMENT_RULES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Configured scheduler queue placement rules.]]>
+      </doc>
+    </field>
+    <field name="USER_GROUP_PLACEMENT_RULE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[UserGroupMappingPlacementRule configuration string.]]>
+      </doc>
+    </field>
+    <field name="APP_NAME_PLACEMENT_RULE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_WEBAPP_UI_ACTIONS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable Resource Manager webapp ui actions]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_UI_ACTIONS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_RESERVATION_SYSTEM_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether the RM should enable Reservation System]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_RESERVATION_SYSTEM_ENABLE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_RESERVATION_SYSTEM_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The class to use as the Reservation System.]]>
+      </doc>
+    </field>
+    <field name="RM_RESERVATION_SYSTEM_PLAN_FOLLOWER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The PlanFollower for the Reservation System.]]>
+      </doc>
+    </field>
+    <field name="RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The step size of the Reservation System.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_RESERVATION_SYSTEM_PLAN_FOLLOWER_TIME_STEP" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_RESERVATION_SYSTEM_MAX_PERIODICITY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The maximum periodicity for the Reservation System.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_RESERVATION_SYSTEM_MAX_PERIODICITY" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_ENABLE_MONITORS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable periodic monitor threads.
+ @see #RM_SCHEDULER_MONITOR_POLICIES]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER_ENABLE_MONITORS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_MONITOR_POLICIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[List of SchedulingEditPolicy classes affecting the scheduler.]]>
+      </doc>
+    </field>
+    <field name="RM_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the RM web application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The https address of the RM web application.]]>
+      </doc>
+    </field>
+    <field name="YARN_SSL_CLIENT_HTTPS_NEED_AUTH_DEFAULT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SSL_SERVER_RESOURCE_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_HTTPS_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_WEBAPP_UI2_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable YARN WebApp V2.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_WEBAPP_UI2_ENABLE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_WEBAPP_UI2_WARFILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_API_SERVICES_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_YARN_API_SYSTEM_SERVICES_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_RESOURCE_TRACKER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_RESOURCE_TRACKER_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_RESOURCE_TRACKER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_AM_EXPIRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The expiry interval for application master reporting.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_AM_EXPIRY_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_EXPIRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How long to wait until a node manager is considered dead.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NM_EXPIRY_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_ACL_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Are acls enabled.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_ACL_ENABLE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_RESERVATION_ACL_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Are reservation acls enabled.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_RESERVATION_ACL_ENABLE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_ADMIN_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[ACL of who can be admin of YARN cluster.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_ADMIN_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_YARN_APP_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[ACL used in case none is found. Allows nothing.]]>
+      </doc>
+    </field>
+    <field name="OPPORTUNISTIC_CONTAINER_ALLOCATION_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Setting that controls whether opportunistic container allocation
+  is enabled or not.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_OPPORTUNISTIC_CONTAINER_ALLOCATION_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="OPP_CONTAINER_ALLOCATION_NODES_NUMBER_USED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of nodes to be used by the Opportunistic Container allocator for
+ dispatching containers during container allocation.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_OPP_CONTAINER_ALLOCATION_NODES_NUMBER_USED" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_SORTING_NODES_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Frequency for computing least loaded NMs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_SORTING_NODES_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_LOAD_COMPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Comparator for determining node load for scheduling of opportunistic
+ containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_LOAD_COMPARATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_LIMIT_STDEV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Value of standard deviation used for calculation of queue limit
+ thresholds.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_LIMIT_STDEV" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_MIN_QUEUE_LENGTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Min length of container queue at NodeManager. This is a cluster-wide
+ configuration that acts as the lower-bound of optimal queue length
+ calculated by the NodeQueueLoadMonitor]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_MIN_QUEUE_LENGTH" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_MAX_QUEUE_LENGTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max length of container queue at NodeManager. This is a cluster-wide
+ configuration that acts as the upper-bound of optimal queue length
+ calculated by the NodeQueueLoadMonitor]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_MAX_QUEUE_LENGTH" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_MIN_QUEUE_WAIT_TIME_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Min queue wait time for a container at a NodeManager.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_MIN_QUEUE_WAIT_TIME_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_MAX_QUEUE_WAIT_TIME_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max queue wait time for a container queue at a NodeManager.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_MAX_QUEUE_WAIT_TIME_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_INTERMEDIATE_DATA_ENCRYPTION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/disable intermediate-data encryption at YARN level. For now, this
+ only is used by the FileSystemRMStateStore to setup right file-system
+ security attributes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_INTERMEDIATE_DATA_ENCRYPTION" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ADMIN_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the RM admin interface.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_ADMIN_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_ADMIN_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ADMIN_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads used to handle RM admin interface.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_ADMIN_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_AM_MAX_ATTEMPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The maximum number of application attempts for
+ an application, if unset by user.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_AM_MAX_ATTEMPTS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="GLOBAL_RM_AM_MAX_ATTEMPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The maximum number of application attempts.
+ It's a global setting for all application masters.]]>
+      </doc>
+    </field>
+    <field name="RM_KEYTAB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The keytab for the resource manager.]]>
+      </doc>
+    </field>
+    <field name="RM_WEBAPP_SPNEGO_USER_NAME_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The kerberos principal to be used for spnego filter for RM.]]>
+      </doc>
+    </field>
+    <field name="RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The kerberos keytab to be used for spnego filter for RM.]]>
+      </doc>
+    </field>
+    <field name="RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Flag to enable override of the default kerberos authentication filter with
+ the RM authentication filter to allow authentication using delegation
+ tokens(fallback to kerberos if the tokens are missing). Only applicable
+ when the http authentication type is kerberos.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_DELEGATION_TOKEN_AUTH_FILTER" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_WEBAPP_ENABLE_CORS_FILTER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable cross origin (CORS) support.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_WEBAPP_ENABLE_CORS_FILTER" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How long to wait until a container is considered dead.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_CONTAINER_ALLOC_EXPIRY_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODES_INCLUDE_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Path to file with nodes to include.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NODES_INCLUDE_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SUBMISSION_PREPROCESSOR_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable submission pre-processor.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SUBMISSION_PREPROCESSOR_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SUBMISSION_PREPROCESSOR_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Path to file with hosts for the submission processor to handle.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SUBMISSION_PREPROCESSOR_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SUBMISSION_PREPROCESSOR_REFRESH_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Submission processor refresh interval.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SUBMISSION_PREPROCESSOR_REFRESH_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODES_EXCLUDE_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Path to file with nodes to exclude.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NODES_EXCLUDE_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads to handle resource tracker calls.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_RESOURCE_TRACKER_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The class to use as the resource scheduler.]]>
+      </doc>
+    </field>
+    <field name="RM_PLACEMENT_CONSTRAINTS_HANDLER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specify which handler will be used to process PlacementConstraints.
+ For details on PlacementConstraints, please refer to
+ {@link org.apache.hadoop.yarn.api.resource.PlacementConstraint}]]>
+      </doc>
+    </field>
+    <field name="DISABLED_RM_PLACEMENT_CONSTRAINTS_HANDLER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This handler rejects all allocate calls made by an application, if they
+ contain a {@link org.apache.hadoop.yarn.api.records.SchedulingRequest}.]]>
+      </doc>
+    </field>
+    <field name="PROCESSOR_RM_PLACEMENT_CONSTRAINTS_HANDLER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Using this handler, the placement of containers with constraints is
+ determined as a pre-processing step before the capacity or the fair
+ scheduler is called. Once the placement is decided, the capacity/fair
+ scheduler is invoked to perform the actual allocation. The advantage of
+ this approach is that it supports all constraint types (affinity,
+ anti-affinity, cardinality). Moreover, it considers multiple containers at
+ a time, which allows to satisfy more constraints than a container-at-a-time
+ approach can achieve. As it sits outside the main scheduler, it can be used
+ by both the capacity and fair schedulers. Note that at the moment it does
+ not account for task priorities within an application, given that such
+ priorities might be conflicting with the placement constraints.]]>
+      </doc>
+    </field>
+    <field name="SCHEDULER_RM_PLACEMENT_CONSTRAINTS_HANDLER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Using this handler, containers with constraints will be placed by the main
+ scheduler. If the configured RM scheduler
+ <pre>yarn.resourcemanager.scheduler.class</pre>
+ cannot handle placement constraints, the corresponding SchedulingRequests
+ will be rejected. As of now, only the capacity scheduler supports
+ SchedulingRequests. In particular, it currently supports anti-affinity
+ constraints (no affinity or cardinality) and places one container at a
+ time. The advantage of this handler compared to the placement-processor is
+ that it follows the same ordering rules for queues (sorted by utilization,
+ priority) and apps (sorted by FIFO/fairness/priority) as the ones followed
+ by the main scheduler.]]>
+      </doc>
+    </field>
+    <field name="RM_PLACEMENT_CONSTRAINTS_ALGORITHM_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Placement Algorithm.]]>
+      </doc>
+    </field>
+    <field name="RM_PLACEMENT_CONSTRAINTS_ALGORITHM_ITERATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Used for BasicPlacementAlgorithm - default SERIAL.]]>
+      </doc>
+    </field>
+    <field name="RM_PLACEMENT_CONSTRAINTS_RETRY_ATTEMPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_PLACEMENT_CONSTRAINTS_RETRY_ATTEMPTS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PLACEMENT_CONSTRAINTS_ALGORITHM_POOL_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_PLACEMENT_CONSTRAINTS_ALGORITHM_POOL_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PLACEMENT_CONSTRAINTS_SCHEDULER_POOL_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_PLACEMENT_CONSTRAINTS_SCHEDULER_POOL_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDULER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_HEARTBEAT_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[RM set next Heartbeat interval for NM]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_HEARTBEAT_INTERVAL_SCALING_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable Heartbeat Interval Scaling based on cpu utilization.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NM_HEARTBEAT_INTERVAL_SCALING_ENABLE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_HEARTBEAT_INTERVAL_MIN_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MIN_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_HEARTBEAT_INTERVAL_MAX_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NM_HEARTBEAT_INTERVAL_MAX_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_HEARTBEAT_INTERVAL_SPEEDUP_FACTOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NM_HEARTBEAT_INTERVAL_SPEEDUP_FACTOR" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NM_HEARTBEAT_INTERVAL_SLOWDOWN_FACTOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NM_HEARTBEAT_INTERVAL_SLOWDOWN_FACTOR" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of worker threads that write the history data.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_HISTORY_WRITER_MULTI_THREADED_DISPATCHER_POOL_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SYSTEM_METRICS_PUBLISHER_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether yarn system metrics is published on the
+  timeline server or not by RM. This configuration setting is for ATS V1.
+  This is now deprecated in favor of SYSTEM_METRICS_PUBLISHER_ENABLED.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SYSTEM_METRICS_PUBLISHER_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether yarn system metrics is published on the
+  timeline server or not by RM and NM. This configuration setting is for
+  ATS v2.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SYSTEM_METRICS_PUBLISHER_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PUBLISH_CONTAINER_EVENTS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether yarn container events are published to
+ the timeline service or not by RM. This configuration setting is for ATS
+ V2]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_PUBLISH_CONTAINER_EVENTS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SYSTEM_METRICS_PUBLISHER_DISPATCHER_POOL_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_TIMELINE_SERVER_V1_PUBLISHER_DISPATCHER_BATCH_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_TIMELINE_SERVER_V1_PUBLISHER_DISPATCHER_BATCH_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_TIMELINE_SERVER_V1_PUBLISHER_INTERVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_TIMELINE_SERVER_V1_PUBLISHER_INTERVAL" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_TIMELINE_SERVER_V1_PUBLISHER_BATCH_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_TIMELINE_SERVER_V1_PUBLISHER_BATCH_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_MAX_CONF_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_DELEGATION_TOKEN_MAX_CONF_SIZE_BYTES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_ALWAYS_CANCEL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_DELEGATION_TOKEN_ALWAYS_CANCEL" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RECOVERY_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_RECOVERY_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_FAIL_FAST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_YARN_FAIL_FAST" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_FAIL_FAST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_WORK_PRESERVING_RECOVERY_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_WORK_PRESERVING_RECOVERY_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_WORK_PRESERVING_RECOVERY_SCHEDULING_WAIT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Zookeeper interaction configs]]>
+      </doc>
+    </field>
+    <field name="RM_ZK_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_NUM_RETRIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ZK_RM_NUM_RETRIES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_ZNODE_SIZE_LIMIT_BYTES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Zookeeper znode limit]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_ZK_ZNODE_SIZE_LIMIT_BYTES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_RETRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_ZK_RETRY_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_TIMEOUT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_ZK_TIMEOUT_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ZK_APPID_NODE_SPLIT_INDEX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ZK_APPID_NODE_SPLIT_INDEX" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ZK_DELEGATION_TOKEN_NODE_SPLIT_INDEX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Index at which the RM Delegation Token ids will be split so that the
+ delegation token znodes stored in the zookeeper RM state store will be
+ stored as two different znodes (parent-child).]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ZK_DELEGATION_TOKEN_NODE_SPLIT_INDEX" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_ZK_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_ZK_AUTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ZK_STATE_STORE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ZK_RM_STATE_STORE_PARENT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Parent znode path under which ZKRMStateStore will create znodes]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ZK_RM_STATE_STORE_PARENT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ZK_RM_STATE_STORE_ROOT_NODE_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Root node ACLs for fencing]]>
+      </doc>
+    </field>
+    <field name="RM_HA_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[HA related configs]]>
+      </doc>
+    </field>
+    <field name="RM_HA_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_HA_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_HA_IDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_HA_ID" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FS_BASED_RM_CONF_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Store the related configuration files in File System]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_FS_BASED_RM_CONF_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CONFIGURATION_PROVIDER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_CONFIGURATION_PROVIDER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCHEDULER_CONFIGURATION_STORE_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILE_CONFIGURATION_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MEMORY_CONFIGURATION_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FS_CONFIGURATION_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ZK_CONFIGURATION_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LEVELDB_CONFIGURATION_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_CONFIGURATION_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDCONF_STORE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDCONF_LEVELDB_COMPACTION_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDCONF_LEVELDB_COMPACTION_INTERVAL_SECS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDCONF_MAX_LOGS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDCONF_LEVELDB_MAX_LOGS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_SCHEDCONF_ZK_MAX_LOGS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCHEDULER_CONFIGURATION_FS_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCHEDULER_CONFIGURATION_FS_MAX_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCHEDULER_CONFIGURATION_FS_MAX_VERSION" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDCONF_STORE_ZK_PARENT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Parent znode path under which ZKConfigurationStore will create znodes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_SCHEDCONF_STORE_ZK_PARENT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_SCHEDULER_MUTATION_ACL_POLICY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_AUTHORIZATION_PROVIDER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AUTO_FAILOVER_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AUTO_FAILOVER_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AUTO_FAILOVER_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AUTO_FAILOVER_EMBEDDED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="This property should never be set to {@code false}.">
+      <doc>
+      <![CDATA[This property controls whether {@link ActiveStandbyElector} leader
+ election should be used when {@link #CURATOR_LEADER_ELECTOR} is
+ {@code false}.
+
+ @deprecated This property should never be set to {@code false}.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_AUTO_FAILOVER_EMBEDDED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="The {@link #AUTO_FAILOVER_EMBEDDED} property is deprecated.">
+      <doc>
+      <![CDATA[The default value for {@link #AUTO_FAILOVER_EMBEDDED}.
+
+ @deprecated The {@link #AUTO_FAILOVER_EMBEDDED} property is deprecated.]]>
+      </doc>
+    </field>
+    <field name="AUTO_FAILOVER_ZK_BASE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AUTO_FAILOVER_ZK_BASE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_PROXY_PROVIDER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_CLIENT_FAILOVER_PROXY_PROVIDER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_MAX_ATTEMPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_SLEEPTIME_BASE_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_SLEEPTIME_MAX_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_RETRIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_CLIENT_FAILOVER_RETRIES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_CLIENT_FAILOVER_RETRIES_ON_SOCKET_TIMEOUTS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_HA_FC_ELECTOR_ZK_RETRIES_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[number of zookeeper operation retry times in ActiveStandbyElector]]>
+      </doc>
+    </field>
+    <field name="CURATOR_LEADER_ELECTOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="Eventually, we want to default to the curator-based
+ implementation and remove the {@link ActiveStandbyElector} based
+ implementation. We should remove this config then.">
+      <doc>
+      <![CDATA[Whether to use the Curator-based elector for leader election.
+
+ @deprecated Eventually, we want to default to the curator-based
+ implementation and remove the {@link ActiveStandbyElector} based
+ implementation. We should remove this config then.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_CURATOR_LEADER_ELECTOR_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The class to use as the persistent store.]]>
+      </doc>
+    </field>
+    <field name="FS_RM_STATE_STORE_URI" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[URI for FileSystemRMStateStore]]>
+      </doc>
+    </field>
+    <field name="FS_RM_STATE_STORE_NUM_RETRIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FS_RM_STATE_STORE_NUM_RETRIES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FS_RM_STATE_STORE_RETRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FS_RM_STATE_STORE_RETRY_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_LEVELDB_STORE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_LEVELDB_COMPACTION_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The time in seconds between full compactions of the leveldb database.
+  Setting the interval to zero disables the full compaction cycles.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_LEVELDB_COMPACTION_INTERVAL_SECS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_MAX_COMPLETED_APPLICATIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The maximum number of completed applications RM keeps. By default equals
+ to {@link #DEFAULT_RM_MAX_COMPLETED_APPLICATIONS}.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_MAX_COMPLETED_APPLICATIONS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The maximum number of completed applications RM state store keeps. By
+ default equals to value of {@link #RM_MAX_COMPLETED_APPLICATIONS}.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_STATE_STORE_MAX_COMPLETED_APPLICATIONS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="This default value is ignored and will be removed in a future
+ release. The default value of
+ {@code yarn.resourcemanager.state-store.max-completed-applications} is the
+ value of {@link #RM_MAX_COMPLETED_APPLICATIONS}.">
+      <doc>
+      <![CDATA[The default value for
+ {@code yarn.resourcemanager.state-store.max-completed-applications}.
+ @deprecated This default value is ignored and will be removed in a future
+ release. The default value of
+ {@code yarn.resourcemanager.state-store.max-completed-applications} is the
+ value of {@link #RM_MAX_COMPLETED_APPLICATIONS}.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_APPLICATION_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default application name]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_APPLICATION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default application type]]>
+      </doc>
+    </field>
+    <field name="APPLICATION_TYPE_LENGTH" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default application type length]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_QUEUE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default queue name]]>
+      </doc>
+    </field>
+    <field name="RM_METRICS_RUNTIME_BUCKETS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Buckets (in minutes) for the number of apps running in each queue.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_METRICS_RUNTIME_BUCKETS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default sizes of the runtime metric buckets in minutes.]]>
+      </doc>
+    </field>
+    <field name="RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_AMRM_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_CONTAINER_TOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NMTOKEN_MASTER_KEY_ROLLING_INTERVAL_SECS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODEMANAGER_MINIMUM_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NODEMANAGER_MINIMUM_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODEMANAGER_UNTRACKED_REMOVAL_TIMEOUT_MSEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeout(msec) for an untracked node to remain in shutdown or decommissioned
+ state.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NODEMANAGER_UNTRACKED_REMOVAL_TIMEOUT_MSEC" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PROXY_USER_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[RM proxy users' prefix]]>
+      </doc>
+    </field>
+    <field name="RM_RESOURCE_PROFILES_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/disable resource profiles.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_RESOURCE_PROFILES_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_RESOURCE_PROFILES_SOURCE_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[File containing resource profiles.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_RESOURCE_PROFILES_SOURCE_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_CLIENT_LOAD_RESOURCETYPES_FROM_SERVER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/disable loading resource-types.xml at client side.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_CLIENT_LOAD_RESOURCETYPES_FROM_SERVER" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODE_GRACEFUL_DECOMMISSION_TIMEOUT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeout in seconds for YARN node graceful decommission.
+ This is the maximal time to wait for running containers and applications
+ to complete before transition a DECOMMISSIONING node into DECOMMISSIONED.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NODE_GRACEFUL_DECOMMISSION_TIMEOUT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DECOMMISSIONING_NODES_WATCHER_POLL_INTERVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Period in seconds of the poll timer task inside DecommissioningNodesWatcher
+ to identify and take care of DECOMMISSIONING nodes missing regular heart beat.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_DECOMMISSIONING_NODES_WATCHER_POLL_INTERVAL" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for all node manager configs.]]>
+      </doc>
+    </field>
+    <field name="NM_OPPORTUNISTIC_CONTAINERS_MAX_QUEUE_LENGTH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max Queue length of <code>OPPORTUNISTIC</code> containers on the NM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_OPPORTUNISTIC_CONTAINERS_MAX_QUEUE_LENGTH" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DIST_SCHEDULING_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Setting that controls whether distributed scheduling is enabled or not.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_DIST_SCHEDULING_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ADMIN_USER_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Environment variables that will be sent to containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_ADMIN_USER_ENV" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ADMIN_FORCE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[PATH components that will be prepended to the user's path.
+ If this is defined and the user does not define PATH, NM will also
+ append ":$PATH" to prevent this from eclipsing the PATH defined in
+ the container. This feature is only available for Linux.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_ADMIN_FORCE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ENV_WHITELIST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Environment variables that containers may override rather than use NodeManager's default.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_ENV_WHITELIST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[address of node manager IPC.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The actual bind address for the NM.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_EXECUTOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[who will execute(launch) the containers.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_STATE_TRANSITION_LISTENERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[List of container state transition listeners.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_EXECUTOR_SCHED_PRIORITY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Adjustment to make to the container os scheduling priority.
+ The valid values for this could vary depending on the platform.
+ On Linux, higher values mean run the containers at a less 
+ favorable priority than the NM. 
+ The value specified is an int.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_EXECUTOR_SCHED_PRIORITY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_MGR_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads container manager uses.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_MGR_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_COLLECTOR_SERVICE_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads container manager uses.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_COLLECTOR_SERVICE_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_DELETE_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads used in cleanup.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DELETE_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_KEYTAB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Keytab for NM.]]>
+      </doc>
+    </field>
+    <field name="NM_LOCAL_DIRS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[List of directories to store localized files in.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCAL_DIRS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of files in each localized directories
+ Avoid tuning this too low.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOCALIZER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Address where the localizer IPC is.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCALIZER_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_LOCALIZER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_COLLECTOR_SERVICE_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Address where the collector service IPC is.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_COLLECTOR_SERVICE_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_COLLECTOR_SERVICE_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PUBLISH_CONTAINER_EVENTS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether yarn container events are published to
+ the timeline service or not by NM. This configuration setting is for ATS
+ V2]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_PUBLISH_CONTAINER_EVENTS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Interval in between cache cleanups.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCALIZER_CACHE_CLEANUP_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOCALIZER_CACHE_TARGET_SIZE_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Target size of localizer cache in MB, per nodemanager. It is a target
+ retention size that only includes resources with PUBLIC and PRIVATE
+ visibility and excludes resources with APPLICATION visibility]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCALIZER_CACHE_TARGET_SIZE_MB" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOCALIZER_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads to handle localization requests.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCALIZER_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOCALIZER_FETCH_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads to use for localization fetching.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOCALIZER_FETCH_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_DIRS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Where to store container logs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_DIRS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_AGGREGATION_THREAD_POOL_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of threads to handle log aggregation in node manager.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_AGGREGATION_THREAD_POOL_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_DEFAULT_CONTAINER_EXECUTOR_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default permissions for container logs.]]>
+      </doc>
+    </field>
+    <field name="NM_DEFAULT_CONTAINER_EXECUTOR_LOG_DIRS_PERMISSIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_DEFAULT_CONTAINER_EXECUTOR_LOG_DIRS_PERMISSIONS_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RESOURCEMANAGER_MINIMUM_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_RESOURCEMANAGER_MINIMUM_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DISK_VALIDATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Disk Validator.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_DISK_VALIDATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_DIAGNOSTICS_MAXIMUM_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Maximum size of contain's diagnostics to keep for relaunching container
+ case.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_DIAGNOSTICS_MAXIMUM_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_RETRY_MINIMUM_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Minimum container restart interval.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_RETRY_MINIMUM_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_QUEUING_USE_PAUSE_FOR_PREEMPTION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Use container pause as the preemption policy over kill in the container
+ queue at a NodeManager.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_QUEUING_USE_PAUSE_FOR_PREEMPTION" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Interval at which the delayed token removal thread runs]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_DELAYED_DELEGATION_TOKEN_REMOVAL_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Delegation Token renewer thread count]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_DELEGATION_TOKEN_RENEWER_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PROXY_USER_PRIVILEGES_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_PROXY_USER_PRIVILEGES_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODE_IP_CACHE_EXPIRY_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The expiry interval for node IP caching. -1 disables the caching]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_NODE_IP_CACHE_EXPIRY_INTERVAL_SECS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_MAX_LOG_AGGREGATION_DIAGNOSTICS_IN_MEMORY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How many diagnostics/failure messages can be saved in RM for
+ log aggregation. It also defines the number of diagnostics/failure
+ messages can be shown in log aggregation web ui.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RM_MAX_LOG_AGGREGATION_DIAGNOSTICS_IN_MEMORY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether to enable log aggregation]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_LOG_AGGREGATION_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_FILE_FORMATS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_FILE_CONTROLLER_FMT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_REMOTE_APP_LOG_DIR_FMT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_REMOTE_APP_LOG_DIR_SUFFIX_FMT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_RETAIN_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How long to wait before deleting aggregated logs, -1 disables.
+ Be careful set this too small and you will spam the name node.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_LOG_AGGREGATION_RETAIN_SECONDS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_DEBUG_FILESIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_LOG_AGGREGATION_DEBUG_FILESIZE" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How long to wait between aggregated log retention checks. If set to
+ a value {@literal <=} 0 then the value is computed as one-tenth of the
+ log retention setting. Be careful set this too small and you will spam
+ the name node.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LOG_AGGREGATION_STATUS_TIME_OUT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How long for ResourceManager to wait for NodeManager to report its
+ log aggregation status. If waiting time of which the log aggregation status
+ is reported from NodeManager exceeds the configured value, RM will report
+ log aggregation status for this NodeManager as TIME_OUT.
+
+ This configuration will be used in NodeManager as well to decide
+ whether and when to delete the cached log aggregation status.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_LOG_AGGREGATION_STATUS_TIME_OUT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_RETAIN_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of seconds to retain logs on the NodeManager. Only applicable if Log
+ aggregation is disabled]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_RETAIN_SECONDS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Define how often NMs wake up and upload log files]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MIN_LOG_ROLLING_INTERVAL_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The allowed hard minimum limit for {@link
+ YarnConfiguration#NM_LOG_AGGREGATION_ROLL_MONITORING_INTERVAL_SECONDS}.]]>
+      </doc>
+    </field>
+    <field name="MIN_LOG_ROLLING_INTERVAL_SECONDS_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_AGGREGATION_NUM_LOG_FILES_SIZE_PER_APP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Define how many aggregated log files per application per NM we can have
+ in remote file system.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_AGGREGATION_NUM_LOG_FILES_SIZE_PER_APP" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_DELETION_THREADS_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads used in log cleanup. Only applicable if Log aggregation
+ is disabled]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_DELETE_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_REMOTE_APP_LOG_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Where to aggregate logs to.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_REMOTE_APP_LOG_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_REMOTE_APP_LOG_DIR_SUFFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The remote log dir will be created at
+ NM_REMOTE_APP_LOG_DIR/${user}/NM_REMOTE_APP_LOG_DIR_SUFFIX/${appId}]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_REMOTE_APP_LOG_DIR_SUFFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_LOG_SERVER_URL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_LOG_SERVER_WEBSERVICE_URL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_TRACKING_URL_GENERATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PMEM_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Amount of memory in MB that can be allocated for containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_PMEM_MB" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_SYSTEM_RESERVED_PMEM_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Amount of memory in MB that has been reserved for non-yarn use.]]>
+      </doc>
+    </field>
+    <field name="NM_PMEM_CHECK_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies whether physical memory check is enabled.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_PMEM_CHECK_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_VMEM_CHECK_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies whether physical memory check is enabled.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_VMEM_CHECK_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_VMEM_PMEM_RATIO" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Conversion ratio for physical memory to virtual memory.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_VMEM_PMEM_RATIO" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ELASTIC_MEMORY_CONTROL_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies whether to do memory check on overall usage.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_ELASTIC_MEMORY_CONTROL_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ELASTIC_MEMORY_CONTROL_OOM_HANDLER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies the OOM handler code.]]>
+      </doc>
+    </field>
+    <field name="NM_ELASTIC_MEMORY_CONTROL_OOM_LISTENER_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The path to the OOM listener.]]>
+      </doc>
+    </field>
+    <field name="NM_ELASTIC_MEMORY_CONTROL_OOM_TIMEOUT_SEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Maximum time in seconds to resolve an OOM situation.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_ELASTIC_MEMORY_CONTROL_OOM_TIMEOUT_SEC" type="java.lang.Integer"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_VCORES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of Virtual CPU Cores which can be allocated for containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_VCORES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_COUNT_LOGICAL_PROCESSORS_AS_CORES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Count logical processors(like hyperthreads) as cores.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_COUNT_LOGICAL_PROCESSORS_AS_CORES" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PCORES_VCORES_MULTIPLIER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Multiplier to convert physical cores to vcores.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_PCORES_VCORES_MULTIPLIER" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Percentage of overall CPU which can be allocated for containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_ENABLE_HARDWARE_CAPABILITY_DETECTION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable or disable node hardware capability detection.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_ENABLE_HARDWARE_CAPABILITY_DETECTION" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_MEMORY_RESOURCE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_MEMORY_RESOURCE_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_MEMORY_RESOURCE_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_MEMORY_RESOURCE_ENFORCED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_MEMORY_RESOURCE_ENFORCED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_MEMORY_RESOURCE_CGROUPS_SWAPPINESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_MEMORY_RESOURCE_CGROUPS_SWAPPINESS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_MEMORY_RESOURCE_CGROUPS_SOFT_LIMIT_PERCENTAGE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_MEMORY_RESOURCE_CGROUPS_SOFT_LIMIT_PERCENTAGE" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CPU_RESOURCE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CPU_RESOURCE_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable cpu isolation.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CPU_RESOURCE_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_DISK_RESOURCE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for disk configurations. Work in progress: This configuration
+ parameter may be changed/removed in the future.]]>
+      </doc>
+    </field>
+    <field name="NM_DISK_RESOURCE_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This setting controls if resource handling for disk operations is enabled.
+ Work in progress: This configuration parameter may be changed/removed in
+ the future]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DISK_RESOURCE_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Disk as a resource is disabled by default.]]>
+      </doc>
+    </field>
+    <field name="NM_NETWORK_RESOURCE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_RESOURCE_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This setting controls if resource handling for network bandwidth is
+ enabled. Work in progress: This configuration parameter may be
+ changed/removed in the future]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NETWORK_RESOURCE_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Network as a resource is disabled by default.]]>
+      </doc>
+    </field>
+    <field name="NM_NETWORK_RESOURCE_INTERFACE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies the interface to be used for applying network throttling rules.
+ Work in progress: This configuration parameter may be changed/removed in
+ the future]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NETWORK_RESOURCE_INTERFACE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_RESOURCE_OUTBOUND_BANDWIDTH_MBIT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies the total available outbound bandwidth on the node. Work in
+ progress: This configuration parameter may be changed/removed in the future]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NETWORK_RESOURCE_OUTBOUND_BANDWIDTH_MBIT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_RESOURCE_OUTBOUND_BANDWIDTH_YARN_MBIT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies the total outbound bandwidth available to YARN containers.
+ defaults to NM_NETWORK_RESOURCE_OUTBOUND_BANDWIDTH_MBIT if not specified.
+ Work in progress: This configuration parameter may be changed/removed in
+ the future]]>
+      </doc>
+    </field>
+    <field name="NM_RESOURCE_PLUGINS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for computation resources, example of computation resources like
+ GPU / FPGA / TPU, etc.]]>
+      </doc>
+    </field>
+    <field name="NM_RESOURCE_PLUGINS_FAIL_FAST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Specifies whether the initialization of the Node Manager should continue
+ if a certain device (GPU, FPGA, etc) was not found in the system. If set
+ to "true", then an exception will be thrown if a device is missing or
+ an error occurred during discovery.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_RESOURCE_PLUGINS_FAIL_FAST" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_GPU_RESOURCE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for gpu configurations. Work in progress: This configuration
+ parameter may be changed/removed in the future.]]>
+      </doc>
+    </field>
+    <field name="NM_GPU_ALLOWED_DEVICES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AUTOMATICALLY_DISCOVER_GPU_DEVICES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_GPU_PATH_TO_EXEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This setting controls where to how to invoke GPU binaries]]>
+      </doc>
+    </field>
+    <field name="NM_GPU_DOCKER_PLUGIN_IMPL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Settings to control which implementation of docker plugin for GPU will be
+ used.
+
+ By default uses NVIDIA docker v1.]]>
+      </doc>
+    </field>
+    <field name="NVIDIA_DOCKER_V1" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NVIDIA_DOCKER_V2" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_GPU_DOCKER_PLUGIN_IMPL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NVIDIA_DOCKER_PLUGIN_V1_ENDPOINT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This setting controls end point of nvidia-docker-v1 plugin]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NVIDIA_DOCKER_PLUGIN_V1_ENDPOINT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_FPGA_RESOURCE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for FPGA configurations. Work in progress: This configuration
+ parameter may be changed/removed in the future.]]>
+      </doc>
+    </field>
+    <field name="NM_FPGA_ALLOWED_DEVICES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_FPGA_PATH_TO_EXEC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_FPGA_VENDOR_PLUGIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_FPGA_VENDOR_PLUGIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_TAG_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_TAG_HANDLER_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NETWORK_TAG_HANDLER_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_TAG_MAPPING_MANAGER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NETWORK_TAG_MAPPING_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NETWORK_RESOURCE_TAG_MAPPING_FILE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[NM Webapp address.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_WEBAPP_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[NM Webapp https address.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_WEBAPP_HTTPS_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WEBAPP_ENABLE_CORS_FILTER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/disable CORS filter.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_WEBAPP_ENABLE_CORS_FILTER" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RESOURCE_MON_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How often to monitor resource in a node.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_RESOURCE_MON_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_MONITOR_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_MONITOR_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_MON_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How often to monitor containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_MON_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_MON_RESOURCE_CALCULATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Class that calculates current resource utilization.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_MON_RESOURCE_CALCULATOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Class that calculates containers current resource utilization.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_MON_PROCESS_TREE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Class that calculates process tree resource utilization.]]>
+      </doc>
+    </field>
+    <field name="PROCFS_USE_SMAPS_BASED_RSS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_PROCFS_USE_SMAPS_BASED_RSS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_LOG_MONITOR_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable switch for container log monitoring.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_LOG_MONITOR_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_LOG_MON_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[How often to monitor logs generated by containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_LOG_MON_INTERVAL_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_LOG_DIR_SIZE_LIMIT_BYTES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The disk space limit for a single container log directory.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_LOG_DIR_SIZE_LIMIT_BYTES" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_LOG_TOTAL_SIZE_LIMIT_BYTES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The disk space limit for all of a container's logs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_LOG_TOTAL_SIZE_LIMIT_BYTES" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_METRICS_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/disable container metrics.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_METRICS_ENABLE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_METRICS_PERIOD_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container metrics flush period. -1 for flush on completion.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_METRICS_PERIOD_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_METRICS_UNREGISTER_DELAY_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The delay time ms to unregister container metrics after completion.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_METRICS_UNREGISTER_DELAY_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_DISK_HEALTH_CHECK_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/Disable disks' health checker. Default is true. An expert level
+ configuration property.]]>
+      </doc>
+    </field>
+    <field name="NM_DISK_HEALTH_CHECK_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Frequency of running disks' health checker.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DISK_HEALTH_CHECK_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[By default, disks' health is checked every 2 minutes.]]>
+      </doc>
+    </field>
+    <field name="NM_MIN_HEALTHY_DISKS_FRACTION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The minimum fraction of number of disks to be healthy for the nodemanager
+ to launch new containers. This applies to nm-local-dirs and nm-log-dirs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_MIN_HEALTHY_DISKS_FRACTION" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[By default, at least 25% of disks are to be healthy to say that the node is
+ healthy in terms of disks.]]>
+      </doc>
+    </field>
+    <field name="NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The maximum percentage of disk space that can be used after which a disk is
+ marked as offline. Values can range from 0.0 to 100.0. If the value is
+ greater than or equal to 100, NM will check for full disk. This applies to
+ nm-local-dirs and nm-log-dirs.
+
+ This applies when disk-utilization-threshold.enabled is true.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[By default, 90% of the disk can be used before it is marked as offline.]]>
+      </doc>
+    </field>
+    <field name="NM_DISK_UTILIZATION_THRESHOLD_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/Disable the disk utilisation percentage
+ threshold for disk health checker.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DISK_UTILIZATION_THRESHOLD_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WM_LOW_PER_DISK_UTILIZATION_PERCENTAGE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The low threshold percentage of disk space used when an offline disk is
+ marked as online. Values can range from 0.0 to 100.0. The value shouldn't
+ be more than NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE. If its value is
+ more than NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE or not set, it will be
+ set to the same value as NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE.
+ This applies to nm-local-dirs and nm-log-dirs.]]>
+      </doc>
+    </field>
+    <field name="NM_MIN_PER_DISK_FREE_SPACE_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The minimum space that must be available on a local dir for it to be used.
+ This applies to nm-local-dirs and nm-log-dirs.
+
+ This applies when disk-free-space-threshold.enabled is true.]]>
+      </doc>
+    </field>
+    <field name="NM_DISK_FREE_SPACE_THRESHOLD_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enable/Disable the minimum disk free
+ space threshold for disk health checker.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DISK_FREE_SPACE_THRESHOLD_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WM_HIGH_PER_DISK_FREE_SPACE_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The minimum space that must be available on an offline
+ disk for it to be marked as online.  The value should not be less
+ than NM_MIN_PER_DISK_FREE_SPACE_MB.  If its value is less than
+ NM_MIN_PER_DISK_FREE_SPACE_MB or is not set, it will be set to the
+ same value as NM_MIN_PER_DISK_FREE_SPACE_MB.
+ This applies to nm-local-dirs and nm-log-dirs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_MIN_PER_DISK_FREE_SPACE_MB" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[By default, all of the disk can be used before it is marked as offline.]]>
+      </doc>
+    </field>
+    <field name="NM_HEALTH_CHECK_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Frequency of running node health script.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_HEALTH_CHECK_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Health check script time out period.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_HEALTH_CHECK_SCRIPT_TIMEOUT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_HEALTH_CHECK_RUN_BEFORE_STARTUP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether or not to run the node health script before the NM
+  starts up.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_HEALTH_CHECK_RUN_BEFORE_STARTUP" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_HEALTH_CHECK_SCRIPT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The health check script to run.]]>
+      </doc>
+    </field>
+    <field name="NM_HEALTH_CHECK_SCRIPT_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The arguments to pass to the health check script.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_LOCALIZER_JAVA_OPTS_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The JVM options used on forking ContainerLocalizer process
+      by container executor.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_LOCALIZER_JAVA_OPTS_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_LOCALIZER_LOG_LEVEL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The log level of container localizer process.]]>
+      </doc>
+    </field>
+    <field name="NM_CONTAINER_LOCALIZER_LOG_LEVEL_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="LINUX_CONTAINER_RUNTIME_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for runtime configuration constants.]]>
+      </doc>
+    </field>
+    <field name="LINUX_CONTAINER_RUNTIME_ALLOWED_RUNTIMES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Comma separated list of runtimes that are allowed when using
+ LinuxContainerExecutor. The standard values are:
+ <ul>
+   <li>default</li>
+   <li>docker</li>
+   <li>javasandbox</li>
+ </ul>]]>
+      </doc>
+    </field>
+    <field name="LINUX_CONTAINER_RUNTIME_CLASS_FMT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_LINUX_CONTAINER_RUNTIME_ALLOWED_RUNTIMES" type="java.lang.String[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default list of allowed runtimes when using LinuxContainerExecutor.]]>
+      </doc>
+    </field>
+    <field name="LINUX_CONTAINER_RUNTIME_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default runtime to be used.]]>
+      </doc>
+    </field>
+    <field name="DOCKER_CONTAINER_RUNTIME_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_DOCKER_IMAGE_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default docker image to be used.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_CONTAINER_CAPABILITIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Capabilities allowed (and added by default) for docker containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_CONTAINER_CAPABILITIES" type="java.lang.String[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[These are the default capabilities added by docker. We'll use the same
+ set here. While these may not be case-sensitive from a docker
+ perspective, it is best to keep these uppercase.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_ALLOW_PRIVILEGED_CONTAINERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Allow privileged containers. Use with extreme care.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_ALLOW_PRIVILEGED_CONTAINERS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Privileged containers are disabled by default.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_ENABLE_USER_REMAPPING" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[enable user remapping.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_ENABLE_USER_REMAPPING" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set enable user remapping as false by default.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_USER_REMAPPING_UID_THRESHOLD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[lower limit for acceptable uids of user remapped user.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_USER_REMAPPING_UID_THRESHOLD" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set user remapping lower uid limit to 1 by default.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_USER_REMAPPING_GID_THRESHOLD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[lower limit for acceptable gids of user remapped user.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_USER_REMAPPING_GID_THRESHOLD" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set user remapping lower gid limit to 1 by default.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_PRIVILEGED_CONTAINERS_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[ACL list for users allowed to run privileged containers.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_PRIVILEGED_CONTAINERS_ACL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default list for users allowed to run privileged containers is empty.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_ALLOWED_CONTAINER_NETWORKS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The set of networks allowed when launching containers using the
+ DockerContainerRuntime.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_ALLOWED_CONTAINER_NETWORKS" type="java.lang.String[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The set of networks allowed when launching containers using the
+ DockerContainerRuntime.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_DEFAULT_CONTAINER_NETWORK" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The network used when launching containers using the
+ DockerContainerRuntime when no network is specified in the request. This
+  network must be one of the (configurable) set of allowed container
+  networks.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_DEFAULT_CONTAINER_NETWORK" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The network used when launching containers using the
+ DockerContainerRuntime when no network is specified in the request and
+ no default network is configured.
+ .]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_ALLOW_HOST_PID_NAMESPACE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Allow host pid namespace for containers. Use with care.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_ALLOW_HOST_PID_NAMESPACE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Host pid namespace for containers is disabled by default.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_ALLOW_DELAYED_REMOVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether or not users are allowed to request that Docker containers honor
+ the debug deletion delay. This is useful for troubleshooting Docker
+ container related launch failures.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_ALLOW_DELAYED_REMOVAL" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default value on whether or not a user can request that Docker
+ containers honor the debug deletion delay.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_STOP_GRACE_PERIOD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="use {@link YarnConfiguration#NM_SLEEP_DELAY_BEFORE_SIGKILL_MS}">
+      <doc>
+      <![CDATA[A configurable value to pass to the Docker Stop command. This value
+ defines the number of seconds between the docker stop command sending
+ a SIGTERM and a SIGKILL.
+
+ @deprecated use {@link YarnConfiguration#NM_SLEEP_DELAY_BEFORE_SIGKILL_MS}]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_DOCKER_STOP_GRACE_PERIOD" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default value for the grace period between the SIGTERM and the
+ SIGKILL in the Docker Stop command.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_DEFAULT_RO_MOUNTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default list of read-only mounts to be bind-mounted into all
+  Docker containers that use DockerContainerRuntime.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_DEFAULT_RW_MOUNTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default list of read-write mounts to be bind-mounted into all
+  Docker containers that use DockerContainerRuntime.]]>
+      </doc>
+    </field>
+    <field name="NM_DOCKER_DEFAULT_TMPFS_MOUNTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default list of tmpfs mounts to be mounted into all
+  Docker containers that use DockerContainerRuntime.]]>
+      </doc>
+    </field>
+    <field name="YARN_CONTAINER_SANDBOX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The mode in which the Java Container Sandbox should run detailed by
+  the JavaSandboxLinuxContainerRuntime.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_CONTAINER_SANDBOX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_CONTAINER_SANDBOX_FILE_PERMISSIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Permissions for application local directories.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_CONTAINER_SANDBOX_FILE_PERMISSIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_CONTAINER_SANDBOX_POLICY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Location for non-default java policy file.]]>
+      </doc>
+    </field>
+    <field name="YARN_CONTAINER_SANDBOX_POLICY_GROUP_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Prefix for group to policy file mapping.]]>
+      </doc>
+    </field>
+    <field name="YARN_CONTAINER_SANDBOX_WHITELIST_GROUP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The group which will run by default without the java security manager.]]>
+      </doc>
+    </field>
+    <field name="NM_LINUX_CONTAINER_EXECUTOR_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The path to the Linux container executor.]]>
+      </doc>
+    </field>
+    <field name="NM_NONSECURE_MODE_LIMIT_USERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[True if linux-container-executor should limit itself to one user
+ when running in non-secure mode.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NONSECURE_MODE_LIMIT_USERS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NONSECURE_MODE_LOCAL_USER_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The UNIX user that containers will run as when Linux-container-executor
+ is used in nonsecure mode (a use case for this is using cgroups).]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NONSECURE_MODE_LOCAL_USER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NONSECURE_MODE_USER_PATTERN_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The allowed pattern for UNIX user names enforced by 
+ Linux-container-executor when used in nonsecure mode (use case for this 
+ is using cgroups). The default value is taken from /usr/sbin/adduser]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NONSECURE_MODE_USER_PATTERN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LINUX_CONTAINER_RESOURCES_HANDLER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The type of resource enforcement to use with the
+  linux container executor.]]>
+      </doc>
+    </field>
+    <field name="NM_LINUX_CONTAINER_CGROUPS_HIERARCHY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The path the linux container executor should use for cgroups]]>
+      </doc>
+    </field>
+    <field name="NM_LINUX_CONTAINER_CGROUPS_MOUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether the linux container executor should mount cgroups if not found]]>
+      </doc>
+    </field>
+    <field name="NM_LINUX_CONTAINER_CGROUPS_MOUNT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Where the linux container executor should mount cgroups if not found]]>
+      </doc>
+    </field>
+    <field name="NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether the apps should run in strict resource usage mode(not allowed to
+ use spare CPU)]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_APPLICATION_MONITOR_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_APPLICATION_MONITOR_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PROXY_TIMEOUT_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFALUT_RM_PROXY_TIMEOUT_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_PROXY_CONNECTION_TIMEOUT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_PROXY_CONNECTION_TIMEOUT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Interval of time the linux container executor should try cleaning up
+ cgroups entry when cleaning up a container. This is required due to what 
+ it seems a race condition because the SIGTERM/SIGKILL is asynch.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_TIMEOUT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Delay between attempts to remove linux cgroup.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LINUX_CONTAINER_CGROUPS_DELETE_DELAY" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Indicates if memory and CPU limits will be set for the Windows Job
+ Object for the containers launched by the default container executor.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_WINDOWS_CONTAINER_MEMORY_LIMIT_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_WINDOWS_CONTAINER_CPU_LIMIT_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WINDOWS_SECURE_CONTAINER_GROUP" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[/* The Windows group that the windows-secure-container-executor should run as.]]>
+      </doc>
+    </field>
+    <field name="NM_LOG_AGG_COMPRESSION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[T-file compression types used to compress aggregated logs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_LOG_AGG_COMPRESSION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PRINCIPAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The kerberos principal for the node manager.]]>
+      </doc>
+    </field>
+    <field name="NM_AUX_SERVICES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_AUX_SERVICE_FMT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_AUX_SERVICES_CLASSPATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_AUX_SERVICE_REMOTE_CLASSPATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_AUX_SERVICES_SYSTEM_CLASSES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_USER_HOME_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_STDERR_PATTERN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_STDERR_PATTERN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINER_STDERR_BYTES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_CONTAINER_STDERR_BYTES" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_WEBAPP_SPNEGO_USER_NAME_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The kerberos principal to be used for spnego filter for NM.]]>
+      </doc>
+    </field>
+    <field name="NM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The kerberos keytab to be used for spnego filter for NM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_USER_HOME_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RECOVERY_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RECOVERY_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_RECOVERY_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RECOVERY_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RECOVERY_COMPACTION_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The time in seconds between full compactions of the NM state database.
+  Setting the interval to zero disables the full compaction cycles.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_RECOVERY_COMPACTION_INTERVAL_SECS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RECOVERY_SUPERVISED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_RECOVERY_SUPERVISED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_AGG_POLICY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_LOG_AGG_POLICY_CLASS_PARAMETERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PROXY_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PROXY_PRINCIPAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The kerberos principal for the proxy.]]>
+      </doc>
+    </field>
+    <field name="PROXY_KEYTAB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Keytab for Proxy.]]>
+      </doc>
+    </field>
+    <field name="PROXY_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address for the web proxy.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_PROXY_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_PROXY_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCETRACKER_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[YARN Service Level Authorization]]>
+      </doc>
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONCLIENT_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCEMANAGER_ADMINISTRATION_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONMASTER_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_DISTRIBUTEDSCHEDULING_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_CONTAINER_MANAGEMENT_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCE_LOCALIZER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONHISTORY_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_COLLECTOR_NODEMANAGER_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONMASTER_NODEMANAGER_PROTOCOL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_SLEEP_DELAY_BEFORE_SIGKILL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[No. of milliseconds to wait between sending a SIGTERM and SIGKILL
+ to a running container]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_SLEEP_DELAY_BEFORE_SIGKILL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PROCESS_KILL_WAIT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max time to wait for a process to come up when trying to cleanup
+ container resources]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_PROCESS_KILL_WAIT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RESOURCEMANAGER_CONNECT_MAX_WAIT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max time to wait to establish a connection to RM]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RESOURCEMANAGER_CONNECT_MAX_WAIT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Time interval between each attempt to connect to RM]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DISPATCHER_DRAIN_EVENTS_TIMEOUT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_DISPATCHER_DRAIN_EVENTS_TIMEOUT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_DISPATCHER_PRINT_EVENTS_INFO_THRESHOLD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The threshold used to trigger the logging of event types and counts
+  in RM's main event dispatcher. Default value is 5000,
+  which means RM will print events info when the queue size cumulatively
+  reaches 5000 every time. Such info can be used to reveal what
+  kind of events that RM is stuck at processing mostly,
+  it can help to narrow down certain performance issues.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_DISPATCHER_PRINT_EVENTS_INFO_THRESHOLD" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_DISPATCHER_CPU_MONITOR_SAMPLES_PER_MIN" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Resource manager dispatcher thread monitor sampling rate.
+ Units are samples per minute.  This controls how often to sample
+ the cpu utilization of the resource manager dispatcher thread.
+ The cpu utilization is displayed on the RM UI as scheduler busy %.
+ Set to zero to disable the dispatcher thread monitor.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_DISPATCHER_CPU_MONITOR_SAMPLES_PER_MIN" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_APPLICATION_CLASSPATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[CLASSPATH for YARN applications. A comma-separated list of CLASSPATH
+ entries]]>
+      </doc>
+    </field>
+    <field name="AMRM_PROXY_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether AMRMProxy is enabled or not.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_AMRM_PROXY_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AMRM_PROXY_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AMRM_PROXY_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AMRM_PROXY_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AMRM_PROXY_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AMRM_PROXY_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AMRM_PROXY_INTERCEPTOR_CLASS_PIPELINE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AMRM_PROXY_INTERCEPTOR_CLASS_PIPELINE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AMRM_PROXY_HA_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AMRM_PROXY_HA_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH" type="java.lang.String[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default platform-agnostic CLASSPATH for YARN applications. A
+ comma-separated list of CLASSPATH entries. The parameter expansion marker
+ will be replaced with real parameter expansion marker ('%' for Windows and
+ '$' for Linux) by NodeManager on container launch. For example: {{VAR}}
+ will be replaced as $VAR on Linux, and %VAR% on Windows.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_APPLICATION_CLASSPATH" type="java.lang.String[]"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[<p>
+ Default platform-specific CLASSPATH for YARN applications. A
+ comma-separated list of CLASSPATH entries constructed based on the client
+ OS environment expansion syntax.
+ </p>
+ <p>
+ Note: Use {@link #DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH} for
+ cross-platform practice i.e. submit an application from a Windows client to
+ a Linux/Unix server or vice versa.
+ </p>]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_CONTAINER_TEMP_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Container temp directory]]>
+      </doc>
+    </field>
+    <field name="IS_MINI_YARN_CLUSTER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_MC_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_MINICLUSTER_FIXED_PORTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether to use fixed ports with the minicluster.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_MINICLUSTER_FIXED_PORTS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default is false to be able to run tests concurrently without port
+ conflicts.]]>
+      </doc>
+    </field>
+    <field name="YARN_MINICLUSTER_USE_RPC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether the NM should use RPC to connect to the RM. Default is false.
+ Can be set to true only when using fixed ports.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_MINICLUSTER_USE_RPC" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Whether users are explicitly trying to control resource monitoring
+ configuration for the MiniYARNCluster. Disabled by default.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_MINICLUSTER_NM_PMEM_MB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Allow changing the memory for the NodeManager in the MiniYARNCluster]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_MINICLUSTER_NM_PMEM_MB" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_APP_CONTAINER_LOG_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The log directory for the containers]]>
+      </doc>
+    </field>
+    <field name="YARN_APP_CONTAINER_LOG_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_APP_CONTAINER_LOG_BACKUPS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_VERSION" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_VERSIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_UI_NAMES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Comma separated list of names for UIs hosted in the timeline server
+ (For pluggable UIs).]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_UI_WEB_PATH_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Relative web path that will serve up this UI (For pluggable UIs).]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline client settings.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_UI_ON_DISK_PATH_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Path to war file or static content directory for this UI
+ (For pluggable UIs).]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting for timeline service v1.5]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_CACHE_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_ACTIVE_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_ACTIVE_DIR_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_DONE_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_DONE_DIR_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITY_GROUP_PLUGIN_CLASSES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITY_GROUP_PLUGIN_CLASSPATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITY_GROUP_PLUGIN_SYSTEM_CLASSES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_SUMMARY_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_SUMMARY_ENTITY_TYPES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_SCAN_INTERVAL_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_SCAN_INTERVAL_SECONDS_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_THREADS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_THREADS_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_APP_CACHE_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_APP_CACHE_SIZE_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_CLEANER_INTERVAL_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_CLEANER_INTERVAL_SECONDS_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_RETAIN_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_RETAIN_SECONDS_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_UNKNOWN_ACTIVE_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_UNKNOWN_ACTIVE_SECONDS_DEFAULT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_CACHE_READ_CACHE_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_CACHE_READ_CACHE_SIZE" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_FD_FLUSH_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_FD_FLUSH_INTERVAL_SECS_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_FD_CLEAN_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_FD_CLEAN_INTERVAL_SECS_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_FD_RETAIN_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_FD_RETAIN_SECS_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_INTERNAL_TIMERS_TTL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_INTERNAL_TIMERS_TTL_SECS_DEFAULT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_INTERNAL_ATTEMPT_DIR_CACHE_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_CLIENT_INTERNAL_ATTEMPT_DIR_CACHE_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYFILE_FS_SUPPORT_APPEND" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_WITH_USER_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_READER_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Settings for timeline service v2.0.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_WRITER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WRITER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_READER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_READER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_HBASE_SCHEMA_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[default schema prefix for hbase tables.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_HBASE_SCHEMA_PREFIX_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[config param name to override schema prefix.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_WRITER_FLUSH_INTERVAL_SECONDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls how often the timeline collector flushes the
+ timeline writer.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WRITER_FLUSH_INTERVAL_SECONDS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_WRITER_ASYNC_QUEUE_CAPACITY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls the capacity of the queue for async writes
+ to timeline collector.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WRITER_ASYNC_QUEUE_CAPACITY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APP_FINAL_VALUE_RETENTION_THRESHOLD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The name for setting that controls how long the final value of
+ a metric of a completed app is retained before merging
+ into the flow sum.]]>
+      </doc>
+    </field>
+    <field name="FLOW_RUN_COPROCESSOR_JAR_HDFS_LOCATION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The name of the setting for the location of the coprocessor
+ jar on hdfs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_HDFS_LOCATION_FLOW_RUN_COPROCESSOR_JAR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[default hdfs location for flowrun coprocessor jar.]]>
+      </doc>
+    </field>
+    <field name="FLOW_NAME_MAX_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[This setting controls the max size of the flow name getting generated
+ in ATSv2 after removing UUID if present.]]>
+      </doc>
+    </field>
+    <field name="FLOW_NAME_DEFAULT_MAX_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default setting for flow name size has no size restriction
+ after removing UUID if present.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_HBASE_CONFIGURATION_FILE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The name for setting that points to an optional HBase configuration
+ (hbase-site.xml file) with settings that will override the ones found on
+ the classpath.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_READ_AUTH_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The name for setting that enables or disables authentication checks
+ for reading timeline service v2 data.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_AGGREGATION_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The name for setting that controls how often in-memory app level
+ aggregation is kicked off in timeline collector.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_AGGREGATION_INTERVAL_SECS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_READ_AUTH_ENABLED" type="java.lang.Boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default setting for authentication checks for reading timeline
+ service v2 data.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_READ_ALLOWED_USERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The name for setting that lists the users and groups who are allowed
+ to read timeline service v2 data. It is a comma separated list of
+ user, followed by space, then comma separated list of groups.
+ It will allow this list of users and groups to read the data
+ and reject everyone else.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_READ_ALLOWED_USERS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The default value for list of the users who are allowed to read
+ timeline service v2 data.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_APP_FINAL_VALUE_RETENTION_THRESHOLD" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls how long the final value of a metric of a
+ completed app is retained before merging into the flow sum. Up to this time
+ after an application is completed out-of-order values that arrive can be
+ recognized and discarded at the cost of increased storage.]]>
+      </doc>
+    </field>
+    <field name="ATS_APP_COLLECTOR_LINGER_PERIOD_IN_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ATS_APP_COLLECTOR_LINGER_PERIOD_IN_MS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NUMBER_OF_ASYNC_ENTITIES_TO_MERGE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NUMBER_OF_ASYNC_ENTITIES_TO_MERGE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FLOW_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[default version for any flow.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_V2_CLIENT_DRAIN_TIME_MILLIS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The time period for which timeline v2 client will wait for draining
+ leftover entities after stop.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_V2_CLIENT_DRAIN_TIME_MILLIS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_HISTORY_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_HISTORY_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether application history service is
+  enabled or not.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_APPLICATION_HISTORY_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_HISTORY_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Application history store class]]>
+      </doc>
+    </field>
+    <field name="APPLICATION_HISTORY_SAVE_NON_AM_CONTAINER_META_INFO" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Save container meta-info in the application history store.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_APPLICATION_HISTORY_SAVE_NON_AM_CONTAINER_META_INFO" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FS_APPLICATION_HISTORY_STORE_URI" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[URI for FileSystemApplicationHistoryStore]]>
+      </doc>
+    </field>
+    <field name="FS_APPLICATION_HISTORY_STORE_COMPRESSION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[T-file compression types used to compress history data.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_FS_APPLICATION_HISTORY_STORE_COMPRESSION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The setting that controls whether timeline service is enabled or not.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[host:port address for timeline service RPC APIs.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The listening endpoint for the timeline service application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_HANDLER_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of threads to handle client RPC API requests.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the timeline service web application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WEBAPP_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The https address of the timeline service web application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_HISTORY_MAX_APPS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Defines the max number of applications could be fetched using
+ REST API or application history protocol and shown in timeline
+ server web ui.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_APPLICATION_HISTORY_MAX_APPS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_STORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service store class.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_TTL_ENABLE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service enable data age off]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_TTL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service length of time to retain data]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_TTL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_ROLLING_PERIOD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service rolling period. Valid values are daily, half_daily,
+ quarter_daily, and hourly.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_ROLLING_PERIOD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Roll a new database each hour.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Implementation specific configuration prefix for Timeline Service
+ leveldb.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb path]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb read cache (uncompressed blocks). This is
+ per rolling instance so should be tuned if using rolling leveldb
+ timeline store]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_READ_CACHE_SIZE" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default leveldb read cache size if no configuration is specified.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_WRITE_BUFFER_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb write buffer size.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_WRITE_BUFFER_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default leveldb write buffer size if no configuration is specified. This
+ is per rolling instance so should be tuned if using rolling leveldb
+ timeline store.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_WRITE_BATCH_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb write batch size. This value can be tuned down
+ to reduce lock time for ttl eviction.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_WRITE_BATCH_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default leveldb write batch size is no configuration is specified]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb start time read cache (number of entities)]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_READ_CACHE_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb start time write cache (number of entities)]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_START_TIME_WRITE_CACHE_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb interval to wait between deletion rounds]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_TTL_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_MAX_OPEN_FILES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service leveldb number of concurrent open files. Tuned this
+ configuration to stay within system limits. This is per rolling instance
+ so should be tuned if using rolling leveldb timeline store.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_LEVELDB_MAX_OPEN_FILES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default leveldb max open files if no configuration is specified.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_PRINCIPAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The Kerberos principal for the timeline server.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_KEYTAB" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The Kerberos keytab for the timeline server.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Enables cross origin support for timeline server.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_HTTP_CROSS_ORIGIN_ENABLED_DEFAULT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default value for cross origin support for timeline server.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_MAX_RETRIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline client call, max retries (-1 means no limit)]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_CLIENT_MAX_RETRIES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline client call, retry interval]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_CLIENT_BEST_EFFORT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline client policy for whether connections are fatal]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_CLIENT_BEST_EFFORT" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_RECOVERY_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Flag to enable recovery of timeline service]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_RECOVERY_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_STATE_STORE_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service state store class]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_STATE_STORE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_LEVELDB_STATE_STORE_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Timeline service state store leveldb path]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_DELEGATION_KEY_UPDATE_INTERVAL" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_DELEGATION_TOKEN_RENEW_INTERVAL" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_DELEGATION_TOKEN_MAX_LIFETIME" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_OFFLINE_AGGREGATION_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PHOENIX_OFFLINE_STORAGE_CONN_STR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="PHOENIX_OFFLINE_STORAGE_CONN_STR_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[whether the shared cache is enabled/disabled]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SHARED_CACHE_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_ROOT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The config key for the shared cache root directory.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SHARED_CACHE_ROOT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_NESTED_LEVEL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The config key for the level of nested directories before getting to the
+ checksum directory.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SHARED_CACHE_NESTED_LEVEL" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_STORE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_STORE_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCM_STORE_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_APP_CHECKER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCM_APP_CHECKER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_ADMIN_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the SCM admin interface.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_ADMIN_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCM_ADMIN_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_ADMIN_CLIENT_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Number of threads used to handle SCM admin interface.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_ADMIN_CLIENT_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the SCM web application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_WEBAPP_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCM_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IN_MEMORY_STORE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IN_MEMORY_STALENESS_PERIOD_MINS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[A resource in the InMemorySCMStore is considered stale if the time since
+ the last reference exceeds the staleness period. This value is specified in
+ minutes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IN_MEMORY_STALENESS_PERIOD_MINS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IN_MEMORY_INITIAL_DELAY_MINS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Initial delay before the in-memory store runs its first check to remove
+ dead initial applications. Specified in minutes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IN_MEMORY_INITIAL_DELAY_MINS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="IN_MEMORY_CHECK_PERIOD_MINS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The frequency at which the in-memory store checks to remove dead initial
+ applications. Specified in minutes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_IN_MEMORY_CHECK_PERIOD_MINS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_CLEANER_PERIOD_MINS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The frequency at which a cleaner task runs. Specified in minutes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_CLEANER_PERIOD_MINS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_CLEANER_INITIAL_DELAY_MINS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Initial delay before the first cleaner task is scheduled. Specified in
+ minutes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_CLEANER_INITIAL_DELAY_MINS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_CLEANER_RESOURCE_SLEEP_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The time to sleep between processing each shared cache resource. Specified
+ in milliseconds.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_CLEANER_RESOURCE_SLEEP_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_UPLOADER_SERVER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the node manager interface in the SCM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_UPLOADER_SERVER_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCM_UPLOADER_SERVER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_UPLOADER_SERVER_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of SCM threads used to handle notify requests from the node
+ manager.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_UPLOADER_SERVER_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_CLIENT_SERVER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the client interface in the SCM.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_CLIENT_SERVER_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SCM_CLIENT_SERVER_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCM_CLIENT_SERVER_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of threads used to handle shared cache manager requests.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SCM_CLIENT_SERVER_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_CHECKSUM_ALGO_IMPL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[the checksum algorithm implementation]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SHARED_CACHE_CHECKSUM_ALGO_IMPL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The replication factor for the node manager uploader for the shared cache.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_SHARED_CACHE_NM_UPLOADER_REPLICATION_FACTOR" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SHARED_CACHE_NM_UPLOADER_THREAD_COUNT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_SHARED_CACHE_NM_UPLOADER_THREAD_COUNT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_FAILOVER_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_FAILOVER_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_CLIENT_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_STATESTORE_CLIENT_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_CACHE_TIME_TO_LIVE_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_CACHE_TIME_TO_LIVE_SECS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_FLUSH_CACHE_FOR_RM_ADDR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_FLUSH_CACHE_FOR_RM_ADDR" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_REGISTRY_BASE_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_REGISTRY_BASE_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_HEARTBEAT_INTERVAL_SECS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_STATESTORE_HEARTBEAT_INTERVAL_SECS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_MACHINE_LIST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_CLUSTER_RESOLVER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_CLUSTER_RESOLVER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_AMRMPROXY_HB_MAX_WAIT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_AMRMPROXY_HB_MAX_WAIT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_AMRMPROXY_SUBCLUSTER_TIMEOUT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_AMRMPROXY_SUBCLUSTER_TIMEOUT" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_POLICY_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_POLICY_MANAGER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_POLICY_MANAGER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_POLICY_MANAGER_PARAMS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_POLICY_MANAGER_PARAMS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_ZK_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_ZK_PARENT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Parent znode path under which ZKRMStateStore will create znodes.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_FEDERATION_STATESTORE_ZK_PARENT_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_SQL_USERNAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_SQL_PASSWORD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_SQL_URL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_SQL_JDBC_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_STATESTORE_SQL_JDBC_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FEDERATION_STATESTORE_SQL_MAXCONNECTIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FEDERATION_STATESTORE_SQL_MAXCONNECTIONS" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_CLIENTRM_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_CLIENTRM_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_CLIENTRM_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_CLIENTRM_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_CLIENTRM_INTERCEPTOR_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_PIPELINE_CACHE_MAX_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_PIPELINE_CACHE_MAX_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_RMADMIN_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_RMADMIN_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_RMADMIN_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_RMADMIN_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_RMADMIN_INTERCEPTOR_CLASS_PIPELINE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_RMADMIN_INTERCEPTOR_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_CLIENTRM_SUBMIT_RETRY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The number of retries for GetNewApplication and SubmitApplication in
+ {@code FederationClientInterceptor}.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ROUTER_CLIENTRM_SUBMIT_RETRY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_WEBAPP_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_USER_CLIENT_THREADS_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_USER_CLIENT_THREADS_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The address of the Router web application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The https address of the Router web application.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_HTTPS_PORT" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_WEBAPP_INTERCEPTOR_CLASS_PIPELINE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_INTERCEPTOR_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_WEBAPP_DEFAULT_INTERCEPTOR_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The interceptor class used in FederationInterceptorREST to communicate with
+ each SubCluster.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_DEFAULT_INTERCEPTOR_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ROUTER_WEBAPP_PARTIAL_RESULTS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The interceptor class used in FederationInterceptorREST should return
+ partial AppReports.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_ROUTER_WEBAPP_PARTIAL_RESULTS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_REGISTRY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_YARN_REGISTRY_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_CLIENT_APP_SUBMISSION_POLL_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Use YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS instead.
+ The interval of the yarn client's querying application state after
+ application submission. The unit is millisecond.]]>
+      </doc>
+    </field>
+    <field name="YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The interval that the yarn client library uses to poll the completion
+ status of the asynchronous API of application client protocol.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[The duration that the yarn client library waits, cumulatively across polls,
+ for an expected state change to occur. Defaults to -1, which indicates no
+ limit.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_YARN_CLIENT_APPLICATION_CLIENT_PROTOCOL_POLL_TIMEOUT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max number of threads in NMClientAsync to process container management
+ events]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CLIENT_MAX_NM_PROXIES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Maximum number of proxy connections to cache for node managers. If set
+ to a value greater than zero then the cache is enabled and the NMClient
+ and MRAppMaster will cache the specified number of node manager proxies.
+ There will be at max one proxy per node manager. Ex. configuring it to a
+ value of 5 will make sure that client will at max have 5 proxies cached
+ with 5 different node managers. These connections for these proxies will
+ be timed out if idle for more than the system wide idle timeout period.
+ Note that this could cause issues on large clusters as many connections
+ could linger simultaneously and lead to a large number of connection
+ threads. The token used for authentication will be used only at
+ connection creation time. If a new token is received then the earlier
+ connection should be closed in order to use the new token. This and
+ {@link YarnConfiguration#NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE} are related
+ and should be in sync (no need for them to be equal).
+ If the value of this property is zero then the connection cache is
+ disabled and connections will use a zero idle timeout to prevent too
+ many connection threads on large clusters.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_CLIENT_MAX_NM_PROXIES" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_NM_CONNECT_MAX_WAIT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max time to wait to establish a connection to NM]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_CLIENT_NM_CONNECT_MAX_WAIT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CLIENT_NM_CONNECT_RETRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Time interval between each attempt to connect to NM]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_CLIENT_NM_CONNECT_RETRY_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_HTTP_POLICY_KEY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_HTTP_POLICY_DEFAULT" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_RESOURCEMANAGER_CONNECT_MAX_WAIT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Max time to wait for NM to connection to RM.
+ When not set, proxy will fall back to use value of
+ RESOURCEMANAGER_CONNECT_MAX_WAIT_MS.]]>
+      </doc>
+    </field>
+    <field name="NM_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Time interval between each NM attempt to connection to RM.
+ When not set, proxy will fall back to use value of
+ RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS.]]>
+      </doc>
+    </field>
+    <field name="NODE_LABELS_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Node-labels configurations]]>
+      </doc>
+    </field>
+    <field name="FS_NODE_LABELS_STORE_IMPL_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Node label store implementation class]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_FS_NODE_LABELS_STORE_IMPL_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FS_NODE_LABELS_STORE_ROOT_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[URI for NodeLabelManager]]>
+      </doc>
+    </field>
+    <field name="NODE_ATTRIBUTE_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Node-attribute configurations.]]>
+      </doc>
+    </field>
+    <field name="FS_NODE_ATTRIBUTE_STORE_IMPL_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Node attribute store implementation class.]]>
+      </doc>
+    </field>
+    <field name="FS_NODE_ATTRIBUTE_STORE_ROOT_DIR" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[File system node attribute store directory.]]>
+      </doc>
+    </field>
+    <field name="NODE_LABELS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Flag to indicate if the node labels feature enabled, by default it's
+ disabled]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NODE_LABELS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NODELABEL_CONFIGURATION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CENTRALIZED_NODELABEL_CONFIGURATION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DELEGATED_CENTALIZED_NODELABEL_CONFIGURATION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DISTRIBUTED_NODELABEL_CONFIGURATION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NODELABEL_CONFIGURATION_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="EXCLUSIVE_ENFORCED_PARTITIONS_SUFFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="EXCLUSIVE_ENFORCED_PARTITIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="MAX_CLUSTER_LEVEL_APPLICATION_PRIORITY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_CLUSTER_LEVEL_APPLICATION_PRIORITY" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APP_ATTEMPT_DIAGNOSTICS_LIMIT_KC" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_APP_ATTEMPT_DIAGNOSTICS_LIMIT_KC" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_LABELS_PROVIDER_CONFIG" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_ATTRIBUTES_PROVIDER_CONFIG" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CONFIG_NODE_DESCRIPTOR_PROVIDER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="SCRIPT_NODE_DESCRIPTOR_PROVIDER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_LABELS_RESYNC_INTERVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NODE_LABELS_RESYNC_INTERVAL" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_ATTRIBUTES_RESYNC_INTERVAL" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NODE_ATTRIBUTES_RESYNC_INTERVAL" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_LABELS_PROVIDER_FETCH_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_LABELS_PROVIDER_FETCH_TIMEOUT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NODE_LABELS_PROVIDER_FETCH_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NODE_LABELS_PROVIDER_FETCH_TIMEOUT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PROVIDER_CONFIGURED_NODE_PARTITION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_PROVIDER_CONFIGURED_NODE_ATTRIBUTES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODE_LABELS_PROVIDER_CONFIG" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_NODE_LABELS_PROVIDER_FETCH_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_RM_NODE_LABELS_PROVIDER_FETCH_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AM_SCHEDULING_NODE_BLACKLISTING_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AM_SCHEDULING_NODE_BLACKLISTING_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="AM_SCHEDULING_NODE_BLACKLISTING_DISABLE_THRESHOLD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_AM_SCHEDULING_NODE_BLACKLISTING_DISABLE_THRESHOLD" type="float"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_SCRIPT_BASED_NODE_LABELS_PROVIDER_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_SCRIPT_BASED_NODE_LABELS_PROVIDER_SCRIPT_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_ATTRIBUTES_PROVIDER_FETCH_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Node attribute provider fetch attributes interval and timeout.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NODE_ATTRIBUTES_PROVIDER_FETCH_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NODE_ATTRIBUTES_PROVIDER_FETCH_TIMEOUT_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NODE_ATTRIBUTES_PROVIDER_FETCH_TIMEOUT_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_SCRIPT_BASED_NODE_ATTRIBUTES_PROVIDER_PATH" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_SCRIPT_BASED_NODE_ATTRIBUTES_PROVIDER_OPTS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DISPLAY_APPS_FOR_LOGGED_IN_USER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FILTER_ENTITY_LIST_BY_USER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_DISPLAY_APPS_FOR_LOGGED_IN_USER" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="ENABLE_REST_APP_SUBMISSIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_ENABLE_REST_APP_SUBMISSIONS" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="REST_CSRF" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CSRF_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CSRF_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_CSRF_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CSRF_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CSRF_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_CSRF_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CSRF_CUSTOM_HEADER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CSRF_CUSTOM_HEADER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_CSRF_CUSTOM_HEADER" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_CSRF_METHODS_TO_IGNORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CSRF_METHODS_TO_IGNORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_CSRF_METHODS_TO_IGNORE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="XFS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="YARN_XFS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_XFS_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_XFS_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_XFS_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="RM_XFS_OPTIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_XFS_OPTIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_XFS_OPTIONS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_READER_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Settings for timeline reader.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_READER_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_READER_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_READER_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_READER_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_READER_STORAGE_MONITOR_INTERVAL_MS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_STORAGE_MONITOR_INTERVAL_MS" type="long"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_COLLECTOR_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Marked collector properties as Private since it run as auxillary service.]]>
+      </doc>
+    </field>
+    <field name="TIMELINE_SERVICE_COLLECTOR_BIND_HOST" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_COLLECTOR_BIND_PORT_RANGES" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_COLLECTOR_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_COLLECTOR_WEBAPP_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="TIMELINE_SERVICE_COLLECTOR_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TIMELINE_SERVICE_COLLECTOR_WEBAPP_HTTPS_ADDRESS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NUMA_AWARENESS_ENABLED" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Settings for NUMA awareness.]]>
+      </doc>
+    </field>
+    <field name="DEFAULT_NM_NUMA_AWARENESS_ENABLED" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NUMA_AWARENESS_READ_TOPOLOGY" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NUMA_AWARENESS_READ_TOPOLOGY" type="boolean"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NUMA_AWARENESS_NODE_IDS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_NUMA_AWARENESS_NUMACTL_CMD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_NM_NUMA_AWARENESS_NUMACTL_CMD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="NM_CONTAINERS_LAUNCHER_CLASS" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Containers launcher implementation to use.]]>
+      </doc>
+    </field>
+    <field name="YARN_WORKFLOW_ID_TAG_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_YARN_WORKFLOW_ID_TAG_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.conf.YarnConfiguration -->
+</package>
+<package name="org.apache.hadoop.yarn.exceptions">
+  <!-- start class org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException -->
+  <class name="ApplicationAttemptNotFoundException" extends="org.apache.hadoop.yarn.exceptions.YarnException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationAttemptNotFoundException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationAttemptNotFoundException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationAttemptNotFoundException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown on
+ {@link ApplicationHistoryProtocol#getApplicationAttemptReport (GetApplicationAttemptReportRequest)}
+ API when the Application Attempt doesn't exist in Application History Server or
+ {@link ApplicationMasterProtocol#allocate(AllocateRequest)} if application
+ doesn't exist in RM.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.ApplicationAttemptNotFoundException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.ApplicationIdNotProvidedException -->
+  <class name="ApplicationIdNotProvidedException" extends="org.apache.hadoop.yarn.exceptions.YarnException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationIdNotProvidedException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationIdNotProvidedException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationIdNotProvidedException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Exception to be thrown when Client submit an application without
+ providing {@link ApplicationId} in {@link ApplicationSubmissionContext}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.ApplicationIdNotProvidedException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException -->
+  <class name="ApplicationNotFoundException" extends="org.apache.hadoop.yarn.exceptions.YarnException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationNotFoundException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationNotFoundException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationNotFoundException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown on
+ {@link ApplicationClientProtocol#getApplicationReport
+ (GetApplicationReportRequest)} API
+ when the Application doesn't exist in RM and AHS]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.ConfigurationException -->
+  <class name="ConfigurationException" extends="org.apache.hadoop.yarn.exceptions.YarnException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ConfigurationException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ConfigurationException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ConfigurationException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown on unrecoverable configuration errors.
+ An example is container launch error due to configuration.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.ConfigurationException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.ContainerNotFoundException -->
+  <class name="ContainerNotFoundException" extends="org.apache.hadoop.yarn.exceptions.YarnException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerNotFoundException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerNotFoundException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerNotFoundException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown on
+ {@link ApplicationHistoryProtocol#getContainerReport (GetContainerReportRequest)}
+ API when the container doesn't exist in AHS]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.ContainerNotFoundException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.ResourceNotFoundException -->
+  <class name="ResourceNotFoundException" extends="org.apache.hadoop.yarn.exceptions.YarnRuntimeException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceNotFoundException" type="org.apache.hadoop.yarn.api.records.Resource, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ResourceNotFoundException" type="org.apache.hadoop.yarn.api.records.Resource, java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ResourceNotFoundException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown when details of an unknown resource type
+ are requested.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.ResourceNotFoundException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.YarnException -->
+  <class name="YarnException" extends="java.lang.Exception"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="YarnException"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="YarnException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="YarnException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="YarnException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[YarnException indicates exceptions from yarn servers. On the other hand,
+ IOExceptions indicates exceptions from RPC layer.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.YarnException -->
+  <!-- start class org.apache.hadoop.yarn.exceptions.YARNFeatureNotEnabledException -->
+  <class name="YARNFeatureNotEnabledException" extends="org.apache.hadoop.yarn.exceptions.YarnException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="YARNFeatureNotEnabledException" type="java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="YARNFeatureNotEnabledException" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="YARNFeatureNotEnabledException" type="java.lang.String, java.lang.Throwable"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[This exception is thrown when a feature is being used which is not enabled
+ yet.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.exceptions.YARNFeatureNotEnabledException -->
+</package>
+<package name="org.apache.hadoop.yarn.server.api">
+  <!-- start class org.apache.hadoop.yarn.server.api.ApplicationInitializationContext -->
+  <class name="ApplicationInitializationContext" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationInitializationContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ApplicationId, java.nio.ByteBuffer"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getUser" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the user-name of the application-submitter
+ 
+ @return user-name]]>
+      </doc>
+    </method>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ApplicationId} of the application
+ 
+ @return applications ID]]>
+      </doc>
+    </method>
+    <method name="getApplicationDataForService" return="java.nio.ByteBuffer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the data sent to the NodeManager via
+ {@link ContainerManagementProtocol#startContainers(StartContainersRequest)}
+ as part of {@link ContainerLaunchContext#getServiceData()}
+ 
+ @return the servicesData for this application.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Initialization context for {@link AuxiliaryService} when starting an
+ application.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.ApplicationInitializationContext -->
+  <!-- start class org.apache.hadoop.yarn.server.api.ApplicationTerminationContext -->
+  <class name="ApplicationTerminationContext" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationTerminationContext" type="org.apache.hadoop.yarn.api.records.ApplicationId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ApplicationId} of the application being stopped.
+ 
+ @return applications ID]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Initialization context for {@link AuxiliaryService} when stopping an
+ application.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.ApplicationTerminationContext -->
+  <!-- start interface org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler -->
+  <interface name="AuxiliaryLocalPathHandler"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getLocalPathForRead" return="org.apache.hadoop.fs.Path"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get a path from the local FS for reading for a given Auxiliary Service.
+ @param path the requested path
+ @return the complete path to the file on a local disk
+ @throws IOException if the file read encounters a problem]]>
+      </doc>
+    </method>
+    <method name="getLocalPathForWrite" return="org.apache.hadoop.fs.Path"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get a path from the local FS for writing for a given Auxiliary Service.
+ @param path the requested path
+ @return the complete path to the file on a local disk
+ @throws IOException if the path creations fails]]>
+      </doc>
+    </method>
+    <method name="getLocalPathForWrite" return="org.apache.hadoop.fs.Path"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="java.lang.String"/>
+      <param name="size" type="long"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get a path from the local FS for writing a file of an estimated size
+ for a given Auxiliary Service.
+ @param path the requested path
+ @param size the size of the file that is going to be written
+ @return the complete path to the file on a local disk
+ @throws IOException if the path creations fails]]>
+      </doc>
+    </method>
+    <method name="getAllLocalPathsForRead" return="java.lang.Iterable"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get all paths from the local FS for reading for a given Auxiliary Service.
+ @param path the requested path
+ @return the complete path list to the file on a local disk as an Iterable
+ @throws IOException if the file read encounters a problem]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[An Interface that can retrieve local directories to read from or write to.
+  Components can implement this interface to link it to
+  their own Directory Handler Service]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler -->
+  <!-- start class org.apache.hadoop.yarn.server.api.AuxiliaryService -->
+  <class name="AuxiliaryService" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AuxiliaryService" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getRecoveryPath" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the path specific to this auxiliary service to use for recovery.
+
+ @return state storage path or null if recovery is not enabled]]>
+      </doc>
+    </method>
+    <method name="initializeApplication"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="initAppContext" type="org.apache.hadoop.yarn.server.api.ApplicationInitializationContext"/>
+      <doc>
+      <![CDATA[A new application is started on this NodeManager. This is a signal to
+ this {@link AuxiliaryService} about the application initialization.
+ 
+ @param initAppContext context for the application's initialization]]>
+      </doc>
+    </method>
+    <method name="stopApplication"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="stopAppContext" type="org.apache.hadoop.yarn.server.api.ApplicationTerminationContext"/>
+      <doc>
+      <![CDATA[An application is finishing on this NodeManager. This is a signal to this
+ {@link AuxiliaryService} about the same.
+ 
+ @param stopAppContext context for the application termination]]>
+      </doc>
+    </method>
+    <method name="getMetaData" return="java.nio.ByteBuffer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Retrieve meta-data for this {@link AuxiliaryService}. Applications using
+ this {@link AuxiliaryService} SHOULD know the format of the meta-data -
+ ideally each service should provide a method to parse out the information
+ to the applications. One example of meta-data is contact information so
+ that applications can access the service remotely. This will only be called
+ after the service's {@link #start()} method has finished. the result may be
+ cached.
+ 
+ <p>
+ The information is passed along to applications via
+ {@link StartContainersResponse#getAllServicesMetaData()} that is returned by
+ {@link ContainerManagementProtocol#startContainers(StartContainersRequest)}
+ </p>
+ 
+ @return meta-data for this service that should be made available to
+         applications.]]>
+      </doc>
+    </method>
+    <method name="initializeContainer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="initContainerContext" type="org.apache.hadoop.yarn.server.api.ContainerInitializationContext"/>
+      <doc>
+      <![CDATA[A new container is started on this NodeManager. This is a signal to
+ this {@link AuxiliaryService} about the container initialization.
+ This method is called when the NodeManager receives the container launch
+ command from the ApplicationMaster and before the container process is 
+ launched.
+
+ @param initContainerContext context for the container's initialization]]>
+      </doc>
+    </method>
+    <method name="stopContainer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="stopContainerContext" type="org.apache.hadoop.yarn.server.api.ContainerTerminationContext"/>
+      <doc>
+      <![CDATA[A container is finishing on this NodeManager. This is a signal to this
+ {@link AuxiliaryService} about the same.
+
+ @param stopContainerContext context for the container termination]]>
+      </doc>
+    </method>
+    <method name="setRecoveryPath"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="recoveryPath" type="org.apache.hadoop.fs.Path"/>
+      <doc>
+      <![CDATA[Set the path for this auxiliary service to use for storing state
+ that will be used during recovery.
+
+ @param recoveryPath where recoverable state should be stored]]>
+      </doc>
+    </method>
+    <method name="getAuxiliaryLocalPathHandler" return="org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Method that gets the local dirs path handler for this Auxiliary Service.
+
+ @return auxiliaryPathHandler object that is used to read from and write to
+ valid local Dirs.]]>
+      </doc>
+    </method>
+    <method name="setAuxiliaryLocalPathHandler"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="auxiliaryLocalPathHandler" type="org.apache.hadoop.yarn.server.api.AuxiliaryLocalPathHandler"/>
+      <doc>
+      <![CDATA[Method that sets the local dirs path handler for this Auxiliary Service.
+
+ @param auxiliaryLocalPathHandler the pathHandler for this auxiliary service]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A generic service that will be started by the NodeManager. This is a service
+ that administrators have to configure on each node by setting
+ {@link YarnConfiguration#NM_AUX_SERVICES}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.AuxiliaryService -->
+  <!-- start class org.apache.hadoop.yarn.server.api.ContainerContext -->
+  <class name="ContainerContext" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource, org.apache.hadoop.yarn.server.api.ContainerType"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource, org.apache.hadoop.yarn.server.api.ContainerType, org.apache.hadoop.yarn.api.records.ExecutionType"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getUser" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get user of the container being initialized or stopped.
+
+ @return the user]]>
+      </doc>
+    </method>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ContainerId} of the container being initialized or stopped.
+
+ @return the container ID]]>
+      </doc>
+    </method>
+    <method name="getResource" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link Resource} the resource capability allocated to the container
+ being initialized or stopped.
+
+ @return the resource capability.]]>
+      </doc>
+    </method>
+    <method name="getContainerType" return="org.apache.hadoop.yarn.server.api.ContainerType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ContainerType} the type of the container
+ being initialized or stopped.
+
+ @return the type of the container]]>
+      </doc>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ExecutionType} the execution type of the container
+ being initialized or stopped.
+
+ @return the execution type of the container]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Base context class for {@link AuxiliaryService} initializing and stopping a
+ container.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.ContainerContext -->
+  <!-- start class org.apache.hadoop.yarn.server.api.ContainerInitializationContext -->
+  <class name="ContainerInitializationContext" extends="org.apache.hadoop.yarn.server.api.ContainerContext"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerInitializationContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerInitializationContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource, org.apache.hadoop.yarn.server.api.ContainerType"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Initialization context for {@link AuxiliaryService} when starting a
+ container.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.ContainerInitializationContext -->
+  <!-- start interface org.apache.hadoop.yarn.server.api.ContainerLogAggregationPolicy -->
+  <interface name="ContainerLogAggregationPolicy"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="parseParameters"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="parameters" type="java.lang.String"/>
+      <doc>
+      <![CDATA[<p>
+ The method used by the NodeManager log aggregation service
+ to initial the policy object with parameters specified by the application
+ or the cluster-wide setting.
+ </p>
+
+ @param parameters parameters with scheme defined by the policy class.]]>
+      </doc>
+    </method>
+    <method name="shouldDoLogAggregation" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logContext" type="org.apache.hadoop.yarn.server.api.ContainerLogContext"/>
+      <doc>
+      <![CDATA[<p>
+ The method used by the NodeManager log aggregation service
+ to ask the policy object if a given container's logs should be aggregated.
+ </p>
+
+ @param logContext ContainerLogContext
+ @return Whether or not the container's logs should be aggregated.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This API is used by NodeManager to decide if a given container's logs
+ should be aggregated at run time.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.server.api.ContainerLogAggregationPolicy -->
+  <!-- start class org.apache.hadoop.yarn.server.api.ContainerLogContext -->
+  <class name="ContainerLogContext" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerLogContext" type="org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.server.api.ContainerType, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ContainerId} of the container.
+
+ @return the container ID]]>
+      </doc>
+    </method>
+    <method name="getContainerType" return="org.apache.hadoop.yarn.server.api.ContainerType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get {@link ContainerType} the type of the container.
+
+ @return the type of the container]]>
+      </doc>
+    </method>
+    <method name="getExitCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the exit code of the container.
+
+ @return the exit code]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Context class for {@link ContainerLogAggregationPolicy}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.ContainerLogContext -->
+  <!-- start class org.apache.hadoop.yarn.server.api.ContainerTerminationContext -->
+  <class name="ContainerTerminationContext" extends="org.apache.hadoop.yarn.server.api.ContainerContext"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerTerminationContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerTerminationContext" type="java.lang.String, org.apache.hadoop.yarn.api.records.ContainerId, org.apache.hadoop.yarn.api.records.Resource, org.apache.hadoop.yarn.server.api.ContainerType"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[Termination context for {@link AuxiliaryService} when stopping a
+ container.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.ContainerTerminationContext -->
+  <!-- start interface org.apache.hadoop.yarn.server.api.SCMAdminProtocol -->
+  <interface name="SCMAdminProtocol"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="runCleanerTask" return="org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.server.api.protocolrecords.RunSharedCacheCleanerTaskRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The method used by administrators to ask SCM to run cleaner task right away
+ </p>
+
+ @param request request <code>SharedCacheManager</code> to run a cleaner task
+ @return <code>SharedCacheManager</code> returns an empty response
+         on success and throws an exception on rejecting the request
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[<p>
+ The protocol between administrators and the <code>SharedCacheManager</code>
+ </p>]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.server.api.SCMAdminProtocol -->
+</package>
+<package name="org.apache.hadoop.yarn.util">
+</package>
+<package name="org.apache.hadoop.yarn.util.constraint">
+  <!-- start class org.apache.hadoop.yarn.util.constraint.PlacementConstraintParser -->
+  <class name="PlacementConstraintParser" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <method name="parseExpression" return="org.apache.hadoop.yarn.api.resource.PlacementConstraint.AbstractConstraint"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="constraintStr" type="java.lang.String"/>
+      <exception name="PlacementConstraintParseException" type="org.apache.hadoop.yarn.util.constraint.PlacementConstraintParseException"/>
+      <doc>
+      <![CDATA[Parses a given constraint expression to a {@link AbstractConstraint},
+ this expression can be any valid form of constraint expressions.
+
+ @param constraintStr expression string
+ @return a parsed {@link AbstractConstraint}
+ @throws PlacementConstraintParseException when given expression
+ is malformed]]>
+      </doc>
+    </method>
+    <method name="parsePlacementSpec" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="expression" type="java.lang.String"/>
+      <exception name="PlacementConstraintParseException" type="org.apache.hadoop.yarn.util.constraint.PlacementConstraintParseException"/>
+      <doc>
+      <![CDATA[Parses a placement constraint specification. A placement constraint spec
+ is a composite expression which is composed by multiple sub constraint
+ expressions delimited by ":". With following syntax:
+
+ <p>Tag1(N1),P1:Tag2(N2),P2:...:TagN(Nn),Pn</p>
+
+ where <b>TagN(Nn)</b> is a key value pair to determine the source
+ allocation tag and the number of allocations, such as:
+
+ <p>foo(3)</p>
+
+ Optional when using NodeAttribute Constraint.
+
+ and where <b>Pn</b> can be any form of a valid constraint expression,
+ such as:
+
+ <ul>
+   <li>in,node,foo,bar</li>
+   <li>notin,node,foo,bar,1,2</li>
+   <li>and(notin,node,foo:notin,node,bar)</li>
+ </ul>
+
+ and NodeAttribute Constraint such as
+
+ <ul>
+   <li>yarn.rm.io/foo=true</li>
+   <li>java=1.7,1.8</li>
+ </ul>
+ @param expression expression string.
+ @return a map of source tags to placement constraint mapping.
+ @throws PlacementConstraintParseException]]>
+      </doc>
+    </method>
+    <field name="EXPRESSION_VAL_DELIM" type="char"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Placement constraint expression parser.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.constraint.PlacementConstraintParser -->
+</package>
+<package name="org.apache.hadoop.yarn.util.resource">
+</package>
+
+</api>
diff --git a/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Client_3.2.4.xml b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Client_3.2.4.xml
new file mode 100644
index 000000000000..b8f2a2e529c2
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Client_3.2.4.xml
@@ -0,0 +1,3006 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:56:07 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop YARN Client 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/jdiff.jar -verbose -classpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/classes:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.2.4.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-3.2.4.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-hdfs-client-3.2.4.jar:/maven/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/maven/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/maven/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/maven/com/google/inject/guice/4.0/guice-4.0.jar:/maven/javax/inject/javax.inject/1/javax.inject-1.jar:/maven/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/maven/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.5/jackson-module-jaxb-annotations-2.10.5.jar:/maven/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/maven/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.5/jackson-jaxrs-json-provider-2.10.5.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.5/jackson-jaxrs-base-2.10.5.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/jdiff.jar -apidir /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/target/site/jdiff/xml -apiname Apache Hadoop YARN Client 3.2.4 -->
+<package name="org.apache.hadoop.yarn.client">
+</package>
+<package name="org.apache.hadoop.yarn.client.api">
+  <!-- start class org.apache.hadoop.yarn.client.api.AHSClient -->
+  <class name="AHSClient" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AHSClient" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createAHSClient" return="org.apache.hadoop.yarn.client.api.AHSClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new instance of AHSClient.]]>
+      </doc>
+    </method>
+    <method name="createAHSv2Client" return="org.apache.hadoop.yarn.client.api.AHSClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getApplicationReport" return="org.apache.hadoop.yarn.api.records.ApplicationReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get a report of the given Application.
+ <p>
+ In secure mode, <code>YARN</code> verifies access to the application, queue
+ etc. before accepting the request.
+ <p>
+ If the user does not have <code>VIEW_APP</code> access then the following
+ fields in the report will be set to stubbed values:
+ <ul>
+   <li>host - set to "N/A"</li>
+   <li>RPC port - set to -1</li>
+   <li>client token - set to "N/A"</li>
+   <li>diagnostics - set to "N/A"</li>
+   <li>tracking URL - set to "N/A"</li>
+   <li>original tracking URL - set to "N/A"</li>
+   <li>resource usage report - all values are -1</li>
+ </ul>
+ 
+ @param appId
+          {@link ApplicationId} of the application that needs a report
+ @return application report
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of all Applications in the cluster.
+ </p>
+ 
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+ 
+ @return a list of reports for all applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttemptReport" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of the given ApplicationAttempt.
+ </p>
+ 
+ <p>
+ In secure mode, <code>YARN</code> verifies access to the application, queue
+ etc. before accepting the request.
+ </p>
+ 
+ @param applicationAttemptId
+          {@link ApplicationAttemptId} of the application attempt that needs
+          a report
+ @return application attempt report
+ @throws YarnException
+ @throws ApplicationAttemptNotFoundException if application attempt
+         not found
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttempts" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of all (ApplicationAttempts) of Application in the cluster.
+ </p>
+ 
+ @param applicationId
+ @return a list of reports for all application attempts for specified
+         application
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainerReport" return="org.apache.hadoop.yarn.api.records.ContainerReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of the given Container.
+ </p>
+ 
+ <p>
+ In secure mode, <code>YARN</code> verifies access to the application, queue
+ etc. before accepting the request.
+ </p>
+ 
+ @param containerId
+          {@link ContainerId} of the container that needs a report
+ @return container report
+ @throws YarnException
+ @throws ContainerNotFoundException if container not found
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of all (Containers) of ApplicationAttempt in the cluster.
+ </p>
+ 
+ @param applicationAttemptId
+ @return a list of reports of all containers for specified application
+         attempt
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.AHSClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.AMRMClient -->
+  <class name="AMRMClient" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AMRMClient" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createAMRMClient" return="org.apache.hadoop.yarn.client.api.AMRMClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new instance of AMRMClient.
+ For usage:
+ <pre>
+ {@code
+ AMRMClient.<T>createAMRMClientContainerRequest()
+ }</pre>
+ @return the newly create AMRMClient instance.]]>
+      </doc>
+    </method>
+    <method name="addSchedulingRequests"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="schedulingRequests" type="java.util.Collection"/>
+      <doc>
+      <![CDATA[Add a Collection of SchedulingRequests. The AMRMClient will ensure that
+ all requests in the same batch are sent in the same allocate call.
+ @param schedulingRequests Collection of Scheduling Requests.]]>
+      </doc>
+    </method>
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appHostName" type="java.lang.String"/>
+      <param name="appHostPort" type="int"/>
+      <param name="appTrackingUrl" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Register the application master. This must be called before any 
+ other interaction
+ @param appHostName Name of the host on which master is running
+ @param appHostPort Port master is listening on
+ @param appTrackingUrl URL at which the master info can be seen
+ @return <code>RegisterApplicationMasterResponse</code>
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appHostName" type="java.lang.String"/>
+      <param name="appHostPort" type="int"/>
+      <param name="appTrackingUrl" type="java.lang.String"/>
+      <param name="placementConstraints" type="java.util.Map"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Register the application master. This must be called before any
+ other interaction
+ @param appHostName Name of the host on which master is running
+ @param appHostPort Port master is listening on
+ @param appTrackingUrl URL at which the master info can be seen
+ @param placementConstraints Placement Constraints mappings.
+ @return <code>RegisterApplicationMasterResponse</code>
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="allocate" return="org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="progressIndicator" type="float"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Request additional containers and receive new container allocations.
+ Requests made via <code>addContainerRequest</code> are sent to the
+ <code>ResourceManager</code>. New containers assigned to the master are
+ retrieved. Status of completed containers and node health updates are also
+ retrieved. This also doubles up as a heartbeat to the ResourceManager and
+ must be made periodically. The call may not always return any new
+ allocations of containers. App should not make concurrent allocate
+ requests. May cause request loss.
+ 
+ <p>
+ Note : If the user has not removed container requests that have already
+ been satisfied, then the re-register may end up sending the entire
+ container requests to the RM (including matched requests). Which would mean
+ the RM could end up giving it a lot of new allocated containers.
+ </p>
+ 
+ @param progressIndicator Indicates progress made by the master
+ @return the response of the allocate request
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="unregisterApplicationMaster"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appStatus" type="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"/>
+      <param name="appMessage" type="java.lang.String"/>
+      <param name="appTrackingUrl" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Unregister the application master. This must be called in the end.
+ @param appStatus Success/Failure status of the master
+ @param appMessage Diagnostics message on failure
+ @param appTrackingUrl New URL to get master info
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="addContainerRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="req" type="T"/>
+      <doc>
+      <![CDATA[Request containers for resources before calling <code>allocate</code>
+ @param req Resource request]]>
+      </doc>
+    </method>
+    <method name="removeContainerRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="req" type="T"/>
+      <doc>
+      <![CDATA[Remove previous container request. The previous container request may have 
+ already been sent to the ResourceManager. So even after the remove request 
+ the app must be prepared to receive an allocation for the previous request 
+ even after the remove request
+ @param req Resource request]]>
+      </doc>
+    </method>
+    <method name="requestContainerResourceChange"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use
+ {@link #requestContainerUpdate(Container, UpdateContainerRequest)}">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Request container resource change before calling <code>allocate</code>.
+ Any previous pending resource change request of the same container will be
+ removed.
+
+ Application that calls this method is expected to maintain the
+ <code>Container</code>s that are returned from previous successful
+ allocations or resource changes. By passing in the existing container and a
+ target resource capability to this method, the application requests the
+ ResourceManager to change the existing resource allocation to the target
+ resource allocation.
+
+ @deprecated use
+ {@link #requestContainerUpdate(Container, UpdateContainerRequest)}
+
+ @param container The container returned from the last successful resource
+                  allocation or resource change
+ @param capability  The target resource capability of the container]]>
+      </doc>
+    </method>
+    <method name="requestContainerUpdate"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <param name="updateContainerRequest" type="org.apache.hadoop.yarn.api.records.UpdateContainerRequest"/>
+      <doc>
+      <![CDATA[Request a container update before calling <code>allocate</code>.
+ Any previous pending update request of the same container will be
+ removed.
+
+ @param container The container returned from the last successful resource
+                  allocation or update
+ @param updateContainerRequest The <code>UpdateContainerRequest</code>.]]>
+      </doc>
+    </method>
+    <method name="releaseAssignedContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[Release containers assigned by the Resource Manager. If the app cannot use
+ the container or wants to give up the container then it can release them.
+ The app needs to make new requests for the released resource capability if
+ it still needs it. eg. it released non-local resources
+ @param containerId]]>
+      </doc>
+    </method>
+    <method name="getAvailableResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the currently available resources in the cluster.
+ A valid value is available after a call to allocate has been made
+ @return Currently available resources]]>
+      </doc>
+    </method>
+    <method name="getClusterNodeCount" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the current number of nodes in the cluster.
+ A valid values is available after a call to allocate has been made
+ @return Current number of nodes in the cluster]]>
+      </doc>
+    </method>
+    <method name="getMatchingRequests" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="resourceName" type="java.lang.String"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Get outstanding <code>ContainerRequest</code>s matching the given 
+ parameters. These ContainerRequests should have been added via
+ <code>addContainerRequest</code> earlier in the lifecycle. For performance,
+ the AMRMClient may return its internal collection directly without creating 
+ a copy. Users should not perform mutable operations on the return value.
+ Each collection in the list contains requests with identical 
+ <code>Resource</code> size that fit in the given capability. In a 
+ collection, requests will be returned in the same order as they were added.
+
+ NOTE: This API only matches Container requests that were created by the
+ client WITHOUT the allocationRequestId being set.
+
+ @return Collection of request matching the parameters]]>
+      </doc>
+    </method>
+    <method name="getMatchingRequests" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="resourceName" type="java.lang.String"/>
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Get outstanding <code>ContainerRequest</code>s matching the given
+ parameters. These ContainerRequests should have been added via
+ <code>addContainerRequest</code> earlier in the lifecycle. For performance,
+ the AMRMClient may return its internal collection directly without creating
+ a copy. Users should not perform mutable operations on the return value.
+ Each collection in the list contains requests with identical
+ <code>Resource</code> size that fit in the given capability. In a
+ collection, requests will be returned in the same order as they were added.
+ specify an <code>ExecutionType</code>.
+
+ NOTE: This API only matches Container requests that were created by the
+ client WITHOUT the allocationRequestId being set.
+
+ @param priority Priority
+ @param resourceName Location
+ @param executionType ExecutionType
+ @param capability Capability
+ @return Collection of request matching the parameters]]>
+      </doc>
+    </method>
+    <method name="getMatchingRequests" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="resourceName" type="java.lang.String"/>
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <param name="profile" type="java.lang.String"/>
+    </method>
+    <method name="getMatchingRequests" return="java.util.Collection"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestId" type="long"/>
+      <doc>
+      <![CDATA[Get outstanding <code>ContainerRequest</code>s matching the given
+ allocationRequestId. These ContainerRequests should have been added via
+ <code>addContainerRequest</code> earlier in the lifecycle. For performance,
+ the AMRMClient may return its internal collection directly without creating
+ a copy. Users should not perform mutable operations on the return value.
+
+ NOTE: This API only matches Container requests that were created by the
+ client WITH the allocationRequestId being set to a non-default value.
+
+ @param allocationRequestId Allocation Request Id
+ @return Collection of request matching the parameters]]>
+      </doc>
+    </method>
+    <method name="updateBlacklist"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="blacklistAdditions" type="java.util.List"/>
+      <param name="blacklistRemovals" type="java.util.List"/>
+      <doc>
+      <![CDATA[Update application's blacklist with addition or removal resources.
+ 
+ @param blacklistAdditions list of resources which should be added to the 
+        application blacklist
+ @param blacklistRemovals list of resources which should be removed from the 
+        application blacklist]]>
+      </doc>
+    </method>
+    <method name="setNMTokenCache"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nmTokenCache" type="org.apache.hadoop.yarn.client.api.NMTokenCache"/>
+      <doc>
+      <![CDATA[Set the NM token cache for the <code>AMRMClient</code>. This cache must
+ be shared with the {@link NMClient} used to manage containers for the
+ <code>AMRMClient</code>
+ <p>
+ If a NM token cache is not set, the {@link NMTokenCache#getSingleton()}
+ singleton instance will be used.
+
+ @param nmTokenCache the NM token cache to use.]]>
+      </doc>
+    </method>
+    <method name="getNMTokenCache" return="org.apache.hadoop.yarn.client.api.NMTokenCache"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the NM token cache of the <code>AMRMClient</code>. This cache must be
+ shared with the {@link NMClient} used to manage containers for the
+ <code>AMRMClient</code>.
+ <p>
+ If a NM token cache is not set, the {@link NMTokenCache#getSingleton()}
+ singleton instance will be used.
+
+ @return the NM token cache.]]>
+      </doc>
+    </method>
+    <method name="registerTimelineV2Client"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="client" type="org.apache.hadoop.yarn.client.api.TimelineV2Client"/>
+      <doc>
+      <![CDATA[Register TimelineV2Client to AMRMClient. Writer's address for the timeline
+ V2 client will be updated dynamically if registered.
+
+ @param client the timeline v2 client to register]]>
+      </doc>
+    </method>
+    <method name="getRegisteredTimelineV2Client" return="org.apache.hadoop.yarn.client.api.TimelineV2Client"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get registered timeline v2 client.
+ @return the registered timeline v2 client]]>
+      </doc>
+    </method>
+    <method name="updateTrackingUrl"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Update application's tracking url on next heartbeat.
+
+ @param trackingUrl new tracking url for this application]]>
+      </doc>
+    </method>
+    <method name="waitFor"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="check" type="java.util.function.Supplier"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Wait for <code>check</code> to return true for each 1000 ms.
+ See also {@link #waitFor(java.util.function.Supplier, int)}
+ and {@link #waitFor(java.util.function.Supplier, int, int)}
+ @param check the condition for which it should wait]]>
+      </doc>
+    </method>
+    <method name="waitFor"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="check" type="java.util.function.Supplier"/>
+      <param name="checkEveryMillis" type="int"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Wait for <code>check</code> to return true for each
+ <code>checkEveryMillis</code> ms.
+ See also {@link #waitFor(java.util.function.Supplier, int, int)}
+ @param check user defined checker
+ @param checkEveryMillis interval to call <code>check</code>]]>
+      </doc>
+    </method>
+    <method name="waitFor"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="check" type="java.util.function.Supplier"/>
+      <param name="checkEveryMillis" type="int"/>
+      <param name="logInterval" type="int"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Wait for <code>check</code> to return true for each
+ <code>checkEveryMillis</code> ms. In the main loop, this method will log
+ the message "waiting in main loop" for each <code>logInterval</code> times
+ iteration to confirm the thread is alive.
+ @param check user defined checker
+ @param checkEveryMillis interval to call <code>check</code>
+ @param logInterval interval to log for each]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.AMRMClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.NMClient -->
+  <class name="NMClient" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NMClient" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createNMClient" return="org.apache.hadoop.yarn.client.api.NMClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new instance of NMClient.]]>
+      </doc>
+    </method>
+    <method name="createNMClient" return="org.apache.hadoop.yarn.client.api.NMClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Create a new instance of NMClient.]]>
+      </doc>
+    </method>
+    <method name="startContainer" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <param name="containerLaunchContext" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Start an allocated container.</p>
+
+ <p>The <code>ApplicationMaster</code> or other applications that use the
+ client must provide the details of the allocated container, including the
+ Id, the assigned node's Id and the token via {@link Container}. In
+ addition, the AM needs to provide the {@link ContainerLaunchContext} as
+ well.</p>
+
+ @param container the allocated container
+ @param containerLaunchContext the context information needed by the
+                               <code>NodeManager</code> to launch the
+                               container
+ @return a map between the auxiliary service names and their outputs
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="increaseContainerResource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Increase the resource of a container.</p>
+
+ <p>The <code>ApplicationMaster</code> or other applications that use the
+ client must provide the details of the container, including the Id and
+ the target resource encapsulated in the updated container token via
+ {@link Container}.
+ </p>
+
+ @param container the container with updated token.
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="updateContainerResource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Update the resources of a container.</p>
+
+ <p>The <code>ApplicationMaster</code> or other applications that use the
+ client must provide the details of the container, including the Id and
+ the target resource encapsulated in the updated container token via
+ {@link Container}.
+ </p>
+
+ @param container the container with updated token.
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="stopContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Stop an started container.</p>
+
+ @param containerId the Id of the started container
+ @param nodeId the Id of the <code>NodeManager</code>
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="getContainerStatus" return="org.apache.hadoop.yarn.api.records.ContainerStatus"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Query the status of a container.</p>
+
+ @param containerId the Id of the started container
+ @param nodeId the Id of the <code>NodeManager</code>
+ 
+ @return the status of a container.
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="reInitializeContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="containerLaunchContex" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="autoCommit" type="boolean"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Re-Initialize the Container.</p>
+
+ @param containerId the Id of the container to Re-Initialize.
+ @param containerLaunchContex the updated ContainerLaunchContext.
+ @param autoCommit commit re-initialization automatically ?
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="restartContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Restart the specified container.</p>
+
+ @param containerId the Id of the container to restart.
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="rollbackLastReInitialization"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Rollback last reInitialization of the specified container.</p>
+
+ @param containerId the Id of the container to restart.
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="commitLastReInitialization"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>Commit last reInitialization of the specified container.</p>
+
+ @param containerId the Id of the container to commit reInitialize.
+
+ @throws YarnException YarnException.
+ @throws IOException IOException.]]>
+      </doc>
+    </method>
+    <method name="cleanupRunningContainersOnStop"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="enabled" type="boolean"/>
+      <doc>
+      <![CDATA[<p>Set whether the containers that are started by this client, and are
+ still running should be stopped when the client stops. By default, the
+ feature should be enabled.</p> However, containers will be stopped only  
+ when service is stopped. i.e. after {@link NMClient#stop()}. 
+
+ @param enabled whether the feature is enabled or not]]>
+      </doc>
+    </method>
+    <method name="setNMTokenCache"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nmTokenCache" type="org.apache.hadoop.yarn.client.api.NMTokenCache"/>
+      <doc>
+      <![CDATA[Set the NM Token cache of the <code>NMClient</code>. This cache must be
+ shared with the {@link AMRMClient} that requested the containers managed
+ by this <code>NMClient</code>
+ <p>
+ If a NM token cache is not set, the {@link NMTokenCache#getSingleton()}
+ singleton instance will be used.
+
+ @param nmTokenCache the NM token cache to use.]]>
+      </doc>
+    </method>
+    <method name="getNMTokenCache" return="org.apache.hadoop.yarn.client.api.NMTokenCache"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the NM token cache of the <code>NMClient</code>. This cache must be
+ shared with the {@link AMRMClient} that requested the containers managed
+ by this <code>NMClient</code>
+ <p>
+ If a NM token cache is not set, the {@link NMTokenCache#getSingleton()}
+ singleton instance will be used.
+
+ @return the NM token cache]]>
+      </doc>
+    </method>
+    <method name="getNodeIdOfStartedContainer" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[Get the NodeId of the node on which container is running. It returns
+ null if the container if container is not found or if it is not running.
+
+ @param containerId Container Id of the container.
+ @return NodeId of the container on which it is running.]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.NMClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.NMTokenCache -->
+  <class name="NMTokenCache" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NMTokenCache"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Creates a NM token cache instance.]]>
+      </doc>
+    </constructor>
+    <method name="getSingleton" return="org.apache.hadoop.yarn.client.api.NMTokenCache"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the singleton NM token cache.
+
+ @return the singleton NM token cache.]]>
+      </doc>
+    </method>
+    <method name="getNMToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAddr" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns NMToken, null if absent. Only the singleton obtained from
+ {@link #getSingleton()} is looked at for the tokens. If you are using your
+ own NMTokenCache that is different from the singleton, use
+ {@link #getToken(String) }
+ 
+ @param nodeAddr
+ @return {@link Token} NMToken required for communicating with node manager]]>
+      </doc>
+    </method>
+    <method name="setNMToken"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAddr" type="java.lang.String"/>
+      <param name="token" type="org.apache.hadoop.yarn.api.records.Token"/>
+      <doc>
+      <![CDATA[Sets the NMToken for node address only in the singleton obtained from
+ {@link #getSingleton()}. If you are using your own NMTokenCache that is
+ different from the singleton, use {@link #setToken(String, Token) }
+ 
+ @param nodeAddr
+          node address (host:port)
+ @param token
+          NMToken]]>
+      </doc>
+    </method>
+    <method name="getToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAddr" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Returns NMToken, null if absent
+ @param nodeAddr
+ @return {@link Token} NMToken required for communicating with node
+         manager]]>
+      </doc>
+    </method>
+    <method name="setToken"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeAddr" type="java.lang.String"/>
+      <param name="token" type="org.apache.hadoop.yarn.api.records.Token"/>
+      <doc>
+      <![CDATA[Sets the NMToken for node address
+ @param nodeAddr node address (host:port)
+ @param token NMToken]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[NMTokenCache manages NMTokens required for an Application Master
+ communicating with individual NodeManagers.
+ <p>
+ By default YARN client libraries {@link AMRMClient} and {@link NMClient} use
+ {@link #getSingleton()} instance of the cache.
+ <ul>
+   <li>
+     Using the singleton instance of the cache is appropriate when running a
+     single ApplicationMaster in the same JVM.
+   </li>
+   <li>
+     When using the singleton, users don't need to do anything special,
+     {@link AMRMClient} and {@link NMClient} are already set up to use the
+     default singleton {@link NMTokenCache}
+     </li>
+ </ul>
+ If running multiple Application Masters in the same JVM, a different cache
+ instance should be used for each Application Master.
+ <ul>
+   <li>
+     If using the {@link AMRMClient} and the {@link NMClient}, setting up
+     and using an instance cache is as follows:
+ <pre>
+   NMTokenCache nmTokenCache = new NMTokenCache();
+   AMRMClient rmClient = AMRMClient.createAMRMClient();
+   NMClient nmClient = NMClient.createNMClient();
+   nmClient.setNMTokenCache(nmTokenCache);
+   ...
+ </pre>
+   </li>
+   <li>
+     If using the {@link AMRMClientAsync} and the {@link NMClientAsync},
+     setting up and using an instance cache is as follows:
+ <pre>
+   NMTokenCache nmTokenCache = new NMTokenCache();
+   AMRMClient rmClient = AMRMClient.createAMRMClient();
+   NMClient nmClient = NMClient.createNMClient();
+   nmClient.setNMTokenCache(nmTokenCache);
+   AMRMClientAsync rmClientAsync = new AMRMClientAsync(rmClient, 1000, [AMRM_CALLBACK]);
+   NMClientAsync nmClientAsync = new NMClientAsync("nmClient", nmClient, [NM_CALLBACK]);
+   ...
+ </pre>
+   </li>
+   <li>
+     If using {@link ApplicationMasterProtocol} and
+     {@link ContainerManagementProtocol} directly, setting up and using an
+     instance cache is as follows:
+ <pre>
+   NMTokenCache nmTokenCache = new NMTokenCache();
+   ...
+   ApplicationMasterProtocol amPro = ClientRMProxy.createRMProxy(conf, ApplicationMasterProtocol.class);
+   ...
+   AllocateRequest allocateRequest = ...
+   ...
+   AllocateResponse allocateResponse = rmClient.allocate(allocateRequest);
+   for (NMToken token : allocateResponse.getNMTokens()) {
+     nmTokenCache.setToken(token.getNodeId().toString(), token.getToken());
+   }
+   ...
+   ContainerManagementProtocolProxy nmPro = ContainerManagementProtocolProxy(conf, nmTokenCache);
+   ...
+   nmPro.startContainer(container, containerContext);
+   ...
+ </pre>
+   </li>
+ </ul>
+ It is also possible to mix the usage of a client ({@code AMRMClient} or
+ {@code NMClient}, or the async versions of them) with a protocol proxy
+ ({@code ContainerManagementProtocolProxy} or
+ {@code ApplicationMasterProtocol}).]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.NMTokenCache -->
+  <!-- start class org.apache.hadoop.yarn.client.api.SharedCacheClient -->
+  <class name="SharedCacheClient" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SharedCacheClient" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createSharedCacheClient" return="org.apache.hadoop.yarn.client.api.SharedCacheClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="use" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="resourceKey" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ The method to claim a resource with the <code>SharedCacheManager.</code>
+ The client uses a checksum to identify the resource and an
+ {@link ApplicationId} to identify which application will be using the
+ resource.
+ </p>
+
+ <p>
+ The <code>SharedCacheManager</code> responds with whether or not the
+ resource exists in the cache. If the resource exists, a <code>URL</code> to
+ the resource in the shared cache is returned. If the resource does not
+ exist, null is returned instead.
+ </p>
+
+ <p>
+ Once a URL has been returned for a resource, that URL is safe to use for
+ the lifetime of the application that corresponds to the provided
+ ApplicationId.
+ </p>
+
+ @param applicationId ApplicationId of the application using the resource
+ @param resourceKey the key (i.e. checksum) that identifies the resource
+ @return URL to the resource, or null if it does not exist]]>
+      </doc>
+    </method>
+    <method name="release"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="resourceKey" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ The method to release a resource with the <code>SharedCacheManager.</code>
+ This method is called once an application is no longer using a claimed
+ resource in the shared cache. The client uses a checksum to identify the
+ resource and an {@link ApplicationId} to identify which application is
+ releasing the resource.
+ </p>
+ 
+ <p>
+ Note: This method is an optimization and the client is not required to call
+ it for correctness.
+ </p>
+ 
+ @param applicationId ApplicationId of the application releasing the
+          resource
+ @param resourceKey the key (i.e. checksum) that identifies the resource]]>
+      </doc>
+    </method>
+    <method name="getFileChecksum" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="sourceFile" type="org.apache.hadoop.fs.Path"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[A convenience method to calculate the checksum of a specified file.
+ 
+ @param sourceFile A path to the input file
+ @return A hex string containing the checksum digest
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[This is the client for YARN's shared cache.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.SharedCacheClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.YarnClient -->
+  <class name="YarnClient" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="YarnClient" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createYarnClient" return="org.apache.hadoop.yarn.client.api.YarnClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new instance of YarnClient.]]>
+      </doc>
+    </method>
+    <method name="createApplication" return="org.apache.hadoop.yarn.client.api.YarnClientApplication"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Obtain a {@link YarnClientApplication} for a new application,
+ which in turn contains the {@link ApplicationSubmissionContext} and
+ {@link org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse}
+ objects.
+ </p>
+
+ @return {@link YarnClientApplication} built for a new application
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="submitApplication" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appContext" type="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Submit a new application to <code>YARN.</code> It is a blocking call - it
+ will not return {@link ApplicationId} until the submitted application is
+ submitted successfully and accepted by the ResourceManager.
+ </p>
+ 
+ <p>
+ Users should provide an {@link ApplicationId} as part of the parameter
+ {@link ApplicationSubmissionContext} when submitting a new application,
+ otherwise it will throw the {@link ApplicationIdNotProvidedException}.
+ </p>
+
+ <p>This internally calls {@link ApplicationClientProtocol#submitApplication
+ (SubmitApplicationRequest)}, and after that, it internally invokes
+ {@link ApplicationClientProtocol#getApplicationReport
+ (GetApplicationReportRequest)} and waits till it can make sure that the
+ application gets properly submitted. If RM fails over or RM restart
+ happens before ResourceManager saves the application's state,
+ {@link ApplicationClientProtocol
+ #getApplicationReport(GetApplicationReportRequest)} will throw
+ the {@link ApplicationNotFoundException}. This API automatically resubmits
+ the application with the same {@link ApplicationSubmissionContext} when it
+ catches the {@link ApplicationNotFoundException}</p>
+
+ @param appContext
+          {@link ApplicationSubmissionContext} containing all the details
+          needed to submit a new application
+ @return {@link ApplicationId} of the accepted application
+ @throws YarnException
+ @throws IOException
+ @see #createApplication()]]>
+      </doc>
+    </method>
+    <method name="failApplicationAttempt"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Fail an application attempt identified by given ID.
+ </p>
+
+ @param applicationAttemptId
+          {@link ApplicationAttemptId} of the attempt to fail.
+ @throws YarnException
+           in case of errors or if YARN rejects the request due to
+           access-control restrictions.
+ @throws IOException
+ @see #getQueueAclsInfo()]]>
+      </doc>
+    </method>
+    <method name="killApplication"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Kill an application identified by given ID.
+ </p>
+ 
+ @param applicationId
+          {@link ApplicationId} of the application that needs to be killed
+ @throws YarnException
+           in case of errors or if YARN rejects the request due to
+           access-control restrictions.
+ @throws IOException
+ @see #getQueueAclsInfo()]]>
+      </doc>
+    </method>
+    <method name="killApplication"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="diagnostics" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Kill an application identified by given ID.
+ </p>
+ @param applicationId {@link ApplicationId} of the application that needs to
+          be killed
+ @param diagnostics for killing an application.
+ @throws YarnException in case of errors or if YARN rejects the request due
+           to access-control restrictions.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationReport" return="org.apache.hadoop.yarn.api.records.ApplicationReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of the given Application.
+ </p>
+ 
+ <p>
+ In secure mode, <code>YARN</code> verifies access to the application, queue
+ etc. before accepting the request.
+ </p>
+ 
+ <p>
+ If the user does not have <code>VIEW_APP</code> access then the following
+ fields in the report will be set to stubbed values:
+ <ul>
+ <li>host - set to "N/A"</li>
+ <li>RPC port - set to -1</li>
+ <li>client token - set to "N/A"</li>
+ <li>diagnostics - set to "N/A"</li>
+ <li>tracking URL - set to "N/A"</li>
+ <li>original tracking URL - set to "N/A"</li>
+ <li>resource usage report - all values are -1</li>
+ </ul>
+ 
+ @param appId
+          {@link ApplicationId} of the application that needs a report
+ @return application report
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getAMRMToken" return="org.apache.hadoop.security.token.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the AMRM token of the application.
+ <p>
+ The AMRM token is required for AM to RM scheduling operations. For 
+ managed Application Masters YARN takes care of injecting it. For unmanaged
+ Applications Masters, the token must be obtained via this method and set
+ in the {@link org.apache.hadoop.security.UserGroupInformation} of the
+ current user.
+ <p>
+ The AMRM token will be returned only if all the following conditions are
+ met:
+ <ul>
+   <li>the requester is the owner of the ApplicationMaster</li>
+   <li>the application master is an unmanaged ApplicationMaster</li>
+   <li>the application master is in ACCEPTED state</li>
+ </ul>
+ Else this method returns NULL.
+
+ @param appId {@link ApplicationId} of the application to get the AMRM token
+ @return the AMRM token if available
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of all Applications in the cluster.
+ </p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @return a list of reports of all running applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTypes" type="java.util.Set"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of Applications
+ matching the given application types in the cluster.
+ </p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @param applicationTypes set of application types you are interested in
+ @return a list of reports of applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of Applications matching the given
+ application states in the cluster.
+ </p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @param applicationStates set of application states you are interested in
+ @return a list of reports of applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTypes" type="java.util.Set"/>
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of Applications matching the given
+ application types and application states in the cluster.
+ </p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @param applicationTypes set of application types you are interested in
+ @param applicationStates set of application states you are interested in
+ @return a list of reports of applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationTypes" type="java.util.Set"/>
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <param name="applicationTags" type="java.util.Set"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of Applications matching the given
+ application types, application states and application tags in the cluster.
+ </p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @param applicationTypes set of application types you are interested in
+ @param applicationStates set of application states you are interested in
+ @param applicationTags set of application tags you are interested in
+ @return a list of reports of applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queues" type="java.util.Set"/>
+      <param name="users" type="java.util.Set"/>
+      <param name="applicationTypes" type="java.util.Set"/>
+      <param name="applicationStates" type="java.util.EnumSet"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report (ApplicationReport) of Applications matching the given users,
+ queues, application types and application states in the cluster. If any of
+ the params is set to null, it is not used when filtering.
+ </p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @param queues set of queues you are interested in
+ @param users set of users you are interested in
+ @param applicationTypes set of application types you are interested in
+ @param applicationStates set of application states you are interested in
+ @return a list of reports of applications
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplications" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a list of ApplicationReports that match the given
+ {@link GetApplicationsRequest}.
+</p>
+
+ <p>
+ If the user does not have <code>VIEW_APP</code> access for an application
+ then the corresponding report will be filtered as described in
+ {@link #getApplicationReport(ApplicationId)}.
+ </p>
+
+ @param request the request object to get the list of applications.
+ @return The list of ApplicationReports that match the request
+ @throws YarnException Exception specific to YARN.
+ @throws IOException Exception mostly related to connection errors.]]>
+      </doc>
+    </method>
+    <method name="getYarnClusterMetrics" return="org.apache.hadoop.yarn.api.records.YarnClusterMetrics"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get metrics ({@link YarnClusterMetrics}) about the cluster.
+ </p>
+ 
+ @return cluster metrics
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getNodeReports" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="states" type="org.apache.hadoop.yarn.api.records.NodeState[]"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of nodes ({@link NodeReport}) in the cluster.
+ </p>
+ 
+ @param states The {@link NodeState}s to filter on. If no filter states are
+          given, nodes in all states will be returned.
+ @return A list of node reports
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getRMDelegationToken" return="org.apache.hadoop.yarn.api.records.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="org.apache.hadoop.io.Text"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a delegation token so as to be able to talk to YARN using those tokens.
+ 
+ @param renewer
+          Address of the renewer who can renew these tokens when needed by
+          securely talking to YARN.
+ @return a delegation token ({@link Token}) that can be used to
+         talk to YARN
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueueInfo" return="org.apache.hadoop.yarn.api.records.QueueInfo"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="queueName" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get information ({@link QueueInfo}) about a given <em>queue</em>.
+ </p>
+ 
+ @param queueName
+          Name of the queue whose information is needed
+ @return queue information
+ @throws YarnException
+           in case of errors or if YARN rejects the request due to
+           access-control restrictions.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getAllQueues" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get information ({@link QueueInfo}) about all queues, recursively if there
+ is a hierarchy
+ </p>
+ 
+ @return a list of queue-information for all queues
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getRootQueueInfos" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get information ({@link QueueInfo}) about top level queues.
+ </p>
+ 
+ @return a list of queue-information for all the top-level queues
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getChildQueueInfos" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="parent" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get information ({@link QueueInfo}) about all the immediate children queues
+ of the given queue
+ </p>
+ 
+ @param parent
+          Name of the queue whose child-queues' information is needed
+ @return a list of queue-information for all queues who are direct children
+         of the given parent queue.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getQueueAclsInfo" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get information about <em>acls</em> for <em>current user</em> on all the
+ existing queues.
+ </p>
+ 
+ @return a list of queue acls ({@link QueueUserACLInfo}) for
+         <em>current user</em>
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttemptReport" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of the given ApplicationAttempt.
+ </p>
+ 
+ <p>
+ In secure mode, <code>YARN</code> verifies access to the application, queue
+ etc. before accepting the request.
+ </p>
+ 
+ @param applicationAttemptId
+          {@link ApplicationAttemptId} of the application attempt that needs
+          a report
+ @return application attempt report
+ @throws YarnException
+ @throws ApplicationAttemptNotFoundException if application attempt
+         not found
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttempts" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of all (ApplicationAttempts) of Application in the cluster.
+ </p>
+ 
+ @param applicationId application id of the app
+ @return a list of reports for all application attempts for specified
+         application.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainerReport" return="org.apache.hadoop.yarn.api.records.ContainerReport"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of the given Container.
+ </p>
+ 
+ <p>
+ In secure mode, <code>YARN</code> verifies access to the application, queue
+ etc. before accepting the request.
+ </p>
+ 
+ @param containerId
+          {@link ContainerId} of the container that needs a report
+ @return container report
+ @throws YarnException
+ @throws ContainerNotFoundException if container not found.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainers" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a report of all (Containers) of ApplicationAttempt in the cluster.
+ </p>
+ 
+ @param applicationAttemptId application attempt id
+ @return a list of reports of all containers for specified application
+         attempts
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="moveApplicationAcrossQueues"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="queue" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Attempts to move the given application to the given queue.
+ </p>
+ 
+ @param appId
+    Application to move.
+ @param queue
+    Queue to place it in to.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="createReservation" return="org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Obtain a {@link GetNewReservationResponse} for a new reservation,
+ which contains the {@link ReservationId} object.
+ </p>
+
+ @return The {@link GetNewReservationResponse} containing a new
+         {@link ReservationId} object.
+ @throws YarnException if reservation cannot be created.
+ @throws IOException if reservation cannot be created.]]>
+      </doc>
+    </method>
+    <method name="submitReservation" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to submit a new reservation to the
+ {@code ResourceManager}.
+ </p>
+ 
+ <p>
+ The client packages all details of its request in a
+ {@link ReservationSubmissionRequest} object. This contains information
+ about the amount of capacity, temporal constraints, and gang needs.
+ Furthermore, the reservation might be composed of multiple stages, with
+ ordering dependencies among them.
+ </p>
+ 
+ <p>
+ In order to respond, a new admission control component in the
+ {@code ResourceManager} performs an analysis of the resources that have
+ been committed over the period of time the user is requesting, verify that
+ the user requests can be fulfilled, and that it respect a sharing policy
+ (e.g., {@code CapacityOverTimePolicy}). Once it has positively determined
+ that the ReservationRequest is satisfiable the {@code ResourceManager}
+ answers with a {@link ReservationSubmissionResponse} that includes a
+ {@link ReservationId}. Upon failure to find a valid allocation the response
+ is an exception with the message detailing the reason of failure.
+ </p>
+ 
+ <p>
+ The semantics guarantees that the {@link ReservationId} returned,
+ corresponds to a valid reservation existing in the time-range request by
+ the user. The amount of capacity dedicated to such reservation can vary
+ overtime, depending of the allocation that has been determined. But it is
+ guaranteed to satisfy all the constraint expressed by the user in the
+ {@link ReservationDefinition}
+ </p>
+ 
+ @param request request to submit a new Reservation
+ @return response contains the {@link ReservationId} on accepting the
+         submission
+ @throws YarnException if the reservation cannot be created successfully
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="updateReservation" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to update an existing Reservation. This is
+ referred to as a re-negotiation process, in which a user that has
+ previously submitted a Reservation.
+ </p>
+ 
+ <p>
+ The allocation is attempted by virtually substituting all previous
+ allocations related to this Reservation with new ones, that satisfy the new
+ {@link ReservationDefinition}. Upon success the previous allocation is
+ atomically substituted by the new one, and on failure (i.e., if the system
+ cannot find a valid allocation for the updated request), the previous
+ allocation remains valid.
+ </p>
+ 
+ @param request to update an existing Reservation (the
+          {@link ReservationUpdateRequest} should refer to an existing valid
+          {@link ReservationId})
+ @return response empty on successfully updating the existing reservation
+ @throws YarnException if the request is invalid or reservation cannot be
+           updated successfully
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="deleteReservation" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to remove an existing Reservation.
+ </p>
+ 
+ @param request to remove an existing Reservation (the
+          {@link ReservationDeleteRequest} should refer to an existing valid
+          {@link ReservationId})
+ @return response empty on successfully deleting the existing reservation
+ @throws YarnException if the request is invalid or reservation cannot be
+           deleted successfully
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="listReservations" return="org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by clients to get the list of reservations in a plan.
+ The reservationId will be used to search for reservations to list if it is
+ provided. Otherwise, it will select active reservations within the
+ startTime and endTime (inclusive).
+ </p>
+
+ @param request to list reservations in a plan. Contains fields to select
+                String queue, ReservationId reservationId, long startTime,
+                long endTime, and a bool includeReservationAllocations.
+
+                queue: Required. Cannot be null or empty. Refers to the
+                reservable queue in the scheduler that was selected when
+                creating a reservation submission
+                {@link ReservationSubmissionRequest}.
+
+                reservationId: Optional. If provided, other fields will
+                be ignored.
+
+                startTime: Optional. If provided, only reservations that
+                end after the startTime will be selected. This defaults
+                to 0 if an invalid number is used.
+
+                endTime: Optional. If provided, only reservations that
+                start on or before endTime will be selected. This defaults
+                to Long.MAX_VALUE if an invalid number is used.
+
+                includeReservationAllocations: Optional. Flag that
+                determines whether the entire reservation allocations are
+                to be returned. Reservation allocations are subject to
+                change in the event of re-planning as described by
+                {@link ReservationDefinition}.
+
+ @return response that contains information about reservations that are
+                being searched for.
+ @throws YarnException if the request is invalid
+ @throws IOException if the request failed otherwise]]>
+      </doc>
+    </method>
+    <method name="getNodeToLabels" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node to labels mappings in existing cluster
+ </p>
+ 
+ @return node to labels mappings
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getLabelsToNodes" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get labels to nodes mapping
+ in existing cluster
+ </p>
+
+ @return node to labels mappings
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getLabelsToNodes" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="labels" type="java.util.Set"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get labels to nodes mapping
+ for specified labels in existing cluster
+ </p>
+
+ @param labels labels for which labels to nodes mapping has to be retrieved
+ @return labels to nodes mappings for specific labels
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getClusterNodeLabels" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node labels in the cluster
+ </p>
+
+ @return cluster node labels collection
+ @throws YarnException when there is a failure in
+           {@link ApplicationClientProtocol}
+ @throws IOException when there is a failure in
+           {@link ApplicationClientProtocol}]]>
+      </doc>
+    </method>
+    <method name="updateApplicationPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to set priority of an application
+ </p>
+ @param applicationId
+ @param priority
+ @return updated priority of an application.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="signalToContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="command" type="org.apache.hadoop.yarn.api.records.SignalContainerCommand"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Signal a container identified by given ID.
+ </p>
+
+ @param containerId
+          {@link ContainerId} of the container that needs to be signaled
+ @param command the signal container command
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="updateApplicationTimeouts" return="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getResourceProfiles" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get the resource profiles available in the RM.
+ </p>
+ @return a Map of the resource profile names to their capabilities
+ @throws YARNFeatureNotEnabledException if resource-profile is disabled
+ @throws YarnException if any error happens inside YARN
+ @throws IOException in case of other errors]]>
+      </doc>
+    </method>
+    <method name="getResourceProfile" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="profile" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get the details of a specific resource profile from the RM.
+ </p>
+ @param profile the profile name
+ @return resource profile name with its capabilities
+ @throws YARNFeatureNotEnabledException if resource-profile is disabled
+ @throws YarnException if any error happens inside YARN
+ @throws IOException in case of other others]]>
+      </doc>
+    </method>
+    <method name="getResourceTypeInfo" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ Get available resource types supported by RM.
+ </p>
+ @return list of supported resource types with detailed information
+ @throws YarnException if any issue happens inside YARN
+ @throws IOException in case of other others]]>
+      </doc>
+    </method>
+    <method name="getClusterAttributes" return="java.util.Set"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get node attributes in the cluster.
+ </p>
+
+ @return cluster node attributes collection
+ @throws YarnException when there is a failure in
+                       {@link ApplicationClientProtocol}
+ @throws IOException   when there is a failure in
+                       {@link ApplicationClientProtocol}]]>
+      </doc>
+    </method>
+    <method name="getAttributesToNodes" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="attributes" type="java.util.Set"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get mapping of AttributeKey to associated
+ NodeToAttributeValue list for specified node attributeKeys in the cluster.
+ </p>
+
+ @param attributes AttributeKeys for which associated NodeToAttributeValue
+          mapping value has to be retrieved. If empty or null is set then
+          will return mapping for all attributeKeys in the cluster
+ @return mapping of AttributeKey to List of associated
+         NodeToAttributeValue's.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getNodeToAttributes" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="hostNames" type="java.util.Set"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[<p>
+ The interface used by client to get all node to attribute mapping in
+ existing cluster.
+ </p>
+
+ @param hostNames HostNames for which host to attributes mapping has to
+                  be retrived.If empty or null is set then will return
+                  all nodes to attributes mapping in cluster.
+ @return Node to attribute mappings
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.YarnClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.YarnClientApplication -->
+  <class name="YarnClientApplication" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="YarnClientApplication" type="org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse, org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getNewApplicationResponse" return="org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getApplicationSubmissionContext" return="org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.YarnClientApplication -->
+</package>
+<package name="org.apache.hadoop.yarn.client.api.async">
+  <!-- start class org.apache.hadoop.yarn.client.api.async.AMRMClientAsync -->
+  <class name="AMRMClientAsync" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AMRMClientAsync" type="int, org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.AbstractCallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AMRMClientAsync" type="org.apache.hadoop.yarn.client.api.AMRMClient, int, org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.AbstractCallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AMRMClientAsync" type="int, org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AMRMClientAsync" type="org.apache.hadoop.yarn.client.api.AMRMClient, int, org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createAMRMClientAsync" return="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="intervalMs" type="int"/>
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.AbstractCallbackHandler"/>
+      <doc>
+      <![CDATA[<p>Create a new instance of AMRMClientAsync.</p>
+
+ @param intervalMs heartbeat interval in milliseconds between AM and RM
+ @param callbackHandler callback handler that processes responses from
+                        the <code>ResourceManager</code>]]>
+      </doc>
+    </method>
+    <method name="createAMRMClientAsync" return="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="client" type="org.apache.hadoop.yarn.client.api.AMRMClient"/>
+      <param name="intervalMs" type="int"/>
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.AbstractCallbackHandler"/>
+      <doc>
+      <![CDATA[<p>Create a new instance of AMRMClientAsync.</p>
+
+ @param client the AMRMClient instance
+ @param intervalMs heartbeat interval in milliseconds between AM and RM
+ @param callbackHandler callback handler that processes responses from
+                        the <code>ResourceManager</code>]]>
+      </doc>
+    </method>
+    <method name="createAMRMClientAsync" return="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #createAMRMClientAsync(int,
+             AMRMClientAsync.AbstractCallbackHandler)} instead.">
+      <param name="intervalMs" type="int"/>
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #createAMRMClientAsync(int,
+             AMRMClientAsync.AbstractCallbackHandler)} instead.]]>
+      </doc>
+    </method>
+    <method name="createAMRMClientAsync" return="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #createAMRMClientAsync(AMRMClient,
+             int, AMRMClientAsync.AbstractCallbackHandler)} instead.">
+      <param name="client" type="org.apache.hadoop.yarn.client.api.AMRMClient"/>
+      <param name="intervalMs" type="int"/>
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #createAMRMClientAsync(AMRMClient,
+             int, AMRMClientAsync.AbstractCallbackHandler)} instead.]]>
+      </doc>
+    </method>
+    <method name="setHeartbeatInterval"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="interval" type="int"/>
+    </method>
+    <method name="getMatchingRequests" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="resourceName" type="java.lang.String"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+    </method>
+    <method name="addSchedulingRequests"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="schedulingRequests" type="java.util.Collection"/>
+      <doc>
+      <![CDATA[Add a Collection of SchedulingRequests. The AMRMClient will ensure that
+ all requests in the same batch are sent in the same allocate call.
+ @param schedulingRequests Collection of Scheduling Requests.]]>
+      </doc>
+    </method>
+    <method name="getMatchingRequests" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="priority" type="org.apache.hadoop.yarn.api.records.Priority"/>
+      <param name="resourceName" type="java.lang.String"/>
+      <param name="executionType" type="org.apache.hadoop.yarn.api.records.ExecutionType"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Returns all matching ContainerRequests that match the given Priority,
+ ResourceName, ExecutionType and Capability.
+
+ NOTE: This matches only requests that were made by the client WITHOUT the
+ allocationRequestId specified.
+
+ @param priority Priority.
+ @param resourceName Location.
+ @param executionType ExecutionType.
+ @param capability Capability.
+ @return All matching ContainerRequests]]>
+      </doc>
+    </method>
+    <method name="getMatchingRequests" return="java.util.Collection"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="allocationRequestId" type="long"/>
+      <doc>
+      <![CDATA[Returns all matching ContainerRequests that match the given
+ AllocationRequestId.
+
+ NOTE: This matches only requests that were made by the client WITH the
+ allocationRequestId specified.
+
+ @param allocationRequestId AllocationRequestId.
+ @return All matching ContainerRequests]]>
+      </doc>
+    </method>
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appHostName" type="java.lang.String"/>
+      <param name="appHostPort" type="int"/>
+      <param name="appTrackingUrl" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Registers this application master with the resource manager. On successful
+ registration, starts the heartbeating thread.
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appHostName" type="java.lang.String"/>
+      <param name="appHostPort" type="int"/>
+      <param name="appTrackingUrl" type="java.lang.String"/>
+      <param name="placementConstraints" type="java.util.Map"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Register the application master. This must be called before any
+ other interaction
+ @param appHostName Name of the host on which master is running
+ @param appHostPort Port master is listening on
+ @param appTrackingUrl URL at which the master info can be seen
+ @param placementConstraints Placement Constraints mappings.
+ @return <code>RegisterApplicationMasterResponse</code>
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="unregisterApplicationMaster"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appStatus" type="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"/>
+      <param name="appMessage" type="java.lang.String"/>
+      <param name="appTrackingUrl" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Unregister the application master. This must be called in the end.
+ @param appStatus Success/Failure status of the master
+ @param appMessage Diagnostics message on failure
+ @param appTrackingUrl New URL to get master info
+ @throws YarnException
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="addContainerRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="req" type="T"/>
+      <doc>
+      <![CDATA[Request containers for resources before calling <code>allocate</code>
+ @param req Resource request]]>
+      </doc>
+    </method>
+    <method name="removeContainerRequest"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="req" type="T"/>
+      <doc>
+      <![CDATA[Remove previous container request. The previous container request may have 
+ already been sent to the ResourceManager. So even after the remove request 
+ the app must be prepared to receive an allocation for the previous request 
+ even after the remove request
+ @param req Resource request]]>
+      </doc>
+    </method>
+    <method name="requestContainerResourceChange"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="use
+ {@link #requestContainerUpdate(Container, UpdateContainerRequest)}">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <param name="capability" type="org.apache.hadoop.yarn.api.records.Resource"/>
+      <doc>
+      <![CDATA[Request container resource change before calling <code>allocate</code>.
+ Any previous pending resource change request of the same container will be
+ removed.
+
+ Application that calls this method is expected to maintain the
+ <code>Container</code>s that are returned from previous successful
+ allocations or resource changes. By passing in the existing container and a
+ target resource capability to this method, the application requests the
+ ResourceManager to change the existing resource allocation to the target
+ resource allocation.
+
+ @deprecated use
+ {@link #requestContainerUpdate(Container, UpdateContainerRequest)}
+
+ @param container The container returned from the last successful resource
+                  allocation or resource change
+ @param capability  The target resource capability of the container]]>
+      </doc>
+    </method>
+    <method name="requestContainerUpdate"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <param name="updateContainerRequest" type="org.apache.hadoop.yarn.api.records.UpdateContainerRequest"/>
+      <doc>
+      <![CDATA[Request a container update before calling <code>allocate</code>.
+ Any previous pending update request of the same container will be
+ removed.
+
+ @param container The container returned from the last successful resource
+                  allocation or update
+ @param updateContainerRequest The <code>UpdateContainerRequest</code>.]]>
+      </doc>
+    </method>
+    <method name="releaseAssignedContainer"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[Release containers assigned by the Resource Manager. If the app cannot use
+ the container or wants to give up the container then it can release them.
+ The app needs to make new requests for the released resource capability if
+ it still needs it. eg. it released non-local resources
+ @param containerId]]>
+      </doc>
+    </method>
+    <method name="getAvailableResources" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the currently available resources in the cluster.
+ A valid value is available after a call to allocate has been made
+ @return Currently available resources]]>
+      </doc>
+    </method>
+    <method name="getClusterNodeCount" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the current number of nodes in the cluster.
+ A valid values is available after a call to allocate has been made
+ @return Current number of nodes in the cluster]]>
+      </doc>
+    </method>
+    <method name="registerTimelineV2Client"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineClient" type="org.apache.hadoop.yarn.client.api.TimelineV2Client"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Register TimelineClient to AMRMClient.
+ @param timelineClient
+ @throws YarnException when this method is invoked even when ATS V2 is not
+           configured.]]>
+      </doc>
+    </method>
+    <method name="getRegisteredTimelineV2Client" return="org.apache.hadoop.yarn.client.api.TimelineV2Client"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get registered timeline client.
+ @return the registered timeline client]]>
+      </doc>
+    </method>
+    <method name="updateBlacklist"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="blacklistAdditions" type="java.util.List"/>
+      <param name="blacklistRemovals" type="java.util.List"/>
+      <doc>
+      <![CDATA[Update application's blacklist with addition or removal resources.
+
+ @param blacklistAdditions list of resources which should be added to the
+        application blacklist
+ @param blacklistRemovals list of resources which should be removed from the
+        application blacklist]]>
+      </doc>
+    </method>
+    <method name="updateTrackingUrl"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="trackingUrl" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Update application's tracking url on next heartbeat.
+
+ @param trackingUrl new tracking url for this application]]>
+      </doc>
+    </method>
+    <method name="waitFor"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="check" type="java.util.function.Supplier"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Wait for <code>check</code> to return true for each 1000 ms.
+ See also {@link #waitFor(java.util.function.Supplier, int)}
+ and {@link #waitFor(java.util.function.Supplier, int, int)}
+ @param check the condition for which it should wait]]>
+      </doc>
+    </method>
+    <method name="waitFor"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="check" type="java.util.function.Supplier"/>
+      <param name="checkEveryMillis" type="int"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Wait for <code>check</code> to return true for each
+ <code>checkEveryMillis</code> ms.
+ See also {@link #waitFor(java.util.function.Supplier, int, int)}
+ @param check user defined checker
+ @param checkEveryMillis interval to call <code>check</code>]]>
+      </doc>
+    </method>
+    <method name="waitFor"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="check" type="java.util.function.Supplier"/>
+      <param name="checkEveryMillis" type="int"/>
+      <param name="logInterval" type="int"/>
+      <exception name="InterruptedException" type="java.lang.InterruptedException"/>
+      <doc>
+      <![CDATA[Wait for <code>check</code> to return true for each
+ <code>checkEveryMillis</code> ms. In the main loop, this method will log
+ the message "waiting in main loop" for each <code>logInterval</code> times
+ iteration to confirm the thread is alive.
+ @param check user defined checker
+ @param checkEveryMillis interval to call <code>check</code>
+ @param logInterval interval to log for each]]>
+      </doc>
+    </method>
+    <field name="client" type="org.apache.hadoop.yarn.client.api.AMRMClient"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="handler" type="org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.CallbackHandler"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="heartbeatIntervalMs" type="java.util.concurrent.atomic.AtomicInteger"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<code>AMRMClientAsync</code> handles communication with the ResourceManager
+ and provides asynchronous updates on events such as container allocations and
+ completions.  It contains a thread that sends periodic heartbeats to the
+ ResourceManager.
+ 
+ It should be used by implementing a CallbackHandler:
+ <pre>
+ {@code
+ class MyCallbackHandler extends AMRMClientAsync.AbstractCallbackHandler {
+   public void onContainersAllocated(List<Container> containers) {
+     [run tasks on the containers]
+   }
+
+   public void onContainersUpdated(List<Container> containers) {
+     [determine if resource allocation of containers have been increased in
+      the ResourceManager, and if so, inform the NodeManagers to increase the
+      resource monitor/enforcement on the containers]
+   }
+
+   public void onContainersCompleted(List<ContainerStatus> statuses) {
+     [update progress, check whether app is done]
+   }
+   
+   public void onNodesUpdated(List<NodeReport> updated) {}
+   
+   public void onReboot() {}
+ }
+ }
+ </pre>
+ 
+ The client's lifecycle should be managed similarly to the following:
+ 
+ <pre>
+ {@code
+ AMRMClientAsync asyncClient = 
+     createAMRMClientAsync(appAttId, 1000, new MyCallbackhandler());
+ asyncClient.init(conf);
+ asyncClient.start();
+ RegisterApplicationMasterResponse response = asyncClient
+    .registerApplicationMaster(appMasterHostname, appMasterRpcPort,
+       appMasterTrackingUrl);
+ asyncClient.addContainerRequest(containerRequest);
+ [... wait for application to complete]
+ asyncClient.unregisterApplicationMaster(status, appMsg, trackingUrl);
+ asyncClient.stop();
+ }
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.async.AMRMClientAsync -->
+  <!-- start class org.apache.hadoop.yarn.client.api.async.NMClientAsync -->
+  <class name="NMClientAsync" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NMClientAsync" type="org.apache.hadoop.yarn.client.api.async.NMClientAsync.AbstractCallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="NMClientAsync" type="java.lang.String, org.apache.hadoop.yarn.client.api.async.NMClientAsync.AbstractCallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="NMClientAsync" type="java.lang.String, org.apache.hadoop.yarn.client.api.NMClient, org.apache.hadoop.yarn.client.api.async.NMClientAsync.AbstractCallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="NMClientAsync" type="org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="Use {@link #NMClientAsync(AbstractCallbackHandler)}
+             instead.">
+      <doc>
+      <![CDATA[@deprecated Use {@link #NMClientAsync(AbstractCallbackHandler)}
+             instead.]]>
+      </doc>
+    </constructor>
+    <constructor name="NMClientAsync" type="java.lang.String, org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="Use {@link #NMClientAsync(String, AbstractCallbackHandler)}
+             instead.">
+      <doc>
+      <![CDATA[@deprecated Use {@link #NMClientAsync(String, AbstractCallbackHandler)}
+             instead.]]>
+      </doc>
+    </constructor>
+    <constructor name="NMClientAsync" type="java.lang.String, org.apache.hadoop.yarn.client.api.NMClient, org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createNMClientAsync" return="org.apache.hadoop.yarn.client.api.async.NMClientAsync"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.NMClientAsync.AbstractCallbackHandler"/>
+    </method>
+    <method name="createNMClientAsync" return="org.apache.hadoop.yarn.client.api.async.NMClientAsync"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="Use {@link #createNMClientAsync(AbstractCallbackHandler)}
+             instead.">
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"/>
+      <doc>
+      <![CDATA[@deprecated Use {@link #createNMClientAsync(AbstractCallbackHandler)}
+             instead.]]>
+      </doc>
+    </method>
+    <method name="startContainerAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <param name="containerLaunchContext" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+    </method>
+    <method name="increaseContainerResourceAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+    </method>
+    <method name="updateContainerResourceAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="container" type="org.apache.hadoop.yarn.api.records.Container"/>
+      <doc>
+      <![CDATA[<p>Update the resources of a container.</p>
+
+ <p>The <code>ApplicationMaster</code> or other applications that use the
+ client must provide the details of the container, including the Id and
+ the target resource encapsulated in the updated container token via
+ {@link Container}.
+ </p>
+
+ @param container the container with updated token.]]>
+      </doc>
+    </method>
+    <method name="reInitializeContainerAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="containerLaunchContex" type="org.apache.hadoop.yarn.api.records.ContainerLaunchContext"/>
+      <param name="autoCommit" type="boolean"/>
+      <doc>
+      <![CDATA[<p>Re-Initialize the Container.</p>
+
+ @param containerId the Id of the container to Re-Initialize.
+ @param containerLaunchContex the updated ContainerLaunchContext.
+ @param autoCommit commit re-initialization automatically ?]]>
+      </doc>
+    </method>
+    <method name="restartContainerAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[<p>Restart the specified container.</p>
+
+ @param containerId the Id of the container to restart.]]>
+      </doc>
+    </method>
+    <method name="rollbackLastReInitializationAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[<p>Rollback last reInitialization of the specified container.</p>
+
+ @param containerId the Id of the container to restart.]]>
+      </doc>
+    </method>
+    <method name="commitLastReInitializationAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <doc>
+      <![CDATA[<p>Commit last reInitialization of the specified container.</p>
+
+ @param containerId the Id of the container to commit reInitialize.]]>
+      </doc>
+    </method>
+    <method name="stopContainerAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+    </method>
+    <method name="getContainerStatusAsync"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+    </method>
+    <method name="getClient" return="org.apache.hadoop.yarn.client.api.NMClient"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setClient"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="client" type="org.apache.hadoop.yarn.client.api.NMClient"/>
+    </method>
+    <method name="getCallbackHandler" return="org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setCallbackHandler"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"/>
+    </method>
+    <field name="client" type="org.apache.hadoop.yarn.client.api.NMClient"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="callbackHandler" type="org.apache.hadoop.yarn.client.api.async.NMClientAsync.CallbackHandler"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[<code>NMClientAsync</code> handles communication with all the NodeManagers
+ and provides asynchronous updates on getting responses from them. It
+ maintains a thread pool to communicate with individual NMs where a number of
+ worker threads process requests to NMs by using {@link NMClientImpl}. The max
+ size of the thread pool is configurable through
+ {@link YarnConfiguration#NM_CLIENT_ASYNC_THREAD_POOL_MAX_SIZE}.
+
+ It should be used in conjunction with a CallbackHandler. For example
+
+ <pre>
+ {@code
+ class MyCallbackHandler extends NMClientAsync.AbstractCallbackHandler {
+   public void onContainerStarted(ContainerId containerId,
+       Map<String, ByteBuffer> allServiceResponse) {
+     [post process after the container is started, process the response]
+   }
+
+   public void onContainerResourceIncreased(ContainerId containerId,
+       Resource resource) {
+     [post process after the container resource is increased]
+   }
+
+   public void onContainerStatusReceived(ContainerId containerId,
+       ContainerStatus containerStatus) {
+     [make use of the status of the container]
+   }
+
+   public void onContainerStopped(ContainerId containerId) {
+     [post process after the container is stopped]
+   }
+
+   public void onStartContainerError(
+       ContainerId containerId, Throwable t) {
+     [handle the raised exception]
+   }
+
+   public void onGetContainerStatusError(
+       ContainerId containerId, Throwable t) {
+     [handle the raised exception]
+   }
+
+   public void onStopContainerError(
+       ContainerId containerId, Throwable t) {
+     [handle the raised exception]
+   }
+ }
+ }
+ </pre>
+
+ The client's life-cycle should be managed like the following:
+
+ <pre>
+ {@code
+ NMClientAsync asyncClient = 
+     NMClientAsync.createNMClientAsync(new MyCallbackhandler());
+ asyncClient.init(conf);
+ asyncClient.start();
+ asyncClient.startContainer(container, containerLaunchContext);
+ [... wait for container being started]
+ asyncClient.getContainerStatus(container.getId(), container.getNodeId(),
+     container.getContainerToken());
+ [... handle the status in the callback instance]
+ asyncClient.stopContainer(container.getId(), container.getNodeId(),
+     container.getContainerToken());
+ [... wait for container being stopped]
+ asyncClient.stop();
+ }
+ </pre>]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.async.NMClientAsync -->
+</package>
+<package name="org.apache.hadoop.yarn.client.api.async.impl">
+</package>
+<package name="org.apache.hadoop.yarn.client.api.impl">
+</package>
+<package name="org.apache.hadoop.yarn.client.cli">
+  <!-- start class org.apache.hadoop.yarn.client.cli.LogsCLI -->
+  <class name="LogsCLI" extends="org.apache.hadoop.conf.Configured"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.util.Tool"/>
+    <constructor name="LogsCLI"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="run" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="createYarnClient" return="org.apache.hadoop.yarn.client.api.YarnClient"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="getAMContainerInfoForRMWebService" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="appId" type="java.lang.String"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="getMatchedContainerLogFiles" return="java.util.Set"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest"/>
+      <param name="useRegex" type="boolean"/>
+      <param name="ignoreSizeLimit" type="boolean"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getResponeFromNMWebService" return="com.sun.jersey.api.client.ClientResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="webServiceClient" type="com.sun.jersey.api.client.Client"/>
+      <param name="request" type="org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest"/>
+      <param name="logFile" type="java.lang.String"/>
+    </method>
+    <method name="getNodeHttpAddressFromRMWebString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest"/>
+      <exception name="ClientHandlerException" type="com.sun.jersey.api.client.ClientHandlerException"/>
+      <exception name="UniformInterfaceException" type="com.sun.jersey.api.client.UniformInterfaceException"/>
+      <exception name="JSONException" type="org.codehaus.jettison.json.JSONException"/>
+    </method>
+    <field name="HELP_CMD" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.cli.LogsCLI -->
+  <!-- start class org.apache.hadoop.yarn.client.cli.SchedConfCLI -->
+  <class name="SchedConfCLI" extends="org.apache.hadoop.conf.Configured"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.util.Tool"/>
+    <constructor name="SchedConfCLI"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="main"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="run" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="args" type="java.lang.String[]"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <doc>
+    <![CDATA[CLI for modifying scheduler configuration.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.cli.SchedConfCLI -->
+</package>
+<package name="org.apache.hadoop.yarn.client.util">
+</package>
+
+</api>
diff --git a/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Common_3.2.4.xml b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Common_3.2.4.xml
new file mode 100644
index 000000000000..5ca1716cca2d
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Common_3.2.4.xml
@@ -0,0 +1,3964 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:54:25 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop YARN Common 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/jdiff.jar -verbose -classpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/classes:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-hdfs-client-3.2.4.jar:/maven/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/maven/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.2.4.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/com/google/inject/guice/4.0/guice-4.0.jar:/maven/javax/inject/javax.inject/1/javax.inject-1.jar:/maven/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.5/jackson-module-jaxb-annotations-2.10.5.jar:/maven/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/maven/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.5/jackson-jaxrs-json-provider-2.10.5.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.5/jackson-jaxrs-base-2.10.5.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/jdiff.jar -apidir /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/site/jdiff/xml -apiname Apache Hadoop YARN Common 3.2.4 -->
+<package name="org.apache.hadoop.yarn">
+  <!-- start class org.apache.hadoop.yarn.ContainerLogAppender -->
+  <class name="ContainerLogAppender" extends="org.apache.log4j.FileAppender"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.io.Flushable"/>
+    <constructor name="ContainerLogAppender"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="activateOptions"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="append"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="event" type="org.apache.log4j.spi.LoggingEvent"/>
+    </method>
+    <method name="flush"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getContainerLogDir" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Getter/Setter methods for log4j.]]>
+      </doc>
+    </method>
+    <method name="setContainerLogDir"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerLogDir" type="java.lang.String"/>
+    </method>
+    <method name="getContainerLogFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setContainerLogFile"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerLogFile" type="java.lang.String"/>
+    </method>
+    <method name="getTotalLogFileSize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setTotalLogFileSize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logSize" type="long"/>
+      <doc>
+      <![CDATA[Setter so that log4j can configure it from the
+  configuration(log4j.properties).]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A simple log4j-appender for container's logs.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.ContainerLogAppender -->
+  <!-- start class org.apache.hadoop.yarn.ContainerRollingLogAppender -->
+  <class name="ContainerRollingLogAppender" extends="org.apache.log4j.RollingFileAppender"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.io.Flushable"/>
+    <constructor name="ContainerRollingLogAppender"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="activateOptions"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="flush"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getContainerLogDir" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Getter/Setter methods for log4j.]]>
+      </doc>
+    </method>
+    <method name="setContainerLogDir"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerLogDir" type="java.lang.String"/>
+    </method>
+    <method name="getContainerLogFile" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setContainerLogFile"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerLogFile" type="java.lang.String"/>
+    </method>
+    <doc>
+    <![CDATA[A simple log4j-appender for container's logs.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.ContainerRollingLogAppender -->
+  <!-- start class org.apache.hadoop.yarn.YarnUncaughtExceptionHandler -->
+  <class name="YarnUncaughtExceptionHandler" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.lang.Thread.UncaughtExceptionHandler"/>
+    <constructor name="YarnUncaughtExceptionHandler"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="uncaughtException"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="t" type="java.lang.Thread"/>
+      <param name="e" type="java.lang.Throwable"/>
+    </method>
+    <doc>
+    <![CDATA[This class is intended to be installed by calling 
+ {@link Thread#setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler)}
+ In the main entry point.  It is intended to try and cleanly shut down
+ programs using the YARN Event framework.
+ 
+ Note: Right now it only will shut down the program if a Error is caught, but
+ not any other exception.  Anything else is just logged.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.YarnUncaughtExceptionHandler -->
+</package>
+<package name="org.apache.hadoop.yarn.api">
+</package>
+<package name="org.apache.hadoop.yarn.client">
+  <!-- start class org.apache.hadoop.yarn.client.AHSProxy -->
+  <class name="AHSProxy" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AHSProxy"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createAHSProxy" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="ahsAddress" type="java.net.InetSocketAddress"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getProxy" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="rmAddress" type="java.net.InetSocketAddress"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.AHSProxy -->
+  <!-- start class org.apache.hadoop.yarn.client.ClientRMProxy -->
+  <class name="ClientRMProxy" extends="org.apache.hadoop.yarn.client.RMProxy"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="createRMProxy" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="configuration" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="protocol" type="java.lang.Class"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a proxy to the ResourceManager for the specified protocol.
+ @param configuration Configuration with all the required information.
+ @param protocol Client protocol for which proxy is being requested.
+ @param <T> Type of proxy.
+ @return Proxy to the ResourceManager for the specified client protocol.
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getRMDelegationTokenService" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get the token service name to be used for RMDelegationToken. Depending
+ on whether HA is enabled or not, this method generates the appropriate
+ service name as a comma-separated list of service addresses.
+
+ @param conf Configuration corresponding to the cluster we need the
+             RMDelegationToken for
+ @return - Service name for RMDelegationToken]]>
+      </doc>
+    </method>
+    <method name="getAMRMTokenService" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getTokenService" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="address" type="java.lang.String"/>
+      <param name="defaultAddr" type="java.lang.String"/>
+      <param name="defaultPort" type="int"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.ClientRMProxy -->
+  <!-- start class org.apache.hadoop.yarn.client.NMProxy -->
+  <class name="NMProxy" extends="org.apache.hadoop.yarn.client.ServerProxy"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NMProxy"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createNMProxy" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="ugi" type="org.apache.hadoop.security.UserGroupInformation"/>
+      <param name="rpc" type="org.apache.hadoop.yarn.ipc.YarnRPC"/>
+      <param name="serverAddress" type="java.net.InetSocketAddress"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.NMProxy -->
+  <!-- start class org.apache.hadoop.yarn.client.RMProxy -->
+  <class name="RMProxy" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RMProxy"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRetryPolicy" return="org.apache.hadoop.io.retry.RetryPolicy"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="retryTime" type="long"/>
+      <param name="retryInterval" type="long"/>
+      <param name="isHAEnabled" type="boolean"/>
+      <doc>
+      <![CDATA[Fetch retry policy from Configuration and create the
+ retry policy with specified retryTime and retry interval.]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.RMProxy -->
+  <!-- start class org.apache.hadoop.yarn.client.ServerProxy -->
+  <class name="ServerProxy" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ServerProxy"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createRetryPolicy" return="org.apache.hadoop.io.retry.RetryPolicy"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="maxWaitTimeStr" type="java.lang.String"/>
+      <param name="defMaxWaitTime" type="long"/>
+      <param name="connectRetryIntervalStr" type="java.lang.String"/>
+      <param name="defRetryInterval" type="long"/>
+    </method>
+    <method name="createRetriableProxy" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="user" type="org.apache.hadoop.security.UserGroupInformation"/>
+      <param name="rpc" type="org.apache.hadoop.yarn.ipc.YarnRPC"/>
+      <param name="serverAddress" type="java.net.InetSocketAddress"/>
+      <param name="retryPolicy" type="org.apache.hadoop.io.retry.RetryPolicy"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.ServerProxy -->
+</package>
+<package name="org.apache.hadoop.yarn.client.api">
+  <!-- start class org.apache.hadoop.yarn.client.api.AppAdminClient -->
+  <class name="AppAdminClient" extends="org.apache.hadoop.service.CompositeService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AppAdminClient"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createAppAdminClient" return="org.apache.hadoop.yarn.client.api.AppAdminClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appType" type="java.lang.String"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[<p>
+ Create a new instance of AppAdminClient.
+ </p>
+
+ @param appType application type
+ @param conf configuration
+ @return app admin client]]>
+      </doc>
+    </method>
+    <method name="actionLaunch" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fileName" type="java.lang.String"/>
+      <param name="appName" type="java.lang.String"/>
+      <param name="lifetime" type="java.lang.Long"/>
+      <param name="queue" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Launch a new YARN application.
+ </p>
+
+ @param fileName specification of application
+ @param appName name of the application
+ @param lifetime lifetime of the application
+ @param queue queue of the application
+ @return exit code
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="actionStop" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Stop a YARN application (attempt to stop gracefully before killing the
+ application). In the case of a long-running service, the service may be
+ restarted later.
+ </p>
+
+ @param appName the name of the application
+ @return exit code
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="actionStart" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Start a YARN application from a previously saved specification. In the
+ case of a long-running service, the service must have been previously
+ launched/started and then stopped, or previously saved but not started.
+ </p>
+
+ @param appName the name of the application
+ @return exit code
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="actionSave" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="fileName" type="java.lang.String"/>
+      <param name="appName" type="java.lang.String"/>
+      <param name="lifetime" type="java.lang.Long"/>
+      <param name="queue" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Save the specification for a YARN application / long-running service.
+ The application may be started later.
+ </p>
+
+ @param fileName specification of application to save
+ @param appName name of the application
+ @param lifetime lifetime of the application
+ @param queue queue of the application
+ @return exit code
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="actionDestroy" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Remove the specification and all application data for a YARN application.
+ The application cannot be running.
+ </p>
+
+ @param appName the name of the application
+ @return exit code
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="actionFlex" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="componentCounts" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Change the number of running containers for a component of a YARN
+ application / long-running service.
+ </p>
+
+ @param appName the name of the application
+ @param componentCounts map of component name to new component count or
+                        amount to change existing component count (e.g.
+                        5, +5, -5)
+ @return exit code
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="enableFastLaunch" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="destinationFolder" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Upload AM dependencies to HDFS. This makes future application launches
+ faster since the dependencies do not have to be uploaded on each launch.
+ </p>
+
+ @param destinationFolder
+          an optional HDFS folder where dependency tarball will be uploaded
+ @return exit code
+ @throws IOException
+           IOException
+ @throws YarnException
+           exception in client or server]]>
+      </doc>
+    </method>
+    <method name="getStatusString" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appIdOrName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Get detailed app specific status string for a YARN application.
+ </p>
+
+ @param appIdOrName appId or appName
+ @return status string
+ @throws IOException IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="initiateUpgrade" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="fileName" type="java.lang.String"/>
+      <param name="autoFinalize" type="boolean"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Initiate upgrade of a long running service.
+
+ @param appName      the name of the application.
+ @param fileName     specification of application upgrade to save.
+ @param autoFinalize when true, finalization of upgrade will be done
+                     automatically.
+ @return exit code
+ @throws IOException   IOException
+ @throws YarnException exception in client or server]]>
+      </doc>
+    </method>
+    <method name="actionUpgradeInstances" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="componentInstances" type="java.util.List"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Upgrade component instances of a long running service.
+
+ @param appName            the name of the application.
+ @param componentInstances the name of the component instances.]]>
+      </doc>
+    </method>
+    <method name="actionUpgradeComponents" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="components" type="java.util.List"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Upgrade components of a long running service.
+
+ @param appName    the name of the application.
+ @param components the name of the components.]]>
+      </doc>
+    </method>
+    <method name="actionCleanUp" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="userName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Operation to be performed by the RM after an application has completed.
+
+ @param appName  the name of the application.
+ @param userName the name of the user.
+ @return exit code]]>
+      </doc>
+    </method>
+    <method name="getInstances" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="components" type="java.util.List"/>
+      <param name="version" type="java.lang.String"/>
+      <param name="containerStates" type="java.util.List"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+    </method>
+    <method name="actionUpgradeExpress" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="fileName" type="java.io.File"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Express upgrade a long running service.
+
+ @param appName  the name of the application
+ @param fileName specification of application upgrade to save.
+ @return exit code]]>
+      </doc>
+    </method>
+    <method name="actionCancelUpgrade" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Cancels the upgrade of the service.
+
+ @param appName the name of the application
+ @return exit code
+ @throws IOException
+ @throws YarnException]]>
+      </doc>
+    </method>
+    <method name="actionDecommissionInstances" return="int"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="componentInstances" type="java.util.List"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Decommission component instances of a long running service.
+
+ @param appName            the name of the application.
+ @param componentInstances the name of the component instances.]]>
+      </doc>
+    </method>
+    <field name="YARN_APP_ADMIN_CLIENT_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_CLASS_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="UNIT_TEST_TYPE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="UNIT_TEST_CLASS_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Client for managing applications.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.AppAdminClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.TimelineClient -->
+  <class name="TimelineClient" extends="org.apache.hadoop.service.CompositeService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.io.Flushable"/>
+    <constructor name="TimelineClient" type="java.lang.String"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createTimelineClient" return="org.apache.hadoop.yarn.client.api.TimelineClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Creates an instance of the timeline v.1.x client.
+ The current UGI when the user initialize the client will be used to do the
+ put and the delegation token operations. The current user may use
+ {@link UserGroupInformation#doAs} another user to construct and initialize
+ a timeline client if the following operations are supposed to be conducted
+ by that user.
+
+ @return the created timeline client instance]]>
+      </doc>
+    </method>
+    <method name="putEntities" return="org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="entities" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEntity[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Send the information of a number of conceptual entities to the timeline
+ server. It is a blocking API. The method will not return until it gets the
+ response from the timeline server.
+ </p>
+ 
+ @param entities
+          the collection of {@link TimelineEntity}
+ @return the error information if the sent entities are not correctly stored
+ @throws IOException if there are I/O errors
+ @throws YarnException if entities are incomplete/invalid]]>
+      </doc>
+    </method>
+    <method name="putEntities" return="org.apache.hadoop.yarn.api.records.timeline.TimelinePutResponse"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="groupId" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEntityGroupId"/>
+      <param name="entities" type="org.apache.hadoop.yarn.api.records.timeline.TimelineEntity[]"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Send the information of a number of conceptual entities to the timeline
+ server. It is a blocking API. The method will not return until it gets the
+ response from the timeline server.
+
+ This API is only for timeline service v1.5
+ </p>
+
+ @param appAttemptId {@link ApplicationAttemptId}
+ @param groupId {@link TimelineEntityGroupId}
+ @param entities
+          the collection of {@link TimelineEntity}
+ @return the error information if the sent entities are not correctly stored
+ @throws IOException if there are I/O errors
+ @throws YarnException if entities are incomplete/invalid]]>
+      </doc>
+    </method>
+    <method name="putDomain"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="domain" type="org.apache.hadoop.yarn.api.records.timeline.TimelineDomain"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Send the information of a domain to the timeline server. It is a
+ blocking API. The method will not return until it gets the response from
+ the timeline server.
+ </p>
+ 
+ @param domain
+          an {@link TimelineDomain} object
+ @throws IOException
+ @throws YarnException]]>
+      </doc>
+    </method>
+    <method name="putDomain"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="domain" type="org.apache.hadoop.yarn.api.records.timeline.TimelineDomain"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Send the information of a domain to the timeline server. It is a
+ blocking API. The method will not return until it gets the response from
+ the timeline server.
+
+ This API is only for timeline service v1.5
+ </p>
+
+ @param domain
+          an {@link TimelineDomain} object
+ @param appAttemptId {@link ApplicationAttemptId}
+ @throws IOException
+ @throws YarnException]]>
+      </doc>
+    </method>
+    <method name="getDelegationToken" return="org.apache.hadoop.security.token.Token"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="renewer" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Get a delegation token so as to be able to talk to the timeline server in a
+ secure way.
+ </p>
+ 
+ @param renewer
+          Address of the renewer who can renew these tokens when needed by
+          securely talking to the timeline server
+ @return a delegation token ({@link Token}) that can be used to talk to the
+         timeline server
+ @throws IOException
+ @throws YarnException]]>
+      </doc>
+    </method>
+    <method name="renewDelegationToken" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineDT" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Renew a timeline delegation token.
+ </p>
+ 
+ @param timelineDT
+          the delegation token to renew
+ @return the new expiration time
+ @throws IOException
+ @throws YarnException]]>
+      </doc>
+    </method>
+    <method name="cancelDelegationToken"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="timelineDT" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[<p>
+ Cancel a timeline delegation token.
+ </p>
+ 
+ @param timelineDT
+          the delegation token to cancel
+ @throws IOException
+ @throws YarnException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A client library that can be used to post some information in terms of a
+ number of conceptual entities. This client library needs to be used along
+ with Timeline V.1.x server versions.
+ Refer {@link TimelineV2Client} for ATS V2 interface.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.TimelineClient -->
+  <!-- start class org.apache.hadoop.yarn.client.api.TimelineReaderClient -->
+  <class name="TimelineReaderClient" extends="org.apache.hadoop.service.CompositeService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineReaderClient" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="createTimelineReaderClient" return="org.apache.hadoop.yarn.client.api.TimelineReaderClient"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new instance of Timeline Reader Client.]]>
+      </doc>
+    </method>
+    <method name="getApplicationEntity" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets application entity.
+ @param appId application id
+ @param fields Fields to be fetched. Defaults to INFO.
+ @param filters Filters to be applied while fetching entities.
+ @return entity of the application
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttemptEntity" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets application attempt entity.
+ @param appAttemptId application attempt id
+ @param fields Fields to be fetched. Defaults to INFO.
+ @param filters Filters to be applied while fetching entities.
+ @return entity associated with application attempt
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getApplicationAttemptEntities" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <param name="limit" type="long"/>
+      <param name="fromId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets application attempt entities.
+ @param appId application id
+ @param fields Fields to be fetched. Defaults to INFO.
+ @param filters Filters to be applied while fetching entities.
+ @param limit Number of entities to return.
+ @param fromId Retrieve next set of generic ids from given fromId
+ @return list of application attempt entities
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainerEntity" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets Timeline entity for the container.
+ @param containerId container id
+ @param fields Fields to be fetched. Defaults to INFO.
+ @param filters Filters to be applied while fetching entities.
+ @return timeline entity for container
+ @throws IOException]]>
+      </doc>
+    </method>
+    <method name="getContainerEntities" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <param name="limit" type="long"/>
+      <param name="fromId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Gets container entities for an application.
+ @param appId application id
+ @param fields Fields to be fetched. Defaults to INFO.
+ @param filters Filters to be applied while fetching entities.
+ @param limit Number of entities to return.
+ @param fromId Retrieve next set of generic ids from given fromId
+ @return list of entities
+ @throws IOException]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A client library that can be used to get Timeline Entities associated with
+ application, application attempt or containers. This client library needs to
+ be used along with time line v.2 server version.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.TimelineReaderClient -->
+</package>
+<package name="org.apache.hadoop.yarn.client.api.impl">
+  <!-- start class org.apache.hadoop.yarn.client.api.impl.TimelineReaderClientImpl -->
+  <class name="TimelineReaderClientImpl" extends="org.apache.hadoop.yarn.client.api.TimelineReaderClient"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineReaderClientImpl"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="serviceInit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="getApplicationEntity" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getApplicationAttemptEntity" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getApplicationAttemptEntities" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <param name="limit" type="long"/>
+      <param name="fromId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getContainerEntity" return="org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getContainerEntities" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="fields" type="java.lang.String"/>
+      <param name="filters" type="java.util.Map"/>
+      <param name="limit" type="long"/>
+      <param name="fromId" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="encodeValue" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="value" type="java.lang.String"/>
+      <exception name="UnsupportedEncodingException" type="java.io.UnsupportedEncodingException"/>
+    </method>
+    <method name="doGetUri" return="com.sun.jersey.api.client.ClientResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="base" type="java.net.URI"/>
+      <param name="path" type="java.lang.String"/>
+      <param name="params" type="javax.ws.rs.core.MultivaluedMap"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <doc>
+    <![CDATA[Implementation of TimelineReaderClient interface.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.client.api.impl.TimelineReaderClientImpl -->
+</package>
+<package name="org.apache.hadoop.yarn.event">
+  <!-- start class org.apache.hadoop.yarn.event.AbstractEvent -->
+  <class name="AbstractEvent" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.event.Event"/>
+    <constructor name="AbstractEvent" type="TYPE"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AbstractEvent" type="TYPE, long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getTimestamp" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getType" return="TYPE"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Parent class of all the events. All events extend this class.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.event.AbstractEvent -->
+  <!-- start class org.apache.hadoop.yarn.event.AsyncDispatcher -->
+  <class name="AsyncDispatcher" extends="org.apache.hadoop.service.AbstractService"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.event.Dispatcher"/>
+    <constructor name="AsyncDispatcher"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AsyncDispatcher" type="java.util.concurrent.BlockingQueue"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AsyncDispatcher" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Set a name for this dispatcher thread.
+ @param dispatcherName name of the dispatcher thread]]>
+      </doc>
+    </constructor>
+    <method name="disableExitOnDispatchException"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="serviceInit"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="serviceStart"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="setDrainEventsOnStop"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="serviceStop"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="dispatch"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="event" type="org.apache.hadoop.yarn.event.Event"/>
+    </method>
+    <method name="register"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventType" type="java.lang.Class"/>
+      <param name="handler" type="org.apache.hadoop.yarn.event.EventHandler"/>
+    </method>
+    <method name="getEventHandler" return="org.apache.hadoop.yarn.event.EventHandler"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isEventThreadWaiting" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="isDrained" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <method name="isStopped" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <field name="eventDispatchers" type="java.util.Map"
+      transient="false" volatile="false"
+      static="false" final="true" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Dispatches {@link Event}s in a separate thread. Currently only single thread
+ does that. Potentially there could be multiple channels for each event type
+ class and a thread pool can be used to dispatch the events.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.event.AsyncDispatcher -->
+  <!-- start interface org.apache.hadoop.yarn.event.Dispatcher -->
+  <interface name="Dispatcher"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getEventHandler" return="org.apache.hadoop.yarn.event.EventHandler"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="register"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventType" type="java.lang.Class"/>
+      <param name="handler" type="org.apache.hadoop.yarn.event.EventHandler"/>
+    </method>
+    <doc>
+    <![CDATA[Event Dispatcher interface. It dispatches events to registered 
+ event handlers based on event types.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.event.Dispatcher -->
+  <!-- start interface org.apache.hadoop.yarn.event.Event -->
+  <interface name="Event"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getType" return="TYPE"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getTimestamp" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Interface defining events api.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.event.Event -->
+  <!-- start interface org.apache.hadoop.yarn.event.EventHandler -->
+  <interface name="EventHandler"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="handle"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="event" type="T"/>
+    </method>
+    <doc>
+    <![CDATA[Interface for handling events of type T
+
+ @param <T> parameterized event of type T]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.event.EventHandler -->
+</package>
+<package name="org.apache.hadoop.yarn.factories">
+</package>
+<package name="org.apache.hadoop.yarn.factory.providers">
+</package>
+<package name="org.apache.hadoop.yarn.logaggregation">
+  <!-- start class org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat -->
+  <class name="AggregatedLogFormat" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AggregatedLogFormat"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat -->
+  <!-- start class org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogKey -->
+  <class name="AggregatedLogFormat.LogKey" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.io.Writable"/>
+    <constructor name="LogKey"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="LogKey" type="org.apache.hadoop.yarn.api.records.ContainerId"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="LogKey" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="obj" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogKey -->
+  <!-- start class org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogReader -->
+  <class name="AggregatedLogFormat.LogReader" extends="java.lang.Object"
+    abstract="false"
+    static="true" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LogReader" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.Path"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+    </constructor>
+    <method name="getApplicationOwner" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns the owner of the application.
+
+ @return the application owner.
+ @throws IOException if we can not get the application owner.]]>
+      </doc>
+    </method>
+    <method name="getApplicationAcls" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns ACLs for the application. An empty map is returned if no ACLs are
+ found.
+
+ @return a map of the Application ACLs.
+ @throws IOException if we can not get the application acls.]]>
+      </doc>
+    </method>
+    <method name="next" return="java.io.DataInputStream"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogKey"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Read the next key and return the value-stream.
+ 
+ @param key the log key
+ @return the valueStream if there are more keys or null otherwise
+ @throws IOException if we can not get the dataInputStream
+ for the next key]]>
+      </doc>
+    </method>
+    <method name="readAcontainerLogs"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="writer" type="java.io.Writer"/>
+      <param name="logUploadedTime" type="long"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Writes all logs for a single container to the provided writer.
+ @param valueStream the valueStream
+ @param writer the log writer
+ @param logUploadedTime the time stamp
+ @throws IOException if we can not read the container logs.]]>
+      </doc>
+    </method>
+    <method name="readAcontainerLogs"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="writer" type="java.io.Writer"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Writes all logs for a single container to the provided writer.
+ @param valueStream the value stream
+ @param writer the log writer
+ @throws IOException if we can not read the container logs.]]>
+      </doc>
+    </method>
+    <method name="readAContainerLogsForALogType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="out" type="java.io.PrintStream"/>
+      <param name="logUploadedTime" type="long"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Keep calling this till you get a {@link EOFException} for getting logs of
+ all types for a single container.
+ 
+ @param valueStream the value stream
+ @param out the print stream
+ @param logUploadedTime the time stamp
+ @throws IOException if we can not read the container log by specifying
+ the container log type.]]>
+      </doc>
+    </method>
+    <method name="readAContainerLogsForALogType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="out" type="java.io.PrintStream"/>
+      <param name="logUploadedTime" type="long"/>
+      <param name="bytes" type="long"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Keep calling this till you get a {@link EOFException} for getting logs of
+ all types for a single container for the specific bytes.
+
+ @param valueStream the value stream
+ @param out the output print stream
+ @param logUploadedTime the log upload time stamp
+ @param bytes the output size of the log
+ @throws IOException if we can not read the container log]]>
+      </doc>
+    </method>
+    <method name="readAContainerLogsForALogType"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="out" type="java.io.PrintStream"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Keep calling this till you get a {@link EOFException} for getting logs of
+ all types for a single container.
+ 
+ @param valueStream the value stream
+ @param out the output print stream
+ @throws IOException if we can not read the container log]]>
+      </doc>
+    </method>
+    <method name="readContainerLogsForALogType" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="out" type="java.io.PrintStream"/>
+      <param name="logUploadedTime" type="long"/>
+      <param name="logType" type="java.util.List"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Keep calling this till you get a {@link EOFException} for getting logs of
+ the specific types for a single container.
+ @param valueStream the value stream
+ @param out the output print stream
+ @param logUploadedTime the log uploaded time stamp
+ @param logType the given log type
+ @throws IOException if we can not read the container logs]]>
+      </doc>
+    </method>
+    <method name="readContainerLogsForALogType" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="valueStream" type="java.io.DataInputStream"/>
+      <param name="out" type="java.io.PrintStream"/>
+      <param name="logUploadedTime" type="long"/>
+      <param name="logType" type="java.util.List"/>
+      <param name="bytes" type="long"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Keep calling this till you get a {@link EOFException} for getting logs of
+ the specific types for a single container.
+ @param valueStream the value stream
+ @param out the output print stream
+ @param logUploadedTime the log uploaded time stamp
+ @param logType the given log type
+ @throws IOException if we can not read the container logs]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogReader -->
+</package>
+<package name="org.apache.hadoop.yarn.logaggregation.filecontroller">
+  <!-- start class org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileController -->
+  <class name="LogAggregationFileController" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="LogAggregationFileController"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="controllerName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Initialize the log file controller.
+ @param conf the Configuration
+ @param controllerName the log controller class name]]>
+      </doc>
+    </method>
+    <method name="initInternal"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Derived classes initialize themselves using this method.
+ @param conf the Configuration]]>
+      </doc>
+    </method>
+    <method name="getRemoteRootLogDir" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the remote root log directory.
+ @return the remote root log directory path]]>
+      </doc>
+    </method>
+    <method name="getRemoteRootLogDirSuffix" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the log aggregation directory suffix.
+ @return the log aggregation directory suffix]]>
+      </doc>
+    </method>
+    <method name="initializeWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="context" type="org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Initialize the writer.
+ @param context the {@link LogAggregationFileControllerContext}
+ @throws IOException if fails to initialize the writer]]>
+      </doc>
+    </method>
+    <method name="closeWriter"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="LogAggregationDFSException" type="org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationDFSException"/>
+      <doc>
+      <![CDATA[Close the writer.
+ @throws LogAggregationDFSException if the closing of the writer fails
+         (for example due to HDFS quota being exceeded)]]>
+      </doc>
+    </method>
+    <method name="write"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logKey" type="org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogKey"/>
+      <param name="logValue" type="org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat.LogValue"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Write the log content.
+ @param logKey the log key
+ @param logValue the log content
+ @throws IOException if fails to write the logs]]>
+      </doc>
+    </method>
+    <method name="postWrite"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="record" type="org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileControllerContext"/>
+      <exception name="Exception" type="java.lang.Exception"/>
+      <doc>
+      <![CDATA[Operations needed after write the log content.
+ @param record the {@link LogAggregationFileControllerContext}
+ @throws Exception if anything fails]]>
+      </doc>
+    </method>
+    <method name="closePrintStream"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.OutputStream"/>
+    </method>
+    <method name="readAggregatedLogs" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logRequest" type="org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest"/>
+      <param name="os" type="java.io.OutputStream"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Output container log.
+ @param logRequest {@link ContainerLogsRequest}
+ @param os the output stream
+ @return true if we can read the aggregated logs successfully
+ @throws IOException if we can not access the log file.]]>
+      </doc>
+    </method>
+    <method name="readAggregatedLogsMeta" return="java.util.List"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="logRequest" type="org.apache.hadoop.yarn.logaggregation.ContainerLogsRequest"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Return a list of {@link ContainerLogMeta} for an application
+ from Remote FileSystem.
+
+ @param logRequest {@link ContainerLogsRequest}
+ @return a list of {@link ContainerLogMeta}
+ @throws IOException if there is no available log file]]>
+      </doc>
+    </method>
+    <method name="renderAggregatedLogsBlock"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="html" type="org.apache.hadoop.yarn.webapp.view.HtmlBlock.Block"/>
+      <param name="context" type="org.apache.hadoop.yarn.webapp.View.ViewContext"/>
+      <doc>
+      <![CDATA[Render Aggregated Logs block.
+ @param html the html
+ @param context the ViewContext]]>
+      </doc>
+    </method>
+    <method name="getApplicationOwner" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="aggregatedLogPath" type="org.apache.hadoop.fs.Path"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns the owner of the application.
+
+ @param aggregatedLogPath the aggregatedLog path
+ @param appId the ApplicationId
+ @return the application owner
+ @throws IOException if we can not get the application owner]]>
+      </doc>
+    </method>
+    <method name="getApplicationAcls" return="java.util.Map"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="aggregatedLogPath" type="org.apache.hadoop.fs.Path"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns ACLs for the application. An empty map is returned if no ACLs are
+ found.
+
+ @param aggregatedLogPath the aggregatedLog path.
+ @param appId the ApplicationId
+ @return a map of the Application ACLs.
+ @throws IOException if we can not get the application acls]]>
+      </doc>
+    </method>
+    <method name="verifyAndCreateRemoteLogDir"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Verify and create the remote log directory.]]>
+      </doc>
+    </method>
+    <method name="createAppDir"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="user" type="java.lang.String"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="userUgi" type="org.apache.hadoop.security.UserGroupInformation"/>
+      <doc>
+      <![CDATA[Create remote Application directory for log aggregation.
+ @param user the user
+ @param appId the application ID
+ @param userUgi the UGI]]>
+      </doc>
+    </method>
+    <method name="getFileSystem" return="org.apache.hadoop.fs.FileSystem"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="createDir"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="fsPerm" type="org.apache.hadoop.fs.permission.FsPermission"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="checkExists" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fs" type="org.apache.hadoop.fs.FileSystem"/>
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+      <param name="fsPerm" type="org.apache.hadoop.fs.permission.FsPermission"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getRemoteNodeLogFileForApp" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="user" type="java.lang.String"/>
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+      <doc>
+      <![CDATA[Get the remote aggregated log path.
+ @param appId the ApplicationId
+ @param user the Application Owner
+ @param nodeId the NodeManager Id
+ @return the remote aggregated log path]]>
+      </doc>
+    </method>
+    <method name="getRemoteAppLogDir" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="appOwner" type="java.lang.String"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Get the remote application directory for log aggregation.
+ @param appId the Application ID
+ @param appOwner the Application Owner
+ @return the remote application directory
+ @throws IOException if can not find the remote application directory]]>
+      </doc>
+    </method>
+    <method name="cleanOldLogs"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="remoteNodeLogFileForApp" type="org.apache.hadoop.fs.Path"/>
+      <param name="nodeId" type="org.apache.hadoop.yarn.api.records.NodeId"/>
+      <param name="userUgi" type="org.apache.hadoop.security.UserGroupInformation"/>
+    </method>
+    <method name="aggregatedLogSuffix" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="fileName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Create the aggregated log suffix. The LogAggregationFileController
+ should call this to get the suffix and append the suffix to the end
+ of each log. This would keep the aggregated log format consistent.
+
+ @param fileName the File Name
+ @return the aggregated log suffix String]]>
+      </doc>
+    </method>
+    <method name="isFsSupportsChmod" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="belongsToAppAttempt" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="appAttemptId" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+      <param name="containerIdStr" type="java.lang.String"/>
+    </method>
+    <field name="TLDIR_PERMISSIONS" type="org.apache.hadoop.fs.permission.FsPermission"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Permissions for the top level directory under which app directories will be
+ created.]]>
+      </doc>
+    </field>
+    <field name="APP_DIR_PERMISSIONS" type="org.apache.hadoop.fs.permission.FsPermission"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Permissions for the Application directory.]]>
+      </doc>
+    </field>
+    <field name="APP_LOG_FILE_UMASK" type="org.apache.hadoop.fs.permission.FsPermission"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="protected"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Umask for the log file.]]>
+      </doc>
+    </field>
+    <field name="LOG_AGGREGATION_FS_SUPPORT_APPEND" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="conf" type="org.apache.hadoop.conf.Configuration"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="remoteRootLogDir" type="org.apache.hadoop.fs.Path"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="remoteRootLogDirSuffix" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="retentionSize" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="fileControllerName" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="fsSupportsChmod" type="boolean"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Base class to implement Log Aggregation File Controller.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.logaggregation.filecontroller.LogAggregationFileController -->
+</package>
+<package name="org.apache.hadoop.yarn.logaggregation.filecontroller.ifile">
+</package>
+<package name="org.apache.hadoop.yarn.logaggregation.filecontroller.tfile">
+</package>
+<package name="org.apache.hadoop.yarn.nodelabels">
+</package>
+<package name="org.apache.hadoop.yarn.nodelabels.event">
+</package>
+<package name="org.apache.hadoop.yarn.security">
+  <!-- start class org.apache.hadoop.yarn.security.AccessRequest -->
+  <class name="AccessRequest" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AccessRequest" type="org.apache.hadoop.yarn.security.PrivilegedEntity, org.apache.hadoop.security.UserGroupInformation, org.apache.hadoop.yarn.security.AccessType, java.lang.String, java.lang.String, java.lang.String, java.util.List"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getUser" return="org.apache.hadoop.security.UserGroupInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAccessType" return="org.apache.hadoop.yarn.security.AccessType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAppId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAppName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getEntity" return="org.apache.hadoop.yarn.security.PrivilegedEntity"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getForwardedAddresses" return="java.util.List"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getRemoteAddress" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[This request object contains all the context information to determine whether
+ a user has permission to access the target entity.
+ user       : the user who's currently accessing
+ accessType : the access type against the entity.
+ entity     : the target object user is accessing.
+ appId      : the associated app Id for current access. This could be null
+              if no app is associated.
+ appName    : the associated app name for current access. This could be null if
+              no app is associated.
+ remoteAddress : The caller's remote ip address.
+ forwardedAddresses : In case this is an http request, this contains the
+                    originating IP address of a client connecting to a web
+                    server through an HTTP proxy or load balancer. This
+                    parameter is null, if it's a RPC request.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.AccessRequest -->
+  <!-- start class org.apache.hadoop.yarn.security.AMRMTokenIdentifier -->
+  <class name="AMRMTokenIdentifier" extends="org.apache.hadoop.security.token.TokenIdentifier"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AMRMTokenIdentifier"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AMRMTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getKind" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getUser" return="org.apache.hadoop.security.UserGroupInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getKeyId" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProto" return="org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.AMRMTokenIdentifierProto"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="KIND_NAME" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[AMRMTokenIdentifier is the TokenIdentifier to be used by
+ ApplicationMasters to authenticate to the ResourceManager.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.AMRMTokenIdentifier -->
+  <!-- start class org.apache.hadoop.yarn.security.AMRMTokenSelector -->
+  <class name="AMRMTokenSelector" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.security.token.TokenSelector"/>
+    <constructor name="AMRMTokenSelector"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="selectToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="service" type="org.apache.hadoop.io.Text"/>
+      <param name="tokens" type="java.util.Collection"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.AMRMTokenSelector -->
+  <!-- start class org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo -->
+  <class name="ContainerManagerSecurityInfo" extends="org.apache.hadoop.security.SecurityInfo"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerManagerSecurityInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getKerberosInfo" return="org.apache.hadoop.security.KerberosInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getTokenInfo" return="org.apache.hadoop.security.token.TokenInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.ContainerManagerSecurityInfo -->
+  <!-- start class org.apache.hadoop.yarn.security.ContainerTokenIdentifier -->
+  <class name="ContainerTokenIdentifier" extends="org.apache.hadoop.security.token.TokenIdentifier"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long, org.apache.hadoop.yarn.api.records.LogAggregationContext"
+      static="false" final="false" visibility="public"
+      deprecated="Use one of the other constructors instead.">
+      <doc>
+      <![CDATA[Creates a instance.
+
+ @param appSubmitter appSubmitter
+ @param containerID container ID
+ @param creationTime creation time
+ @param expiryTimeStamp expiry timestamp
+ @param hostName hostname
+ @param logAggregationContext log aggregation context
+ @param masterKeyId master key ID
+ @param priority priority
+ @param r resource needed by the container
+ @param rmIdentifier ResourceManager identifier
+ @deprecated Use one of the other constructors instead.]]>
+      </doc>
+    </constructor>
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long, org.apache.hadoop.yarn.api.records.LogAggregationContext, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long, org.apache.hadoop.yarn.api.records.LogAggregationContext, java.lang.String, org.apache.hadoop.yarn.server.api.ContainerType"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, int, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long, org.apache.hadoop.yarn.api.records.LogAggregationContext, java.lang.String, org.apache.hadoop.yarn.server.api.ContainerType, org.apache.hadoop.yarn.api.records.ExecutionType"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, int, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long, org.apache.hadoop.yarn.api.records.LogAggregationContext, java.lang.String, org.apache.hadoop.yarn.server.api.ContainerType, org.apache.hadoop.yarn.api.records.ExecutionType, long"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Convenience Constructor for existing clients.
+
+ @param containerID containerID
+ @param containerVersion containerVersion
+ @param hostName hostName
+ @param appSubmitter appSubmitter
+ @param r resource
+ @param expiryTimeStamp expiryTimeStamp
+ @param masterKeyId masterKeyId
+ @param rmIdentifier rmIdentifier
+ @param priority priority
+ @param creationTime creationTime
+ @param logAggregationContext logAggregationContext
+ @param nodeLabelExpression nodeLabelExpression
+ @param containerType containerType
+ @param executionType executionType
+ @param allocationRequestId allocationRequestId]]>
+      </doc>
+    </constructor>
+    <constructor name="ContainerTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ContainerId, int, java.lang.String, java.lang.String, org.apache.hadoop.yarn.api.records.Resource, long, int, long, org.apache.hadoop.yarn.api.records.Priority, long, org.apache.hadoop.yarn.api.records.LogAggregationContext, java.lang.String, org.apache.hadoop.yarn.server.api.ContainerType, org.apache.hadoop.yarn.api.records.ExecutionType, long, java.util.Set"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a Container Token Identifier.
+
+ @param containerID containerID
+ @param containerVersion containerVersion
+ @param hostName hostName
+ @param appSubmitter appSubmitter
+ @param r resource
+ @param expiryTimeStamp expiryTimeStamp
+ @param masterKeyId masterKeyId
+ @param rmIdentifier rmIdentifier
+ @param priority priority
+ @param creationTime creationTime
+ @param logAggregationContext logAggregationContext
+ @param nodeLabelExpression nodeLabelExpression
+ @param containerType containerType
+ @param executionType executionType
+ @param allocationRequestId allocationRequestId
+ @param allocationTags Set of allocation Tags.]]>
+      </doc>
+    </constructor>
+    <constructor name="ContainerTokenIdentifier"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor needed by RPC layer/SecretManager.]]>
+      </doc>
+    </constructor>
+    <method name="getContainerID" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getApplicationSubmitter" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNmHostAddress" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getResource" return="org.apache.hadoop.yarn.api.records.Resource"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getExpiryTimeStamp" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getMasterKeyId" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPriority" return="org.apache.hadoop.yarn.api.records.Priority"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getCreationTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getRMIdentifier" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the RMIdentifier of RM in which containers are allocated.
+ @return RMIdentifier]]>
+      </doc>
+    </method>
+    <method name="getContainerType" return="org.apache.hadoop.yarn.server.api.ContainerType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the ContainerType of container to allocate.
+ @return ContainerType]]>
+      </doc>
+    </method>
+    <method name="getExecutionType" return="org.apache.hadoop.yarn.api.records.ExecutionType"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the ExecutionType of container to allocate
+ @return ExecutionType]]>
+      </doc>
+    </method>
+    <method name="getProto" return="org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.ContainerTokenIdentifierProto"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getLogAggregationContext" return="org.apache.hadoop.yarn.api.records.LogAggregationContext"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocationRequestId" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getKind" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getUser" return="org.apache.hadoop.security.UserGroupInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getVersion" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the Container version
+ @return container version]]>
+      </doc>
+    </method>
+    <method name="getNodeLabelExpression" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the node-label-expression in the original ResourceRequest]]>
+      </doc>
+    </method>
+    <method name="getAllcationTags" return="java.util.Set"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="KIND" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[TokenIdentifier for a container. Encodes {@link ContainerId},
+ {@link Resource} needed by the container and the target NMs host-address.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.ContainerTokenIdentifier -->
+  <!-- start class org.apache.hadoop.yarn.security.ContainerTokenSelector -->
+  <class name="ContainerTokenSelector" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.security.token.TokenSelector"/>
+    <constructor name="ContainerTokenSelector"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="selectToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="service" type="org.apache.hadoop.io.Text"/>
+      <param name="tokens" type="java.util.Collection"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.ContainerTokenSelector -->
+  <!-- start class org.apache.hadoop.yarn.security.NMTokenIdentifier -->
+  <class name="NMTokenIdentifier" extends="org.apache.hadoop.security.token.TokenIdentifier"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NMTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId, org.apache.hadoop.yarn.api.records.NodeId, java.lang.String, int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="NMTokenIdentifier"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Default constructor needed by RPC/Secret manager]]>
+      </doc>
+    </constructor>
+    <method name="getApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNodeId" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getApplicationSubmitter" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getKeyId" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getKind" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getUser" return="org.apache.hadoop.security.UserGroupInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProto" return="org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.NMTokenIdentifierProto"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="KIND" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.NMTokenIdentifier -->
+  <!-- start class org.apache.hadoop.yarn.security.SchedulerSecurityInfo -->
+  <class name="SchedulerSecurityInfo" extends="org.apache.hadoop.security.SecurityInfo"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SchedulerSecurityInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getKerberosInfo" return="org.apache.hadoop.security.KerberosInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getTokenInfo" return="org.apache.hadoop.security.token.TokenInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.SchedulerSecurityInfo -->
+</package>
+<package name="org.apache.hadoop.yarn.security.admin">
+  <!-- start class org.apache.hadoop.yarn.security.admin.AdminSecurityInfo -->
+  <class name="AdminSecurityInfo" extends="org.apache.hadoop.security.SecurityInfo"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AdminSecurityInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getKerberosInfo" return="org.apache.hadoop.security.KerberosInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getTokenInfo" return="org.apache.hadoop.security.token.TokenInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.admin.AdminSecurityInfo -->
+</package>
+<package name="org.apache.hadoop.yarn.security.client">
+  <!-- start class org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager -->
+  <class name="BaseClientToAMTokenSecretManager" extends="org.apache.hadoop.security.token.SecretManager"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="BaseClientToAMTokenSecretManager"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[A base {@link SecretManager} for AMs to extend and validate Client-RM tokens
+ issued to clients by the RM using the underlying master-key shared by RM to
+ the AMs on their launch. All the methods are called by either Hadoop RPC or
+ YARN, so this class is strictly for the purpose of inherit/extend and
+ register with Hadoop RPC.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager -->
+  <!-- start class org.apache.hadoop.yarn.security.client.ClientRMSecurityInfo -->
+  <class name="ClientRMSecurityInfo" extends="org.apache.hadoop.security.SecurityInfo"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ClientRMSecurityInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getKerberosInfo" return="org.apache.hadoop.security.KerberosInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getTokenInfo" return="org.apache.hadoop.security.token.TokenInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.ClientRMSecurityInfo -->
+  <!-- start class org.apache.hadoop.yarn.security.client.ClientTimelineSecurityInfo -->
+  <class name="ClientTimelineSecurityInfo" extends="org.apache.hadoop.security.SecurityInfo"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ClientTimelineSecurityInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getKerberosInfo" return="org.apache.hadoop.security.KerberosInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="getTokenInfo" return="org.apache.hadoop.security.token.TokenInfo"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.ClientTimelineSecurityInfo -->
+  <!-- start class org.apache.hadoop.yarn.security.client.ClientToAMTokenIdentifier -->
+  <class name="ClientToAMTokenIdentifier" extends="org.apache.hadoop.security.token.TokenIdentifier"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ClientToAMTokenIdentifier"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ClientToAMTokenIdentifier" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getApplicationAttemptID" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getClientName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProto" return="org.apache.hadoop.yarn.proto.YarnSecurityTokenProtos.ClientToAMTokenIdentifierProto"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="write"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="out" type="java.io.DataOutput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="readFields"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.DataInput"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="getKind" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getUser" return="org.apache.hadoop.security.UserGroupInformation"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="hashCode" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="equals" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="other" type="java.lang.Object"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="KIND_NAME" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.ClientToAMTokenIdentifier -->
+  <!-- start class org.apache.hadoop.yarn.security.client.ClientToAMTokenSecretManager -->
+  <class name="ClientToAMTokenSecretManager" extends="org.apache.hadoop.yarn.security.client.BaseClientToAMTokenSecretManager"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ClientToAMTokenSecretManager" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId, byte[]"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="retrievePassword" return="byte[]"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="identifier" type="org.apache.hadoop.yarn.security.client.ClientToAMTokenIdentifier"/>
+      <exception name="SecretManager.InvalidToken" type="org.apache.hadoop.security.token.SecretManager.InvalidToken"/>
+    </method>
+    <method name="getMasterKey" return="javax.crypto.SecretKey"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptID" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"/>
+    </method>
+    <method name="setMasterKey"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="byte[]"/>
+    </method>
+    <doc>
+    <![CDATA[A simple {@link SecretManager} for AMs to validate Client-RM tokens issued to
+ clients by the RM using the underlying master-key shared by RM to the AMs on
+ their launch. All the methods are called by either Hadoop RPC or YARN, so
+ this class is strictly for the purpose of inherit/extend and register with
+ Hadoop RPC.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.ClientToAMTokenSecretManager -->
+  <!-- start class org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier -->
+  <class name="RMDelegationTokenIdentifier" extends="org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="RMDelegationTokenIdentifier"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="RMDelegationTokenIdentifier" type="org.apache.hadoop.io.Text, org.apache.hadoop.io.Text, org.apache.hadoop.io.Text"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new delegation token identifier
+ @param owner the effective username of the token owner
+ @param renewer the username of the renewer
+ @param realUser the real username of the token owner]]>
+      </doc>
+    </constructor>
+    <method name="getKind" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="KIND_NAME" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Delegation Token Identifier that identifies the delegation tokens from the 
+ Resource Manager.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier -->
+  <!-- start class org.apache.hadoop.yarn.security.client.RMDelegationTokenSelector -->
+  <class name="RMDelegationTokenSelector" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.security.token.TokenSelector"/>
+    <constructor name="RMDelegationTokenSelector"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="selectToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="service" type="org.apache.hadoop.io.Text"/>
+      <param name="tokens" type="java.util.Collection"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.RMDelegationTokenSelector -->
+  <!-- start class org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier -->
+  <class name="TimelineDelegationTokenIdentifier" extends="org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineDelegationTokenIdentifier"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="TimelineDelegationTokenIdentifier" type="org.apache.hadoop.io.Text, org.apache.hadoop.io.Text, org.apache.hadoop.io.Text"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create a new timeline delegation token identifier
+
+ @param owner the effective username of the token owner
+ @param renewer the username of the renewer
+ @param realUser the real username of the token owner]]>
+      </doc>
+    </constructor>
+    <method name="getKind" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="KIND_NAME" type="org.apache.hadoop.io.Text"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.TimelineDelegationTokenIdentifier -->
+  <!-- start class org.apache.hadoop.yarn.security.client.TimelineDelegationTokenSelector -->
+  <class name="TimelineDelegationTokenSelector" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.security.token.TokenSelector"/>
+    <constructor name="TimelineDelegationTokenSelector"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="selectToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="service" type="org.apache.hadoop.io.Text"/>
+      <param name="tokens" type="java.util.Collection"/>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.security.client.TimelineDelegationTokenSelector -->
+</package>
+<package name="org.apache.hadoop.yarn.server.api">
+</package>
+<package name="org.apache.hadoop.yarn.server.api.impl.pb.client">
+</package>
+<package name="org.apache.hadoop.yarn.server.api.impl.pb.service">
+</package>
+<package name="org.apache.hadoop.yarn.sharedcache">
+  <!-- start interface org.apache.hadoop.yarn.sharedcache.SharedCacheChecksum -->
+  <interface name="SharedCacheChecksum"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="computeChecksum" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="in" type="java.io.InputStream"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Calculate the checksum of the passed input stream.
+
+ @param in <code>InputStream</code> to be checksumed
+ @return the message digest of the input stream
+ @throws IOException]]>
+      </doc>
+    </method>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.sharedcache.SharedCacheChecksum -->
+  <!-- start class org.apache.hadoop.yarn.sharedcache.SharedCacheChecksumFactory -->
+  <class name="SharedCacheChecksumFactory" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="SharedCacheChecksumFactory"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getChecksum" return="org.apache.hadoop.yarn.sharedcache.SharedCacheChecksum"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Get a new <code>SharedCacheChecksum</code> object based on the configurable
+ algorithm implementation
+ (see <code>yarn.sharedcache.checksum.algo.impl</code>)
+
+ @return <code>SharedCacheChecksum</code> object]]>
+      </doc>
+    </method>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.sharedcache.SharedCacheChecksumFactory -->
+</package>
+<package name="org.apache.hadoop.yarn.state">
+  <!-- start class org.apache.hadoop.yarn.state.InvalidStateTransitionException -->
+  <class name="InvalidStateTransitionException" extends="org.apache.hadoop.yarn.state.InvalidStateTransitonException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="InvalidStateTransitionException" type="java.lang.Enum, java.lang.Enum"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <doc>
+    <![CDATA[The exception that happens when you call invalid state transition.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.state.InvalidStateTransitionException -->
+  <!-- start class org.apache.hadoop.yarn.state.InvalidStateTransitonException -->
+  <class name="InvalidStateTransitonException" extends="org.apache.hadoop.yarn.exceptions.YarnRuntimeException"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="Use {@link InvalidStateTransitionException} instead.">
+    <constructor name="InvalidStateTransitonException" type="java.lang.Enum, java.lang.Enum"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getCurrentState" return="java.lang.Enum"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getEvent" return="java.lang.Enum"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[@deprecated Use {@link InvalidStateTransitionException} instead.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.state.InvalidStateTransitonException -->
+  <!-- start interface org.apache.hadoop.yarn.state.MultipleArcTransition -->
+  <interface name="MultipleArcTransition"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="transition" return="STATE"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="operand" type="OPERAND"/>
+      <param name="event" type="EVENT"/>
+      <doc>
+      <![CDATA[Transition hook.
+ @return the postState. Post state must be one of the 
+                      valid post states registered in StateMachine.
+ @param operand the entity attached to the FSM, whose internal 
+                state may change.
+ @param event causal event]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Hook for Transition. 
+ Post state is decided by Transition hook. Post state must be one of the 
+ valid post states registered in StateMachine.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.state.MultipleArcTransition -->
+  <!-- start interface org.apache.hadoop.yarn.state.SingleArcTransition -->
+  <interface name="SingleArcTransition"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="transition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="operand" type="OPERAND"/>
+      <param name="event" type="EVENT"/>
+      <doc>
+      <![CDATA[Transition hook.
+ 
+ @param operand the entity attached to the FSM, whose internal 
+                state may change.
+ @param event causal event]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[Hook for Transition. This lead to state machine to move to 
+ the post state as registered in the state machine.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.state.SingleArcTransition -->
+  <!-- start interface org.apache.hadoop.yarn.state.StateMachine -->
+  <interface name="StateMachine"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getCurrentState" return="STATE"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="doTransition" return="STATE"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="eventType" type="EVENTTYPE"/>
+      <param name="event" type="EVENT"/>
+      <exception name="InvalidStateTransitionException" type="org.apache.hadoop.yarn.state.InvalidStateTransitionException"/>
+    </method>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.state.StateMachine -->
+  <!-- start class org.apache.hadoop.yarn.state.StateMachineFactory -->
+  <class name="StateMachineFactory" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="StateMachineFactory" type="STATE"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructor
+
+ This is the only constructor in the API.]]>
+      </doc>
+    </constructor>
+    <method name="addTransition" return="org.apache.hadoop.yarn.state.StateMachineFactory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="preState" type="STATE"/>
+      <param name="postState" type="STATE"/>
+      <param name="eventType" type="EVENTTYPE"/>
+      <doc>
+      <![CDATA[@return a NEW StateMachineFactory just like {@code this} with the current
+          transition added as a new legal transition.  This overload
+          has no hook object.
+
+         Note that the returned StateMachineFactory is a distinct
+         object.
+
+         This method is part of the API.
+
+ @param preState pre-transition state
+ @param postState post-transition state
+ @param eventType stimulus for the transition]]>
+      </doc>
+    </method>
+    <method name="addTransition" return="org.apache.hadoop.yarn.state.StateMachineFactory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="preState" type="STATE"/>
+      <param name="postState" type="STATE"/>
+      <param name="eventTypes" type="java.util.Set"/>
+      <doc>
+      <![CDATA[@return a NEW StateMachineFactory just like {@code this} with the current
+          transition added as a new legal transition.  This overload
+          has no hook object.
+
+
+         Note that the returned StateMachineFactory is a distinct
+         object.
+
+         This method is part of the API.
+
+ @param preState pre-transition state
+ @param postState post-transition state
+ @param eventTypes List of stimuli for the transitions]]>
+      </doc>
+    </method>
+    <method name="addTransition" return="org.apache.hadoop.yarn.state.StateMachineFactory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="preState" type="STATE"/>
+      <param name="postState" type="STATE"/>
+      <param name="eventTypes" type="java.util.Set"/>
+      <param name="hook" type="org.apache.hadoop.yarn.state.SingleArcTransition"/>
+      <doc>
+      <![CDATA[@return a NEW StateMachineFactory just like {@code this} with the current
+          transition added as a new legal transition
+
+         Note that the returned StateMachineFactory is a distinct
+         object.
+
+         This method is part of the API.
+
+ @param preState pre-transition state
+ @param postState post-transition state
+ @param eventTypes List of stimuli for the transitions
+ @param hook transition hook]]>
+      </doc>
+    </method>
+    <method name="addTransition" return="org.apache.hadoop.yarn.state.StateMachineFactory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="preState" type="STATE"/>
+      <param name="postState" type="STATE"/>
+      <param name="eventType" type="EVENTTYPE"/>
+      <param name="hook" type="org.apache.hadoop.yarn.state.SingleArcTransition"/>
+      <doc>
+      <![CDATA[@return a NEW StateMachineFactory just like {@code this} with the current
+          transition added as a new legal transition
+
+         Note that the returned StateMachineFactory is a distinct object.
+
+         This method is part of the API.
+
+ @param preState pre-transition state
+ @param postState post-transition state
+ @param eventType stimulus for the transition
+ @param hook transition hook]]>
+      </doc>
+    </method>
+    <method name="addTransition" return="org.apache.hadoop.yarn.state.StateMachineFactory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="preState" type="STATE"/>
+      <param name="postStates" type="java.util.Set"/>
+      <param name="eventType" type="EVENTTYPE"/>
+      <param name="hook" type="org.apache.hadoop.yarn.state.MultipleArcTransition"/>
+      <doc>
+      <![CDATA[@return a NEW StateMachineFactory just like {@code this} with the current
+          transition added as a new legal transition
+
+         Note that the returned StateMachineFactory is a distinct object.
+
+         This method is part of the API.
+
+ @param preState pre-transition state
+ @param postStates valid post-transition states
+ @param eventType stimulus for the transition
+ @param hook transition hook]]>
+      </doc>
+    </method>
+    <method name="installTopology" return="org.apache.hadoop.yarn.state.StateMachineFactory"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[@return a StateMachineFactory just like {@code this}, except that if
+         you won't need any synchronization to build a state machine
+
+         Note that the returned StateMachineFactory is a distinct object.
+
+         This method is part of the API.
+
+         The only way you could distinguish the returned
+         StateMachineFactory from {@code this} would be by
+         measuring the performance of the derived 
+         {@code StateMachine} you can get from it.
+
+ Calling this is optional.  It doesn't change the semantics of the factory,
+   if you call it then when you use the factory there is no synchronization.]]>
+      </doc>
+    </method>
+    <method name="make" return="org.apache.hadoop.yarn.state.StateMachine"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="operand" type="OPERAND"/>
+      <param name="initialState" type="STATE"/>
+      <param name="listener" type="org.apache.hadoop.yarn.state.StateTransitionListener"/>
+      <doc>
+      <![CDATA[A StateMachine that accepts a transition listener.
+ @param operand the object upon which the returned
+                {@link StateMachine} will operate.
+ @param initialState the state in which the returned
+                {@link StateMachine} will start.
+ @param listener An implementation of a {@link StateTransitionListener}.
+ @return A (@link StateMachine}.]]>
+      </doc>
+    </method>
+    <method name="make" return="org.apache.hadoop.yarn.state.StateMachine"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="operand" type="OPERAND"/>
+      <param name="initialState" type="STATE"/>
+    </method>
+    <method name="make" return="org.apache.hadoop.yarn.state.StateMachine"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="operand" type="OPERAND"/>
+    </method>
+    <method name="generateStateGraph" return="org.apache.hadoop.yarn.state.Graph"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="name" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate a graph represents the state graph of this StateMachine
+ @param name graph name
+ @return Graph object generated]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[State machine topology.
+ This object is semantically immutable.  If you have a
+ StateMachineFactory there's no operation in the API that changes
+ its semantic properties.
+
+ @param <OPERAND> The object type on which this state machine operates.
+ @param <STATE> The state of the entity.
+ @param <EVENTTYPE> The external eventType to be handled.
+ @param <EVENT> The event object.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.state.StateMachineFactory -->
+  <!-- start interface org.apache.hadoop.yarn.state.StateTransitionListener -->
+  <interface name="StateTransitionListener"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="preTransition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="OPERAND"/>
+      <param name="beforeState" type="STATE"/>
+      <param name="eventToBeProcessed" type="EVENT"/>
+      <doc>
+      <![CDATA[Pre Transition Hook. This will be called before transition.
+ @param op Operand.
+ @param beforeState State before transition.
+ @param eventToBeProcessed Incoming Event.]]>
+      </doc>
+    </method>
+    <method name="postTransition"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="op" type="OPERAND"/>
+      <param name="beforeState" type="STATE"/>
+      <param name="afterState" type="STATE"/>
+      <param name="processedEvent" type="EVENT"/>
+      <doc>
+      <![CDATA[Post Transition Hook. This will be called after the transition.
+ @param op Operand.
+ @param beforeState State before transition.
+ @param afterState State after transition.
+ @param processedEvent Processed Event.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A State Transition Listener.
+ It exposes a pre and post transition hook called before and
+ after the transition.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.state.StateTransitionListener -->
+</package>
+<package name="org.apache.hadoop.yarn.util">
+  <!-- start class org.apache.hadoop.yarn.util.AbstractLivelinessMonitor -->
+  <class name="AbstractLivelinessMonitor" extends="org.apache.hadoop.service.AbstractService"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AbstractLivelinessMonitor" type="java.lang.String, org.apache.hadoop.yarn.util.Clock"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AbstractLivelinessMonitor" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="serviceStart"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="serviceStop"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="expire"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="ob" type="O"/>
+    </method>
+    <method name="setExpireInterval"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="expireInterval" type="int"/>
+    </method>
+    <method name="getExpireInterval" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="o" type="O"/>
+    </method>
+    <method name="setMonitorInterval"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="monitorInterval" type="long"/>
+    </method>
+    <method name="receivedPing"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ob" type="O"/>
+    </method>
+    <method name="register"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ob" type="O"/>
+    </method>
+    <method name="register"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ob" type="O"/>
+      <param name="expireTime" type="long"/>
+    </method>
+    <method name="unregister"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="ob" type="O"/>
+    </method>
+    <method name="resetTimer"
+      abstract="false" native="false" synchronized="true"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setResetTimeOnStart"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="resetTimeOnStart" type="boolean"/>
+    </method>
+    <field name="DEFAULT_EXPIRE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A simple liveliness monitor with which clients can register, trust the
+ component to monitor liveliness, get a call-back on expiry and then finally
+ unregister.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.AbstractLivelinessMonitor -->
+  <!-- start class org.apache.hadoop.yarn.util.ApplicationClassLoader -->
+  <class name="ApplicationClassLoader" extends="org.apache.hadoop.util.ApplicationClassLoader"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ApplicationClassLoader" type="java.net.URL[], java.lang.ClassLoader, java.util.List"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ApplicationClassLoader" type="java.lang.String, java.lang.ClassLoader, java.util.List"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="MalformedURLException" type="java.net.MalformedURLException"/>
+    </constructor>
+    <doc>
+    <![CDATA[This type has been deprecated in favor of
+ {@link org.apache.hadoop.util.ApplicationClassLoader}. All new uses of
+ ApplicationClassLoader should use that type instead.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.ApplicationClassLoader -->
+  <!-- start class org.apache.hadoop.yarn.util.BoundedAppender -->
+  <class name="BoundedAppender" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="BoundedAppender" type="int"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="append" return="org.apache.hadoop.yarn.util.BoundedAppender"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="csq" type="java.lang.CharSequence"/>
+      <doc>
+      <![CDATA[Append a {@link CharSequence} considering {@link #limit}, truncating
+ from the head of {@code csq} or {@link #messages} when necessary.
+
+ @param csq the {@link CharSequence} to append
+ @return this]]>
+      </doc>
+    </method>
+    <method name="length" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get current length of messages considering truncates
+ without header and ellipses.
+
+ @return current length]]>
+      </doc>
+    </method>
+    <method name="getLimit" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a string representation of the actual contents, displaying also a
+ header and ellipses when there was a truncate.
+
+ @return String representation of the {@link #messages}]]>
+      </doc>
+    </method>
+    <field name="TRUNCATED_MESSAGES_TEMPLATE" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A {@link CharSequence} appender that considers its {@link #limit} as upper
+ bound.
+ <p>
+ When {@link #limit} would be reached on append, past messages will be
+ truncated from head, and a header telling the user about truncation will be
+ prepended, with ellipses in between header and messages.
+ <p>
+ Note that header and ellipses are not counted against {@link #limit}.
+ <p>
+ An example:
+
+ <pre>
+ {@code
+   // At the beginning it's an empty string
+   final Appendable shortAppender = new BoundedAppender(80);
+   // The whole message fits into limit
+   shortAppender.append(
+       "message1 this is a very long message but fitting into limit\n");
+   // The first message is truncated, the second not
+   shortAppender.append("message2 this is shorter than the previous one\n");
+   // The first message is deleted, the second truncated, the third
+   // preserved
+   shortAppender.append("message3 this is even shorter message, maybe.\n");
+   // The first two are deleted, the third one truncated, the last preserved
+   shortAppender.append("message4 the shortest one, yet the greatest :)");
+   // Current contents are like this:
+   // Diagnostic messages truncated, showing last 80 chars out of 199:
+   // ...s is even shorter message, maybe.
+   // message4 the shortest one, yet the greatest :)
+ }
+ </pre>
+ <p>
+ Note that <tt>null</tt> values are {@link #append(CharSequence) append}ed
+ just like in {@link StringBuilder#append(CharSequence) original
+ implementation}.
+ <p>
+ Note that this class is not thread safe.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.BoundedAppender -->
+  <!-- start interface org.apache.hadoop.yarn.util.Clock -->
+  <interface name="Clock"    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <method name="getTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[A simple clock interface that gives you time.]]>
+    </doc>
+  </interface>
+  <!-- end interface org.apache.hadoop.yarn.util.Clock -->
+  <!-- start class org.apache.hadoop.yarn.util.ConverterUtils -->
+  <class name="ConverterUtils" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ConverterUtils"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getPathFromYarnURL" return="org.apache.hadoop.fs.Path"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="url" type="org.apache.hadoop.yarn.api.records.URL"/>
+      <exception name="URISyntaxException" type="java.net.URISyntaxException"/>
+      <doc>
+      <![CDATA[return a hadoop path from a given url
+ This method is deprecated, use {@link URL#toPath()} instead.
+ 
+ @param url
+          url to convert
+ @return path from {@link URL}
+ @throws URISyntaxException]]>
+      </doc>
+    </method>
+    <method name="getYarnUrlFromPath" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="path" type="org.apache.hadoop.fs.Path"/>
+    </method>
+    <method name="getYarnUrlFromURI" return="org.apache.hadoop.yarn.api.records.URL"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uri" type="java.net.URI"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="toApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="recordFactory" type="org.apache.hadoop.yarn.factories.RecordFactory"/>
+      <param name="applicationIdStr" type="java.lang.String"/>
+    </method>
+    <method name="toString" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="cId" type="org.apache.hadoop.yarn.api.records.ContainerId"/>
+    </method>
+    <method name="toNodeId" return="org.apache.hadoop.yarn.api.records.NodeId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="nodeIdStr" type="java.lang.String"/>
+    </method>
+    <method name="toContainerId" return="org.apache.hadoop.yarn.api.records.ContainerId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerIdStr" type="java.lang.String"/>
+    </method>
+    <method name="toApplicationAttemptId" return="org.apache.hadoop.yarn.api.records.ApplicationAttemptId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="applicationAttemptIdStr" type="java.lang.String"/>
+    </method>
+    <method name="toApplicationId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appIdStr" type="java.lang.String"/>
+    </method>
+    <method name="convertFromYarn" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protoToken" type="org.apache.hadoop.yarn.api.records.Token"/>
+      <param name="serviceAddr" type="java.net.InetSocketAddress"/>
+      <doc>
+      <![CDATA[Convert a protobuf token into a rpc token and set its service. Supposed
+ to be used for tokens other than RMDelegationToken. For
+ RMDelegationToken, use
+ {@link #convertFromYarn(org.apache.hadoop.yarn.api.records.Token,
+ org.apache.hadoop.io.Text)} instead.
+
+ @param protoToken the yarn token
+ @param serviceAddr the connect address for the service
+ @return rpc token]]>
+      </doc>
+    </method>
+    <method name="convertFromYarn" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="protoToken" type="org.apache.hadoop.yarn.api.records.Token"/>
+      <param name="service" type="org.apache.hadoop.io.Text"/>
+      <doc>
+      <![CDATA[Convert a protobuf token into a rpc token and set its service.
+
+ @param protoToken the yarn token
+ @param service the service for the token]]>
+      </doc>
+    </method>
+    <field name="APPLICATION_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="CONTAINER_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="APPLICATION_ATTEMPT_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[This class contains a set of utilities which help converting data structures
+ from/to 'serializableFormat' to/from hadoop/nativejava data structures.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.ConverterUtils -->
+  <!-- start class org.apache.hadoop.yarn.util.MonotonicClock -->
+  <class name="MonotonicClock" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.util.Clock"/>
+    <constructor name="MonotonicClock"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get current time from some arbitrary time base in the past, counting in
+ milliseconds, and not affected by settimeofday or similar system clock
+ changes.
+ @return a monotonic clock that counts in milliseconds.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A monotonic clock from some arbitrary time base in the past, counting in
+ milliseconds, and not affected by settimeofday or similar system clock
+ changes.
+ This is appropriate to use when computing how much longer to wait for an
+ interval to expire.
+ This function can return a negative value and it must be handled correctly
+ by callers. See the documentation of System#nanoTime for caveats.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.MonotonicClock -->
+  <!-- start class org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree -->
+  <class name="ResourceCalculatorProcessTree" extends="org.apache.hadoop.conf.Configured"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ResourceCalculatorProcessTree" type="java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create process-tree instance with specified root process.
+
+ Subclass must override this.
+ @param root process-tree root-process]]>
+      </doc>
+    </constructor>
+    <method name="initialize"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Initialize the object.
+ @throws YarnException Throws an exception on error.]]>
+      </doc>
+    </method>
+    <method name="updateProcessTree"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Update the process-tree with latest state.
+
+ Each call to this function should increment the age of the running
+ processes that already exist in the process tree. Age is used other API's
+ of the interface.]]>
+      </doc>
+    </method>
+    <method name="getProcessTreeDump" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get a dump of the process-tree.
+
+ @return a string concatenating the dump of information of all the processes
+         in the process-tree]]>
+      </doc>
+    </method>
+    <method name="getVirtualMemorySize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the virtual memory used by all the processes in the
+ process-tree.
+
+ @return virtual memory used by the process-tree in bytes,
+ {@link #UNAVAILABLE} if it cannot be calculated.]]>
+      </doc>
+    </method>
+    <method name="getRssMemorySize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the resident set size (rss) memory used by all the processes
+ in the process-tree.
+
+ @return rss memory used by the process-tree in bytes,
+ {@link #UNAVAILABLE} if it cannot be calculated.]]>
+      </doc>
+    </method>
+    <method name="getVirtualMemorySize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="olderThanAge" type="int"/>
+      <doc>
+      <![CDATA[Get the virtual memory used by all the processes in the
+ process-tree that are older than the passed in age.
+
+ @param olderThanAge processes above this age are included in the
+                     memory addition
+ @return virtual memory used by the process-tree in bytes for
+ processes older than the specified age, {@link #UNAVAILABLE} if it
+ cannot be calculated.]]>
+      </doc>
+    </method>
+    <method name="getRssMemorySize" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="olderThanAge" type="int"/>
+      <doc>
+      <![CDATA[Get the resident set size (rss) memory used by all the processes
+ in the process-tree that are older than the passed in age.
+
+ @param olderThanAge processes above this age are included in the
+                     memory addition
+ @return rss memory used by the process-tree in bytes for
+ processes older than specified age, {@link #UNAVAILABLE} if it cannot be
+ calculated.]]>
+      </doc>
+    </method>
+    <method name="getCumulativeCpuTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the CPU time in millisecond used by all the processes in the
+ process-tree since the process-tree was created
+
+ @return cumulative CPU time in millisecond since the process-tree
+ created, {@link #UNAVAILABLE} if it cannot be calculated.]]>
+      </doc>
+    </method>
+    <method name="getCpuUsagePercent" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the CPU usage by all the processes in the process-tree based on
+ average between samples as a ratio of overall CPU cycles similar to top.
+ Thus, if 2 out of 4 cores are used this should return 200.0.
+ Note: UNAVAILABLE will be returned in case when CPU usage is not
+ available. It is NOT advised to return any other error code.
+
+ @return percentage CPU usage since the process-tree was created,
+ {@link #UNAVAILABLE} if CPU usage cannot be calculated or not available.]]>
+      </doc>
+    </method>
+    <method name="checkPidPgrpidForMatch" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Verify that the tree process id is same as its process group id.
+ @return true if the process id matches else return false.]]>
+      </doc>
+    </method>
+    <method name="getResourceCalculatorProcessTree" return="org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="pid" type="java.lang.String"/>
+      <param name="clazz" type="java.lang.Class"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Create the ResourceCalculatorProcessTree rooted to specified process 
+ from the class name and configure it. If class name is null, this method
+ will try and return a process tree plugin available for this system.
+
+ @param pid process pid of the root of the process tree
+ @param clazz class-name
+ @param conf configure the plugin with this.
+
+ @return ResourceCalculatorProcessTree or null if ResourceCalculatorPluginTree
+         is not available for this system.]]>
+      </doc>
+    </method>
+    <field name="UNAVAILABLE" type="int"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[Interface class to obtain process resource usage
+ NOTE: This class should not be used by external users, but only by external
+ developers to extend and include their own process-tree implementation, 
+ especially for platforms other than Linux and Windows.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.ResourceCalculatorProcessTree -->
+  <!-- start class org.apache.hadoop.yarn.util.SystemClock -->
+  <class name="SystemClock" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="true" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.util.Clock"/>
+    <constructor name="SystemClock"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getInstance" return="org.apache.hadoop.yarn.util.SystemClock"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Implementation of {@link Clock} that gives the current time from the system
+ clock in milliseconds.
+ 
+ NOTE: Do not use this to calculate a duration of expire or interval to sleep,
+ because it will be broken by settimeofday. Please use {@link MonotonicClock}
+ instead.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.SystemClock -->
+  <!-- start class org.apache.hadoop.yarn.util.UTCClock -->
+  <class name="UTCClock" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="org.apache.hadoop.yarn.util.Clock"/>
+    <constructor name="UTCClock"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <doc>
+    <![CDATA[Implementation of {@link Clock} that gives the current UTC time in
+ milliseconds.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.UTCClock -->
+</package>
+<package name="org.apache.hadoop.yarn.util.resource">
+</package>
+<package name="org.apache.hadoop.yarn.util.timeline">
+  <!-- start class org.apache.hadoop.yarn.util.timeline.TimelineUtils -->
+  <class name="TimelineUtils" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="TimelineUtils"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="dumpTimelineRecordtoJSON" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+      <exception name="JsonGenerationException" type="com.fasterxml.jackson.core.JsonGenerationException"/>
+      <exception name="JsonMappingException" type="com.fasterxml.jackson.databind.JsonMappingException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Serialize a POJO object into a JSON string not in a pretty format
+ 
+ @param o
+          an object to serialize
+ @return a JSON string
+ @throws IOException
+ @throws JsonMappingException
+ @throws JsonGenerationException]]>
+      </doc>
+    </method>
+    <method name="dumpTimelineRecordtoJSON" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="o" type="java.lang.Object"/>
+      <param name="pretty" type="boolean"/>
+      <exception name="JsonGenerationException" type="com.fasterxml.jackson.core.JsonGenerationException"/>
+      <exception name="JsonMappingException" type="com.fasterxml.jackson.databind.JsonMappingException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Serialize a POJO object into a JSON string
+ 
+ @param o
+          an object to serialize
+ @param pretty
+          whether in a pretty format or not
+ @return a JSON string
+ @throws IOException
+ @throws JsonMappingException
+ @throws JsonGenerationException]]>
+      </doc>
+    </method>
+    <method name="timelineServiceEnabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the timeline service is enabled via configuration.
+
+ @param conf the configuration
+ @return whether the timeline service is enabled.]]>
+      </doc>
+    </method>
+    <method name="getTimelineServiceVersion" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns the timeline service version. It does not check whether the
+ timeline service itself is enabled.
+
+ @param conf the configuration
+ @return the timeline service version as a float.]]>
+      </doc>
+    </method>
+    <method name="timelineServiceV1_5Enabled" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Returns whether the timeline service v.1.5 is enabled by default via
+ configuration.
+
+ @param conf the configuration
+ @return whether the timeline service v.1.5 is enabled. V.1.5 refers to a
+ version equal to 1.5.]]>
+      </doc>
+    </method>
+    <method name="createTimelineAbout" return="org.apache.hadoop.yarn.api.records.timeline.TimelineAbout"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="about" type="java.lang.String"/>
+    </method>
+    <method name="getTimelineTokenServiceAddress" return="java.net.InetSocketAddress"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="buildTimelineTokenService" return="org.apache.hadoop.io.Text"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+    </method>
+    <method name="generateDefaultFlowName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appName" type="java.lang.String"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+    </method>
+    <method name="generateFlowNameTag" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flowName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate flow name tag.
+
+ @param flowName flow name that identifies a distinct flow application which
+                 can be run repeatedly over time
+ @return flow name tag.]]>
+      </doc>
+    </method>
+    <method name="shortenFlowName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flowName" type="java.lang.String"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <doc>
+      <![CDATA[Shortens the flow name for the configured size by removing UUID if present.
+
+ @param flowName which has to be shortened
+ @param conf to resize the flow name
+ @return shortened flowName]]>
+      </doc>
+    </method>
+    <method name="generateFlowVersionTag" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flowVersion" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Generate flow version tag.
+
+ @param flowVersion flow version that keeps track of the changes made to the
+                    flow
+ @return flow version tag.]]>
+      </doc>
+    </method>
+    <method name="generateFlowRunIdTag" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="true" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="flowRunId" type="long"/>
+      <doc>
+      <![CDATA[Generate flow run ID tag.
+
+ @param flowRunId flow run ID that identifies one instance (or specific
+                  execution) of that flow
+ @return flow run id tag.]]>
+      </doc>
+    </method>
+    <field name="FLOW_NAME_TAG_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_VERSION_TAG_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="FLOW_RUN_ID_TAG_PREFIX" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <field name="DEFAULT_FLOW_VERSION" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[The helper class for the timeline module.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.util.timeline.TimelineUtils -->
+</package>
+<package name="org.apache.hadoop.yarn.webapp.util">
+</package>
+
+</api>
diff --git a/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Server_Common_3.2.4.xml b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Server_Common_3.2.4.xml
new file mode 100644
index 000000000000..d06cc2fe00f6
--- /dev/null
+++ b/hadoop-yarn-project/hadoop-yarn/dev-support/jdiff/Apache_Hadoop_YARN_Server_Common_3.2.4.xml
@@ -0,0 +1,1412 @@
+<?xml version="1.0" encoding="iso-8859-1" standalone="no"?>
+<!-- Generated by the JDiff Javadoc doclet -->
+<!-- (http://www.jdiff.org) -->
+<!-- on Tue Jul 12 12:55:00 GMT 2022 -->
+
+<api
+  xmlns:xsi='http://www.w3.org/2001/XMLSchema-instance'
+  xsi:noNamespaceSchemaLocation='api.xsd'
+  name="Apache Hadoop YARN Server Common 3.2.4"
+  jdversion="1.0.9">
+
+<!--  Command line arguments =  -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/jdiff.jar -verbose -classpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/classes:/build/source/hadoop-common-project/hadoop-common/target/hadoop-common-3.2.4.jar:/maven/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/maven/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/maven/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/maven/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/maven/commons-codec/commons-codec/1.11/commons-codec-1.11.jar:/maven/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar:/maven/commons-net/commons-net/3.6/commons-net-3.6.jar:/maven/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/maven/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/maven/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar:/maven/org/eclipse/jetty/jetty-server/9.4.43.v20210629/jetty-server-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-http/9.4.43.v20210629/jetty-http-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-io/9.4.43.v20210629/jetty-io-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util/9.4.43.v20210629/jetty-util-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-servlet/9.4.43.v20210629/jetty-servlet-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-security/9.4.43.v20210629/jetty-security-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-util-ajax/9.4.43.v20210629/jetty-util-ajax-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-webapp/9.4.43.v20210629/jetty-webapp-9.4.43.v20210629.jar:/maven/org/eclipse/jetty/jetty-xml/9.4.43.v20210629/jetty-xml-9.4.43.v20210629.jar:/maven/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/maven/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/maven/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/maven/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/maven/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/maven/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/maven/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/maven/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/maven/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/maven/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/maven/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/maven/ch/qos/reload4j/reload4j/1.2.18.3/reload4j-1.2.18.3.jar:/maven/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/maven/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/maven/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/maven/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/maven/org/slf4j/slf4j-api/1.7.35/slf4j-api-1.7.35.jar:/maven/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/maven/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/maven/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/maven/com/google/re2j/re2j/1.1/re2j-1.1.jar:/maven/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/build/source/hadoop-common-project/hadoop-auth/target/hadoop-auth-3.2.4.jar:/maven/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/maven/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/maven/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/maven/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/maven/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/maven/com/jcraft/jsch/0.1.55/jsch-0.1.55.jar:/maven/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar:/maven/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar:/maven/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar:/maven/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/maven/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/maven/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/maven/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/maven/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/maven/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/maven/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/maven/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/maven/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/maven/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/maven/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/maven/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/maven/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/maven/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/maven/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/maven/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/maven/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/maven/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar:/maven/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/maven/com/fasterxml/woodstox/woodstox-core/5.3.0/woodstox-core-5.3.0.jar:/maven/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-3.2.4.jar:/maven/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar:/maven/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-3.2.4.jar:/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/hadoop-hdfs-client-3.2.4.jar:/maven/com/squareup/okhttp/okhttp/2.7.5/okhttp-2.7.5.jar:/maven/com/squareup/okio/okio/1.6.0/okio-1.6.0.jar:/maven/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/maven/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/maven/com/google/inject/guice/4.0/guice-4.0.jar:/maven/javax/inject/javax.inject/1/javax.inject-1.jar:/maven/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/maven/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/maven/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar:/maven/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.10.5/jackson-module-jaxb-annotations-2.10.5.jar:/maven/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar:/maven/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.10.5/jackson-jaxrs-json-provider-2.10.5.jar:/maven/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.10.5/jackson-jaxrs-base-2.10.5.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-registry/target/hadoop-yarn-registry-3.2.4.jar:/maven/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar:/maven/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/maven/com/google/guava/guava/27.0-jre/guava-27.0-jre.jar:/maven/com/google/guava/failureaccess/1.0/failureaccess-1.0.jar:/maven/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/maven/org/checkerframework/checker-qual/2.5.2/checker-qual-2.5.2.jar:/maven/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/maven/com/google/j2objc/j2objc-annotations/1.1/j2objc-annotations-1.1.jar:/maven/org/codehaus/mojo/animal-sniffer-annotations/1.17/animal-sniffer-annotations-1.17.jar:/maven/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/build/source/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-3.2.4.jar:/usr/lib/jvm/java-8-openjdk-amd64/lib/tools.jar:/maven/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/maven/org/apache/zookeeper/zookeeper/3.4.14/zookeeper-3.4.14.jar:/maven/com/github/spotbugs/spotbugs-annotations/3.1.9/spotbugs-annotations-3.1.9.jar:/maven/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/maven/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/maven/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/maven/org/apache/geronimo/specs/geronimo-jcache_1.0_spec/1.0-alpha-1/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/maven/org/ehcache/ehcache/3.3.1/ehcache-3.3.1.jar:/maven/com/zaxxer/HikariCP-java7/2.4.12/HikariCP-java7-2.4.12.jar:/maven/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar:/maven/xml-apis/xml-apis/1.4.01/xml-apis-1.4.01.jar -sourcepath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/java -doclet org.apache.hadoop.classification.tools.IncludePublicAnnotationsJDiffDoclet -docletpath /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/hadoop-annotations.jar:/build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/jdiff.jar -apidir /build/source/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/site/jdiff/xml -apiname Apache Hadoop YARN Server Common 3.2.4 -->
+<package name="org.apache.hadoop.yarn.server">
+</package>
+<package name="org.apache.hadoop.yarn.server.api">
+</package>
+<package name="org.apache.hadoop.yarn.server.api.impl.pb.client">
+</package>
+<package name="org.apache.hadoop.yarn.server.api.impl.pb.service">
+</package>
+<package name="org.apache.hadoop.yarn.server.api.records">
+  <!-- start class org.apache.hadoop.yarn.server.api.records.NodeHealthStatus -->
+  <class name="NodeHealthStatus" extends="java.lang.Object"
+    abstract="true"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="NodeHealthStatus"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getIsNodeHealthy" return="boolean"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Is the node healthy?
+ @return <code>true</code> if the node is healthy, else <code>false</code>]]>
+      </doc>
+    </method>
+    <method name="getHealthReport" return="java.lang.String"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>diagnostic health report</em> of the node.
+ @return <em>diagnostic health report</em> of the node]]>
+      </doc>
+    </method>
+    <method name="getLastHealthReportTime" return="long"
+      abstract="true" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the <em>last timestamp</em> at which the health report was received.
+ @return <em>last timestamp</em> at which the health report was received]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[{@code NodeHealthStatus} is a summary of the health status of the node.
+ <p>
+ It includes information such as:
+ <ul>
+   <li>
+     An indicator of whether the node is healthy, as determined by the
+     health-check script.
+   </li>
+   <li>The previous time at which the health status was reported.</li>
+   <li>A diagnostic report on the health status.</li>
+ </ul>
+ 
+ @see NodeReport
+ @see ApplicationClientProtocol#getClusterNodes(org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest)]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.api.records.NodeHealthStatus -->
+</package>
+<package name="org.apache.hadoop.yarn.server.api.records.impl.pb">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.failover">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.policies">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.policies.amrmproxy">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.policies.dao">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.policies.exceptions">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.policies.manager">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.policies.router">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.resolver">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store.exception">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store.impl">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store.metrics">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store.records">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store.records.impl.pb">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.store.utils">
+</package>
+<package name="org.apache.hadoop.yarn.server.federation.utils">
+</package>
+<package name="org.apache.hadoop.yarn.server.metrics">
+</package>
+<package name="org.apache.hadoop.yarn.server.records">
+</package>
+<package name="org.apache.hadoop.yarn.server.records.impl.pb">
+</package>
+<package name="org.apache.hadoop.yarn.server.scheduler">
+</package>
+<package name="org.apache.hadoop.yarn.server.security.http">
+</package>
+<package name="org.apache.hadoop.yarn.server.sharedcache">
+</package>
+<package name="org.apache.hadoop.yarn.server.uam">
+  <!-- start class org.apache.hadoop.yarn.server.uam.UnmanagedAMPoolManager -->
+  <class name="UnmanagedAMPoolManager" extends="org.apache.hadoop.service.AbstractService"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UnmanagedAMPoolManager" type="java.util.concurrent.ExecutorService"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="serviceStart"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="Exception" type="java.lang.Exception"/>
+    </method>
+    <method name="serviceStop"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="Exception" type="java.lang.Exception"/>
+      <doc>
+      <![CDATA[Normally we should finish all applications before stop. If there are still
+ UAMs running, force kill all of them. Do parallel kill because of
+ performance reasons.
+
+ TODO: move waiting for the kill to finish into a separate thread, without
+ blocking the serviceStop.]]>
+      </doc>
+    </method>
+    <method name="createAndRegisterNewUAM" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="registerRequest" type="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="queueName" type="java.lang.String"/>
+      <param name="submitter" type="java.lang.String"/>
+      <param name="appNameSuffix" type="java.lang.String"/>
+      <param name="keepContainersAcrossApplicationAttempts" type="boolean"/>
+      <param name="rmName" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Create a new UAM and register the application, without specifying uamId and
+ appId. We will ask for an appId from RM and use it as the uamId.
+
+ @param registerRequest RegisterApplicationMasterRequest
+ @param conf configuration for this UAM
+ @param queueName queue of the application
+ @param submitter submitter name of the UAM
+ @param appNameSuffix application name suffix for the UAM
+ @param keepContainersAcrossApplicationAttempts keep container flag for UAM
+          recovery.
+ @param rmName name of the YarnRM
+ @see ApplicationSubmissionContext
+          #setKeepContainersAcrossApplicationAttempts(boolean)
+ @return uamId for the UAM
+ @throws YarnException if registerApplicationMaster fails
+ @throws IOException if registerApplicationMaster fails]]>
+      </doc>
+    </method>
+    <method name="launchUAM" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="queueName" type="java.lang.String"/>
+      <param name="submitter" type="java.lang.String"/>
+      <param name="appNameSuffix" type="java.lang.String"/>
+      <param name="keepContainersAcrossApplicationAttempts" type="boolean"/>
+      <param name="rmName" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Launch a new UAM, using the provided uamId and appId.
+
+ @param uamId uam Id
+ @param conf configuration for this UAM
+ @param appId application id for the UAM
+ @param queueName queue of the application
+ @param submitter submitter name of the UAM
+ @param appNameSuffix application name suffix for the UAM
+ @param keepContainersAcrossApplicationAttempts keep container flag for UAM
+          recovery.
+ @param rmName name of the YarnRM
+ @see ApplicationSubmissionContext
+          #setKeepContainersAcrossApplicationAttempts(boolean)
+ @return UAM token
+ @throws YarnException if fails
+ @throws IOException if fails]]>
+      </doc>
+    </method>
+    <method name="reAttachUAM"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="queueName" type="java.lang.String"/>
+      <param name="submitter" type="java.lang.String"/>
+      <param name="appNameSuffix" type="java.lang.String"/>
+      <param name="uamToken" type="org.apache.hadoop.security.token.Token"/>
+      <param name="rmName" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Re-attach to an existing UAM, using the provided uamIdentifier.
+
+ @param uamId uam Id
+ @param conf configuration for this UAM
+ @param appId application id for the UAM
+ @param queueName queue of the application
+ @param submitter submitter name of the UAM
+ @param appNameSuffix application name suffix for the UAM
+ @param uamToken UAM token
+ @param rmName name of the YarnRM
+ @throws YarnException if fails
+ @throws IOException if fails]]>
+      </doc>
+    </method>
+    <method name="createUAM" return="org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="conf" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <param name="queueName" type="java.lang.String"/>
+      <param name="submitter" type="java.lang.String"/>
+      <param name="appNameSuffix" type="java.lang.String"/>
+      <param name="keepContainersAcrossApplicationAttempts" type="boolean"/>
+      <param name="rmName" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Creates the UAM instance. Pull out to make unit test easy.
+
+ @param conf Configuration
+ @param appId application id
+ @param queueName queue of the application
+ @param submitter submitter name of the application
+ @param appNameSuffix application name suffix
+ @param keepContainersAcrossApplicationAttempts keep container flag for UAM
+ @param rmName name of the YarnRM
+ @return the UAM instance]]>
+      </doc>
+    </method>
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <param name="registerRequest" type="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Register application master for the UAM.
+
+ @param uamId uam Id
+ @param registerRequest RegisterApplicationMasterRequest
+ @return register response
+ @throws YarnException if register fails
+ @throws IOException if register fails]]>
+      </doc>
+    </method>
+    <method name="allocateAsync"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"/>
+      <param name="callback" type="org.apache.hadoop.yarn.util.AsyncCallback"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[AllocateAsync to an UAM.
+
+ @param uamId uam Id
+ @param request AllocateRequest
+ @param callback callback for response
+ @throws YarnException if allocate fails
+ @throws IOException if allocate fails]]>
+      </doc>
+    </method>
+    <method name="finishApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Finish an UAM/application.
+
+ @param uamId uam Id
+ @param request FinishApplicationMasterRequest
+ @return FinishApplicationMasterResponse
+ @throws YarnException if finishApplicationMaster call fails
+ @throws IOException if finishApplicationMaster call fails]]>
+      </doc>
+    </method>
+    <method name="getAllUAMIds" return="java.util.Set"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Get the id of all running UAMs.
+
+ @return uamId set]]>
+      </doc>
+    </method>
+    <method name="hasUAMId" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <doc>
+      <![CDATA[Return whether an UAM exists.
+
+ @param uamId uam Id
+ @return UAM exists or not]]>
+      </doc>
+    </method>
+    <method name="getAMRMClientRelayer" return="org.apache.hadoop.yarn.server.AMRMClientRelayer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Return the rmProxy relayer of an UAM.
+
+ @param uamId uam Id
+ @return the rmProxy relayer
+ @throws YarnException if fails]]>
+      </doc>
+    </method>
+    <method name="getRequestQueueSize" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="uamId" type="java.lang.String"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+    </method>
+    <method name="drainUAMHeartbeats"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="LOG" type="org.slf4j.Logger"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[A service that manages a pool of UAM managers in
+ {@link UnmanagedApplicationManager}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.uam.UnmanagedAMPoolManager -->
+  <!-- start class org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager -->
+  <class name="UnmanagedApplicationManager" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="UnmanagedApplicationManager" type="org.apache.hadoop.conf.Configuration, org.apache.hadoop.yarn.api.records.ApplicationId, java.lang.String, java.lang.String, java.lang.String, boolean, java.lang.String"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Constructor.
+
+ @param conf configuration
+ @param appId application Id to use for this UAM
+ @param queueName the queue of the UAM
+ @param submitter user name of the app
+ @param appNameSuffix the app name suffix to use
+ @param rmName name of the YarnRM
+ @param keepContainersAcrossApplicationAttempts keep container flag for UAM
+          recovery. See {@link ApplicationSubmissionContext
+          #setKeepContainersAcrossApplicationAttempts(boolean)}]]>
+      </doc>
+    </constructor>
+    <method name="launchUAM" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Launch a new UAM in the resource manager.
+
+ @return identifier uam identifier
+ @throws YarnException if fails
+ @throws IOException if fails]]>
+      </doc>
+    </method>
+    <method name="reAttachUAM"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="amrmToken" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Re-attach to an existing UAM in the resource manager.
+
+ @param amrmToken the UAM token
+ @throws IOException if re-attach fails
+ @throws YarnException if re-attach fails]]>
+      </doc>
+    </method>
+    <method name="createUAMProxy"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="amrmToken" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="IOException" type="java.io.IOException"/>
+    </method>
+    <method name="registerApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Registers this {@link UnmanagedApplicationManager} with the resource
+ manager.
+
+ @param request RegisterApplicationMasterRequest
+ @return register response
+ @throws YarnException if register fails
+ @throws IOException if register fails]]>
+      </doc>
+    </method>
+    <method name="finishApplicationMaster" return="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.FinishApplicationMasterRequest"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Unregisters from the resource manager and stops the request handler thread.
+
+ @param request the finishApplicationMaster request
+ @return the response
+ @throws YarnException if finishAM call fails
+ @throws IOException if finishAM call fails]]>
+      </doc>
+    </method>
+    <method name="forceKillApplication" return="org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Force kill the UAM.
+
+ @return kill response
+ @throws IOException if fails to create rmProxy
+ @throws YarnException if force kill fails]]>
+      </doc>
+    </method>
+    <method name="allocateAsync"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="request" type="org.apache.hadoop.yarn.api.protocolrecords.AllocateRequest"/>
+      <param name="callback" type="org.apache.hadoop.yarn.util.AsyncCallback"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Sends the specified heart beat request to the resource manager and invokes
+ the callback asynchronously with the response.
+
+ @param request the allocate request
+ @param callback the callback method for the request
+ @throws YarnException if registerAM is not called yet]]>
+      </doc>
+    </method>
+    <method name="getAppId" return="org.apache.hadoop.yarn.api.records.ApplicationId"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the application id of the UAM.
+
+ @return application id of the UAM]]>
+      </doc>
+    </method>
+    <method name="getAMRMClientRelayer" return="org.apache.hadoop.yarn.server.AMRMClientRelayer"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Returns the rmProxy relayer of this UAM.
+
+ @return rmProxy relayer of the UAM]]>
+      </doc>
+    </method>
+    <method name="createRMProxy" return="T"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="protocol" type="java.lang.Class"/>
+      <param name="config" type="org.apache.hadoop.conf.Configuration"/>
+      <param name="user" type="org.apache.hadoop.security.UserGroupInformation"/>
+      <param name="token" type="org.apache.hadoop.security.token.Token"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Returns RM proxy for the specified protocol type. Unit test cases can
+ override this method and return mock proxy instances.
+
+ @param protocol protocal of the proxy
+ @param config configuration
+ @param user ugi for the proxy connection
+ @param token token for the connection
+ @param <T> type of the proxy
+ @return the proxy instance
+ @throws IOException if fails to create the proxy]]>
+      </doc>
+    </method>
+    <method name="initializeUnmanagedAM" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="appId" type="org.apache.hadoop.yarn.api.records.ApplicationId"/>
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Launch and initialize an unmanaged AM. First, it creates a new application
+ on the RM and negotiates a new attempt id. Then it waits for the RM
+ application attempt state to reach YarnApplicationAttemptState.LAUNCHED
+ after which it returns the AM-RM token.
+
+ @param appId application id
+ @return the UAM token
+ @throws IOException if initialize fails
+ @throws YarnException if initialize fails]]>
+      </doc>
+    </method>
+    <method name="getUAMToken" return="org.apache.hadoop.security.token.Token"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <exception name="YarnException" type="org.apache.hadoop.yarn.exceptions.YarnException"/>
+      <doc>
+      <![CDATA[Gets the amrmToken of the unmanaged AM.
+
+ @return the amrmToken of the unmanaged AM.
+ @throws IOException if getApplicationReport fails
+ @throws YarnException if getApplicationReport fails]]>
+      </doc>
+    </method>
+    <method name="getRequestQueueSize" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="setHandlerThread"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+      <param name="thread" type="org.apache.hadoop.yarn.server.AMHeartbeatRequestHandler"/>
+    </method>
+    <method name="drainHeartbeatThread"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </method>
+    <field name="APP_NAME" type="java.lang.String"
+      transient="false" volatile="false"
+      static="true" final="true" visibility="public"
+      deprecated="not deprecated">
+    </field>
+    <doc>
+    <![CDATA[UnmanagedApplicationManager is used to register unmanaged application and
+ negotiate for resources from resource managers. An unmanagedAM is an AM that
+ is not launched and managed by the RM. Allocate calls are handled
+ asynchronously using {@link AsyncCallback}.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager -->
+</package>
+<package name="org.apache.hadoop.yarn.server.utils">
+  <!-- start class org.apache.hadoop.yarn.server.utils.LeveldbIterator -->
+  <class name="LeveldbIterator" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <implements name="java.util.Iterator"/>
+    <implements name="java.io.Closeable"/>
+    <constructor name="LeveldbIterator" type="org.iq80.leveldb.DB"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an iterator for the specified database]]>
+      </doc>
+    </constructor>
+    <constructor name="LeveldbIterator" type="org.iq80.leveldb.DB, org.iq80.leveldb.ReadOptions"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an iterator for the specified database]]>
+      </doc>
+    </constructor>
+    <constructor name="LeveldbIterator" type="org.iq80.leveldb.DBIterator"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Create an iterator using the specified underlying DBIterator]]>
+      </doc>
+    </constructor>
+    <method name="seek"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="key" type="byte[]"/>
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Repositions the iterator so the key of the next BlockElement
+ returned greater than or equal to the specified targetKey.]]>
+      </doc>
+    </method>
+    <method name="seekToFirst"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Repositions the iterator so is is at the beginning of the Database.]]>
+      </doc>
+    </method>
+    <method name="seekToLast"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Repositions the iterator so it is at the end of of the Database.]]>
+      </doc>
+    </method>
+    <method name="hasNext" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Returns <tt>true</tt> if the iteration has more elements.]]>
+      </doc>
+    </method>
+    <method name="next" return="java.util.Map.Entry"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Returns the next element in the iteration.]]>
+      </doc>
+    </method>
+    <method name="peekNext" return="java.util.Map.Entry"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Returns the next element in the iteration, without advancing the
+ iteration.]]>
+      </doc>
+    </method>
+    <method name="hasPrev" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[@return true if there is a previous entry in the iteration.]]>
+      </doc>
+    </method>
+    <method name="prev" return="java.util.Map.Entry"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[@return the previous element in the iteration and rewinds the iteration.]]>
+      </doc>
+    </method>
+    <method name="peekPrev" return="java.util.Map.Entry"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[@return the previous element in the iteration, without rewinding the
+ iteration.]]>
+      </doc>
+    </method>
+    <method name="remove"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="DBException" type="org.iq80.leveldb.DBException"/>
+      <doc>
+      <![CDATA[Removes from the database the last element returned by the iterator.]]>
+      </doc>
+    </method>
+    <method name="close"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <exception name="IOException" type="java.io.IOException"/>
+      <doc>
+      <![CDATA[Closes the iterator.]]>
+      </doc>
+    </method>
+    <doc>
+    <![CDATA[A wrapper for a DBIterator to translate the raw RuntimeExceptions that
+ can be thrown into DBExceptions.]]>
+    </doc>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.utils.LeveldbIterator -->
+</package>
+<package name="org.apache.hadoop.yarn.server.webapp">
+</package>
+<package name="org.apache.hadoop.yarn.server.webapp.dao">
+  <!-- start class org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo -->
+  <class name="AppAttemptInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AppAttemptInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AppAttemptInfo" type="org.apache.hadoop.yarn.api.records.ApplicationAttemptReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAppAttemptId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getRpcPort" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getOriginalTrackingUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDiagnosticsInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAppAttemptState" return="org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAmContainerId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getStartedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFinishedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="appAttemptId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="host" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="rpcPort" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="trackingUrl" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="originalTrackingUrl" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="diagnosticsInfo" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="appAttemptState" type="org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="amContainerId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="startedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="finishedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo -->
+  <!-- start class org.apache.hadoop.yarn.server.webapp.dao.AppAttemptsInfo -->
+  <class name="AppAttemptsInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AppAttemptsInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="info" type="org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo"/>
+    </method>
+    <method name="getAttempts" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="attempt" type="java.util.ArrayList"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.webapp.dao.AppAttemptsInfo -->
+  <!-- start class org.apache.hadoop.yarn.server.webapp.dao.AppInfo -->
+  <class name="AppInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AppInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="AppInfo" type="org.apache.hadoop.yarn.api.records.ApplicationReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getAppId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getCurrentAppAttemptId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getUser" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getName" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getQueue" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getType" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getHost" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getRpcPort" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAppState" return="org.apache.hadoop.yarn.api.records.YarnApplicationState"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getRunningContainers" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocatedCpuVcores" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocatedMemoryMB" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocatedGpus" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getReservedCpuVcores" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getReservedMemoryMB" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getReservedGpus" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getProgress" return="float"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDiagnosticsInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getOriginalTrackingUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getTrackingUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFinalAppStatus" return="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getSubmittedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getLaunchTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getStartedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFinishedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getElapsedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getApplicationTags" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="isUnmanagedApp" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPriority" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAppNodeLabelExpression" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAmNodeLabelExpression" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAggregateResourceAllocation" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAggregatePreemptedResourceAllocation" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="appId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="currentAppAttemptId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="user" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="name" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="queue" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="type" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="host" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="rpcPort" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="appState" type="org.apache.hadoop.yarn.api.records.YarnApplicationState"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="runningContainers" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="progress" type="float"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="diagnosticsInfo" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="originalTrackingUrl" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="trackingUrl" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="finalAppStatus" type="org.apache.hadoop.yarn.api.records.FinalApplicationStatus"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="startedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="finishedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="elapsedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="applicationTags" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="priority" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="unmanagedApplication" type="boolean"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.webapp.dao.AppInfo -->
+  <!-- start class org.apache.hadoop.yarn.server.webapp.dao.AppsInfo -->
+  <class name="AppsInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="AppsInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="appinfo" type="org.apache.hadoop.yarn.server.webapp.dao.AppInfo"/>
+    </method>
+    <method name="getApps" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="app" type="java.util.ArrayList"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.webapp.dao.AppsInfo -->
+  <!-- start class org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo -->
+  <class name="ContainerInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainerInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <constructor name="ContainerInfo" type="org.apache.hadoop.yarn.api.records.ContainerReport"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="getContainerId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocatedMB" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocatedVCores" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAssignedNodeId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getPriority" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getStartedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getFinishedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getElapsedTime" return="long"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getDiagnosticsInfo" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getLogUrl" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getContainerExitStatus" return="int"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getContainerState" return="org.apache.hadoop.yarn.api.records.ContainerState"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNodeHttpAddress" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getNodeId" return="java.lang.String"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <method name="getAllocatedResources" return="java.util.Map"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <doc>
+      <![CDATA[Return a map of the allocated resources. The map key is the resource name,
+ and the value is the resource value.
+
+ @return the allocated resources map]]>
+      </doc>
+    </method>
+    <method name="hasCustomResources" return="boolean"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="containerId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="allocatedMB" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="allocatedVCores" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="assignedNodeId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="priority" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="startedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="finishedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="elapsedTime" type="long"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="diagnosticsInfo" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="logUrl" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="containerExitStatus" type="int"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="containerState" type="org.apache.hadoop.yarn.api.records.ContainerState"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="nodeHttpAddress" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="nodeId" type="java.lang.String"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+    <field name="allocatedResources" type="java.util.Map"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo -->
+  <!-- start class org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo -->
+  <class name="ContainersInfo" extends="java.lang.Object"
+    abstract="false"
+    static="false" final="false" visibility="public"
+    deprecated="not deprecated">
+    <constructor name="ContainersInfo"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </constructor>
+    <method name="add"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+      <param name="containerInfo" type="org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo"/>
+    </method>
+    <method name="getContainers" return="java.util.ArrayList"
+      abstract="false" native="false" synchronized="false"
+      static="false" final="false" visibility="public"
+      deprecated="not deprecated">
+    </method>
+    <field name="container" type="java.util.ArrayList"
+      transient="false" volatile="false"
+      static="false" final="false" visibility="protected"
+      deprecated="not deprecated">
+    </field>
+  </class>
+  <!-- end class org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo -->
+</package>
+
+</api>
