diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/AzureServiceErrorCode.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/AzureServiceErrorCode.java
index 60e7f92d2705..8bc31c4f92b2 100644
--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/AzureServiceErrorCode.java
+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/contracts/services/AzureServiceErrorCode.java
@@ -46,6 +46,7 @@ public enum AzureServiceErrorCode {
   EGRESS_OVER_ACCOUNT_LIMIT(null, HttpURLConnection.HTTP_UNAVAILABLE, "Egress is over the account limit."),
   INVALID_QUERY_PARAMETER_VALUE("InvalidQueryParameterValue", HttpURLConnection.HTTP_BAD_REQUEST, null),
   AUTHORIZATION_PERMISSION_MISS_MATCH("AuthorizationPermissionMismatch", HttpURLConnection.HTTP_FORBIDDEN, null),
+  ACCOUNT_REQUIRES_HTTPS("AccountRequiresHttps", HttpURLConnection.HTTP_BAD_REQUEST, null),
   UNKNOWN(null, -1, null);
 
   private final String errorCode;
diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestClientUrlScheme.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestClientUrlScheme.java
index ad889838ff1d..44665f50c11f 100644
--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestClientUrlScheme.java
+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestClientUrlScheme.java
@@ -29,6 +29,8 @@
 import org.junit.runners.Parameterized;
 
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;
+import org.apache.hadoop.fs.azurebfs.contracts.services.AzureServiceErrorCode;
 import org.apache.hadoop.fs.azurebfs.services.AbfsClient;
 import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
 import org.apache.hadoop.fs.azurebfs.constants.FileSystemUriSchemes;
@@ -81,8 +83,25 @@ public void testClientUrlScheme() throws Exception {
     Configuration config = getRawConfiguration();
     config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, fsUrl.toString());
     config.setBoolean(FS_AZURE_ALWAYS_USE_HTTPS, alwaysUseHttps);
-
-    AbfsClient client = this.getFileSystem(config).getAbfsClient();
+    // HTTP is enabled only when "abfs://XXX" is used and FS_AZURE_ALWAYS_USE_HTTPS
+    // is set as false, otherwise HTTPS should be used.
+    boolean expectHttpConnection = !useSecureScheme && !alwaysUseHttps;
+
+    AbfsClient client = null;
+    try {
+      client = this.getFileSystem(config).getAbfsClient();
+    } catch (AbfsRestOperationException e) {
+      if (AzureServiceErrorCode.ACCOUNT_REQUIRES_HTTPS.equals(e.getErrorCode())
+          && expectHttpConnection) {
+        // if we get here, the error message was the account supports HTTPS only
+        // and this parameterized test is trying to create an HTTP one.
+        // we can implicitly infer that the scheme setup went through,
+        // otherwise it would not have been rejected at the far end
+        return;
+      } else {
+        throw e;
+      }
+    }
 
     Field baseUrlField = AbfsClient.class.
             getDeclaredField("baseUrl");
@@ -90,9 +109,7 @@ public void testClientUrlScheme() throws Exception {
 
     String url = ((URL) baseUrlField.get(client)).toString();
 
-    // HTTP is enabled only when "abfs://XXX" is used and FS_AZURE_ALWAYS_USE_HTTPS
-    // is set as false, otherwise HTTPS should be used.
-    if (!useSecureScheme && !alwaysUseHttps) {
+    if (expectHttpConnection) {
       Assert.assertTrue(url.startsWith(FileSystemUriSchemes.HTTP_SCHEME));
     } else {
       Assert.assertTrue(url.startsWith(FileSystemUriSchemes.HTTPS_SCHEME));
